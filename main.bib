@Article{Katharopoulos,
  author        = {Katharopoulos, Angelos and Fleuret, Fran{\c{c}}ois},
  title         = {{Not All Samples Are Created Equal: Deep Learning with Importance Sampling}},
  abstract      = {Deep neural network training spends most of the computation on examples that are properly handled , and could be ignored. We propose to mitigate this phenomenon with a principled importance sampling scheme that fo-cuses computation on "informative" examples, and reduces the variance of the stochastic gradients during training. Our contribution is twofold: first, we derive a tractable upper bound to the per-sample gradient norm, and second we derive an estimator of the variance reduction achieved with importance sampling, which enables us to switch it on when it will result in an actual speedup. The resulting scheme can be used by changing a few lines of code in a standard SGD procedure, and we demonstrate experimentally, on image classification, CNN fine-tuning, and RNN training , that for a fixed wall-clock time budget, it provides a reduction of the train losses of up to an order of magnitude and a relative improvement of test errors between 5% and 17%.},
  archiveprefix = {arXiv},
  arxivid       = {1803.00942v3},
  eprint        = {1803.00942v3},
  file          = {:home/antonio/Documents/bibliography/files/Katharopoulos, Fleuret - Unknown - Not All Samples Are Created Equal Deep Learning with Importance Sampling.pdf:pdf},
  groups        = {General deep learning},
}

@Article{Nabian2021,
  author        = {Nabian, Mohammad Amin and Gladstone, Rini Jasmine and Meidani, Hadi},
  journal       = {Computer-Aided Civil and Infrastructure Engineering},
  title         = {{Efficient training of physics-informed neural networks via importance sampling}},
  year          = {2021},
  issn          = {1467-8667},
  month         = {aug},
  number        = {8},
  pages         = {962--977},
  volume        = {36},
  abstract      = {Physics-informed neural networks (PINNs) are a class of deep neural networks that are trained, using automatic differentiation, to compute the response of systems governed by partial differential equations (PDEs). The training of PINNs is simulation free, and does not require any training data set to be obtained from numerical PDE solvers. Instead, it only requires the physical problem description, including the governing laws of physics, domain geometry, initial/boundary conditions, and the material properties. This training usually involves solving a nonconvex optimization problem using variants of the stochastic gradient descent method, with the gradient of the loss function approximated on a batch of collocation points, selected randomly in each iteration according to a uniform distribution. Despite the success of PINNs in accurately solving a wide variety of PDEs, the method still requires improvements in terms of computational efficiency. To this end, in this paper, we study the performance of an importance sampling approach for efficient training of PINNs. Using numerical examples together with theoretical evidences, we show that in each training iteration, sampling the collocation points according to a distribution proportional to the loss function will improve the convergence behavior of the PINNs training. Additionally, we show that providing a piecewise constant approximation to the loss function for faster importance sampling can further improve the training efficiency. This importance sampling approach is straightforward and easy to implement in the existing PINN codes, and also does not introduce any new hyperparameter to calibrate. The numerical examples include elasticity, diffusion, and plane stress problems, through which we numerically verify the accuracy and efficiency of the importance sampling approach compared to the predominant uniform sampling approach.},
  archiveprefix = {arXiv},
  arxivid       = {2104.12325},
  doi           = {10.1111/MICE.12685},
  eprint        = {2104.12325},
  groups        = {PDEs and neural networks},
  publisher     = {John Wiley & Sons, Ltd},
  url           = {https://onlinelibrary.wiley.com/doi/full/10.1111/mice.12685 https://onlinelibrary.wiley.com/doi/abs/10.1111/mice.12685 https://onlinelibrary.wiley.com/doi/10.1111/mice.12685},
}

@Article{Han2021,
  author        = {Han, Jiequn and Hu, Ruimeng and Long, Jihao},
  title         = {{A Class of Dimensionality-free Metrics for the Convergence of Empirical Measures}},
  year          = {2021},
  abstract      = {This paper concerns the convergence of empirical measures in high dimensions. We propose a new class of metrics and show that under such metrics, the convergence is free of the curse of dimensionality (CoD). Such a feature is critical for high-dimensional analysis and stands in contrast to classical metrics (e.g., the Wasserstein distance). The proposed metrics originate from the maximum mean discrepancy, which we generalize by proposing specific criteria for selecting test function spaces to guarantee the property of being free of CoD. Therefore, we call this class of metrics the generalized maximum mean discrepancy (GMMD). Examples of the selected test function spaces include the reproducing kernel Hilbert space, Barron space, and flow-induced function spaces. Three applications of the proposed metrics are presented: 1. The convergence of empirical measure in the case of random variables; 2. The convergence of n-particle system to the solution to McKean-Vlasov stochastic differential equation; 3. The construction of an $\epsilon$-Nash equilibrium for a homogeneous n-player game by its mean-field limit. As a byproduct, we prove that, given a distribution close to the target distribution measured by GMMD and a certain representation of the target distribution, we can generate a distribution close to the target one in terms of the Wasserstein distance and relative entropy. Overall, we show that the proposed class of metrics is a powerful tool to analyze the convergence of empirical measures in high dimensions without CoD.},
  archiveprefix = {arXiv},
  arxivid       = {2104.12036v2},
  eprint        = {2104.12036v2},
  file          = {:home/antonio/Documents/bibliography/files/Han, Hu, Long - 2021 - A Class of Dimensionality-free Metrics for the Convergence of Empirical Measures.pdf:pdf},
  groups        = {General deep learning},
  keywords      = {Generalized maximum mean discrepancy, McKean-Vlasov stochastic differential equation, curse of dimensionality, empirical measure, mean-field games},
}

@Article{Li2021,
  author    = {Li, Xun and Koene, Erik and van Manen, Dirk-Jan and Robertsson, Johan and Curtis, Andrew},
  journal   = {Journal of Computational Physics},
  title     = {{Elastic immersive wavefield modelling}},
  year      = {2021},
  issn      = {0021-9991},
  month     = {nov},
  pages     = {110826},
  doi       = {10.1016/J.JCP.2021.110826},
  groups    = {Ultrasound and wave physics},
  publisher = {Academic Press},
  url       = {https://linkinghub.elsevier.com/retrieve/pii/S002199912100721X},
}

@Article{Hwang,
  author        = {Hwang, Rakhoon and Lee, Jae Yong and Shin, Jin Young and Hwang, Hyung Ju},
  title         = {{Solving PDE-constrained Control Problems using Operator Learning}},
  abstract      = {The modeling and control of complex physical dynamics are essential in real-world problems. We propose a novel framework that is generally applicable to solving PDE-constrained optimal control problems by introducing surrogate models for PDE solution operators with special regularizers. The procedure of the proposed framework is divided into two phases: solution operator learning for PDE constraints (Phase 1) and searching for optimal control (Phase 2). Once the surrogate model is trained in Phase 1, the optimal control can be inferred in Phase 2 without intensive computations. Our framework can be applied to both data-driven and data-free cases. We demonstrate the successful application of our method to various optimal control problems for different control variables with diverse PDE constraints from the Poisson equation to Burgers' equation.},
  archiveprefix = {arXiv},
  arxivid       = {2111.04941v1},
  eprint        = {2111.04941v1},
  file          = {:home/antonio/Documents/bibliography/files/Hwang et al. - Unknown - Solving PDE-constrained Control Problems using Operator Learning.pdf:pdf},
  groups        = {PDEs and neural networks},
}

@Article{Li2021a,
  author        = {Li, Zongyi and Zheng, Hongkai and Kovachki, Nikola and Jin, David and Chen, Haoxuan and Liu, Burigede and Azizzadenesheli, Kamyar and Anandkumar, Anima},
  title         = {{Physics-Informed Neural Operator for Learning Partial Differential Equations}},
  year          = {2021},
  abstract      = {Machine learning methods have recently shown promise in solving partial differential equations (PDEs). They can be classified into two broad categories: approximating the solution function and learning the solution operator. The Physics-Informed Neural Network (PINN) is an example of the former while the Fourier neural operator (FNO) is an example of the latter. Both these approaches have shortcomings. The optimization in PINN is challenging and prone to failure, especially on multi-scale dynamic systems. FNO does not suffer from this optimization issue since it carries out supervised learning on a given dataset, but obtaining such data may be too expensive or infeasible. In this work, we propose the physics-informed neural operator (PINO), where we combine the operating-learning and function-optimization frameworks. This integrated approach improves convergence rates and accuracy over both PINN and FNO models. In the operator-learning phase, PINO learns the solution operator over multiple instances of the parametric PDE family. In the test-time optimization phase, PINO optimizes the pre-trained operator ansatz for the querying instance of the PDE. Experiments show PINO outperforms previous ML methods on many popular PDE families while retaining the extraordinary speed-up of FNO compared to solvers. In particular, PINO accurately solves long temporal transient flows and Kolmogorov flows.},
  archiveprefix = {arXiv},
  arxivid       = {2111.03794v1},
  eprint        = {2111.03794v1},
  file          = {:home/antonio/Documents/bibliography/files/Li et al. - 2021 - Physics-Informed Neural Operator for Learning Partial Differential Equations.pdf:pdf},
  groups        = {PDEs and neural networks},
}

@Article{Chrysos,
  author        = {Chrysos, Grigorios G and Moschoglou, Stylianos and Bouritsas, Giorgos and Deng, Jiankang and Panagakis, Yannis and Zafeiriou, Stefanos},
  title         = {{Deep Polynomial Neural Networks}},
  abstract      = {Deep Convolutional Neural Networks (DCNNs) are currently the method of choice both for generative, as well as for discriminative learning in computer vision and machine learning. The success of DCNNs can be attributed to the careful selection of their building blocks (e.g., residual blocks, rectifiers, sophisticated normalization schemes, to mention but a few). In this paper, we propose $\Pi$-Nets, a new class of function approximators based on polynomial expansions. $\Pi$-Nets are polynomial neural networks, i.e., the output is a high-order polynomial of the input. The unknown parameters, which are naturally represented by high-order tensors, are estimated through a collective tensor factorization with factors sharing. We introduce three tensor decompositions that significantly reduce the number of parameters and show how they can be efficiently implemented by hierarchical neural networks. We empirically demonstrate that $\Pi$-Nets are very expressive and they even produce good results without the use of non-linear activation functions in a large battery of tasks and signals, i.e., images, graphs, and audio. When used in conjunction with activation functions, $\Pi$-Nets produce state-of-the-art results in three challenging tasks, i.e. image generation, face verification and 3D mesh representation learning. The source code is available at https://github.com/grigorisg9gr/polynomial_nets.},
  archiveprefix = {arXiv},
  arxivid       = {2006.13026v2},
  eprint        = {2006.13026v2},
  file          = {:home/antonio/Documents/bibliography/files/Chrysos et al. - Unknown - Deep Polynomial Neural Networks.pdf:pdf},
  groups        = {Representation, architectures and DL layers},
  keywords      = {Index Terms-Polynomial neural networks, discriminative models, face verification !, generative models, high-order polynomials, tensor decompositions},
  url           = {https://github.com/grigorisg9gr/polynomial_nets.},
}

@Article{Karniadakis,
  author   = {Karniadakis, George Em and Kevrekidis, Ioannis G and Lu, Lu and Perdikaris, Paris and Wang, Sifan and Yang, Liu},
  journal  = {Nature Reviews Physics},
  title    = {{Physics-informed machine learning}},
  abstract = {0123456789();: Modelling and forecasting the dynamics of multiphysics and multiscale systems remains an open scientific problem. Take for instance the Earth system, a uniquely complex system whose dynamics are intricately governed by the interaction of physical, chemical and biological processes taking place on spatiotemporal scales that span 17 orders of magnitude 1. In the past 50 years, there has been tremendous progress in understanding multiscale physics in diverse applications, from geophysics to biophysics, by numerically solving partial differential equations (PDEs) using finite differences, finite elements, spectral and even meshless methods. Despite relentless progress, modelling and predicting the evolution of nonlinear multiscale systems with inhomogeneous cascades-of-scales by using classical analytical or computational tools inevitably faces severe challenges and introduces prohibitive cost and multiple sources of uncertainty. Moreover, solving inverse problems (for inferring material properties in functional materials or discovering missing physics in reactive transport, for example) is often prohibitively expensive and requires complex formulations, new algorithms and elaborate computer codes. Most importantly , solving real-life physical problems with missing, gappy or noisy boundary conditions through traditional approaches is currently impossible. This is where and why observational data play a crucial role. With the prospect of more than a trillion sensors in the next decade, including airborne, seaborne and satellite remote sensing, a wealth of multi-fidelity observations is ready to be explored through data-driven methods. However, despite the volume, velocity and variety of available (collected or generated) data streams, in many real cases it is still not possible to seamlessly incorporate such multi-fidelity data into existing physical models. Mathematical (and practical) data-assimilation efforts have been blossoming; yet the wealth and the spatiotem-poral heterogeneity of available data, along with the lack of universally acceptable models, underscores the need for a transformative approach. This is where machine learning (ML) has come into play. It can explore massive design spaces, identify multi-dimensional correlations and manage ill-posed problems. It can, for instance, help to detect climate extremes or statistically predict dynamic variables such as precipitation or vegetation productivity 2,3. Deep learning approaches, in particular, naturally provide tools for automatically extracting features from massive amounts of multi-fidelity observational data that are currently available and characterized by unprecedented spatial and temporal coverage 4. They can also help to link these features with existing approximate models and exploit them in building new predictive tools. Even for biophysical and biomedical modelling, this synergistic integration between ML tools and multiscale and multiphysics models has been recently advocated 5. Abstract | Despite great progress in simulating multiphysics problems using the numerical discretization of partial differential equations (PDEs), one still cannot seamlessly incorporate noisy data into existing algorithms, mesh generation remains complex, and high-dimensional problems governed by parameterized PDEs cannot be tackled. Moreover, solving inverse problems with hidden physics is often prohibitively expensive and requires different formulations and elaborate computer codes. Machine learning has emerged as a promising alternative, but training deep neural networks requires big data, not always available for scientific problems. Instead, such networks can be trained from additional information obtained by enforcing the physical laws (for example, at random points in the continuous space-time domain). Such physics-informed learning integrates (noisy) data and mathematical models, and implements them through neural networks or other kernel-based regression networks. Moreover, it may be possible to design specialized network architectures that automatically satisfy some of the physical invariants for better accuracy, faster training and improved generalization. Here, we review some of the prevailing trends in embedding physics into machine learning, present some of the current capabilities and limitations and discuss diverse applications of physics-informed learning both for forward and inverse problems, including discovering hidden physics and tackling high-dimensional problems.},
  doi      = {10.1038/s42254-021-00314-5},
  file     = {:home/antonio/Documents/bibliography/files/Karniadakis et al. - Unknown - Physics-informed machine learning.pdf:pdf},
  groups   = {PDEs and neural networks},
  isbn     = {0123456789},
  url      = {www.nature.com/natrevphys},
}

@Article{Faucher2021,
  author        = {Faucher, Florian and Kirisits, Clemens and Quellmalz, Michael and Scherzer, Otmar and Setterqvist, Eric},
  title         = {{Diffraction Tomography, Fourier Reconstruction, and Full Waveform Inversion}},
  year          = {2021},
  abstract      = {In this paper, we study the mathematical imaging problem of diffraction tomography (DT), which is an inverse scattering technique used to find material properties of an object by illuminating it with probing waves and recording the scattered waves. Conventional DT relies on the Fourier diffraction theorem, which is applicable under the condition of weak scattering. However, if the object has high contrasts or is too large compared to the wavelength, it tends to produce multiple scattering, which complicates the reconstruction. We give a survey on diffraction tomography and compare the reconstruction of low and high contrast objects. We also implement and compare the reconstruction using the full waveform inversion method which, contrary to the Born and Rytov approximations, works with the total field and is more robust to multiple scattering.},
  archiveprefix = {arXiv},
  arxivid       = {2110.07921v1},
  eprint        = {2110.07921v1},
  file          = {:home/antonio/Documents/bibliography/files/Faucher et al. - 2021 - Diffraction Tomography, Fourier Reconstruction, and Full Waveform Inversion.pdf:pdf},
  groups        = {Ultrasound and wave imaging},
  url           = {https://ffaucher.gitlab.io/hawen-website/},
}

@Article{Ngom2021,
  author    = {Ngom, Marieme and Marin, Oana},
  journal   = {Statistical Analysis and Data Mining},
  title     = {{Fourier neural networks as function approximators and differential equation solvers}},
  year      = {2021},
  abstract  = {We present a Fourier neural network (FNN) that can be mapped directly to the Fourier decomposition. The choice of activation and loss function yields results that replicate a Fourier series expansion closely while preserving a straightforward architecture with a single hidden layer. The simplicity of this network architecture facilitates the integration with any other higher-complexity networks, at a data pre- or postprocessing stage. We validate this FNN on naturally periodic smooth functions and on piecewise continuous periodic functions. We showcase the use of this FNN for modeling or solving partial differential equations with periodic boundary conditions. The main advantages of the current approach are the validity of the solution outside the training region, interpretability of the trained model, and simplicity of use.},
  doi       = {10.1002/SAM.11531},
  file      = {:home/antonio/Documents/bibliography/files/Ngom, Marin - 2021 - Fourier neural networks as function approximators and differential equation solvers.pdf:pdf},
  groups    = {PDEs and neural networks},
  keywords  = {Fourier decomposition, differential equations, neural networks},
  publisher = {John Wiley and Sons Inc},
}

@Article{Fathony,
  author   = {Fathony, Rizal and {Kumar Sahu}, Anit and Willmott, Devin and {Zico Kolter}, J},
  title    = {{MULTIPLICATIVE FILTER NETWORKS}},
  abstract = {Although deep networks are typically used to approximate functions over high dimensional inputs, recent work has increased interest in neural networks as function approximators for low-dimensional-but-complex functions, such as representing images as a function of pixel coordinates, solving differential equations, or representing signed distance functions or neural radiance fields. Key to these recent successes has been the use of new elements such as sinusoidal nonlineari-ties or Fourier features in positional encodings, which vastly outperform simple ReLU networks. In this paper, we propose and empirically demonstrate that an arguably simpler class of function approximators can work just as well for such problems: multiplicative filter networks. In these networks, we avoid traditional compositional depth altogether, and simply multiply together (linear functions of) sinusoidal or Gabor wavelet functions applied to the input. This representation has the notable advantage that the entire function can simply be viewed as a linear function approximator over an exponential number of Fourier or Gabor basis functions , respectively. Despite this simplicity, when compared to recent approaches that use Fourier features with ReLU networks or sinusoidal activation networks, we show that these multiplicative filter networks largely outperform or match the performance of these approaches on the domains highlighted in these past works.},
  file     = {:home/antonio/Documents/bibliography/files/Fathony et al. - Unknown - MULTIPLICATIVE FILTER NETWORKS(2).pdf:pdf;:home/antonio/Documents/bibliography/files/Fathony et al. - Unknown - MULTIPLICATIVE FILTER NETWORKS.pdf:pdf},
  groups   = {Representation, architectures and DL layers},
}

@Article{Yang,
  author        = {Yang, Yan and Gao, Angela F and Castellanos, Jorge C and Ross, Zachary E and Azizzadenesheli, Kamyar and Clayton, Robert W},
  title         = {{Seismic wave propagation and inversion with Neural Operators}},
  abstract      = {Seismic wave propagation forms the basis for most aspects of seismological research, yet solving the wave equation is a major computational burden that inhibits the progress of research. This is exaspirated by the fact that new simulations must be performed when the velocity structure or source location is perturbed. Here, we explore a prototype framework for learning general solutions using a recently developed machine learning paradigm called Neural Operator. A trained Neural Operator can compute a solution in negligible time for any velocity structure or source location. We develop a scheme to train Neural Operators on an ensemble of simulations performed with random velocity models and source locations. As Neural Operators are grid-free, it is possible to evaluate solutions on higher resolution velocity models than trained on, providing additional computational efficiency. We illustrate the method with the 2D acoustic wave equation and demonstrate the method's applicability to seismic tomography, using reverse mode automatic differentiation to compute gradients of the wavefield with respect to the velocity structure. The developed procedure is nearly an order of magnitude faster than using conventional numerical methods for full waveform inversion.},
  archiveprefix = {arXiv},
  arxivid       = {2108.05421v1},
  eprint        = {2108.05421v1},
  file          = {:home/antonio/Documents/bibliography/files/Yang et al. - Unknown - Seismic wave propagation and inversion with Neural Operators.pdf:pdf},
  groups        = {Helmholtz and waves},
  keywords      = {Fourier neural operator, forward model, inverse tomography, wave propagation},
}

@Article{Lin,
  author        = {Lin, Guochang and Hu, Pipi and Chen, Fukai and Chen, Xiang and Chen, Junqing and Wang, Jun and Shi, Zuoqiang},
  title         = {{BINet: Learning to Solve Partial Differential Equations with Boundary Integral Networks}},
  abstract      = {We propose a method combining boundary integral equations and neural networks (BINet) to solve partial differential equations (PDEs) in both bounded and unbounded domains. Unlike existing solutions that directly operate over original PDEs, BINet learns to solve, as a proxy, associated boundary integral equations using neural networks. The benefits are threefold. Firstly, only the boundary conditions need to be fitted since the PDE can be automatically satisfied with single or double layer representations according to the potential theory. Secondly, the dimension of the boundary integral equations is typically smaller, and as such, the sample complexity can be reduced significantly. Lastly, in the proposed method, all differential operators of the original PDEs have been removed, hence the numerical efficiency and stability are improved. Adopting neural tangent kernel (NTK) techniques, we provide proof of the convergence of BINets in the limit that the width of the neural network goes to infinity. Extensive numerical experiments show that, without calculating high-order derivatives, BINet is much easier to train and usually gives more accurate solutions, especially in the cases that the boundary conditions are not smooth enough. Further, BINet outperforms strong baselines for both one single PDE and parameterized PDEs in the bounded and unbounded domains.},
  archiveprefix = {arXiv},
  arxivid       = {2110.00352v1},
  eprint        = {2110.00352v1},
  file          = {:home/antonio/Documents/bibliography/files/Lin et al. - Unknown - BINet Learning to Solve Partial Differential Equations with Boundary Integral Networks.pdf:pdf},
  groups        = {PDEs and neural networks},
}

@Misc{,
  title   = {{A stable parareal-like method for the second order wave equation | Elsevier Enhanced Reader}},
  groups  = {Ultrasound and wave physics},
  url     = {https://reader.elsevier.com/reader/sd/pii/S0021999119308617?token=C120FE136B6ABD32D1ABC28B8C6E463DC84AFA406C8C4B91DB8C166FC4E935F9CBAF2EB75F7F345DC1E0ECAC7A20F4A4&originRegion=eu-west-1&originCreation=20211005162633},
  urldate = {2021-10-05},
}

@Article{Liu,
  author        = {Liu, Guan-Horng and Chen, Tianrong and Theodorou, Evangelos A},
  title         = {{Second-Order Neural ODE Optimizer}},
  abstract      = {We propose a novel second-order optimization framework for training the emerging deep continuous-time models, specifically the Neural Ordinary Differential Equations (Neural ODEs). Since their training already involves expensive gradient computation by solving a backward ODE, deriving efficient second-order methods becomes highly nontrivial. Nevertheless, inspired by the recent Optimal Control (OC) interpretation of training deep networks, we show that a specific continuous-time OC methodology, called Differential Programming, can be adopted to derive backward ODEs for higher-order derivatives at the same O(1) memory cost. We further explore a low-rank representation of the second-order derivatives and show that it leads to efficient preconditioned updates with the aid of Kronecker-based factorization. The resulting method converges much faster than first-order baselines in wall-clock time, and the improvement remains consistent across various applications , e.g. image classification, generative flow, and time-series prediction. Our framework also enables direct architecture optimization, such as the integration time of Neural ODEs, with second-order feedback policies, strengthening the OC perspective as a principled tool of analyzing optimization in deep learning.},
  archiveprefix = {arXiv},
  arxivid       = {2109.14158v1},
  eprint        = {2109.14158v1},
  file          = {:home/antonio/Documents/bibliography/files/Liu, Chen, Theodorou - Unknown - Second-Order Neural ODE Optimizer.pdf:pdf},
  groups        = {Training},
  isbn          = {2109.14158v1},
}

@Article{gong2021convergence,
  author   = {Gong, Shihua and Gander, Martin J and Graham, Ivan G and Lafontaine, David and Spence, Euan A},
  journal  = {arXiv preprint arXiv:2106.05218},
  title    = {Convergence of parallel overlapping domain decomposition methods for the Helmholtz equation},
  year     = {2021},
  file     = {:home/antonio/Documents/bibliography/files/Gong et al. - 2021 - Convergence of parallel overlapping domain decomposition methods for the Helmholtz equation.pdf:pdf},
  groups   = {Ultrasound and wave physics},
  keywords = {Domain decomposition, Helmholtz equation, High frequency, Impedance transmission condition, Overlapping subdo-mains, Schwarz method},
}

@Article{Saharia,
  author        = {Saharia, Chitwan and Ho, Jonathan and Chan, William and Salimans, Tim and Fleet, David J and Norouzi, Mohammad},
  title         = {{Image Super-Resolution via Iterative Refinement}},
  abstract      = {We present SR3, an approach to image Super-Resolution via Repeated Refinement. SR3 adapts denoising diffusion probabilistic models [17, 48] to conditional image generation and performs super-resolution through a stochastic iterative denoising process. Output generation starts with pure Gaussian noise and iteratively refines the noisy output using a U-Net model trained on denoising at various noise levels. SR3 exhibits strong performance on super-resolution tasks at different magnification factors, on faces and natural images. We conduct human evaluation on a standard 8× face super-resolution task on CelebA-HQ, comparing with SOTA GAN methods. SR3 achieves a fool rate close to 50%, suggesting photo-realistic outputs, while GANs do not exceed a fool rate of 34%. We further show the effectiveness of SR3 in cascaded image generation, where gen-erative models are chained with super-resolution models, yielding a competitive FID score of 11.3 on ImageNet.},
  archiveprefix = {arXiv},
  arxivid       = {2104.07636v2},
  eprint        = {2104.07636v2},
  file          = {:home/antonio/Documents/bibliography/files/Saharia et al. - Unknown - Image Super-Resolution via Iterative Refinement.pdf:pdf},
  groups        = {Super Resolution},
}

@Article{Tetali2021,
  author        = {Tetali, Harsha Vardhan and Harley, Joel B and Haeffele, Benjamin D},
  title         = {{Wave-Informed Matrix Factorization with Global Optimality Guarantees}},
  year          = {2021},
  abstract      = {With the recent success of representation learning methods, which includes deep learning as a special case, there has been considerable interest in developing representation learning techniques that can incorporate known physical constraints into the learned representation. As one example, in many applications that involve a signal propagating through physical media (e.g., optics, acoustics, fluid dynamics, etc), it is known that the dynamics of the signal must satisfy constraints imposed by the wave equation. Here we propose a matrix factorization technique that decomposes such signals into a sum of components, where each component is regularized to ensure that it satisfies wave equation constraints. Although our proposed formulation is non-convex, we prove that our model can be efficiently solved to global optimality in polynomial time. We demonstrate the benefits of our work by applications in structural health monitoring, where prior work has attempted to solve this problem using sparse dictionary learning approaches that do not come with any theoretical guarantees regarding convergence to global optimality and employ heuristics to capture desired physical constraints. Representation learning has gained importance in fields that utilize data generated through physical processes, such as weather forecasting [1], manufacturing [2], structural health monitoring [3], acoustics [4], and medical imaging [5]. However, in general, the features learned through generic machine learning algorithms typically do not correspond to physically interpretable quantities. Yet, learning physically consistent and interpretable features can improve our understanding of 1) the physically viable information about the data and 2) the composition of the system or process generating it. As a result, in recent years modified learning paradigms, suited to different physical application domains, have begun to draw interest and discussion [6]. For example, several researchers have designed physics-informed neural networks to learn approximate solutions to a partial differential equation [7, 8, 9, 10, 11]. These have been recently applied to ultrasonic surface waves to extract velocity parameters and denoise data [12]. Similar physics-guided neural networks [6, 13, 14, 15] use physics-based regularizations to improve data processing, demonstrating that regression tasks (such as estimating the temperature throughout a lake) can be more accurate and robust when compared with purely physics-based solutions or purely data-driven solutions. These approaches demonstrate the strong potential for physics-informed machine learning but remain early in their study.},
  archiveprefix = {arXiv},
  arxivid       = {2107.09144v2},
  eprint        = {2107.09144v2},
  file          = {:home/antonio/Documents/bibliography/files/Tetali, Harley, Haeffele - 2021 - Wave-Informed Matrix Factorization with Global Optimality Guarantees.pdf:pdf},
}

@Article{Pestourie,
  author   = {Pestourie, Rapha{\"{e}}l and Chomette, Gr{\'{e}}goire and Mroueh, Youssef and Das, Payel and Radovitzky, Raul and Johnson, Steven G},
  title    = {Active learning of deep surrogates for PDEs},
  abstract = {Surrogate models for partial-differential equations are widely used in the design of metamaterials to rapidly evaluate the behavior of composable components. However , the training cost of accurate surrogates by machine learning can rapidly increase with the number of variables. We present an active learning algorithm and apply it to train deep surrogates of Helmholtz's equation and linear elasticity in solid mechanics. For the two problems of interest, our algorithm reduces the number of simulations required compared to uniform random samples by more than an order of magnitude for a neural-network surrogate model and by four, respectively. Results show that the surrogate evaluation is faster than a direct solve by over two orders of magnitude and over five orders of magnitude, respectively.},
  file     = {:home/antonio/Documents/bibliography/files/Pestourie et al. - Unknown - ACTIVE LEARNING OF DEEP SURROGATES FOR PDES.pdf:pdf},
  groups   = {PDEs and neural networks},
}

@Article{Holguin,
  author   = {Holguin, Francisco and Portwood, Gavin},
  title    = {{MULTIGRID SOLVER WITH SUPER-RESOLVED INTER-POLATION}},
  abstract = {The multigrid algorithm is an efficient numerical method for solving a variety of elliptic partial differential equations (PDEs). The method damps errors at progressively finer grid scales, resulting in faster convergence compared to standard iterative methods such as Gauss-Seidel. The prolongation, or coarse-to-fine interpolation operator within the multigrid algorithm lends itself to a data-driven treatment with ML super resolution, commonly used to increase the resolution of images. We (i) propose the novel integration of a super resolution generative adversarial network (GAN) model with the multigrid algorithm as the prolonga-tion operator and (ii) show that the GAN-interpolation improves the convergence properties of the multigrid in comparison to cubic spline interpolation on a class of multiscale PDEs typically solved in physics and engineering simulations.},
  file     = {:home/antonio/Documents/bibliography/files/Holguin, Portwood - Unknown - MULTIGRID SOLVER WITH SUPER-RESOLVED INTER-POLATION.pdf:pdf},
  groups   = {Ultrasound and wave physics},
}

@Article{Roberts,
  author   = {Roberts, Nicholas and Khodak, Mikhail and Dao, Tri and Li, Liam and R{\'{e}}, Christopher and Talwalkar, Ameet},
  title    = {{LEARNING OPERATIONS FOR NEURAL PDE SOLVERS}},
  abstract = {In recent years neural networks have been identified as candidates for fast partial differential equation (PDE) solvers, leading to numerous approaches to designing network layers that attempt to go beyond the usual convolution-based way of working with multi-dimensional data. We take a neural architecture search (NAS) inspired approach, introducing a relaxed space of neural operations that contains numerous types of layers including multi-channel convolutions and the recent state-of-the-art Fourier Neural Operators (FNOs) of Li et al. (2021b). To do so we exploit the fact that many operations of interest are linear maps diagonalized by efficient matrices such as the discrete Fourier transform (DFT); allowing these matrices to vary as additional "architecture parameters" of the model yields our Expressive Diagonalization (XD) operations. Empirically, we demonstrate that XD-operations outperform FNOs using a similar network across multiple problem settings while using fewer parameters in the case of 2d and 3d domains.},
  file     = {:home/antonio/Documents/bibliography/files/Roberts et al. - Unknown - LEARNING OPERATIONS FOR NEURAL PDE SOLVERS.pdf:pdf},
  groups   = {PDEs and neural networks},
  url      = {https://github.com/nick11roberts/xd},
}

@Article{RojasGomez,
  author   = {Rojas-G{\'{o}}mez, Ren{\'{a}}n and Yang, Jihyun and Lin, Youzuo and Theiler, James and Wohlberg, Brendt},
  title    = {{Physics-Consistent Data-driven Seismic Inversion with Adaptive Data Augmentation}},
  abstract = {Solving the seismic full-waveform inversion (FWI) problem can be challenging due to its ill-posedness and high computational cost. We develop a new hybrid computational approach to solve FWI that combines physics-based models with data-driven methodologies. In particular, we develop a data augmentation strategy that can not only improve the representativity of the training set, but also incorporate important governing physics into the training process and therefore improve the inversion accuracy. We demonstrate our method with an example of monitoring subsurface carbon sequestration leakage. Our method yields higher accuracy and greater generalization ability than purely physics-based and purely data-driven approaches.},
  file     = {:home/antonio/Documents/bibliography/files/Rojas-G{\'{o}}mez et al. - Unknown - Physics-Consistent Data-driven Seismic Inversion with Adaptive Data Augmentation.pdf:pdf},
  groups   = {Helmholtz and waves},
}

@Article{Um,
  author   = {Um, Kiwon and Fei, Yun and Holl, Philipp and Brand, Robert and Thuerey, Nils},
  title    = {{Differentiable Physics for Improving the Accuracy of Iterative PDE-Solvers with Neural Networks}},
  abstract = {Finding accurate solutions to partial differential equations (PDEs) is a crucial task for a wide range of fields in physics and engineering. We target the problem of reducing numerical errors of iterative PDE solvers and compare different learning approaches for finding complex correction functions. In particular, we highlight the performance of differentiable physics networks for a wide variety of PDEs, from non-linear advection-diffusion systems to three-dimensional Navier-Stokes flows.},
  file     = {:home/antonio/Documents/bibliography/files/Um et al. - Unknown - Differentiable Physics for Improving the Accuracy of Iterative PDE-Solvers with Neural Networks.pdf:pdf},
  groups   = {Differentiable programming and simulation},
}

@Article{BenjaminErichson♥,
  author        = {{Benjamin Erichson ♥}, N and Muehlebach, Michael and Mahoney, Michael W},
  title         = {{PHYSICS-INFORMED AUTOENCODERS FOR LYAPUNOV-STABLE FLUID FLOW PREDICTION}},
  abstract      = {In addition to providing high-profile successes in computer vision and natural language processing, neural networks also provide an emerging set of techniques for scientific problems. Such data-driven models, however, typically ignore physical insights from the scientific system under consideration. Among other things, a "physics-informed" model formulation should encode some degree of stability or robustness or well-conditioning (in that a small change of the input will not lead to drastic changes in the output), characteristic of the underlying scientific problem. We investigate whether it is possible to include physics-informed prior knowledge for improving the model quality (e.g., generalization performance, sensitivity to parameter tuning, or robustness in the presence of noisy data). To that extent, we focus on the stability of an equilibrium, one of the most basic properties a dynamic system can have, via the lens of Lyapunov analysis. For the prototypical problem of fluid flow prediction, we show that models preserving Lyapunov stability improve the generalization error and reduce the prediction uncertainty.},
  archiveprefix = {arXiv},
  arxivid       = {1905.10866v1},
  eprint        = {1905.10866v1},
  file          = {:home/antonio/Documents/bibliography/files/Benjamin Erichson ♥, Muehlebach, Mahoney - Unknown - PHYSICS-INFORMED AUTOENCODERS FOR LYAPUNOV-STABLE FLUID FLOW PREDICTION.pdf:pdf},
  groups        = {PDEs and neural networks},
}

@Article{Kochkov,
  author   = {Kochkov, Dmitrii and Sanchez-Gonzalez, Alvaro and Smith, Jamie and Research, Google and Pfaff, Tobias and Battaglia, Peter and Brenner, Michael P},
  title    = {{Learning latent field dynamics of PDEs}},
  abstract = {We present a new approach to learning surrogate models for simulation of complex physical systems described by nonlinear partial differential equations. It aims to capture three features of PDEs: locality, time continuity and formation of elementary patterns in the solution by learning a local, low dimensional latent representation and corresponding time evolution. We show that our method achieves top performance and competitive inference speed compared to baseline methods while operating with a 4-times more compact representation. Since the models learn local representations of the solution, they generalize to different system sizes that feature qualitatively different behavior without retraining.},
  file     = {:home/antonio/Documents/bibliography/files/Kochkov et al. - Unknown - Learning latent field dynamics of PDEs.pdf:pdf},
  groups   = {Latent},
}

@Article{Lange2021,
  author   = {Lange, Henning and Brunton, Steven L and Kutz, J Nathan},
  journal  = {Journal of Machine Learning Research},
  title    = {{From Fourier to Koopman: Spectral Methods for Long-term Time Series Prediction}},
  year     = {2021},
  pages    = {1--38},
  volume   = {22},
  abstract = {We propose spectral methods for long-term forecasting of temporal signals stemming from linear and nonlinear quasi-periodic dynamical systems. For linear signals, we introduce an algorithm with similarities to the Fourier transform but which does not rely on periodicity assumptions, allowing for forecasting given potentially arbitrary sampling intervals. We then extend this algorithm to handle nonlinearities by leveraging Koopman theory. The resulting algorithm performs a spectral decomposition in a nonlinear, data-dependent basis. The optimization objective for both algorithms is highly non-convex. However, expressing the objective in the frequency domain allows us to compute global optima of the error surface in a scalable and efficient manner, partially by exploiting the computational properties of the Fast Fourier Transform. Because of their close relation to Bayesian Spectral Analysis , uncertainty quantification metrics are a natural byproduct of the spectral forecasting methods. We extensively benchmark these algorithms against other leading forecasting methods on a range of synthetic experiments as well as in the context of real-world power systems and fluid flows.},
  file     = {:home/antonio/Documents/bibliography/files/Lange, Brunton, Kutz - 2021 - From Fourier to Koopman Spectral Methods for Long-term Time Series Prediction.pdf:pdf},
  groups   = {Dynamics and control},
  url      = {http://jmlr.org/papers/v22/20-406.html.},
}

@Article{Pal2021,
  author        = {Pal, Avik and Ma, Yingbo and Shah, Viral and Rackauckas, Christopher},
  title         = {{Opening the Blackbox: Accelerating Neural Differential Equations by Regularizing Internal Solver Heuristics}},
  year          = {2021},
  pages         = {139},
  abstract      = {Democratization of machine learning requires ar-chitectures that automatically adapt to new problems. Neural Differential Equations (NDEs) have emerged as a popular modeling framework by removing the need for ML practitioners to choose the number of layers in a recurrent model. While we can control the computational cost by choosing the number of layers in standard architectures, in NDEs the number of neural network evaluations for a forward pass can depend on the number of steps of the adaptive ODE solver. But, can we force the NDE to learn the version with the least steps while not increasing the training cost? Current strategies to overcome slow prediction require high order automatic differentiation, leading to significantly higher training time. We describe a novel regularization method that uses the internal cost heuristics of adaptive differential equation solvers combined with discrete adjoint sensitivities to guide the training process towards learning NDEs that are easier to solve. This approach opens up the blackbox numerical analysis behind the differential equation solver's algorithm and directly uses its local error estimates and stiffness heuristics as cheap and accurate cost estimates. We incorporate our method without any change in the underlying NDE framework and show that our method extends beyond Ordinary Differential Equations to accommodate Neural Stochastic Differential Equations. We demonstrate how our approach can halve the prediction time and, unlike other methods which can increase the training time by an order of magnitude, we demonstrate similar reduction in training times. Together this showcases how the knowledge embedded within Figure 1. Training and Prediction Performance of Regularized NDEs We obtain an average training and prediction speedup of 1.45x and 1.84x respectively for our best model on supervised classification and time series problems. state-of-the-art equation solvers can be used to enhance machine learning.},
  archiveprefix = {arXiv},
  arxivid       = {2105.03918v1},
  eprint        = {2105.03918v1},
  file          = {:home/antonio/Documents/bibliography/files/Pal et al. - 2021 - Opening the Blackbox Accelerating Neural Differential Equations by Regularizing Internal Solver Heuristics.pdf:pdf},
  groups        = {PDEs and neural networks},
  url           = {https://github.com/avik-pal/RegNeuralODE.},
}

@Article{Bassey,
  author        = {Bassey, Joshua and Li, Xiangfang and Qian, Lijun},
  title         = {{A Survey of Complex-Valued Neural Networks}},
  abstract      = {Artificial neural networks (ANNs) based machine learning models and especially deep learning models have been widely applied in computer vision, signal processing, wireless communications, and many other domains, where complex numbers occur either naturally or by design. However, most of the current implementations of ANNs and machine learning frameworks are using real numbers rather than complex numbers. There are growing interests in building ANNs using complex numbers, and exploring the potential advantages of the so called complex-valued neural networks (CVNNs) over their real-valued counterparts. In this paper, we discuss the recent development of CVNNs by performing a survey of the works on CVNNs in the literature. Specifically, detailed review of various CVNNs in terms of activation function, learning and optimization, input and output representations, and their applications in tasks such as signal processing and computer vision are provided, followed by a discussion on some pertinent challenges and future research directions.},
  archiveprefix = {arXiv},
  arxivid       = {2101.12249v1},
  eprint        = {2101.12249v1},
  file          = {:home/antonio/Documents/bibliography/files/Bassey, Li, Qian - Unknown - A Survey of Complex-Valued Neural Networks.pdf:pdf},
  groups        = {Representation, architectures and DL layers},
  keywords      = {Index Terms-complex-valued neural networks, complex num-ber, deep learning, machine learning},
}

@Article{Chen,
  author        = {Chen, Xuanhong and Wang, Hang and Ni, Bingbing},
  title         = {{X-volution: On the Unification of Convolution and Self-attention}},
  abstract      = {Convolution and self-attention are acting as two fundamental building blocks in deep neural networks, where the former extracts local image features in a linear way while the latter non-locally encodes high-order contextual relationships. Though essentially complementary to each other, i.e., first-/high-order, stat-of-the-art ar-chitectures, i.e., CNNs or transformers, lack a principled way to simultaneously apply both operations in a single computational module, due to their heterogeneous computing pattern and excessive burden of global dot-product for visual tasks. In this work, we theoretically derive a global self-attention approximation scheme, which approximates self-attention via the convolution operation on transformed features. Based on the approximate scheme, we establish a multi-branch elementary module composed of both convolution and self-attention operation, capable of unifying both local and non-local feature interaction. Importantly, once trained, this multi-branch module could be conditionally converted into a single standard convolution operation via structural re-parameterization, rendering a pure convo-lution styled operator named X-volution, ready to be plugged into any modern networks as an atomic operation. Extensive experiments demonstrate that the proposed X-volution, achieves highly competitive visual understanding improvements (+1.2% top-1 accuracy on ImageNet classification, +1.7 box AP and +1.5 mask AP on COCO detection and segmentation).},
  archiveprefix = {arXiv},
  arxivid       = {2106.02253v2},
  eprint        = {2106.02253v2},
  file          = {:home/antonio/Documents/bibliography/files/Chen, Wang, Ni - Unknown - X-volution On the Unification of Convolution and Self-attention.pdf:pdf},
  groups        = {Representation, architectures and DL layers},
}

@Article{Li,
  author   = {Li, Duo and Hu, Jie and Wang, Changhu and Li, Xiangtai and She, Qi and Zhu, Lei and Zhang, Tong and Chen, Qifeng},
  title    = {{Involution: Inverting the Inherence of Convolution for Visual Recognition}},
  abstract = {Convolution has been the core ingredient of modern neu-ral networks, triggering the surge of deep learning in vision. In this work, we rethink the inherent principles of standard convolution for vision tasks, specifically spatial-agnostic and channel-specific. Instead, we present a novel atomic operation for deep neural networks by inverting the aforementioned design principles of convolution, coined as involution. We additionally demystify the recent popular self-attention operator and subsume it into our invo-lution family as an over-complicated instantiation. The proposed involution operator could be leveraged as fundamental bricks to build the new generation of neural networks for visual recognition, powering different deep learning models on several prevalent benchmarks, including Im-ageNet classification, COCO detection and segmentation, together with Cityscapes segmentation. Our involution-based models improve the performance of convolutional baselines using ResNet-50 by up to 1.6% top-1 accuracy, 2.5% and 2.4% bounding box AP, and 4.7% mean IoU absolutely while compressing the computational cost to 66%, 65%, 72%, and 57% on the above benchmarks, respectively. Code and pre-trained models for all the tasks are available at https://github.com/d-li14/involution.},
  file     = {:home/antonio/Documents/bibliography/files/Li et al. - Unknown - Involution Inverting the Inherence of Convolution for Visual Recognition.pdf:pdf},
  groups   = {Representation, architectures and DL layers},
  url      = {https://github.com/d-li14/involution.},
}

@Article{Lafitte2018,
  author   = {Lafitte, Pauline and Ramdani, Karim and Vion, Alexandre and Geuzaine, Christophe},
  journal  = {ESAIM: PROCEEDINGS AND SURVEYS},
  title    = {Improved Sweeping Preconditioners For Domain Decomposition Algorithms Applied To Time-harmonic Helmholtz And Maxwell Problems},
  year     = {2018},
  pages    = {93--111},
  volume   = {61},
  abstract = {Sweeping-type algorithms have recently gained a lot of interest for the solution of high-frequency time-harmonic wave problems, in particular when used in combination with perfectly matched layers. However, an inherent problem with sweeping approaches is the sequential nature of the process, which makes them inadequate for efficient implementation on parallel computers. We propose several improvements to the double-sweep preconditioner originally presented in [18], which uses sweeping as a matrix-free preconditioner for a Schwarz domain decomposition method. Similarly, the improved pre-conditioners are based on approximations of the inverse of the Schwarz iteration operator: the general methodology is to apply well-known algebraic techniques to the operator seen as a matrix, which in turn is processed to obtain equivalent matrix-free routines that we use as preconditioners. A notable feature of the new variants is the introduction of partial sweeps that can be performed concurrently in order to make a better usage of the resources. As these modifications still leave some unexploited computational power, we also propose to combine them with right-hand side pipelining to further improve parallelism and achieve significant speed-ups. Examples are presented on high-frequency Helmholtz and Maxwell problems, in two and three dimensions, to demonstrate the properties of our improvements on parallel computer architectures.},
  doi      = {10.1051/proc/201861093},
  groups   = {Helmholtz},
  url      = {https://doi.org/10.1051/proc/201861093},
}

@Article{Kochkov2021,
  author   = {Kochkov, Dmitrii and Smith, Jamie A and Alieva, Ayya and Wang, Qing and Brenner, Michael P and Hoyer, Stephan and Bertozzi, Andrea L and Designed, S H and Performed, S H and {Analyzed Data;}, S H},
  title    = {{Machine learning-accelerated computational fluid dynamics}},
  year     = {2021},
  abstract = {Numerical simulation of fluids plays an essential role in modeling many physical phenomena, such as weather, climate, aerodynamics , and plasma physics. Fluids are well described by the Navier-Stokes equations, but solving these equations at scale remains daunting, limited by the computational cost of resolving the smallest spatiotemporal features. This leads to unfavorable trade-offs between accuracy and tractability. Here we use end-to-end deep learning to improve approximations inside computational fluid dynamics for modeling two-dimensional turbulent flows. For both direct numerical simulation of turbulence and large-eddy simulation, our results are as accurate as baseline solvers with 8 to 10× finer resolution in each spatial dimension, resulting in 40-to 80-fold computational speedups. Our method remains stable during long simulations and generalizes to forcing functions and Reynolds numbers outside of the flows where it is trained, in contrast to black-box machine-learning approaches. Our approach exemplifies how scientific computing can leverage machine learning and hardware accelerators to improve simulations without sacrificing accuracy or generalization. machine learning | turbulence | computational physics | nonlinear partial differential equations S imulation of complex physical systems described by non-linear partial differential equations (PDEs) is central to engineering and physical science, with applications ranging from weather (1, 2) and climate (3, 4) and engineering design of vehicles or engines (5) to wildfires (6) and plasma physics (7). Despite a direct link between the equations of motion and the basic laws of physics, it is impossible to carry out direct numerical simulations at the scale required for these important problems. This fundamental issue has stymied progress in scientific computation for decades and arises from the fact that an accurate simulation must resolve the smallest spatiotemporal scales. A paradigmatic example is turbulent fluid flow (8), underlying simulations of weather, climate, and aerodynamics. The size of the smallest eddy is tiny: For an airplane with chord length of 2 m, the smallest length scale (the Kolomogorov scale) (9) is O(10 −6) m. Classical methods for computational fluid dynamics (CFD), such as finite differences, finite volumes, finite elements, and pseudo-spectral methods, are only accurate if fields vary smoothly on the mesh, and hence meshes must resolve the smallest features to guarantee convergence. For a turbulent fluid flow, the requirement to resolve the smallest flow features implies a computational cost scaling like Re 3 , where Re = UL/$\nu$, with U and L the typical velocity and length scales and $\nu$ the kine-matic viscosity. A 10-fold increase in Re leads to a thousandfold increase in the computational cost. Consequently, direct numerical simulation (DNS) for, e.g., climate and weather, is impossible. Instead, it is traditional to use smoothed versions of the Navier-Stokes equations (10, 11) that allow coarser grids while sacrificing accuracy, such as Reynolds averaged Navier-Stokes (12, 13) and large-eddy simulation (LES) (14, 15). For example, current state-of-the-art LES with mesh sizes of O(10) to O(100) million has been used in the design of internal combustion engines (16), gas turbine engines (17, 18), and turbomachinery (19). Despite promising progress in LES over the last two decades, there are severe limits to what can be accurately simulated. This is mainly due to the first-order dependence of LES on the subgrid-scale (SGS) model, especially for flows whose rate controlling scale is unresolved (20). Here, we introduce a method for calculating the accurate time evolution of solutions to nonlinear PDEs, while using an order-of-magnitude coarser grid than is traditionally required for the same accuracy. This is a type of numerical solver that does not average unresolved degrees of freedom but instead uses discrete equations that give pointwise accurate solutions on an unresolved grid. We discover these algorithms using machine learning (ML), by replacing the components of traditional solvers most affected by the loss of resolution with learned alternatives. As shown in Fig. 1A, for a two-dimensional DNS of a turbulent flow our algorithm maintains accuracy while using 10× coarser resolution in each dimension, resulting in a ∼ 80-fold improvement in computational time with respect to an advanced numerical method of similar accuracy. The model learns how to interpolate local features of solutions and hence can accurately generalize to different flow conditions such as different forcings and even different Reynolds numbers (Fig. 1B). We also apply the method to a high-resolution LES simulation of a turbulent flow and show similar performance enhancements , maintaining pointwise accuracy on Re = 100, 000 LES simulations using 8× coarser grids with ∼ 40-fold computational speedup. There has been a flurry of recent work using ML to improve turbulence modeling. One major family of approaches uses ML Significance Accurate simulation of fluids is important for many science and engineering problems but is very computationally demanding. In contrast, machine-learning models can approximate physics very quickly but at the cost of accuracy. Here we show that using machine learning inside traditional fluid simulations can improve both accuracy and speed, even on examples very different from the training data. Our approach opens the door to applying machine learning to large-scale physical modeling tasks like airplane design and climate prediction.},
  doi      = {10.1073/pnas.2101784118/-/DCSupplemental.y},
  file     = {:home/antonio/Documents/bibliography/files/Kochkov et al. - 2021 - Machine learning-accelerated computational fluid dynamics.pdf:pdf;:home/antonio/Documents/bibliography/files/Kochkov et al. - 2021 - Machine learning-accelerated computational fluid dynamics(2).pdf:pdf},
  groups   = {PDEs and neural networks},
}

@Article{DanielFreeman2021,
  author        = {{Daniel Freeman}, C and Frey, Erik and {Raichuk Google Research Sertan Girgin Google Research Igor Mordatch Google Research Olivier Bachem}, Anton},
  title         = {{Brax-A Differentiable Physics Engine for Large Scale Rigid Body Simulation}},
  year          = {2021},
  abstract      = {We present Brax, an open source library for rigid body simulation with a focus on performance and parallelism on accelerators, written in JAX. We present results on a suite of tasks inspired by the existing reinforcement learning literature, but remade in our engine. Additionally, we provide reimplementations of PPO, SAC, ES, and direct policy optimization in JAX that compile alongside our environments, allowing the learning algorithm and the environment processing to occur on the same device, and to scale seamlessly on accelerators. Finally, we include notebooks that facilitate training of performant policies on common OpenAI Gym MuJoCo-like tasks in minutes. Figure 1: The suite of examples environments included in the initial release of Brax. From left to right: ant, fetch, grasp, halfcheetah, and humanoid. 1 Summary of Contributions Brax trains locomotion and dexterous manipulation policies in seconds to minutes using just one modern accelerator. Brax achieves this by making extensive use of auto-vectorization, device-parallelism, just-in-time compilation, and auto-differentiation primitives of the JAX[1] library. In doing so, it unlocks simulation of simple rigidbody physics systems in thousands of independent environments across hundreds of connected accelerators. For an individual accelerator, Brax reaches millions of simulation steps per second on environments like OpenAI Gym's MuJoCo Ant[2]. See Sec. 6 for more details, or our Colab[3] to train a policy interactively. The structure of the paper is as follows: we first provide motivation for our engine in Sec. 2. In Sec. 3, we describe the architecture of Brax, starting from the low level physics primitives, how they interact, and how they can be extended for practitioners interested in physics based simulation. In Sec. 4, we review our ProtoBuf environment specification, and detail how it can be used to construct rich physically simulated tasks, including the suite of tasks bundled in this initial release. In Sec. 5, we tour some of the reinforcement learning algorithms bundled with Brax. In Sec. 6, we catalog scaling behavior of Brax on accelerators as well as performance comparisons between Brax and MuJoCo Preprint. Under review.},
  archiveprefix = {arXiv},
  arxivid       = {2106.13281v1},
  eprint        = {2106.13281v1},
  file          = {:home/antonio/Documents/bibliography/files/Daniel Freeman, Frey, Raichuk Google Research Sertan Girgin Google Research Igor Mordatch Google Research Olivier Bachem - 2021 - Brax-A.pdf:pdf},
  groups        = {Differentiable programming and simulation},
}

@Article{Yu2021,
  author        = {Yu, Chris and Schumacher, Henrik and Crane, Keenan},
  journal       = {ACM Transactions on Graphics},
  title         = {{Repulsive Curves}},
  year          = {2021},
  issn          = {15577368},
  number        = {2},
  volume        = {40},
  abstract      = {Curves play a fundamental role across computer graphics, physical simulation, and mathematical visualization, yet most tools for curve design do nothing to prevent crossings or self-intersections. This article develops efficient algorithms for (self-)repulsion of plane and space curves that are well-suited to problems in computational design. Our starting point is the so-called tangent-point energy, which provides an infinite barrier to self-intersection. In contrast to local collision detection strategies used in, e.g., physical simulation, this energy considers interactions between all pairs of points, and is hence useful for global shape optimization: local minima tend to be aesthetically pleasing, physically valid, and nicely distributed in space. A reformulation of gradient descent based on a Sobolev-Slobodeckij inner product enables us to make rapid progress toward local minima-independent of curve resolution. We also develop a hierarchical multigrid scheme that significantly reduces the per-step cost of optimization. The energy is easily integrated with a variety of constraints and penalties (e.g., inextensibility, or obstacle avoidance), which we use for applications including curve packing, knot untangling, graph embedding, non-crossing spline interpolation, flow visualization, and robotic path planning.},
  archiveprefix = {arXiv},
  arxivid       = {2006.07859},
  doi           = {10.1145/3439429},
  eprint        = {2006.07859},
  file          = {:home/antonio/Downloads/RepulsiveCurves.pdf:pdf},
  groups        = {Computer Vision},
  keywords      = {Computational design, curves, knots, shape optimization},
}

@Article{Moseley2021,
  author        = {Moseley, Ben and Markham, Andrew and Nissen-Meyer, Tarje},
  title         = {{FINITE BASIS PHYSICS-INFORMED NEURAL NETWORKS (FBPINNS): A SCALABLE DOMAIN DECOMPOSITION APPROACH FOR SOLVING DIFFERENTIAL EQUATIONS A PREPRINT}},
  year          = {2021},
  abstract      = {Recently, physics-informed neural networks (PINNs) have offered a powerful new paradigm for solving problems relating to differential equations. Compared to classical numerical methods PINNs have several advantages, for example their ability to provide mesh-free solutions of differential equations and their ability to carry out forward and inverse modelling within the same optimisation problem. Whilst promising, a key limitation to date is that PINNs have struggled to accurately and efficiently solve problems with large domains and/or multi-scale solutions, which is crucial for their real-world application. Multiple significant and related factors contribute to this issue, including the increasing complexity of the underlying PINN optimisation problem as the problem size grows and the spectral bias of neural networks. In this work we propose a new, scalable approach for solving large problems relating to differential equations called Finite Basis PINNs (FBPINNs). FBPINNs are inspired by classical finite element methods, where the solution of the differential equation is expressed as the sum of a finite set of basis functions with compact support. In FBPINNs neural networks are used to learn these basis functions, which are defined over small, overlapping subdomains. FBINNs are designed to address the spectral bias of neural networks by using separate input normalisation over each subdomain, and reduce the complexity of the underlying optimisation problem by using many smaller neural networks in a parallel divide-and-conquer approach. Our numerical experiments show that FBPINNs are effective in solving both small and larger, multi-scale problems, outperforming standard PINNs in both accuracy and computational resources required, potentially paving the way to the application of PINNs on large, real-world problems.},
  archiveprefix = {arXiv},
  arxivid       = {2107.07871v1},
  eprint        = {2107.07871v1},
  file          = {:home/antonio/Documents/bibliography/files/Moseley, Markham, Nissen-Meyer - 2021 - FINITE BASIS PHYSICS-INFORMED NEURAL NETWORKS (FBPINNS) A SCALABLE DOMAIN DECOMPOSITION APPROACH.pdf:pdf},
  groups        = {PDEs and neural networks},
  keywords      = {Differential equations {\textperiodcentered}, Domain decomposition {\textperiodcentered}, Forward modelling {\textperiodcentered}, Learnable basis functions {\textperiodcentered}, Multi-scale modelling {\textperiodcentered}, Parallel computing, Physics informed neural networks {\textperiodcentered}, Spectral bias issue {\textperiodcentered}},
}

@Article{Engquist2018,
  author   = {Engquist, Bj{\"{o}}rn and Zhao, Hongkai},
  journal  = {Communications on Pure and Applied Mathematics},
  title    = {{Approximate Separability of the Green's Function of the Helmholtz Equation in the High Frequency Limit}},
  year     = {2018},
  issn     = {10970312},
  number   = {11},
  pages    = {2220--2274},
  volume   = {71},
  abstract = {The minimum number of terms that are needed in a separable approximation for a Green's function reveals the intrinsic complexity of the solution space of the underlying differential equation. It also has implications for whether low-rank structures exist in the linear system after numerical discretization. The Green's function for a coercive elliptic differential operator in divergence form was shown to be highly separable [2], and efficient numerical algorithms exploiting low-rank structures of the discretized systems were developed. In this work, a new approach to study the approximate separability of the Green's function of the Helmholtz equation in the high-frequency limit is developed. We show (1) lower bounds based on an explicit characterization of the correlation between two Green's functions and a tight dimension estimate for the best linear subspace to approximate a set of decorrelated Green's functions, (2) upper bounds based on constructing specific separable approximations, and (3) sharpness of these bounds for a few case studies of practical interest. {\textcopyright} 2018 Wiley Periodicals, Inc.},
  doi      = {10.1002/cpa.21755},
  file     = {:home/antonio/Downloads/cpa.21755.pdf:pdf},
  groups   = {Helmholtz},
}

@Article{Manek2019,
  author        = {Manek, Gaurav and {Zico Kolter}, J.},
  journal       = {Advances in Neural Information Processing Systems},
  title         = {{Learning stable deep dynamics models}},
  year          = {2019},
  issn          = {10495258},
  number        = {NeurIPS},
  pages         = {1--9},
  volume        = {32},
  abstract      = {Deep networks are commonly used to model dynamical systems, predicting how the state of a system will evolve over time (either autonomously or in response to control inputs). Despite the predictive power of these systems, it has been difficult to make formal claims about the basic properties of the learned systems. In this paper, we propose an approach for learning dynamical systems that are guaranteed to be stable over the entire state space. The approach works by jointly learning a dynamics model and Lyapunov function that guarantees non-expansiveness of the dynamics under the learned Lyapunov function. We show that such learning systems are able to model simple dynamical systems and can be combined with additional deep generative models to learn complex dynamics, such as video textures, in a fully end-to-end fashion.},
  archiveprefix = {arXiv},
  arxivid       = {2001.06116},
  eprint        = {2001.06116},
  file          = {:home/antonio/Downloads/2001.06116.pdf:pdf},
  groups        = {Latent},
}

@Article{Dogra2020,
  author        = {Dogra, Akshunna S. and Redman, William T},
  title         = {{Optimizing Neural Networks via Koopman Operator Theory}},
  year          = {2020},
  issn          = {10495258},
  number        = {NeurIPS},
  pages         = {1--18},
  abstract      = {Koopman operator theory, a powerful framework for discovering the underlying dynamics of nonlinear dynamical systems, was recently shown to be intimately connected with neural network training. In this work, we take the first steps in making use of this connection. As Koopman operator theory is a linear theory, a successful implementation of it in evolving network weights and biases offers the promise of accelerated training, especially in the context of deep networks, where optimization is inherently a non-convex problem. We show that Koopman operator theoretic methods allow for accurate predictions of weights and biases of feedforward, fully connected deep networks over a non-trivial range of training time. During this window, we find that our approach is >10x faster than various gradient descent based methods (e.g. Adam, Adadelta, Adagrad), in line with our complexity analysis. We end by highlighting open questions in this exciting intersection between dynamical systems and neural network theory, and additional methods by which our results may be generalized.},
  archiveprefix = {arXiv},
  arxivid       = {2006.02361},
  eprint        = {2006.02361},
  file          = {:home/antonio/Downloads/2006.02361.pdf:pdf},
  groups        = {Training},
  url           = {http://arxiv.org/abs/2006.02361},
}

@Article{Sander2021,
  author        = {Sander, Michael E. and Ablin, Pierre and Blondel, Mathieu and Peyr{\'{e}}, Gabriel},
  title         = {{Momentum Residual Neural Networks}},
  year          = {2021},
  abstract      = {The training of deep residual neural networks (ResNets) with backpropagation has a memory cost that increases linearly with respect to the depth of the network. A way to circumvent this issue is to use reversible architectures. In this paper, we propose to change the forward rule of a ResNet by adding a momentum term. The resulting networks, momentum residual neural networks (Momentum ResNets), are invertible. Unlike previous invertible architectures, they can be used as a drop-in replacement for any existing ResNet block. We show that Momentum ResNets can be interpreted in the infinitesimal step size regime as second-order ordinary differential equations (ODEs) and exactly characterize how adding momentum progressively increases the representation capabilities of Momentum ResNets. Our analysis reveals that Momentum ResNets can learn any linear mapping up to a multiplicative factor, while ResNets cannot. In a learning to optimize setting, where convergence to a fixed point is required, we show theoretically and empirically that our method succeeds while existing invertible architectures fail. We show on CIFAR and ImageNet that Momentum ResNets have the same accuracy as ResNets, while having a much smaller memory footprint, and show that pre-trained Momentum ResNets are promising for fine-tuning models.},
  archiveprefix = {arXiv},
  arxivid       = {2102.07870},
  eprint        = {2102.07870},
  file          = {:home/antonio/Downloads/2102.07870.pdf:pdf},
  groups        = {General deep learning},
  url           = {http://arxiv.org/abs/2102.07870},
}

@Article{Blondel2021,
  author        = {Blondel, Mathieu and Berthet, Quentin and Cuturi, Marco and Frostig, Roy and Hoyer, Stephan and Llinares-L{\'{o}}pez, Felipe and Pedregosa, Fabian and Vert, Jean-Philippe},
  title         = {{Efficient and Modular Implicit Differentiation}},
  year          = {2021},
  abstract      = {Automatic differentiation (autodiff) has revolutionized machine learning. It allows expressing complex computations by composing elementary ones in creative ways and removes the burden of computing their derivatives by hand. More recently, differentiation of optimization problem solutions has attracted widespread attention with applications such as optimization as a layer, and in bi-level problems such as hyper-parameter optimization and meta-learning. However, the formulas for these derivatives often involve case-by-case tedious mathematical derivations. In this paper, we propose a unified, efficient and modular approach for implicit differentiation of optimization problems. In our approach, the user defines (in Python in the case of our implementation) a function $F$ capturing the optimality conditions of the problem to be differentiated. Once this is done, we leverage autodiff of $F$ and implicit differentiation to automatically differentiate the optimization problem. Our approach thus combines the benefits of implicit differentiation and autodiff. It is efficient as it can be added on top of any state-of-the-art solver and modular as the optimality condition specification is decoupled from the implicit differentiation mechanism. We show that seemingly simple principles allow to recover many recently proposed implicit differentiation methods and create new ones easily. We demonstrate the ease of formulating and solving bi-level optimization problems using our framework. We also showcase an application to the sensitivity analysis of molecular dynamics.},
  archiveprefix = {arXiv},
  arxivid       = {2105.15183},
  eprint        = {2105.15183},
  file          = {:home/antonio/Downloads/2105.15183.pdf:pdf},
  groups        = {General deep learning},
  url           = {http://arxiv.org/abs/2105.15183},
}

@Article{Khan2021,
  author        = {Khan, Mohammad Emtiyaz and Rue, H{\aa}vard},
  title         = {{The Bayesian Learning Rule}},
  year          = {2021},
  pages         = {1--37},
  abstract      = {We show that many machine-learning algorithms are specific instances of a single algorithm called the Bayesian learning rule. The rule, derived from Bayesian principles, yields a wide-range of algorithms from fields such as optimization, deep learning, and graphical models. This includes classical algorithms such as ridge regression, Newton's method, and Kalman filter, as well as modern deep-learning algorithms such as stochastic-gradient descent, RMSprop, and Dropout. The key idea in deriving such algorithms is to approximate the posterior using candidate distributions estimated by using natural gradients. Different candidate distributions result in different algorithms and further approximations to natural gradients give rise to variants of those algorithms. Our work not only unifies, generalizes, and improves existing algorithms, but also helps us design new ones.},
  archiveprefix = {arXiv},
  arxivid       = {2107.04562},
  eprint        = {2107.04562},
  file          = {:home/antonio/Downloads/2107.04562.pdf:pdf},
  groups        = {Training, General deep learning},
  url           = {http://arxiv.org/abs/2107.04562},
}

@Article{Vicol2021,
  author = {Vicol, Paul and Metz, Luke},
  title  = {{Unbiased Gradient Estimation in Unrolled Computation Graphs with Persistent Evolution Strategies}},
  year   = {2021},
  file   = {:home/antonio/Downloads/vicol21a.pdf:pdf},
  groups = {Training, General deep learning},
}

@Article{Kidger2021,
  author        = {Kidger, Patrick and Foster, James and Li, Xuechen and Oberhauser, Harald and Lyons, Terry},
  title         = {{Neural SDEs as Infinite-Dimensional GANs}},
  year          = {2021},
  number        = {1},
  abstract      = {Stochastic differential equations (SDEs) are a staple of mathematical modelling of temporal dynamics. However, a fundamental limitation has been that such models have typically been relatively inflexible, which recent work introducing Neural SDEs has sought to solve. Here, we show that the current classical approach to fitting SDEs may be approached as a special case of (Wasserstein) GANs, and in doing so the neural and classical regimes may be brought together. The input noise is Brownian motion, the output samples are time-evolving paths produced by a numerical solver, and by parameterising a discriminator as a Neural Controlled Differential Equation (CDE), we obtain Neural SDEs as (in modern machine learning parlance) continuous-time generative time series models. Unlike previous work on this problem, this is a direct extension of the classical approach without reference to either prespecified statistics or density functions. Arbitrary drift and diffusions are admissible, so as the Wasserstein loss has a unique global minima, in the infinite data limit any SDE may be learnt. Example code has been made available as part of the \texttt{torchsde} repository.},
  archiveprefix = {arXiv},
  arxivid       = {2102.03657},
  eprint        = {2102.03657},
  file          = {:home/antonio/Downloads/2102.03657.pdf:pdf},
  groups        = {General deep learning},
  url           = {http://arxiv.org/abs/2102.03657},
}

@Article{Piche2021,
  author        = {Pich{\'{e}}, Alexandre and Marino, Joseph and Marconi, Gian Maria and Pal, Christopher and Khan, Mohammad Emtiyaz},
  title         = {{Beyond Target Networks: Improving Deep $Q$-learning with Functional Regularization}},
  year          = {2021},
  abstract      = {Target networks are at the core of recent success in Reinforcement Learning. They stabilize the training by using old parameters to estimate the $Q$-values, but this also limits the propagation of newly-encountered rewards which could ultimately slow down the training. In this work, we propose an alternative training method based on functional regularization which does not have this deficiency. Unlike target networks, our method uses up-to-date parameters to estimate the target $Q$-values, thereby speeding up training while maintaining stability. Surprisingly, in some cases, we can show that target networks are a special, restricted type of functional regularizers. Using this approach, we show empirical improvements in sample efficiency and performance across a range of Atari and simulated robotics environments.},
  archiveprefix = {arXiv},
  arxivid       = {2106.02613},
  eprint        = {2106.02613},
  file          = {:home/antonio/Downloads/2106.02613.pdf:pdf},
  groups        = {RL},
  url           = {http://arxiv.org/abs/2106.02613},
}

@Article{Bubeck2021,
  author        = {Bubeck, S{\'{e}}bastien and Sellke, Mark},
  title         = {{A Universal Law of Robustness via Isoperimetry}},
  year          = {2021},
  pages         = {1--13},
  abstract      = {Classically, data interpolation with a parametrized model class is possible as long as the number of parameters is larger than the number of equations to be satisfied. A puzzling phenomenon in deep learning is that models are trained with many more parameters than what this classical theory would suggest. We propose a theoretical explanation for this phenomenon. We prove that for a broad class of data distributions and model classes, overparametrization is necessary if one wants to interpolate the data smoothly. Namely we show that smooth interpolation requires $d$ times more parameters than mere interpolation, where $d$ is the ambient data dimension. We prove this universal law of robustness for any smoothly parametrized function class with polynomial size weights, and any covariate distribution verifying isoperimetry. In the case of two-layers neural networks and Gaussian covariates, this law was conjectured in prior work by Bubeck, Li and Nagaraj. We also give an interpretation of our result as an improved generalization bound for model classes consisting of smooth functions.},
  archiveprefix = {arXiv},
  arxivid       = {2105.12806},
  eprint        = {2105.12806},
  file          = {:home/antonio/Downloads/2105.12806.pdf:pdf},
  groups        = {General deep learning},
  url           = {http://arxiv.org/abs/2105.12806},
}

@Article{Lorraine2021,
  author        = {Lorraine, Jonathan and Acuna, David and Vicol, Paul and Duvenaud, David},
  title         = {{Complex Momentum for Optimization in Games}},
  year          = {2021},
  number        = {c},
  abstract      = {We generalize gradient descent with momentum for optimization in differentiable games to have complex-valued momentum. We give theoretical motivation for our method by proving convergence on bilinear zero-sum games for simultaneous and alternating updates. Our method gives real-valued parameter updates, making it a drop-in replacement for standard optimizers. We empirically demonstrate that complex-valued momentum can improve convergence in realistic adversarial games - like generative adversarial networks - by showing we can find better solutions with an almost identical computational cost. We also show a practical generalization to a complex-valued Adam variant, which we use to train BigGAN to better inception scores on CIFAR-10.},
  archiveprefix = {arXiv},
  arxivid       = {2102.08431},
  eprint        = {2102.08431},
  file          = {:home/antonio/Downloads/2102.08431.pdf:pdf},
  groups        = {RL},
  url           = {http://arxiv.org/abs/2102.08431},
}

@Article{Luna2021,
  author        = {Luna, Kevin and Klymko, Katherine and Blaschke, Johannes P.},
  title         = {{Accelerating GMRES with Deep Learning in Real-Time}},
  year          = {2021},
  pages         = {1--19},
  abstract      = {GMRES is a powerful numerical solver used to find solutions to extremely large systems of linear equations. These systems of equations appear in many applications in science and engineering. Here we demonstrate a real-time machine learning algorithm that can be used to accelerate the time-to-solution for GMRES. Our framework is novel in that is integrates the deep learning algorithm in an in situ fashion: the AI-accelerator gradually learns how to optimizes the time to solution without requiring user input (such as a pre-trained data set). We describe how our algorithm collects data and optimizes GMRES. We demonstrate our algorithm by implementing an accelerated (MLGMRES) solver in Python. We then use MLGMRES to accelerate a solver for the Poisson equation -- a class of linear problems that appears in may applications. Informed by the properties of formal solutions to the Poisson equation, we test the performance of different neural networks. Our key takeaway is that networks which are capable of learning non-local relationships perform well, without needing to be scaled with the input problem size, making them good candidates for the extremely large problems encountered in high-performance computing. For the inputs studied, our method provides a roughly 2$\times$ acceleration.},
  archiveprefix = {arXiv},
  arxivid       = {2103.10975},
  eprint        = {2103.10975},
  file          = {:home/antonio/Downloads/2103.10975.pdf:pdf},
  groups        = {Acceleration},
  url           = {http://arxiv.org/abs/2103.10975},
}

@Article{Schmidhuber2019,
  author        = {Schmidhuber, Juergen},
  title         = {{Reinforcement Learning Upside Down: Don't Predict Rewards -- Just Map Them to Actions}},
  year          = {2019},
  abstract      = {We transform reinforcement learning (RL) into a form of supervised learning (SL) by turning traditional RL on its head, calling this Upside Down RL (UDRL). Standard RL predicts rewards, while UDRL instead uses rewards as task-defining inputs, together with representations of time horizons and other computable functions of historic and desired future data. UDRL learns to interpret these input observations as commands, mapping them to actions (or action probabilities) through SL on past (possibly accidental) experience. UDRL generalizes to achieve high rewards or other goals, through input commands such as: get lots of reward within at most so much time! A separate paper [63] on first experiments with UDRL shows that even a pilot version of UDRL can outperform traditional baseline algorithms on certain challenging RL problems. We also also conceptually simplify an approach [60] for teaching a robot to imitate humans. First videotape humans imitating the robot's current behaviors, then let the robot learn through SL to map the videos (as input commands) to these behaviors, then let it generalize and imitate videos of humans executing previously unknown behavior. This Imitate-Imitator concept may actually explain why biological evolution has resulted in parents who imitate the babbling of their babies.},
  archiveprefix = {arXiv},
  arxivid       = {1912.02875},
  eprint        = {1912.02875},
  file          = {:home/antonio/Downloads/1912.02875.pdf:pdf},
  groups        = {RL},
  url           = {http://arxiv.org/abs/1912.02875},
}

@Article{Gao2020,
  author        = {Gao, Christina and Isaacson, Joshua and Krause, Claudius},
  journal       = {Machine Learning: Science and Technology},
  title         = {{ i- flow : High-dimensional integration and sampling with normalizing flows }},
  year          = {2020},
  issn          = {2632-2153},
  number        = {4},
  pages         = {045023},
  volume        = {1},
  abstract      = {In many fields of science, high-dimensional integration is required. Numerical methods have been developed to evaluate these complex integrals. We introduce the code i-flow, a python package that performs high-dimensional numerical integration utilizing normalizing flows. Normalizing flows are machine-learned, bijective mappings between two distributions. i-flow can also be used to sample random points according to complicated distributions in high dimensions. We compare i-flow to other algorithms for high-dimensional numerical integration and show that i-flow outperforms them for high dimensional correlated integrals. The i-flow code is publicly available on gitlab at https://gitlab.com/i-flow/i-flow.},
  archiveprefix = {arXiv},
  arxivid       = {2001.05486},
  doi           = {10.1088/2632-2153/abab62},
  eprint        = {2001.05486},
  file          = {:home/antonio/Downloads/2001.05486.pdf:pdf},
  groups        = {Normalizing flows},
}

@Article{Tolstikhin2018,
  author        = {Tolstikhin, Ilya and Bousquet, Olivier and Gelly, Sylvain and Sch{\"{o}}lkopf, Bernhard},
  journal       = {6th International Conference on Learning Representations, ICLR 2018 - Conference Track Proceedings},
  title         = {{Wasserstein auto-encoders}},
  year          = {2018},
  pages         = {1--16},
  abstract      = {We propose the Wasserstein Auto-Encoder (WAE)—a new algorithm for building a generative model of the data distribution. WAE minimizes a penalized form of the Wasserstein distance between the model distribution and the target distribution, which leads to a different regularizer than the one used by the Variational Auto-Encoder (VAE) (Kingma & Welling, 2014). This regularizer encourages the encoded training distribution to match the prior. We compare our algorithm with several other techniques and show that it is a generalization of adversarial auto-encoders (AAE) (Makhzani et al., 2016). Our experiments show that WAE shares many of the properties of VAEs (stable training, encoder-decoder architecture, nice latent manifold structure) while generating samples of better quality, as measured by the FID score.},
  archiveprefix = {arXiv},
  arxivid       = {1711.01558},
  eprint        = {1711.01558},
  file          = {:home/antonio/Downloads/1902.09323.pdf:pdf},
  groups        = {General deep learning},
}

@Article{Kawaguchi2021,
  author        = {Kawaguchi, Kenji},
  title         = {{On the Theory of Implicit Deep Learning: Global Convergence with Implicit Layers}},
  year          = {2021},
  pages         = {1--38},
  abstract      = {A deep equilibrium model uses implicit layers, which are implicitly defined through an equilibrium point of an infinite sequence of computation. It avoids any explicit computation of the infinite sequence by finding an equilibrium point directly via root-finding and by computing gradients via implicit differentiation. In this paper, we analyze the gradient dynamics of deep equilibrium models with nonlinearity only on weight matrices and non-convex objective functions of weights for regression and classification. Despite non-convexity, convergence to global optimum at a linear rate is guaranteed without any assumption on the width of the models, allowing the width to be smaller than the output dimension and the number of data points. Moreover, we prove a relation between the gradient dynamics of the deep implicit layer and the dynamics of trust region Newton method of a shallow explicit layer. This mathematically proven relation along with our numerical observation suggests the importance of understanding implicit bias of implicit layers and an open problem on the topic. Our proofs deal with implicit layers, weight tying and nonlinearity on weights, and differ from those in the related literature.},
  archiveprefix = {arXiv},
  arxivid       = {2102.07346},
  eprint        = {2102.07346},
  file          = {:home/antonio/Downloads/2102.07346.pdf:pdf},
  groups        = {Implicit- and Meta- learning},
  url           = {http://arxiv.org/abs/2102.07346},
}

@Article{Kian2021,
  author = {Kian, Bryan and Low, Hsiang and Jaillet, Patrick},
  title  = {{Learning to Learn with Gaussian Processes}},
  year   = {2021},
  number = {Uai},
  file   = {:home/antonio/Downloads/uai2021.560.preliminary.pdf:pdf},
  groups = {General deep learning},
}

@Article{Transformers2021,
  author = {Transformers, Bstract and Transformer, Ntroduction},
  title  = {{（spotlight）Random Feature Attention}},
  year   = {2021},
  pages  = {1--19},
  file   = {:home/antonio/Downloads/random_feature_attention.pdf:pdf},
  groups = {Attention},
}

@Article{LeeThorp2021,
  author        = {Lee-Thorp, James and Ainslie, Joshua and Eckstein, Ilya and Ontanon, Santiago},
  title         = {{FNet: Mixing Tokens with Fourier Transforms}},
  year          = {2021},
  pages         = {1--18},
  abstract      = {We show that Transformer encoder architectures can be massively sped up, with limited accuracy costs, by replacing the self-attention sublayers with simple linear transformations that "mix" input tokens. These linear transformations, along with standard nonlinearities in feed-forward layers, prove competent at modeling semantic relationships in several text classification tasks. Most surprisingly, we find that replacing the self-attention sublayer in a Transformer encoder with a standard, unparameterized Fourier Transform achieves 92-97% of the accuracy of BERT counterparts on the GLUE benchmark, but trains nearly seven times faster on GPUs and twice as fast on TPUs. The resulting model, FNet, also scales very efficiently to long inputs. Specifically, when compared to the "efficient" Transformers on the Long Range Arena benchmark, FNet matches the accuracy of the most accurate models, but is faster than the fastest models across all sequence lengths on GPUs (and across relatively shorter lengths on TPUs). Finally, FNet has a light memory footprint and is particularly efficient at smaller model sizes: for a fixed speed and accuracy budget, small FNet models outperform Transformer counterparts.},
  archiveprefix = {arXiv},
  arxivid       = {2105.03824},
  eprint        = {2105.03824},
  file          = {:home/antonio/Downloads/2105.03824.pdf:pdf},
  groups        = {Attention},
  url           = {http://arxiv.org/abs/2105.03824},
}

@Article{Dhariwal2021,
  author        = {Dhariwal, Prafulla and Nichol, Alex},
  title         = {{Diffusion Models Beat GANs on Image Synthesis}},
  year          = {2021},
  abstract      = {We show that diffusion models can achieve image sample quality superior to the current state-of-the-art generative models. We achieve this on unconditional image synthesis by finding a better architecture through a series of ablations. For conditional image synthesis, we further improve sample quality with classifier guidance: a simple, compute-efficient method for trading off diversity for fidelity using gradients from a classifier. We achieve an FID of 2.97 on ImageNet 128$\times$128, 4.59 on ImageNet 256$\times$256, and 7.72 on ImageNet 512$\times$512, and we match BigGAN-deep even with as few as 25 forward passes per sample, all while maintaining better coverage of the distribution. Finally, we find that classifier guidance combines well with upsampling diffusion models, further improving FID to 3.94 on ImageNet 256$\times$256 and 3.85 on ImageNet 512$\times$512. We release our code at https://github.com/openai/guided-diffusion},
  archiveprefix = {arXiv},
  arxivid       = {2105.05233},
  eprint        = {2105.05233},
  file          = {:home/antonio/Downloads/2105.05233.pdf:pdf},
  groups        = {Diffusion},
  url           = {http://arxiv.org/abs/2105.05233},
}

@Article{Sohn2015,
  author   = {Sohn, Kihyuk and Yan, Xinchen and Lee, Honglak},
  journal  = {Advances in Neural Information Processing Systems},
  title    = {{Learning structured output representation using deep conditional generative models}},
  year     = {2015},
  issn     = {10495258},
  pages    = {3483--3491},
  volume   = {2015-Janua},
  abstract = {Supervised deep learning has been successfully applied to many recognition problems. Although it can approximate a complex many-to-one function well when a large amount of training data is provided, it is still challenging to model complex structured output representations that effectively perform probabilistic inference and make diverse predictions. In this work, we develop a deep conditional generative model for structured output prediction using Gaussian latent variables. The model is trained efficiently in the framework of stochastic gradient variational Bayes, and allows for fast prediction using stochastic feed-forward inference. In addition, we provide novel strategies to build robust structured prediction algorithms, such as input noise-injection and multi-scale prediction objective at training. In experiments, we demonstrate the effectiveness of our proposed algorithm in comparison to the deterministic deep neural network counterparts in generating diverse but realistic structured output predictions using stochastic inference. Furthermore, the proposed training methods are complimentary, which leads to strong pixel-level object segmentation and semantic labeling performance on Caltech-UCSD Birds 200 and the subset of Labeled Faces in the Wild dataset.},
  file     = {:home/antonio/Downloads/NIPS-2015-learning-structured-output-representation-using-deep-conditional-generative-models-Paper.pdf:pdf},
  groups   = {General deep learning},
}

@Article{Zambaldi2019,
  author   = {Zambaldi, Vinicius and Raposo, David and Santoro, Adam and Bapst, Victor and Li, Yujia and Babuschkin, Igor and Tuyls, Karl and Reichert, David and Lillicrap, Timothy and Lockhart, Edward and Shanahan, Murray and Langston, Victoria and Pascanu, Razvan and Botvinick, Matthew and Vinyals, Oriol and Battaglia, Peter},
  journal  = {7th International Conference on Learning Representations, ICLR 2019},
  title    = {{Deep reinforcement learning with relational inductive biases}},
  year     = {2019},
  pages    = {1--18},
  abstract = {We introduce an approach for augmenting model-free deep reinforcement learning agents with a mechanism for relational reasoning over structured representations, which improves performance, learning efficiency, generalization, and interpretability. Our architecture encodes an image as a set of vectors, and applies an iterative message-passing procedure to discover and reason about relevant entities and relations in a scene. In six of seven StarCraft II Learning Environment mini-games, our agent achieved state-of-the-art performance, and surpassed human grandmaster-level on four. In a novel navigation and planning task, our agent's performance and learning efficiency far exceeded non-relational baselines, it was able to generalize to more complex scenes than it had experienced during training. Moreover, when we examined its learned internal representations, they reflected important structure about the problem and the agent's intentions. The main contribution of this work is to introduce techniques for representing and reasoning about states in model-free deep reinforcement learning agents via relational inductive biases. Our experiments show this approach can offer advantages in efficiency, generalization, and interpretability, and can scale up to meet some of the most challenging test environments in modern artificial intelligence.},
  file     = {:home/antonio/Downloads/deep_reinforcement_learning_wi.pdf:pdf},
  groups   = {RL},
}

@Article{Schlag2021,
  author        = {Schlag, Imanol and Irie, Kazuki and Schmidhuber, J{\"{u}}rgen},
  title         = {{Linear Transformers Are Secretly Fast Weight Programmers}},
  year          = {2021},
  abstract      = {We show the formal equivalence of linearised self-attention mechanisms and fast weight controllers from the early '90s, where a ``slow" neural net learns by gradient descent to program the ``fast weights" of another net through sequences of elementary programming instructions which are additive outer products of self-invented activation patterns (today called keys and values). Such Fast Weight Programmers (FWPs) learn to manipulate the contents of a finite memory and dynamically interact with it. We infer a memory capacity limitation of recent linearised softmax attention variants, and replace the purely additive outer products by a delta rule-like programming instruction, such that the FWP can more easily learn to correct the current mapping from keys to values. The FWP also learns to compute dynamically changing learning rates. We also propose a new kernel function to linearise attention which balances simplicity and effectiveness. We conduct experiments on synthetic retrieval problems as well as standard machine translation and language modelling tasks which demonstrate the benefits of our methods.},
  archiveprefix = {arXiv},
  arxivid       = {2102.11174},
  eprint        = {2102.11174},
  file          = {:home/antonio/Downloads/2102.11174.pdf:pdf},
  groups        = {Attention},
  url           = {http://arxiv.org/abs/2102.11174},
}

@Article{Venkataraman2021,
  author        = {Venkataraman, Shobha and Amos, Brandon},
  title         = {{Neural Fixed-Point Acceleration for Convex Optimization}},
  year          = {2021},
  abstract      = {Fixed-point iterations are at the heart of numerical computing and are often a computational bottleneck in real-time applications, which typically instead need a fast solution of moderate accuracy. Classical acceleration methods for fixed-point problems focus on designing algorithms with theoretical guarantees that apply to any fixed-point problem. We present neural fixed-point acceleration, a framework to automatically learn to accelerate convex fixed-point problems that are drawn from a distribution, using ideas from meta-learning and classical acceleration algorithms. We apply our framework to SCS, the state-of-the-art solver for convex cone programming, and design models and loss functions to overcome the challenges of learning over unrolled optimization and acceleration instabilities. Our work brings neural acceleration into any optimization problem expressible with CVXPY. The source code behind this paper is available at https://github.com/facebookresearch/neural-scs},
  archiveprefix = {arXiv},
  arxivid       = {2107.10254},
  eprint        = {2107.10254},
  file          = {:home/antonio/Downloads/venkataraman2021Neural_F_P_Acceleration_Convex_Optimization.pdf:pdf;:home/antonio/Documents/bibliography/files/Venkataraman, Amos - 2021 - Neural Fixed-Point Acceleration for Convex Optimization.pdf:pdf},
  groups        = {Acceleration},
  url           = {http://arxiv.org/abs/2107.10254},
}

@Article{Krieken2021,
  author        = {van Krieken, Emile and Tomczak, Jakub M. and ten Teije, Annette},
  title         = {{Storchastic: A Framework for General Stochastic Automatic Differentiation}},
  year          = {2021},
  abstract      = {Modelers use automatic differentiation of computation graphs to implement complex Deep Learning models without defining gradient computations. However, modelers often use sampling methods to estimate intractable expectations such as in Reinforcement Learning and Variational Inference. Current methods for estimating gradients through these sampling steps are limited: They are either only applicable to continuous random variables and differentiable functions, or can only use simple but high variance score-function estimators. To overcome these limitations, we introduce Storchastic, a new framework for automatic differentiation of stochastic computation graphs. Storchastic allows the modeler to choose from a wide variety of gradient estimation methods at each sampling step, to optimally reduce the variance of the gradient estimates. Furthermore, Storchastic is provably unbiased for estimation of any-order gradients, and generalizes variance reduction techniques to higher-order gradient estimates. Finally, we implement Storchastic as a PyTorch library.},
  archiveprefix = {arXiv},
  arxivid       = {2104.00428},
  eprint        = {2104.00428},
  file          = {:home/antonio/Downloads/2104.00428.pdf:pdf},
  groups        = {Differentiable programming and simulation},
  url           = {http://arxiv.org/abs/2104.00428},
}

@Article{Raffinot2008,
  author   = {Raffinot, Mathieu},
  journal  = {Society},
  title    = {{Waveholtz: Iterative solution of the helmholtz equation via the wave equation}},
  year     = {2008},
  number   = {3},
  pages    = {1022--1039},
  volume   = {22},
  file     = {:home/antonio/Documents/bibliography/files/Raffinot - 2008 - Waveholtz Iterative solution of the helmholtz equation via the wave equation.pdf:pdf},
  groups   = {Helmholtz},
  keywords = {05c05, 05c62, 060651331, 1, 10, 1137, 68r99, ams subject classifications, common interval, doi, interval was introduced by, introduction, modular decomposition, p q-tree, permutation, the notion of common, uno and},
}

@Article{Peng2021,
  author        = {Peng, Zhichao and Appel{\"{o}}, Daniel},
  title         = {{EM-WaveHoltz: A flexible frequency-domain method built from time-domain solvers}},
  year          = {2021},
  pages         = {1--13},
  abstract      = {A novel approach to computing time-harmonic solutions of Maxwell's equations by time-domain simulations is presented. The method, EM-WaveHoltz, results in a positive definite system of equations which makes it amenable to iterative solution with the conjugate gradient method or with GMRES. Theoretical results guaranteeing the convergence of the method away from resonances is presented. Numerical examples illustrating the properties of EM-WaveHoltz are given.},
  archiveprefix = {arXiv},
  arxivid       = {2103.14789},
  eprint        = {2103.14789},
  file          = {:home/antonio/Documents/bibliography/files/Peng, Appel{\"{o}} - 2021 - EM-WaveHoltz A flexible frequency-domain method built from time-domain solvers.pdf:pdf},
  groups        = {Helmholtz, Helmholtz and waves},
  url           = {http://arxiv.org/abs/2103.14789},
}

@Article{Arnold2021,
  author        = {Arnold, Anton and Geevers, Sjoerd and Perugia, Ilaria and Ponomarev, Dmitry},
  title         = {{An adaptive finite element method for high-frequency scattering problems with variable coefficients}},
  year          = {2021},
  pages         = {1--29},
  abstract      = {We introduce a new method for the numerical approximation of time-harmonic acoustic scattering problems stemming from material inhomogeneities. The method works for any frequency $\omega$, but is especially efficient for high-frequency problems. It is based on a time-domain approach and consists of three steps: \emph{i)} computation of a suitable incoming plane wavelet with compact support in the propagation direction; \emph{ii)} solving a scattering problem in the time domain for the incoming plane wavelet; \emph{iii)} reconstruction of the time-harmonic solution from the time-domain solution via a Fourier transform in time. An essential ingredient of the new method is a front-tracking mesh adaptation algorithm for solving the problem in \emph{ii)}. By exploiting the limited support of the wave front, this allows us to make the number of the required degrees of freedom to reach a given accuracy significantly less dependent on the frequency $\omega$, as shown in the numerical experiments. We also present a new algorithm for computing the Fourier transform in \emph{iii)} that exploits the reduced number of degrees of freedom corresponding to the adapted meshes.},
  archiveprefix = {arXiv},
  arxivid       = {2103.02511},
  eprint        = {2103.02511},
  file          = {:home/antonio/Documents/bibliography/files/Arnold et al. - 2021 - An adaptive finite element method for high-frequency scattering problems with variable coefficients.pdf:pdf},
  groups        = {Helmholtz, Helmholtz and waves},
  keywords      = {35l05, 65m50, 65m60, a, adaptive fem, and i, arnold, by the austrian science, front-tracking mesh, fund, fwf, geevers, helmholtz equation, limiting amplitude principle, mathematics subject classification 35j05, perugia have been funded, problem, s, scattering problem, time-domain wave, variable coefficients},
  url           = {http://arxiv.org/abs/2103.02511},
}

@Article{Jiao2021,
  author        = {Jiao, Yuling and Lai, Yanming and Lu, Xiliang and Yang, Zhijian},
  title         = {{Deep Neural Networks with ReLU-Sine-Exponential Activations Break Curse of Dimensionality on H\"older Class}},
  year          = {2021},
  month         = {feb},
  abstract      = {In this paper, we construct neural networks with ReLU, sine and $2^x$ as activation functions. For general continuous $f$ defined on $[0,1]^d$ with continuity modulus $\omega_f(\cdot)$, we construct ReLU-sine-$2^x$ networks that enjoy an approximation rate $\mathcal{O}(\omega_f(\sqrt{d})\cdot2^{-M}+\omega_{f}\left(\frac{\sqrt{d}}{N}\right))$, where $M,N\in \mathbb{N}^{+}$ denote the hyperparameters related to widths of the networks. As a consequence, we can construct ReLU-sine-$2^x$ network with the depth $5$ and width $\max\left\{\left\lceil2d^{3/2}\left(\frac{3\mu}{\epsilon}\right)^{1/{\alpha}}\right\rceil,2\left\lceil\log_2\frac{3\mu d^{\alpha/2}}{2\epsilon}\right\rceil+2\right\}$ that approximates $f\in \mathcal{H}_{\mu}^{\alpha}([0,1]^d)$ within a given tolerance $\epsilon >0$ measured in $L^p$ norm $p\in[1,\infty)$, where $\mathcal{H}_{\mu}^{\alpha}([0,1]^d)$ denotes the H\"older continuous function class defined on $[0,1]^d$ with order $\alpha \in (0,1]$ and constant $\mu > 0$. Therefore, the ReLU-sine-$2^x$ networks overcome the curse of dimensionality on $\mathcal{H}_{\mu}^{\alpha}([0,1]^d)$. In addition to its supper expressive power, functions implemented by ReLU-sine-$2^x$ networks are (generalized) differentiable, enabling us to apply SGD to train.},
  archiveprefix = {arXiv},
  arxivid       = {2103.00542},
  eprint        = {2103.00542},
  file          = {:home/antonio/Documents/bibliography/files/Jiao et al. - 2021 - Deep Neural Networks with ReLU-Sine-Exponential Activations Break Curse of Dimensionality on Holder Class.pdf:pdf},
  groups        = {Representation, architectures and DL layers},
  url           = {http://arxiv.org/abs/2103.00542},
}

@TechReport{Kothari,
  author   = {Kothari, Konik and {De Hoop}, Maarten and Dokmani´cdokmani´c, Ivan},
  title    = {{Learning the Geometry of Wave-Based Imaging}},
  abstract = {We propose a general physics-based deep learning architecture for wave-based imaging problems. A key difficulty in imaging problems with a varying background wave speed is that the medium "bends" the waves differently depending on their position and direction. This space-bending geometry makes the equivariance to translations of convolutional networks an undesired inductive bias. We build an interpretable neural architecture inspired by Fourier integral operators (FIOs) which approximate the wave physics. FIOs model a wide range of imaging modalities, from seismology and radar to Doppler and ultrasound. We focus on learning the geometry of wave propagation captured by FIOs, which is implicit in the data, via a loss based on optimal transport. The proposed FIONet performs significantly better than the usual baselines on a number of imaging inverse problems, especially in out-of-distribution tests.},
  file     = {:home/antonio/Documents/bibliography/files/Kothari, De Hoop, Dokmani´cdokmani´c - Unknown - Learning the Geometry of Wave-Based Imaging.pdf:pdf},
  groups   = {Ultrasound and wave imaging},
}

@Article{Kim2019,
  author    = {Kim, Dojin},
  journal   = {Symmetry},
  title     = {{A modified PML acoustic wave equation}},
  year      = {2019},
  issn      = {20738994},
  month     = {feb},
  number    = {2},
  volume    = {11},
  abstract  = {In this paper, we consider a two-dimensional acoustic wave equation in an unbounded domain and introduce a modified model of the classical un-split perfectly matched layer (PML). We apply a regularization technique to a lower order regularity term employed in the auxiliary variable in the classical PML model. In addition, we propose a staggered finite difference method for discretizing the regularized system. The regularized system and numerical solution are analyzed in terms of the well-posedness and stability with the standard Galerkin method and von Neumann stability analysis, respectively. In particular, the existence and uniqueness of the solution for the regularized system are proved and the Courant-Friedrichs-Lewy (CFL) condition of the staggered finite difference method is determined. To support the theoretical results, we demonstrate a non-reflection property of acoustic waves in the layers.},
  doi       = {10.3390/sym11020177},
  file      = {:home/antonio/Documents/bibliography/files/Kim - 2019 - A modified PML acoustic wave equation.pdf:pdf},
  groups    = {Ultrasound and wave physics},
  keywords  = {Acoustic wave equation, Perfectly matched layer, Stability, Well-posedness},
  publisher = {MDPI AG},
}

@TechReport{Druskin,
  author   = {Druskin, Vladimir and Knizhnerman, Leonid},
  title    = {{On the Continuum Limit of a Discrete Inverse Spectral Problem on Optimal Finite Difference Grids}},
  abstract = {We consider finite difference approximations of solutions of inverse Sturm-Liou-ville problems in bounded intervals. Using three-point finite difference schemes, we discretize the equations on so-called optimal grids constructed as follows: For a staggered grid with 2k points, we ask that the finite difference operator (a k × k Jacobi matrix) and the Sturm-Liouville differential operator share the k lowest eigenvalues and the values of the orthonormal eigenfunctions at one end of the interval. This requirement determines uniquely the entries in the Jacobi matrix, which are grid cell averages of the coefficients in the continuum problem. If these coefficients are known, we can find the grid, which we call optimal because it gives, by design, a finite difference operator with a prescribed spectral measure. We focus attention on the inverse problem, where neither the coefficients nor the grid are known. A key question in inversion is how to parametrize the coefficients, i.e., how to choose the grid. It is clear that, to be successful, this grid must be close to the optimal one, which is unknown. Fortunately, as we show here, the grid dependence on the unknown coefficients is weak, so the inversion can be done on a precom-puted grid for an a priori guess of the unknown coefficients. This observation leads to a simple yet efficient inversion algorithm, which gives coefficients that converge pointwise to the true solution as the number k of data points tends to infinity. The cornerstone of our convergence proof is showing that optimal grids provide an implicit, natural regularization of the inverse problem, by giving reconstructions with uniformly bounded total variation. The analysis is based on a novel, explicit perturbation analysis of Lanczos recursions and on a discrete Gel fand-Levitan formulation.},
  file     = {:home/antonio/Documents/bibliography/files/Druskin, Knizhnerman - Unknown - On the Continuum Limit of a Discrete Inverse Spectral Problem on Optimal Finite Difference Grids.pdf:pdf},
  groups   = {Numerical computing},
}

@Article{Mehta2021,
  author        = {Mehta, Ishit and Gharbi, Micha{\"{e}}l and Barnes, Connelly and Shechtman, Eli and Ramamoorthi, Ravi and Chandraker, Manmohan},
  title         = {{Modulated Periodic Activations for Generalizable Local Functional Representations}},
  year          = {2021},
  month         = {apr},
  abstract      = {Multi-Layer Perceptrons (MLPs) make powerful functional representations for sampling and reconstruction problems involving low-dimensional signals like images,shapes and light fields. Recent works have significantly improved their ability to represent high-frequency content by using periodic activations or positional encodings. This often came at the expense of generalization: modern methods are typically optimized for a single signal. We present a new representation that generalizes to multiple instances and achieves state-of-the-art fidelity. We use a dual-MLP architecture to encode the signals. A synthesis network creates a functional mapping from a low-dimensional input (e.g. pixel-position) to the output domain (e.g. RGB color). A modulation network maps a latent code corresponding to the target signal to parameters that modulate the periodic activations of the synthesis network. We also propose a local-functional representation which enables generalization. The signal's domain is partitioned into a regular grid,with each tile represented by a latent code. At test time, the signal is encoded with high-fidelity by inferring (or directly optimizing) the latent code-book. Our approach produces generalizable functional representations of images, videos and shapes, and achieves higher reconstruction quality than prior works that are optimized for a single signal.},
  archiveprefix = {arXiv},
  arxivid       = {2104.03960},
  eprint        = {2104.03960},
  file          = {:home/antonio/Documents/bibliography/files/Mehta et al. - 2021 - Modulated Periodic Activations for Generalizable Local Functional Representations.pdf:pdf},
  groups        = {Representation, architectures and DL layers},
  url           = {http://arxiv.org/abs/2104.03960},
}

@Article{Finn2017,
  author        = {Finn, Chelsea and Abbeel, Pieter and Levine, Sergey},
  title         = {{Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks}},
  year          = {2017},
  month         = {mar},
  abstract      = {We propose an algorithm for meta-learning that is model-agnostic, in the sense that it is compatible with any model trained with gradient descent and applicable to a variety of different learning problems, including classification, regression, and reinforcement learning. The goal of meta-learning is to train a model on a variety of learning tasks, such that it can solve new learning tasks using only a small number of training samples. In our approach, the parameters of the model are explicitly trained such that a small number of gradient steps with a small amount of training data from a new task will produce good generalization performance on that task. In effect, our method trains the model to be easy to fine-tune. We demonstrate that this approach leads to state-of-the-art performance on two few-shot image classification benchmarks, produces good results on few-shot regression, and accelerates fine-tuning for policy gradient reinforcement learning with neural network policies.},
  archiveprefix = {arXiv},
  arxivid       = {1703.03400},
  eprint        = {1703.03400},
  file          = {:home/antonio/Documents/bibliography/files/Finn, Abbeel, Levine - 2017 - Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks.pdf:pdf},
  groups        = {Implicit- and Meta- learning},
  url           = {http://arxiv.org/abs/1703.03400},
}

@Article{Taus2020,
  author        = {Taus, Matthias and Zepeda-N{\'{u}}{\~{n}}ez, Leonardo and Hewett, Russell J. and Demanet, Laurent},
  journal       = {Journal of Computational Physics},
  title         = {{L-Sweeps: A scalable, parallel preconditioner for the high-frequency Helmholtz equation}},
  year          = {2020},
  issn          = {10902716},
  number        = {1},
  pages         = {1--49},
  volume        = {420},
  abstract      = {We present the first fast solver for the high-frequency Helmholtz equation that scales optimally in parallel for a single right-hand side. The L-sweeps approach achieves this scalability by departing from the usual propagation pattern, in which information flows in a 180∘ degree cone from interfaces in a layered decomposition. Instead, with L-sweeps, information propagates in 90∘ cones induced by a Cartesian domain decomposition (CDD). We extend the notion of accurate transmission conditions to CDDs and introduce a new sweeping strategy to efficiently track the wave fronts as they propagate through the CDD. The new approach decouples the subdomains at each wave front, so that they can be processed in parallel, resulting in better parallel scalability than previously demonstrated in the literature. The method has an overall O((N/p)log⁡$\omega$) empirical run-time for N=nd total degrees-of-freedom in a d-dimensional problem, frequency $\omega$, and p=O(n) processors. We introduce the algorithm and provide a complexity analysis for our parallel implementation of the solver. We corroborate all claims in several two- and three-dimensional numerical examples involving constant, smooth, and discontinuous wave speeds.},
  archiveprefix = {arXiv},
  arxivid       = {1909.01467},
  doi           = {10.1016/j.jcp.2020.109706},
  eprint        = {1909.01467},
  file          = {:home/antonio/Documents/bibliography/files/Taus et al. - 2020 - L-Sweeps A scalable, parallel preconditioner for the high-frequency Helmholtz equation.pdf:pdf},
  groups        = {Helmholtz},
  keywords      = {Fast high-frequency solvers, Helmholtz equation, High performance computing, Wave propagation},
}

@Article{Osnabrugge2016,
  author        = {Osnabrugge, Gerwin and Leedumrongwatthanakun, Saroch and Vellekoop, Ivo M.},
  journal       = {Journal of Computational Physics},
  title         = {{A convergent Born series for solving the inhomogeneous Helmholtz equation in arbitrarily large media}},
  year          = {2016},
  issn          = {10902716},
  pages         = {113--124},
  volume        = {322},
  abstract      = {We present a fast method for numerically solving the inhomogeneous Helmholtz equation. Our iterative method is based on the Born series, which we modified to achieve convergence for scattering media of arbitrary size and scattering strength. Compared to pseudospectral time-domain simulations, our modified Born approach is two orders of magnitude faster and nine orders of magnitude more accurate in benchmark tests in 1, 2, and 3-dimensional systems.},
  archiveprefix = {arXiv},
  arxivid       = {1601.05997},
  doi           = {10.1016/j.jcp.2016.06.034},
  eprint        = {1601.05997},
  file          = {:home/antonio/Documents/bibliography/files/Osnabrugge, Leedumrongwatthanakun, Vellekoop - 2016 - A convergent Born series for solving the inhomogeneous Helmholtz equation in arbit.pdf:pdf},
  groups        = {Helmholtz},
  keywords      = {Born series, Helmholtz equation, Inhomogeneous medium, Pseudospectral time-domain method, Time-independent Schr{\"{o}}dinger equation},
  publisher     = {Elsevier Inc.},
  url           = {http://dx.doi.org/10.1016/j.jcp.2016.06.034},
}

@Article{Oktay2020,
  author        = {Oktay, Deniz and McGreivy, Nick and Aduol, Joshua and Beatson, Alex and Adams, Ryan P.},
  journal       = {arXiv},
  title         = {{Randomized Automatic Differentiation}},
  year          = {2020},
  issn          = {23318422},
  pages         = {1--19},
  abstract      = {The successes of deep learning, variational inference, and many other fields have been aided by specialized implementations of reverse-mode automatic differentiation (AD) to compute gradients of mega-dimensional objectives. The AD techniques underlying these tools were designed to compute exact gradients to numerical precision, but modern machine learning models are almost always trained with stochastic gradient descent. Why spend computation and memory on exact (minibatch) gradients only to use them for stochastic optimization? We develop a general framework and approach for randomized automatic differentiation (RAD), which allows unbiased gradient estimates to be computed with reduced memory in return for variance. We examine limitations of the general approach, and argue that we must leverage problem specific structure to realize benefits. We develop RAD techniques for a variety of simple neural network architectures, and show that for a fixed memory budget, RAD converges in fewer iterations than using a small batch size for feedforward networks, and in a similar number for recurrent networks. We also show that RAD can be applied to scientific computing, and use it to develop a low-memory stochastic gradient method for optimizing the control parameters of a linear reaction-diffusion PDE representing a fission reactor.},
  archiveprefix = {arXiv},
  arxivid       = {2007.10412},
  eprint        = {2007.10412},
  file          = {:home/antonio/Documents/bibliography/files/Oktay et al. - 2020 - Randomized Automatic Differentiation.pdf:pdf;:home/antonio/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Oktay et al. - 2021 - Randomized automatic differentiation.pdf:pdf},
  groups        = {Differentiable programming and simulation},
}

@Article{rusch2020coupled,
  author  = {Rusch, T Konstantin and Mishra, Siddhartha},
  journal = {arXiv preprint arXiv:2010.00951},
  title   = {Coupled Oscillatory Recurrent Neural Network (coRNN): An accurate and (gradient) stable architecture for learning long time dependencies},
  year    = {2020},
  groups  = {Representation, architectures and DL layers},
}

@Article{Dieleman2021,
  author        = {Dieleman, Sander and Nash, Charlie and Engel, Jesse and Simonyan, Karen},
  title         = {{Variable-rate discrete representation learning}},
  year          = {2021},
  abstract      = {Semantically meaningful information content in perceptual signals is usually unevenly distributed. In speech signals for example, there are often many silences, and the speed of pronunciation can vary considerably. In this work, we propose slow autoencoders (SlowAEs) for unsupervised learning of high-level variable-rate discrete representations of sequences, and apply them to speech. We show that the resulting event-based representations automatically grow or shrink depending on the density of salient information in the input signals, while still allowing for faithful signal reconstruction. We develop run-length Transformers (RLTs) for event-based representation modelling and use them to construct language models in the speech domain, which are able to generate grammatical and semantically coherent utterances and continuations.},
  archiveprefix = {arXiv},
  arxivid       = {2103.06089},
  eprint        = {2103.06089},
  file          = {:home/antonio/Documents/bibliography/files/Dieleman et al. - 2021 - Variable-rate discrete representation learning.pdf:pdf},
  groups        = {Representation, architectures and DL layers},
  url           = {http://arxiv.org/abs/2103.06089},
}

@Misc{oh2021boil,
  author        = {Jaehoon Oh and Hyungjun Yoo and ChangHwan Kim and Se-Young Yun},
  title         = {BOIL: Towards Representation Change for Few-shot Learning},
  year          = {2021},
  archiveprefix = {arXiv},
  eprint        = {2008.08882},
  groups        = {Implicit- and Meta- learning},
  primaryclass  = {cs.LG},
}

@Misc{kong2021diffwave,
  author        = {Zhifeng Kong and Wei Ping and Jiaji Huang and Kexin Zhao and Bryan Catanzaro},
  title         = {DiffWave: A Versatile Diffusion Model for Audio Synthesis},
  year          = {2021},
  archiveprefix = {arXiv},
  eprint        = {2009.09761},
  groups        = {Diffusion},
  primaryclass  = {eess.AS},
}

@Misc{petersen2021deep,
  author        = {Brenden K. Petersen and Mikel Landajuela Larma and T. Nathan Mundhenk and Claudio P. Santiago and Soo K. Kim and Joanne T. Kim},
  title         = {Deep symbolic regression: Recovering mathematical expressions from data via risk-seeking policy gradients},
  year          = {2021},
  archiveprefix = {arXiv},
  eprint        = {1912.04871},
  groups        = {General deep learning},
  primaryclass  = {cs.LG},
}

@Article{Bronstein2017,
  author        = {Bronstein, Michael M. and Bruna, Joan and Lecun, Yann and Szlam, Arthur and Vandergheynst, Pierre and May, C V},
  journal       = {IEEE Signal Processing Magazine},
  title         = {{Geometric Deep Learning: Going beyond Euclidean data}},
  year          = {2017},
  issn          = {10535888},
  number        = {4},
  pages         = {18--42},
  volume        = {34},
  abstract      = {Many scientific fields study data with an underlying structure that is non-Euclidean. Some examples include social networks in computational social sciences, sensor networks in communications, functional networks in brain imaging, regulatory networks in genetics, and meshed surfaces in computer graphics. In many applications, such geometric data are large and complex (in the case of social networks, on the scale of billions) and are natural targets for machine-learning techniques. In particular, we would like to use deep neural networks, which have recently proven to be powerful tools for a broad range of problems from computer vision, natural-language processing, and audio analysis. However, these tools have been most successful on data with an underlying Euclidean or grid-like structure and in cases where the invariances of these structures are built into networks used to model them.},
  archiveprefix = {arXiv},
  arxivid       = {1611.08097},
  doi           = {10.1109/MSP.2017.2693418},
  eprint        = {1611.08097},
  file          = {:home/antonio/Documents/bibliography/files/Bronstein et al. - Unknown - Geometric deep learning going beyond Euclidean data.pdf:pdf;:home/antonio/Documents/bibliography/files/Bronstein et al. - 2017 - Geometric Deep Learning Going beyond Euclidean data.pdf:pdf},
  groups        = {Equivariant etc},
  publisher     = {IEEE},
}

@Article{appelo2020waveholtz,
  author    = {Appelo, Daniel and Garcia, Fortino and Runborg, Olof},
  journal   = {SIAM Journal on Scientific Computing},
  title     = {WaveHoltz: iterative solution of the Helmholtz equation via the wave equation},
  year      = {2020},
  number    = {4},
  pages     = {A1950--A1983},
  volume    = {42},
  groups    = {Helmholtz and wave algorithms},
  publisher = {SIAM},
}

@Article{Beatson2001,
  author   = {Beatson, Rick and Greengard, Leslie},
  journal  = {New York University},
  title    = {{A short course on fast multipole methods}},
  year     = {2001},
  pages    = {1--37},
  abstract = {In this series of lectures, we describe the analytic and computational foundations of fast multipole methods, as well as some of their applications. They are most easily understood, perhaps, in the case of particle simulations, where they reduce the cost of computing all pairwise interactions in a system of N particles from O(N 2)toO(N)orO(N log N) operations. They are equally useful, however, in solving certain partial differential equations by first recasting them as integral equations. We will draw heavily from the existing literature, especially Greengard, Greengard and Rokhlin, Greengard and Strain.},
  file     = {:home/antonio/Documents/bibliography/files/Beatson, Greengard - 2001 - A short course on fast multipole methods.pdf:pdf},
  groups   = {Numerical computing},
  url      = {papers2://publication/uuid/97D12A32-D158-4ECD-A01F-5E78522490BD},
}

@Article{Ying2015,
  author   = {Ying, Lexing},
  journal  = {Multiscale Modeling and Simulation},
  title    = {{Sparsifying preconditioner for pseudospectral approximations of indefinite systems on periodic structures}},
  year     = {2015},
  issn     = {15403467},
  number   = {2},
  pages    = {459--471},
  volume   = {13},
  abstract = {This paper introduces the sparsifying preconditioner for the pseudospectral approximation of highly indefinite systems on periodic structures, which include the frequency-domain response problems of the Helmholtz equation and the Schrodinger equation as examples. This approach transforms the dense system of the pseudospectral discretization approximately into a sparse system via an equivalent integral reformulation and a specially designed sparsifying operator. The resulting sparse system is then solved efficiently with sparse linear algebra algorithms and serves as a reasonably accurate preconditioner. When combined with standard iterative methods, this new preconditioner results in small iteration counts. Numerical results are provided for the Helmholtz equation and the Schrodinger in both two and three dimensions to demonstrate the effectiveness of this new preconditioner.},
  doi      = {10.1137/140985159},
  file     = {:home/antonio/Documents/bibliography/files/Ying - 2015 - Sparsifying preconditioner for pseudospectral approximations of indefinite systems on periodic structures.pdf:pdf},
  groups   = {Acceleration},
  keywords = {Helmholtz equation, Indefinite matrix, Periodic structure, Preconditioner, Pseudospectral approximation, Schr{\"{o}}dinger equation, Sparse linear algebra},
}

@Article{Ibeid2016,
  author        = {Ibeid, Huda and Yokota, Rio and Keyes, David},
  title         = {{A Matrix-free Preconditioner for the Helmholtz Equation based on the Fast Multipole Method}},
  year          = {2016},
  pages         = {1--29},
  abstract      = {Fast multipole methods (FMM) were originally developed for accelerating $N$-body problems for particle-based methods. FMM is more than an $N$-body solver, however. Recent efforts to view the FMM as an elliptic Partial Differential Equation (PDE) solver have opened the possibility to use it as a preconditioner for a broader range of applications. FMM can solve Helmholtz problems with optimal $\mathcal{O}(N \log N)$ complexity, has compute-bound inner kernels, and highly asynchronous communication patterns. The combination of these features makes FMM an interesting candidate as a preconditioner for sparse solvers on architectures of the future. The use of FMM as a preconditioner allows us to use lower order multipole expansions than would be required as a solver because individual solves need not be accurate. This reduces the amount of computation and communication significantly and makes the time-to-solution competitive with state-of-the-art preconditioners. Furthermore, the high asynchronicity of FMM allows it to scale to much larger core counts than factorization-based and multilevel methods. We describe our tests in reproducible details with freely available codes.},
  archiveprefix = {arXiv},
  arxivid       = {1608.02461},
  eprint        = {1608.02461},
  file          = {:home/antonio/Documents/bibliography/files/Ibeid, Yokota, Keyes - 2016 - A Matrix-free Preconditioner for the Helmholtz Equation based on the Fast Multipole Method.pdf:pdf},
  groups        = {Helmholtz and wave algorithms, Acceleration},
  keywords      = {fast multipole method, helmholtz equation, preconditioning},
  url           = {http://arxiv.org/abs/1608.02461},
}

@Article{Yashchuk2020,
  author   = {Yashchuk, Ivan},
  title    = {{Bringing PDEs to Jax With Forward and Reverse Modes Automatic Differentiation}},
  year     = {2020},
  pages    = {1--6},
  abstract = {Partial differential equations (PDEs) are used to describe a variety of physical phenomena. Often these equations do not have analytical solutions and numerical approximations are used instead. One of the common methods to solve PDEs is the finite element method. Computing derivative information of the solution with respect to the input parameters is important in many tasks in scientific computing. We extend JAX automatic differentiation library with an interface to Fire-drake finite element library. High-level symbolic representation of PDEs allows bypassing differentiating through low-level possibly many iterations of the underlying nonlinear solvers. Differentiating through Firedrake solvers is done using tangent-linear and adjoint equations. This enables the efficient composition of finite element solvers with arbitrary differentiable programs. The code is available at github.com/IvanYashchuk/jax-firedrake.},
  file     = {:home/antonio/Documents/bibliography/files/Yashchuk - 2020 - Bringing PDEs to Jax With Forward and Reverse Modes Automatic Differentiation.pdf:pdf},
  groups   = {Differentiable programming and simulation},
  language = {en},
}

@Article{Tan2019,
  author   = {Tan, Mingxing and Le, Quoc V.},
  journal  = {arXiv},
  title    = {{EfficientNet: Rethinking model scaling for convolutional neural networks}},
  year     = {2019},
  issn     = {23318422},
  abstract = {Convolutional Neural Networks (ConvNets) are commonly developed at a fixed resource budget, and then scaled up for better accuracy if more resources are available. In this paper, we systematically study model scaling and identify that carefully balancing network depth, width, and resolution can lead to better performance. Based on this observation, we propose a new scaling method that uniformly scales all dimensions of depth/width/resolution using a simple yet highly effective compound coefficient. We demonstrate the effectiveness of this method on scaling up MobileNets and ResNet. To go even further, we use neural architecture search to design a new baseline network and scale it up to obtain a family of models, called EfficientNets, which achieve much better accuracy and efficiency than previous ConvNets. In particular, our EfficientNet-B7 achieves state-of-the-art 84.4% top-1 / 97.1% top-5 accuracy on ImageNet, while being 8.4x smaller and 6.1x faster on inference than the best existing ConvNet. Our EfficientNets also transfer well and achieve state-of-the-art accuracy on CIFAR-100 (91.7%), Flowers (98.8%), and 3 other transfer learning datasets, with an order of magnitude fewer parameters. Source code is at https://github.com/tensorflow/tpu/tree/ master/models/official/efficientnet.},
  file     = {:home/antonio/Documents/bibliography/files/Tan, Le - 2019 - EfficientNet Rethinking model scaling for convolutional neural networks.pdf:pdf},
  groups   = {Representation, architectures and DL layers},
}

@Article{Ulyanov2020,
  author        = {Ulyanov, Dmitry and Vedaldi, Andrea and Lempitsky, Victor},
  journal       = {International Journal of Computer Vision},
  title         = {{Deep Image Prior}},
  year          = {2020},
  issn          = {15731405},
  month         = {nov},
  number        = {7},
  pages         = {1867--1888},
  volume        = {128},
  abstract      = {Deep convolutional networks have become a popular tool for image generation and restoration. Generally, their excellent performance is imputed to their ability to learn realistic image priors from a large number of example images. In this paper, we show that, on the contrary, the structure of a generator network is sufficient to capture a great deal of low-level image statistics prior to any learning. In order to do so, we show that a randomly-initialized neural network can be used as a handcrafted prior with excellent results in standard inverse problems such as denoising, super-resolution, and inpainting. Furthermore, the same prior can be used to invert deep neural representations to diagnose them, and to restore images based on flash-no flash input pairs. Apart from its diverse applications, our approach highlights the inductive bias captured by standard generator network architectures. It also bridges the gap between two very popular families of image restoration methods: learning-based methods using deep convolutional networks and learning-free methods based on handcrafted image priors such as self-similarity (Code and supplementary material are available at https://dmitryulyanov.github.io/deep_image_prior).},
  archiveprefix = {arXiv},
  arxivid       = {1711.10925},
  doi           = {10.1007/s11263-020-01303-4},
  eprint        = {1711.10925},
  file          = {:home/antonio/Documents/bibliography/files/Ulyanov, Vedaldi, Lempitsky - 2020 - Deep Image Prior.pdf:pdf},
  groups        = {General deep learning},
  keywords      = {Computer Science - Computer Vision and Pattern Rec, Convolutional networks, Generative deep networks, Image denoising, Image restoration, Image superresolution, Inverse problems, Natural image prior, Statistics - Machine Learning},
  language      = {en},
  mendeley-tags = {Computer Science - Computer Vision and Pattern Rec,Statistics - Machine Learning},
  url           = {http://arxiv.org/abs/1711.10925},
}

@Article{Waheed2021,
  author        = {bin Waheed, Umair and Alkhalifah, Tariq and Haghighat, Ehsan and Song, Chao and Virieux, Jean},
  title         = {{PINNtomo: Seismic tomography using physics-informed neural networks}},
  year          = {2021},
  pages         = {1--9},
  abstract      = {Seismic traveltime tomography using transmission data is widely used to image the Earth's interior from global to local scales. In seismic imaging, it is used to obtain velocity models for subsequent depth-migration or full-waveform inversion. In addition, cross-hole tomography has been successfully applied for a variety of applications, including mineral exploration, reservoir monitoring, and CO2 injection and sequestration. Conventional tomography techniques suffer from a number of limitations, including the use of a smoothing regularizer that is agnostic to the physics of wave propagation. Here, we propose a novel tomography method to address these challenges using developments in the field of scientific machine learning. Using seismic traveltimes observed at seismic stations covering part of the computational model, we train neural networks to approximate the traveltime factor and the velocity fields, subject to the physics-informed regularizer formed by the factored eikonal equation. This allows us to better compensate for the ill-posedness of the tomography problem compared to conventional methods and results in a number of other attractive features, including computational efficiency. We show the efficacy of the proposed method and its capabilities through synthetic tests for surface seismic and cross-hole geometries. Contrary to conventional techniques, we find the performance of the proposed method to be agnostic to the choice of the initial velocity model.},
  archiveprefix = {arXiv},
  arxivid       = {2104.01588},
  eprint        = {2104.01588},
  file          = {:home/antonio/Documents/bibliography/files/Waheed et al. - 2021 - PINNtomo Seismic tomography using physics-informed neural networks.pdf:pdf},
  groups        = {Helmholtz and waves},
  url           = {http://arxiv.org/abs/2104.01588},
}

@Article{Choi2017,
  author   = {Choi, Yunjey and Choi, Minje and Kim, Munyoung and Ha, Jung Woo and Kim, Sunghun and Choo, Jaegul},
  journal  = {arXiv},
  title    = {{StarGAN: Unified generative adversarial networks for multi-domain image-to-image translation}},
  year     = {2017},
  issn     = {23318422},
  abstract = {Recent studies have shown remarkable success in image-to-image translation for two domains. However, existing approaches have limited scalability and robustness in han-dling more than two domains, since different models should be built independently for every pair of image domains. To address this limitation, we propose StarGAN, a novel and scalable approach that can perform image-to-image trans-lations for multiple domains using only a single model. Such a unified model architecture of StarGAN allows simul-taneous training of multiple datasets with different domains within a single network. This leads to StarGAN's superior quality of translated images compared to existing models as well as the novel capability of flexibly translating an input image to any desired target domain. We empirically demon-strate the effectiveness of our approach on a facial attribute transfer and a facial expression synthesis tasks.},
  file     = {:home/antonio/Documents/bibliography/files/Choi et al. - 2017 - StarGAN Unified generative adversarial networks for multi-domain image-to-image translation.pdf:pdf},
  groups   = {GANs},
}

@Article{Li2021b,
  author        = {Li, Bei and Du, Quan and Zhou, Tao and Zhou, Shuhan and Zeng, Xin and Xiao, Tong and Zhu, Jingbo},
  title         = {{ODE Transformer: An Ordinary Differential Equation-Inspired Model for Neural Machine Translation}},
  year          = {2021},
  abstract      = {It has been found that residual networks are an Euler discretization of solutions to Ordinary Differential Equations (ODEs). In this paper, we explore a deeper relationship between Transformer and numerical methods of ODEs. We show that a residual block of layers in Transformer can be described as a higher-order solution to ODEs. This leads us to design a new architecture (call it ODE Transformer) analogous to the Runge-Kutta method that is well motivated in ODEs. As a natural extension to Transformer, ODE Transformer is easy to implement and parameter efficient. Our experiments on three WMT tasks demonstrate the genericity of this model, and large improvements in performance over several strong baselines. It achieves 30.76 and 44.11 BLEU scores on the WMT'14 En-De and En-Fr test data. This sets a new state-of-the-art on the WMT'14 En-Fr task.},
  archiveprefix = {arXiv},
  arxivid       = {2104.02308},
  eprint        = {2104.02308},
  file          = {:home/antonio/Documents/bibliography/files/Li et al. - 2021 - ODE Transformer An Ordinary Differential Equation-Inspired Model for Neural Machine Translation.pdf:pdf},
  groups        = {Normalizing flows},
  url           = {http://arxiv.org/abs/2104.02308},
}

@article{Joyce2018,
abstract = {In this paper we demonstrate that through the use of adversarial training and additional unsupervised costs it is possible to train a multi-class anatomical segmen-tation algorithm without any ground-truth labels for the data set to be segmented. Specifically, using labels from a different data set of the same anatomy (although potentially in a different modality) we train a model to synthesise realistic multi-channel label masks from input cardiac images in both CT and MRI, through adversarial learning. However, as is to be expected, generating realistic mask images is not, on its own, sufficient for the segmentation task: the model can use the input image as a source of noise and synthesise highly realistic segmenta-tion masks that do no necessarily correspond spatially to the input. To overcome this, we introduce additional unsupervised costs, and demonstrate that these provide sufficient further guidance to produce good segmentation results. We test our proposed method on both CT and MR data from the multi-modal whole heart segmentation challenge (MM-WHS) [1], and show the effect of our unsupervised costs on improving the segmentation results, in comparison to a variant without them.},
author = {Joyce, Thomas and Chartsias, Agisilaos and Tsaftaris, Sotirios A},
file = {:home/antonio/Documents/bibliography/files/Joyce, Chartsias, Tsaftaris - 2018 - 2018 - Deep Multi-Class Segmentation Without Ground-Truth Labels.pdf:pdf},
number = {Midl},
pages = {1--9},
title = {{2018 - Deep Multi-Class Segmentation Without Ground-Truth Labels}},
year = {2018}
}

@Article{Buchholz2021,
  author        = {Buchholz, Tim-Oliver and Jug, Florian},
  title         = {{Fourier Image Transformer}},
  year          = {2021},
  pages         = {1--8},
  abstract      = {Transformer architectures show spectacular performance on NLP tasks and have recently also been used for tasks such as image completion or image classification. Here we propose to use a sequential image representation, where each prefix of the complete sequence describes the whole image at reduced resolution. Using such Fourier Domain Encodings (FDEs), an auto-regressive image completion task is equivalent to predicting a higher resolution output given a low-resolution input. Additionally, we show that an encoder-decoder setup can be used to query arbitrary Fourier coefficients given a set of Fourier domain observations. We demonstrate the practicality of this approach in the context of computed tomography (CT) image reconstruction. In summary, we show that Fourier Image Transformer (FIT) can be used to solve relevant image analysis tasks in Fourier space, a domain inherently inaccessible to convolutional architectures.},
  archiveprefix = {arXiv},
  arxivid       = {2104.02555},
  eprint        = {2104.02555},
  file          = {:home/antonio/Documents/bibliography/files/Buchholz, Jug - 2021 - Fourier Image Transformer.pdf:pdf},
  groups        = {Attention},
  url           = {http://arxiv.org/abs/2104.02555},
}

@Article{Max”Jiang2020,
  author   = {Max”Jiang, Chiyu and Sud, Avneesh and Makadia, Ameesh and Huang, Jingwei and Nie{\ss}ner, Matthias and Funkhouser, Thomas},
  journal  = {arXiv},
  title    = {{Local implicit grid representations for 3D scenes}},
  year     = {2020},
  issn     = {23318422},
  abstract = {Shape priors learned from data are commonly used to reconstruct 3D objects from partial or noisy data. Yet no such shape priors are available for indoor scenes, since typical 3D autoencoders cannot handle their scale, complexity, or diversity. In this paper, we introduce Local Implicit Grid Representations, a new 3D shape representation designed for scalability and generality. The motivating idea is that most 3D surfaces share geometric details at some scale – i.e., at a scale smaller than an entire object and larger than a small patch. We train an autoencoder to learn an embedding of local crops of 3D shapes at that size. Then, we use the decoder as a component in a shape optimization that solves for a set of latent codes on a regular grid of overlapping crops such that an interpolation of the decoded local shapes matches a partial or noisy observation. We demonstrate the value of this proposed approach for 3D surface reconstruction from sparse point observations, showing significantly better results than alternative approaches.},
  file     = {:home/antonio/Documents/bibliography/files/Max”Jiang et al. - 2020 - Local implicit grid representations for 3D scenes.pdf:pdf},
  groups   = {Implicit- and Meta- learning},
}

@Article{Beknazaryan2021,
  author        = {Beknazaryan, Aleksandr},
  title         = {{Deep neural network approximation of analytic functions}},
  year          = {2021},
  pages         = {1--14},
  abstract      = {We provide an entropy bound for the spaces of neural networks with piecewise linear activation functions, such as the ReLU and the absolute value functions. This bound generalizes the known entropy bound for the space of linear functions on $\mathbb{R}^d$ and it depends on the value at the point $(1,1,...,1)$ of the networks obtained by taking the absolute values of all parameters of original networks. Keeping this value together with the depth, width and the parameters of the networks to have logarithmic dependence on $1/\varepsilon$, we $\varepsilon$-approximate functions that are analytic on certain regions of $\mathbb{C}^d$. As a statistical application we derive an oracle inequality for the expected error of the considered penalized deep neural network estimators.},
  archiveprefix = {arXiv},
  arxivid       = {2104.02095},
  eprint        = {2104.02095},
  file          = {:home/antonio/Documents/bibliography/files/Beknazaryan - 2021 - Deep neural network approximation of analytic functions.pdf:pdf},
  groups        = {Representation, architectures and DL layers},
  keywords      = {analytic functions, approximation theory, entropy estimation, neural networks, prediction guarantees},
  url           = {http://arxiv.org/abs/2104.02095},
}

@Article{Holl2020,
  author        = {Holl, Philipp and Koltun, Vladlen and Thuerey, Nils},
  journal       = {arXiv},
  title         = {{Learning To Control Pdes With Differentiable Physics}},
  year          = {2020},
  issn          = {23318422},
  number        = {NeurIPS},
  pages         = {1--5},
  abstract      = {Predicting outcomes and planning interactions with the physical world are longstanding goals for machine learning. A variety of such tasks involves continuous physical systems, which can be described by partial differential equations (PDEs) with many degrees of freedom. Existing methods that aim to control the dynamics of such systems are typically limited to relatively short time frames or a small number of interaction parameters. We present a novel hierarchical predictor-corrector scheme which enables neural networks to learn to understand and control complex nonlinear physical systems over long time frames. We propose to split the problem into two distinct tasks: planning and control. To this end, we introduce a predictor network that plans optimal trajectories and a control network that infers the corresponding control parameters. Both stages are trained end-to-end using a differentiable PDE solver. We demonstrate that our method successfully develops an understanding of complex physical systems and learns to control them for tasks involving PDEs such as the incompressible Navier-Stokes equations.},
  archiveprefix = {arXiv},
  arxivid       = {2001.07457},
  eprint        = {2001.07457},
  file          = {:home/antonio/Documents/bibliography/files/Holl, Koltun, Thuerey - 2020 - Learning To Control Pdes With Differentiable Physics.pdf:pdf},
  groups        = {Differentiable programming and simulation},
}

@Article{Tancik2020,
  author        = {Tancik, Matthew and Mildenhall, Ben and Wang, Terrance and Schmidt, Divi and Srinivasan, Pratul P. and Barron, Jonathan T. and Ng, Ren},
  journal       = {arXiv},
  title         = {{Learned initializations for optimizing coordinate-based neural representations}},
  year          = {2020},
  issn          = {23318422},
  abstract      = {Coordinate-based neural representations have shown significant promise as an alternative to discrete, array-based representations for complex low dimensional signals. However, optimizing a coordinate-based network from randomly initialized weights for each new signal is inefficient. We propose applying standard meta-learning algorithms to learn the initial weight parameters for these fully-connected networks based on the underlying class of signals being represented (e.g., images of faces or 3D models of chairs). Despite requiring only a minor change in implementation, using these learned initial weights enables faster convergence during optimization and can serve as a strong prior over the signal class being modeled, resulting in better generalization when only partial observations of a given signal are available. We explore these benefits across a variety of tasks, including representing 2D images, reconstructing CT scans, and recovering 3D shapes and scenes from 2D image observations.},
  archiveprefix = {arXiv},
  arxivid       = {2012.02189},
  eprint        = {2012.02189},
  file          = {:home/antonio/Documents/bibliography/files/Tancik et al. - 2020 - Learned initializations for optimizing coordinate-based neural representations.pdf:pdf},
  groups        = {Implicit- and Meta- learning},
}

@article{You2020,
abstract = {Deep neural networks have shown exceptional learning capability and generalizability in the source domain when massive labeled data is provided. However, the well-trained models often fail in the target domain due to the domain shift. Unsupervised domain adaptation aims to improve network performance when applying robust models trained on medical images from source domains to a new target domain. In this work, we present an approach based on the Wasserstein distance guided disentangled representation to achieve 3D multi-domain liver segmentation. Concretely, we embed images onto a shared content space capturing shared feature-level information across domains and domain-specific appearance spaces. The existing mutual information-based representation learning approaches often fail to capture complete representations in multi-domain medical imaging tasks. To mitigate these issues, we utilize Wasserstein distance to learn more complete representation, and introduces a content discriminator to further facilitate the representation disentanglement. Experiments demonstrate that our method outperforms the state-of-the-art on the multi-modality liver segmentation task.},
archivePrefix = {arXiv},
arxivId = {2009.02831},
author = {You, Chenyu and Yang, Junlin and Chapiro, Julius and Duncan, James S.},
doi = {10.1007/978-3-030-61166-8_17},
eprint = {2009.02831},
file = {:home/antonio/Documents/bibliography/files/You et al. - 2020 - Unsupervised Wasserstein Distance Guided Domain Adaptation for 3D Multi-domain Liver Segmentation.pdf:pdf},
isbn = {9783030611651},
issn = {16113349},
journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
pages = {155--163},
title = {{Unsupervised Wasserstein Distance Guided Domain Adaptation for 3D Multi-domain Liver Segmentation}},
volume = {12446 LNCS},
year = {2020}
}

@article{Hu2018,
abstract = {Convolutional neural networks are built upon the con-volution operation, which extracts informative features by fusing spatial and channel-wise information together within local receptive fields. In order to boost the representa-tional power of a network, several recent approaches have shown the benefit of enhancing spatial encoding. In this work, we focus on the channel relationship and propose a novel architectural unit, which we term the "Squeeze-and-Excitation" (SE) block, that adaptively recalibrates channel-wise feature responses by explicitly modelling in-terdependencies between channels. We demonstrate that by stacking these blocks together, we can construct SENet ar-chitectures that generalise extremely well across challenging datasets. Crucially, we find that SE blocks produce significant performance improvements for existing state-of-the-art deep architectures at minimal additional computational cost. SENets formed the foundation of our ILSVRC 2017 classification submission which won first place and significantly reduced the top-5 error to 2.251%, achieving a ∼25% relative improvement over the winning entry of 2016. Code and models are available at https: //github.com/hujie-frank/SENet.},
author = {Hu, Jie},
file = {:home/antonio/Documents/bibliography/files/Hu - 2018 - Squeeze-and-Excitation_Networks_CVPR_2018_paper.pdf.pdf:pdf},
journal = {Cvpr},
pages = {7132--7141},
title = {{Squeeze-and-Excitation_Networks_CVPR_2018_paper.pdf}},
url = {http://openaccess.thecvf.com/content_cvpr_2018/html/Hu_Squeeze-and-Excitation_Networks_CVPR_2018_paper.html},
year = {2018}
}

@Article{Ramachandran2019,
  author        = {Ramachandran, Prajit and Parmar, Niki and Vaswani, Ashish and Bello, Irwan and Levskayay, Anselm and Shlens, Jonathon},
  journal       = {arXiv},
  title         = {{Stand-alone self-attention in vision models}},
  year          = {2019},
  issn          = {23318422},
  number        = {NeurIPS},
  pages         = {1--13},
  abstract      = {Convolutions are a fundamental building block of modern computer vision systems. Recent approaches have argued for going beyond convolutions in order to capture long-range dependencies. These efforts focus on augmenting convolutional models with content-based interactions, such as self-attention and non-local means, to achieve gains on a number of vision tasks. The natural question that arises is whether attention can be a stand-alone primitive for vision models instead of serving as just an augmentation on top of convolutions. In developing and testing a pure self-attention vision model, we verify that self-attention can indeed be an effective stand-alone layer. A simple procedure of replacing all instances of spatial convolutions with a form of self-attention applied to ResNet model produces a fully self-attentional model that outperforms the baseline on ImageNet classification with 12% fewer FLOPS and 29% fewer parameters. On COCO object detection, a pure self-attention model matches the mAP of a baseline RetinaNet while having 39% fewer FLOPS and 34% fewer parameters. Detailed ablation studies demonstrate that self-attention is especially impactful when used in later layers. These results establish that stand-alone self-attention is an important addition to the vision practitioner's toolbox.},
  archiveprefix = {arXiv},
  arxivid       = {1906.05909},
  eprint        = {1906.05909},
  file          = {:home/antonio/Documents/bibliography/files/Ramachandran et al. - 2019 - Stand-alone self-attention in vision models(2).pdf:pdf;:home/antonio/Documents/bibliography/files/Ramachandran et al. - 2019 - Stand-alone self-attention in vision models.pdf:pdf},
  groups        = {Attention},
}

@Article{Long2018,
  author        = {Long, Mingsheng and Cao, Zhangjie and Wang, Jianmin and Jordan, Michael I.},
  journal       = {Advances in Neural Information Processing Systems},
  title         = {{Conditional adversarial domain adaptation}},
  year          = {2018},
  issn          = {10495258},
  number        = {NeurIPS},
  pages         = {1640--1650},
  volume        = {2018-Decem},
  abstract      = {Adversarial learning has been embedded into deep networks to learn disentangled and transferable representations for domain adaptation. Existing adversarial domain adaptation methods may not effectively align different domains of multimodal distributions native in classification problems. In this paper, we present conditional adversarial domain adaptation, a principled framework that conditions the adversarial adaptation models on discriminative information conveyed in the classifier predictions. Conditional domain adversarial networks (CDANs) are designed with two novel conditioning strategies: multilinear conditioning that captures the cross-covariance between feature representations and classifier predictions to improve the discriminability, and entropy conditioning that controls the uncertainty of classifier predictions to guarantee the transferability. With theoretical guarantees and a few lines of codes, the approach has exceeded state-of-the-art results on five datasets.},
  archiveprefix = {arXiv},
  arxivid       = {1705.10667},
  eprint        = {1705.10667},
  file          = {:home/antonio/Documents/bibliography/files/Long et al. - 2018 - Conditional adversarial domain adaptation.pdf:pdf},
  groups        = {GANs},
}

@Article{Yi2017,
  author   = {Yi, Zili and Zhang, Hao and Tan, Ping and Gong, Minglun},
  journal  = {arXiv},
  title    = {{DualGAN: Unsupervised dual learning for image-to-image translation}},
  year     = {2017},
  issn     = {23318422},
  abstract = {Conditional Generative Adversarial Networks (GANs) for cross-domain image-to-image translation have made much progress recently [7, 8, 21, 12, 4, 18]. Depending on the task complexity, thousands to millions of labeled image pairs are needed to train a conditional GAN. However, human labeling is expensive, even impractical, and large quantities of data may not always be available. Inspired by dual learning from natural language translation [23], we develop a novel dual-GAN mechanism, which enables image translators to be trained from two sets of unlabeled images from two domains. In our architecture, the primal GAN learns to translate images from domain U to those in domain V , while the dual GAN learns to invert the task. The closed loop made by the primal and dual tasks allows images from either domain to be translated and then reconstructed. Hence a loss function that accounts for the reconstruction error of images can be used to train the translators. Experiments on multiple image translation tasks with unlabeled data show considerable performance gain of DualGAN over a single GAN. For some tasks, DualGAN can even achieve comparable or slightly better results than conditional GAN trained on fully labeled data.},
  file     = {:home/antonio/Documents/bibliography/files/Yi et al. - 2017 - DualGAN Unsupervised dual learning for image-to-image translation.pdf:pdf},
  groups   = {GANs},
}

@Article{Defazio2021,
  author        = {Defazio, Aaron and Jelassi, Samy},
  title         = {{Adaptivity without Compromise: A Momentumized, Adaptive, Dual Averaged Gradient Method for Stochastic Optimization}},
  year          = {2021},
  pages         = {1--31},
  abstract      = {We introduce MADGRAD, a novel optimization method in the family of AdaGrad adaptive gradient methods. MADGRAD shows excellent performance on deep learning optimization problems from multiple fields, including classification and image-to-image tasks in vision, and recurrent and bidirectionally-masked models in natural language processing. For each of these tasks, MADGRAD matches or outperforms both SGD and ADAM in test set performance, even on problems for which adaptive methods normally perform poorly.},
  archiveprefix = {arXiv},
  arxivid       = {2101.11075},
  eprint        = {2101.11075},
  file          = {:home/antonio/Documents/bibliography/files/Defazio, Jelassi - 2021 - Adaptivity without Compromise A Momentumized, Adaptive, Dual Averaged Gradient Method for Stochastic Optimizat.pdf:pdf},
  groups        = {Training},
  url           = {http://arxiv.org/abs/2101.11075},
}

@Article{Srivastava2017,
  author        = {Srivastava, Akash and Valkov, Lazar and Russell, Chris and Gutmann, Michael U. and Sutton, Charles},
  journal       = {Advances in Neural Information Processing Systems},
  title         = {{VEEGAN: Reducing mode collapse in GANs using implicit variational learning}},
  year          = {2017},
  issn          = {10495258},
  number        = {Nips 2017},
  pages         = {3309--3319},
  volume        = {2017-Decem},
  abstract      = {Deep generative models provide powerful tools for distributions over complicated manifolds, such as those of natural images. But many of these methods, including generative adversarial networks (GANs), can be difficult to train, in part because they are prone to mode collapse, which means that they characterize only a few modes of the true distribution. To address this, we introduce VEEGAN, which features a reconstructor network, reversing the action of the generator by mapping from data to noise. Our training objective retains the original asymptotic consistency guarantee of GANs, and can be interpreted as a novel autoencoder loss over the noise. In sharp contrast to a traditional autoencoder over data points, VEEGAN does not require specifying a loss function over the data, but rather only over the representations, which are standard normal by assumption. On an extensive set of synthetic and real world image datasets, VEEGAN indeed resists mode collapsing to a far greater extent than other recent GAN variants, and produces more realistic samples.},
  archiveprefix = {arXiv},
  arxivid       = {1705.07761},
  eprint        = {1705.07761},
  file          = {:home/antonio/Documents/bibliography/files/Srivastava et al. - 2017 - VEEGAN Reducing mode collapse in GANs using implicit variational learning.pdf:pdf},
  groups        = {GANs, Implicit- and Meta- learning},
}

@Article{Chan2020,
  author        = {Chan, Eric R. and Monteiro, Marco and Kellnhofer, Petr and Wu, Jiajun and Wetzstein, Gordon},
  journal       = {arXiv},
  title         = {{pi-GAN: Periodic implicit generative adversarial networks for 3D-aware image synthesis}},
  year          = {2020},
  issn          = {23318422},
  abstract      = {We have witnessed rapid progress on 3D-aware image synthesis, leveraging recent advances in generative visual models and neural rendering. Existing approaches however fall short in two ways: first, they may lack an underlying 3D representation or rely on view-inconsistent rendering, hence synthesizing images that are not multi-view consistent; second, they often depend upon representation network architectures that are not expressive enough, and their results thus lack in image quality. We propose a novel generative model, named Periodic Implicit Generative Adversarial Networks ($\pi$-GAN or pi-GAN), for high-quality 3D-aware image synthesis. $\pi$-GAN leverages neural representations with periodic activation functions and volumetric rendering to represent scenes as view-consistent 3D representations with fine detail. The proposed approach obtains state-of-the-art results for 3D-aware image synthesis with multiple real and synthetic datasets.},
  archiveprefix = {arXiv},
  arxivid       = {2012.00926},
  eprint        = {2012.00926},
  file          = {:home/antonio/Documents/bibliography/files/Chan et al. - 2020 - pi-GAN Periodic implicit generative adversarial networks for 3D-aware image synthesis.pdf:pdf},
  groups        = {GANs, Implicit- and Meta- learning},
}

@Article{Sim2020,
  author        = {Sim, Byeongsu and Oh, Gyutaek and Kim, Jeongsol and Jung, Chanyong and Ye, Jong Chul},
  journal       = {SIAM Journal on Imaging Sciences},
  title         = {{Optimal transport driven CycleGAN for unsupervised learning in inverse problems}},
  year          = {2020},
  issn          = {19364954},
  number        = {4},
  pages         = {2281--2306},
  volume        = {13},
  abstract      = {To improve the performance of classical generative adversarial networks (GANs), Wasserstein generative adversarial networks (WGANs) were developed as a Kantorovich dual formulation of the optimal transport (OT) problem using Wasserstein-1 distance. However, it was not clear how CycleGANtype generative models can be derived from the OT theory. Here we show that a novel CycleGAN architecture can be derived as a Kantorovich dual OT formulation if a penalized least squares (PLS) cost with deep learning--based inverse path penalty is used as a transportation cost. One of the most important advantages of this formulation is that depending on the knowledge of the forward problem, distinct variations of CycleGAN architecture can be derived: for example, one with two pairs of generators and discriminators, and the other with only a single pair of generator and discriminator. Even for the two generator cases, we show that the structural knowledge of the forward operator can lead to a simpler generator architecture which significantly simplifies the neural network training. The new CycleGAN formulation, which we call the OT-CycleGAN, has been applied for various biomedical imaging problems, such as accelerated magnetic resonance imaging (MRI), super-resolution microscopy, and low-dose X-ray computed tomography (CT). Experimental results confirm the efficacy and flexibility of the theory.},
  archiveprefix = {arXiv},
  arxivid       = {1909.12116},
  doi           = {10.1137/20M1317992},
  eprint        = {1909.12116},
  file          = {:home/antonio/Documents/bibliography/files/Sim et al. - 2020 - Optimal transport driven CycleGAN for unsupervised learning in inverse problems.pdf:pdf},
  groups        = {GANs},
  keywords      = {CycleGAN, Inverse problems, Optimal transport, Penalized least squares, Unsupervised learning},
}

@Article{Skorokhodov2020,
  author        = {Skorokhodov, Ivan and Ignatyev, Savva and Elhoseiny, Mohamed},
  journal       = {arXiv},
  title         = {{Adversarial generation of continuous images}},
  year          = {2020},
  issn          = {23318422},
  abstract      = {In most existing learning systems, images are typically viewed as 2D pixel arrays. However, in another paradigm gaining popularity, a 2D image is represented as an implicit neural representation (INR) — an MLP that predicts an RGB pixel value given its (x, y) coordinate. In this paper, we propose two novel architectural techniques for building INR-based image decoders: factorized multiplicative modulation and multi-scale INRs, and use them to build a state-of-the-art continuous image GAN. Previous attempts to adapt INRs for image generation were limited to MNIST-like datasets and do not scale to complex real-world data. Our proposed architectural design improves the performance of continuous image generators by ×6-40 times and reaches FID scores of 6.27 on LSUN bedroom 256×256 and 16.32 on FFHQ 1024 × 1024, greatly reducing the gap between continuous image GANs and pixel-based ones. To the best of our knowledge, these are the highest reported scores for an image generator, that consists entirely of fully-connected layers. Apart from that, we explore several exciting properties of INR-based decoders, like out-of-the-box superresolution, meaningful image-space interpolation, accelerated inference of low-resolution images, an ability to extrapolate outside of image boundaries and strong geometric prior. The source code is available at https://github.com/universome/inr-gan.},
  archiveprefix = {arXiv},
  arxivid       = {2011.12026},
  eprint        = {2011.12026},
  file          = {:home/antonio/Documents/bibliography/files/Skorokhodov, Ignatyev, Elhoseiny - 2020 - Adversarial generation of continuous images.pdf:pdf},
  groups        = {GANs},
}

@Article{Lu2018,
  author   = {Lu, Guansong and Zhou, Zhiming and Song, Yuxuan and Ren, Kan and Yu, Yong},
  journal  = {arXiv},
  title    = {{Guiding the One-to-one Mapping in CycleGAN via optimal transport}},
  year     = {2018},
  issn     = {23318422},
  abstract = {CycleGAN is capable of learning a one-to-one mapping between two data distributions without paired examples, achieving the task of unsupervised data translation. However, there is no theoretical guarantee on the property of the learned one-to-one mapping in CycleGAN. In this paper, we experimentally find that, under some circumstances, the one-to-one mapping learned by CycleGAN is just a random one within the large feasible solution space. Based on this observation, we explore to add extra constraints such that the one-to-one mapping is controllable and satisfies more properties related to specific tasks. We propose to solve an optimal transport mapping restrained by a task-specific cost function that reflects the desired properties, and use the barycenters of optimal transport mapping to serve as references for CycleGAN. Our experiments indicate that the proposed algorithm is capable of learning a one-to-one mapping with the desired properties.},
  file     = {:home/antonio/Documents/bibliography/files/Lu et al. - 2018 - Guiding the One-to-one Mapping in CycleGAN via optimal transport.pdf:pdf},
  groups   = {GANs},
}

@Article{Anokhin2020,
  author        = {Anokhin, Ivan and Demochkin, Kirill and Khakhulin, Taras and Sterkin, Gleb and Lempitsky, Victor and Korzhenkov, Denis},
  journal       = {arXiv},
  title         = {{Image generators with conditionally-independent pixel synthesis}},
  year          = {2020},
  issn          = {23318422},
  abstract      = {Existing image generator networks rely heavily on spatial convolutions and, optionally, self-attention blocks in order to gradually synthesize images in a coarse-to-fine manner. Here, we present a new architecture for image generators, where the color value at each pixel is computed independently given the value of a random latent vector and the coordinate of that pixel. No spatial convolutions or similar operations that propagate information across pixels are involved during the synthesis. We analyze the modeling capabilities of such generators when trained in an adversarial fashion, and observe the new generators to achieve similar generation quality to state-of-the-art convolutional generators. We also investigate several interesting properties unique to the new architecture.},
  archiveprefix = {arXiv},
  arxivid       = {2011.13775},
  eprint        = {2011.13775},
  file          = {:home/antonio/Documents/bibliography/files/Anokhin et al. - 2020 - Image generators with conditionally-independent pixel synthesis.pdf:pdf},
  groups        = {GANs},
}

@Article{Alfarraj2020,
  author        = {Alfarraj, Motaz and AlRegib, Ghassan},
  journal       = {SEG International Exposition and Annual Meeting 2019},
  title         = {{Semi-supervised learning for acoustic impedance inversion}},
  year          = {2020},
  issn          = {1052-3812},
  number        = {May},
  pages         = {2298--2302},
  abstract      = {Recent applications of deep learning in the seismic domain have shown great potential in different areas such as inversion and interpretation. Deep learning algorithms, in general, require tremendous amounts of labeled data to train properly. To overcome this issue, we propose a semi-supervised framework for acoustic impedance inversion based on convolutional and recurrent neural networks. Specifically, seismic traces and acoustic impedance traces are modeled as time series. Then, a neural-network-based inversion model comprising convolutional and recurrent neural layers is used to invert seismic data for acoustic impedance. The proposed workflow uses well log data to guide the inversion. In addition, it utilizes a learned seismic forward model to regularize the training and to serve as a geophysical constraint for the inversion. The proposed workflow achieves an average correlation of 98% between the estimated and target elastic impedance using 20 AI traces for training.},
  archiveprefix = {arXiv},
  arxivid       = {1905.13412},
  doi           = {10.1190/segam2019-3215902.1},
  eprint        = {1905.13412},
  file          = {:home/antonio/Documents/bibliography/files/Alfarraj, AlRegib - 2020 - Semi-supervised learning for acoustic impedance inversion.pdf:pdf},
  groups        = {Ultrasound and wave imaging},
}

@Article{Yang2020,
  author   = {Yang, Xiao},
  journal  = {Journal of Physics: Conference Series},
  title    = {{An Overview of the Attention Mechanisms in Computer Vision}},
  year     = {2020},
  issn     = {17426596},
  number   = {1},
  volume   = {1693},
  abstract = {Deep convolutional neural network (CNN) plays an important role in the field of computer vision and image processing. In order to further improve the performance of CNN, scholars have conducted a series of new explorations, such as the improvement of activation functions, the construction of new loss functions, the regularization of parameters and the development of new network structures. However, every breakthrough of CNN comes from the innovation of network structure, whose design can be inspired by exploring the cognitive process of human brain. As one of the important features of human visual system, visual attention mechanism is essential in image generation, scene classification, target detection and tracking when applied in the field of computer vision. Focusing on the models of attention mechanisms commonly used in computer vision, their categorizations, principles, and outlook are summarized in this overview.},
  doi      = {10.1088/1742-6596/1693/1/012173},
  file     = {:home/antonio/Documents/bibliography/files/Yang - 2020 - An Overview of the Attention Mechanisms in Computer Vision.pdf:pdf},
  groups   = {Attention},
}

@article{Gallucci2021,
author = {Gallucci, Alessio and Pezzotti, Nicola and Znamenskiy, Dmitry and Petkovic, Milan},
doi = {10.1117/12.2580664},
file = {:home/antonio/Documents/bibliography/files/Gallucci et al. - 2021 - A latent space exploration for microscopic skin lesion augmentations with VQ-VAE-2 and PixelSNAIL.pdf:pdf},
number = {February},
pages = {102},
title = {{A latent space exploration for microscopic skin lesion augmentations with VQ-VAE-2 and PixelSNAIL}},
year = {2021}
}

@Article{Hu2017,
  author        = {Hu, Yuanming},
  title         = {{DiffTaiChi}},
  year          = {2017},
  pages         = {1--8},
  archiveprefix = {arXiv},
  arxivid       = {arXiv:1611.01652v1},
  eprint        = {arXiv:1611.01652v1},
  file          = {:home/antonio/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hu - 2017 - DiffTaiChi.pdf:pdf},
  groups        = {Differentiable programming and simulation},
  url           = {https://arxiv.org/pdf/1611.01652v1.pdfhttps://openreview.net/pdf?id=r1lEjlHKPH},
}

@Article{Bachlechner2020,
  author        = {Bachlechner, Thomas and Majumder, Bodhisattwa Prasad and Mao, Huanru Henry and Cottrell, Garrison W. and McAuley, Julian},
  journal       = {arXiv},
  title         = {{ReZero is all you need: Fast convergence at large depth}},
  year          = {2020},
  issn          = {23318422},
  number        = {1},
  pages         = {1--14},
  abstract      = {Deep networks have enabled significant performance gains across domains, but they often suffer from vanishing/exploding gradients. This is especially true for Transformer architectures where depth beyond 12 layers is difficult to train without large datasets and computational budgets. In general, we find that inefficient signal propagation impedes learning in deep networks. In Transformers, multi-head self-attention is the main cause of this poor signal propagation. To facilitate deep signal propagation, we propose ReZero, a simple change to the architecture that initializes an arbitrary layer as the identity map, using a single additional learned parameter per layer. We apply this technique to language modeling and find that we can easily train ReZero-Transformer networks over a hundred layers. When applied to 12 layer Transformers, ReZero converges 56% faster on enwiki8. ReZero applies beyond Transformers to other residual networks, enabling 1,500% faster convergence for deep fully connected networks and 32% faster convergence for a ResNet-56 trained on CIFAR 10.},
  archiveprefix = {arXiv},
  arxivid       = {2003.04887},
  eprint        = {2003.04887},
  file          = {:home/antonio/Documents/bibliography/files/Bachlechner et al. - 2020 - ReZero is all you need Fast convergence at large depth.pdf:pdf},
  groups        = {Representation, architectures and DL layers},
}

@Article{Mukherjee2021,
  author        = {Mukherjee, Subhadip and {\"{O}}ktem, Ozan and Sch{\"{o}}nlieb, Carola-Bibiane},
  title         = {{Adversarially learned iterative reconstruction for imaging inverse problems}},
  year          = {2021},
  pages         = {1--13},
  abstract      = {In numerous practical applications, especially in medical image reconstruction, it is often infeasible to obtain a large ensemble of ground-truth/measurement pairs for supervised learning. Therefore, it is imperative to develop unsupervised learning protocols that are competitive with supervised approaches in performance. Motivated by the maximum-likelihood principle, we propose an unsupervised learning framework for solving ill-posed inverse problems. Instead of seeking pixel-wise proximity between the reconstructed and the ground-truth images, the proposed approach learns an iterative reconstruction network whose output matches the ground-truth in distribution. Considering tomographic reconstruction as an application, we demonstrate that the proposed unsupervised approach not only performs on par with its supervised variant in terms of objective quality measures but also successfully circumvents the issue of over-smoothing that supervised approaches tend to suffer from. The improvement in reconstruction quality comes at the expense of higher training complexity, but, once trained, the reconstruction time remains the same as its supervised counterpart.},
  archiveprefix = {arXiv},
  arxivid       = {2103.16151},
  eprint        = {2103.16151},
  file          = {:home/antonio/Documents/bibliography/files/Mukherjee, {\"{O}}ktem, Sch{\"{o}}nlieb - 2021 - Adversarially learned iterative reconstruction for imaging inverse problems.pdf:pdf},
  groups        = {Inverse problems},
  keywords      = {gans, generative adversarial networks, inverse problems, iterative recon-, struction, unsupervised learning},
  url           = {http://arxiv.org/abs/2103.16151},
}

@Article{Huang2021,
  author        = {Huang, Zhishen and Ye, Siqi and McCann, Michael T. and Ravishankar, Saiprasad},
  title         = {{Model-based Reconstruction with Learning: From Unsupervised to Supervised and Beyond}},
  year          = {2021},
  pages         = {1--20},
  abstract      = {Many techniques have been proposed for image reconstruction in medical imaging that aim to recover high-quality images especially from limited or corrupted measurements. Model-based reconstruction methods have been particularly popular (e.g., in magnetic resonance imaging and tomographic modalities) and exploit models of the imaging system's physics together with statistical models of measurements, noise and often relatively simple object priors or regularizers. For example, sparsity or low-rankness based regularizers have been widely used for image reconstruction from limited data such as in compressed sensing. Learning-based approaches for image reconstruction have garnered much attention in recent years and have shown promise across biomedical imaging applications. These methods include synthesis dictionary learning, sparsifying transform learning, and different forms of deep learning involving complex neural networks. We briefly discuss classical model-based reconstruction methods and then review reconstruction methods at the intersection of model-based and learning-based paradigms in detail. This review includes many recent methods based on unsupervised learning, and supervised learning, as well as a framework to combine multiple types of learned models together.},
  archiveprefix = {arXiv},
  arxivid       = {2103.14528},
  eprint        = {2103.14528},
  file          = {:home/antonio/Documents/bibliography/files/Huang et al. - 2021 - Model-based Reconstruction with Learning From Unsupervised to Supervised and Beyond.pdf:pdf},
  groups        = {Inverse problems},
  url           = {http://arxiv.org/abs/2103.14528},
}

@Misc{Putzky2017,
  author        = {Putzky, Patrick and Welling, Max},
  month         = {jun},
  title         = {{Recurrent inference machines for solving inverse problems}},
  year          = {2017},
  abstract      = {Much of the recent research on solving iterative inference problems focuses on moving away from hand-chosen inference algorithms and towards learned inference. In the latter, the inference process is unrolled in time and interpreted as a recurrent neural network (RNN) which allows for joint learning of model and inference parameters with back-propagation through time. In this framework, the RNN architecture is directly derived from a hand-chosen inference algorithm, effectively limiting its capabilities. We propose a learning framework, called Recurrent Inference Machines (RIM), in which we turn algorithm construction the other way round: Given data and a task, train an RNN to learn an inference algorithm. Because RNNs are Turing complete [1, 2] they are capable to implement any inference algorithm. The framework allows for an abstraction which removes the need for domain knowledge. We demonstrate in several image restoration experiments that this abstraction is effective, allowing us to achieve state-of-the-art performance on image denoising and super-resolution tasks and superior across-task generalization.},
  archiveprefix = {arXiv},
  arxivid       = {1706.04008},
  booktitle     = {arXiv},
  eprint        = {1706.04008},
  file          = {:home/antonio/Documents/bibliography/files/Putzky, Welling - 2017 - Recurrent inference machines for solving inverse problems.pdf:pdf},
  groups        = {Inverse problems},
  issn          = {23318422},
  keywords      = {Computer Science - Computer Vision and Pattern Rec, Computer Science - Neural and Evolutionary Computi},
  language      = {en},
  mendeley-tags = {Computer Science - Computer Vision and Pattern Rec,Computer Science - Neural and Evolutionary Computi},
  number        = {2},
  pages         = {1--12},
  url           = {http://arxiv.org/abs/1706.04008},
}

@Article{Lagaris1998,
  author        = {Lagaris, Isaac Elias and Likas, Aristidis and Fotiadis, Dimitrios I.},
  journal       = {IEEE Transactions on Neural Networks},
  title         = {{Artificial neural networks for solving ordinary and partial differential equations}},
  year          = {1998},
  issn          = {10459227},
  month         = {sep},
  number        = {5},
  pages         = {987--1000},
  volume        = {9},
  abstract      = {We present a method to solve initial and boundary value problems using artificial neural networks. A trial solution of the differential equation is written as a sum of two parts. The first part satisfies the initial/boundary conditions and contains no adjustable parameters. The second part is constructed so as not to affect the initial/boundary conditions. This part involves a feedforward neural network containing adjustable parameters (the weights). Hence by construction the initial/boundary conditions are satisfied and the network is trained to satisfy the differential equation. The applicability of this approach ranges from single ordinary differential equations (ODE's), to systems of coupled ODE's and also to partial differential equations (PDE's). In this article, we illustrate the method by solving a variety of model problems and present comparisons with solutions obtained using the Galekrkin finite element method for several cases of partial differential equations. With the advent of neuroprocessors and digital signal processors the method becomes particularly interesting due to the expected essential gains in the execution speed. {\textcopyright} 1998 IEEE.},
  archiveprefix = {arXiv},
  arxivid       = {physics/9705023},
  doi           = {10.1109/72.712178},
  eprint        = {9705023},
  file          = {:home/antonio/Documents/bibliography/files/Lagaris, Likas, Fotiadis - 1998 - Artificial neural networks for solving ordinary and partial differential equations.pdf:pdf},
  groups        = {PDEs and neural networks},
  keywords      = {Collocation method, Finite elements, Neural networks, Neuroprocessors, Nonlinear Sciences - Cellular Automata and Lattice, Ordinary differential equations, Partial differential equations, Physics - Computational Physics, Quantum Physics},
  language      = {en},
  mendeley-tags = {Nonlinear Sciences - Cellular Automata and Lattice,Physics - Computational Physics,Quantum Physics},
  primaryclass  = {physics},
  url           = {http://arxiv.org/abs/physics/9705023},
}

@Article{Li2020,
  author        = {Li, Hongliang and Bhatt, Manish and Qu, Zhen and Zhang, Shiming and Hartel, Martin C. and Khademhosseini, Ali and Cloutier, Guy},
  journal       = {arXiv},
  title         = {{Deep Learning in Ultrasound Elastography Imaging}},
  year          = {2020},
  issn          = {23318422},
  number        = {1},
  volume        = {108},
  abstract      = {It is known that changes in the mechanical properties of tissues are associated with the onset and progression of certain diseases. Ultrasound elastography is a technique to characterize tissue stiffness using ultrasound imaging either by measuring tissue strain using quasi-static elastography or natural organ pulsation elastography, or by tracing a propagated shear wave induced by a source or a natural vibration using dynamic elastography. In recent years, deep learning has begun to emerge in ultrasound elastography research. In this review, several common deep learning frameworks in the computer vision community, such as multilayer perceptron, convolutional neural network, and recurrent neural network are described. Then, recent advances in ultrasound elastography using such deep learning techniques are revisited in terms of algorithm development and clinical diagnosis. Finally, the current challenges and future developments of deep learning in ultrasound elastography are prospected.},
  archiveprefix = {arXiv},
  arxivid       = {2010.07360},
  eprint        = {2010.07360},
  file          = {:home/antonio/Documents/bibliography/files/Li et al. - 2020 - Deep Learning in Ultrasound Elastography Imaging.pdf:pdf},
  groups        = {Ultrasound and wave imaging, Inverse problems},
  keywords      = {Artificial intelligence, Deep learning, Elastography, Ultrasound},
}

@Article{Li2020a,
  author        = {Li, Zongyi and Kovachki, Nikola and Azizzadenesheli, Kamyar and Liu, Burigede and Bhattacharya, Kaushik and Stuart, Andrew and Anandkumar, Anima},
  journal       = {arXiv:2010.08895 [cs, math]},
  title         = {{Fourier Neural Operator for Parametric Partial Differential Equations}},
  year          = {2020},
  month         = {oct},
  number        = {2016},
  pages         = {1--16},
  abstract      = {The classical development of neural networks has primarily focused on learning mappings between finite-dimensional Euclidean spaces. Recently, this has been generalized to neural operators that learn mappings between function spaces. For partial differential equations (PDEs), neural operators directly learn the mapping from any functional parametric dependence to the solution. Thus, they learn an entire family of PDEs, in contrast to classical methods which solve one instance of the equation. In this work, we formulate a new neural operator by parameterizing the integral kernel directly in Fourier space, allowing for an expressive and efficient architecture. We perform experiments on Burgers' equation, Darcy flow, and Navier-Stokes equation. The Fourier neural operator is the first ML-based method to successfully model turbulent flows with zero-shot super-resolution. It is up to three orders of magnitude faster compared to traditional PDE solvers. Additionally, it achieves superior accuracy compared to previous learning-based solvers under fixed resolution.},
  archiveprefix = {arXiv},
  arxivid       = {2010.08895},
  eprint        = {2010.08895},
  file          = {:home/antonio/Documents/bibliography/files/Li et al. - 2020 - Fourier Neural Operator for Parametric Partial Differential Equations.pdf:pdf},
  groups        = {PDEs and neural networks},
  keywords      = {Computer Science - Machine Learning, Mathematics - Numerical Analysis},
  language      = {en},
  mendeley-tags = {Computer Science - Machine Learning,Mathematics - Numerical Analysis},
  url           = {http://arxiv.org/abs/2010.08895},
}

@article{Nash2021,
abstract = {The high dimensionality of images presents architecture and sampling-efficiency challenges for likelihood-based generative models. Previous approaches such as VQ-VAE use deep autoencoders to obtain compact representations, which are more practical as inputs for likelihood-based models. We present an alternative approach, inspired by common image compression methods like JPEG, and convert images to quantized discrete cosine transform (DCT) blocks, which are represented sparsely as a sequence of DCT channel, spatial location, and DCT coefficient triples. We propose a Transformer-based autoregressive architecture, which is trained to sequentially predict the conditional distribution of the next element in such sequences, and which scales effectively to high resolution images. On a range of image datasets, we demonstrate that our approach can generate high quality, diverse images, with sample metric scores competitive with state of the art methods. We additionally show that simple modifications to our method yield effective image colorization and super-resolution models.},
archivePrefix = {arXiv},
arxivId = {2103.03841},
author = {Nash, Charlie and Menick, Jacob and Dieleman, Sander and Battaglia, Peter W.},
eprint = {2103.03841},
file = {:home/antonio/Documents/bibliography/files/Nash et al. - 2021 - Generating Images with Sparse Representations.pdf:pdf},
title = {{Generating Images with Sparse Representations}},
url = {http://arxiv.org/abs/2103.03841},
volume = {3},
year = {2021}
}

@Article{Dramsch2021,
  author        = {Dramsch, Jesper S{\"{o}}ren and L{\"{u}}thje, Mikael and Christensen, Anders Nymark},
  journal       = {Computers and Geosciences},
  title         = {{Complex-valued neural networks for machine learning on non-stationary physical data}},
  year          = {2021},
  issn          = {00983004},
  month         = {nov},
  number        = {November 2019},
  volume        = {146},
  abstract      = {Deep learning has become an area of interest in most scientific areas, including physical sciences. Modern networks apply real-valued transformations on the data. Particularly, convolutions in convolutional neural networks discard phase information entirely. Many deterministic signals, such as seismic data or electrical signals, contain significant information in the phase of the signal. We explore complex-valued deep convolutional networks to leverage non-linear feature maps. Seismic data commonly has a lowcut filter applied, to attenuate noise from ocean waves and similar long wavelength contributions. In non-stationary data, the phase content can stabilize training and improve the generalizability of neural networks. While it has been shown that phase content can be restored in deep neural networks, we show how including phase information in feature maps improves both training and inference from deterministic physical data. Furthermore, we show that smaller complex networks outperform larger real-valued networks.},
  archiveprefix = {arXiv},
  arxivid       = {1905.12321},
  doi           = {10.1016/j.cageo.2020.104643},
  eprint        = {1905.12321},
  file          = {:home/antonio/Documents/bibliography/files/Dramsch, L{\"{u}}thje, Christensen - 2021 - Complex-valued neural networks for machine learning on non-stationary physical data.pdf:pdf},
  groups        = {Representation, architectures and DL layers},
  keywords      = {Computer Science - Computer Vision and Pattern Rec, Computer Science - Machine Learning, Deep learning, Geophysics, Machine learning, Neural networks, Physics - Computational Physics, Physics - Geophysics, Physics-based machine learning, Seismic, Statistics - Machine Learning},
  language      = {en},
  mendeley-tags = {Computer Science - Computer Vision and Pattern Rec,Computer Science - Machine Learning,Physics - Computational Physics,Physics - Geophysics,Statistics - Machine Learning},
  url           = {http://arxiv.org/abs/1905.12321},
}

@Article{Herzberg2021,
  author        = {Herzberg, William and Rowe, Daniel B. and Hauptmann, Andreas and Hamilton, Sarah J.},
  title         = {{Graph Convolutional Networks for Model-Based Learning in Nonlinear Inverse Problems}},
  year          = {2021},
  pages         = {1--10},
  abstract      = {The majority of model-based learned image reconstruction methods in medical imaging have been limited to uniform domains, such as pixelated images. If the underlying model is solved on nonuniform meshes, arising from a finite element method typical for nonlinear inverse problems, interpolation and embeddings are needed. To overcome this, we present a flexible framework to extend model-based learning directly to nonuniform meshes, by interpreting the mesh as a graph and formulating our network architectures using graph convolutional neural networks. This gives rise to the proposed iterative Graph Convolutional Newton's Method (GCNM), which directly includes the forward model into the solution of the inverse problem, while all updates are directly computed by the network on the problem specific mesh. We present results for Electrical Impedance Tomography, a severely ill-posed nonlinear inverse problem that is frequently solved via optimization-based methods, where the forward problem is solved by finite element methods. Results for absolute EIT imaging are compared to standard iterative methods as well as a graph residual network. We show that the GCNM has strong generalizability to different domain shapes, out of distribution data as well as experimental data, from purely simulated training data.},
  archiveprefix = {arXiv},
  arxivid       = {2103.15138},
  eprint        = {2103.15138},
  file          = {:home/antonio/Documents/bibliography/files/Herzberg et al. - 2021 - Graph Convolutional Networks for Model-Based Learning in Nonlinear Inverse Problems.pdf:pdf},
  groups        = {Inverse problems},
  url           = {http://arxiv.org/abs/2103.15138},
}

@Article{Frolov2021,
  author        = {Frolov, Stanislav and Hinz, Tobias and Raue, Federico and Hees, J{\"{o}}rn and Dengel, Andreas},
  title         = {{Adversarial Text-to-Image Synthesis: A Review}},
  year          = {2021},
  abstract      = {With the advent of generative adversarial networks, synthesizing images from textual descriptions has recently become an active research area. It is a flexible and intuitive way for conditional image generation with significant progress in the last years regarding visual realism, diversity, and semantic alignment. However, the field still faces several challenges that require further research efforts such as enabling the generation of high-resolution images with multiple objects, and developing suitable and reliable evaluation metrics that correlate with human judgement. In this review, we contextualize the state of the art of adversarial text-to-image synthesis models, their development since their inception five years ago, and propose a taxonomy based on the level of supervision. We critically examine current strategies to evaluate text-to-image synthesis models, highlight shortcomings, and identify new areas of research, ranging from the development of better datasets and evaluation metrics to possible improvements in architectural design and model training. This review complements previous surveys on generative adversarial networks with a focus on text-to-image synthesis which we believe will help researchers to further advance the field.},
  archiveprefix = {arXiv},
  arxivid       = {2101.09983},
  eprint        = {2101.09983},
  file          = {:home/antonio/Documents/bibliography/files/Frolov et al. - 2021 - Adversarial Text-to-Image Synthesis A Review.pdf:pdf},
  keywords      = {generative adversarial networks, text-to-image synthesis},
  url           = {http://arxiv.org/abs/2101.09983},
}

@Article{Farrell2013,
  author        = {Farrell, P. E. and Ham, D. A. and Funke, S. W. and Rognes, M. E.},
  journal       = {SIAM Journal on Scientific Computing},
  title         = {{Automated derivation of the adjoint of high-level transient finite element programs}},
  year          = {2013},
  issn          = {10648275},
  number        = {4},
  pages         = {1--27},
  volume        = {35},
  abstract      = {In this paper we demonstrate a new technique for deriving discrete adjoint and tangent linear models of a finite element model. The technique is significantly more efficient and automatic than standard algorithmic differentiation techniques. The approach relies on a high-level symbolic representation of the forward problem. In contrast to developing a model directly in Fortran or C++, high-level systems allow the developer to express the variational problems to be solved in near-mathematical notation. As such, these systems have a key advantage: since the mathematical structure of the problem is preserved, they are more amenable to automated analysis and manipulation. The framework introduced here is implemented in a freely available software package named dolfin-adjoint, based on the FEniCS Project. Our approach to automated adjoint derivation relies on run-time annotation of the temporal structure of the model and employs the FEniCS finite element form compiler to automatically generate the low-level code for the derived models. This approach requires only trivial changes to a large class of forward models, including complicated time-dependent nonlinear models. The adjoint model automatically employs optimal checkpointing schemes to mitigate storage requirements for nonlinear models, without any user management or intervention. Furthermore, both the tangent linear and adjoint models naturally work in parallel, without any need to differentiate through calls to MPI or to parse OpenMP directives. The generality, applicability, and efficiency of the approach are demonstrated with examples from a wide range of scientific applications. {\textcopyright} 2013 Society for Industrial and Applied Mathematics.},
  archiveprefix = {arXiv},
  arxivid       = {1204.5577},
  doi           = {10.1137/120873558},
  eprint        = {1204.5577},
  file          = {:home/antonio/Documents/bibliography/files/Farrell et al. - 2013 - Automated derivation of the adjoint of high-level transient finite element programs.pdf:pdf},
  groups        = {Differentiable programming and simulation},
  keywords      = {Adjoint, Code generation, Dolfin-adjoint, FEniCS project, Libadjoint, Tangent linear},
}

@Article{Wilson1991,
  author        = {Wilson, L. S.},
  journal       = {Processing},
  title         = {{Description of Broad-Band Pulsed Doppler Ultrasound Processing Using Two-Dimensional Fourier Transform}},
  year          = {1991},
  issn          = {01617346},
  number        = {4},
  pages         = {301--315},
  volume        = {315},
  abstract      = {Considering data from a Doppler sample volume as a two-dimensional function of depth and time, the properties of its two-dimensional fast Fourier transform (2DFFT) are discussed. It is shown that the 2DFET of idealized Doppler data from moving scatterers is a line whose slope is the velocity of the scatterers. Aliasing, finite bandwidth effects, and spectral broadening due to transit time effects receive simple descriptions in this scheme. Existing processing schemes can be described graphically in this unifying description. Processing of broad band pulsed Doppler ultrasound can incorporate a correction for aliasing if based on the two-dimensional Fourier transform, and this has been tested using data from tissue-mimicking phantom in a tank-based experiment. o 1991 Academic Press, Inc.},
  doi           = {10.1177/016173469101300401},
  groups        = {Classical US imaging},
  keywords      = {Folder - 1D Doppler, doppler, fourier transform, signal processing, two-dimensional, ultrasound},
  language      = {en},
  mendeley-tags = {Folder - 1D Doppler,doppler,fourier transform,signal processing,two-dimensional,ultrasound},
  pmid          = {1759323},
}

@Misc{Zhang2017,
  author        = {Zhang, Jian and Ghanem, Bernard},
  title         = {{ISTA-net: Interpretable optimization-inspired deep network for image compressive sensing}},
  year          = {2017},
  abstract      = {With the aim of developing a fast yet accurate algorithm for compressive sensing (CS) reconstruction of natural images, we combine in this paper the merits of two existing categories of CS methods: the structure insights of traditional optimization-based methods and the speed of recent network-based ones. Specifically, we propose a novel structured deep network, dubbed ISTA-Net, which is inspired by the Iterative Shrinkage-Thresholding Algorithm (ISTA) for optimizing a general ℓ1norm CS reconstruction model. To cast ISTA into deep network form, we develop an effective strategy to solve the proximal mapping associated with the sparsity-inducing regularizer using nonlinear transforms. All the parameters in ISTA-Net (e.g. nonlinear transforms, shrinkage thresholds, step sizes, etc.) are learned end-to-end, rather than being hand-crafted. Moreover, considering that the residuals of natural images are more compressible, an enhanced version of ISTA-Net in the residual domain, dubbed ISTA-Net+, is derived to further improve CS reconstruction. Extensive CS experiments demonstrate that the proposed ISTA-Nets outperform existing state-of-the-art optimization-based and networkbased CS methods by large margins, while maintaining fast computational speed. Our source codes are available: http://jianzhang.tech/projects/ISTA-Net.},
  archiveprefix = {arXiv},
  arxivid       = {1705.06869},
  booktitle     = {arXiv},
  eprint        = {1705.06869},
  groups        = {Inverse problems},
  issn          = {23318422},
  keywords      = {ADMM, ADMM-Net, CS-MRI, Computer Science - Computer Vision and Pattern Rec, Computer Science - Multimedia, Deep learning, Discriminative learning},
  language      = {en},
  mendeley-tags = {Computer Science - Computer Vision and Pattern Rec,Computer Science - Multimedia},
  pages         = {4},
  url           = {http://arxiv.org/abs/1705.06869 http://arxiv.org/abs/1706.07929},
}

@Misc{Wu2018,
  author        = {Wu, Yue and Lin, Youzuo},
  month         = {oct},
  title         = {{InversionNet: A real-time and accurate full waveform inversion with CNNs and continuous CRFs}},
  year          = {2018},
  abstract      = {Full-waveform inversion problems are usually formulated as optimization problems, where the forward-wave propagation operator f maps the subsurface velocity structures to seismic signals. The existing computational methods for solving full-waveform inversion are not only computationally expensive, but also yields low-resolution results because of the ill-posedness and cycle skipping issues of full-waveform inversion. To resolve those issues, we employ machine-learning techniques to solve the full-waveform inversion. Specifically, we focus on applying the convolutional neural network (CNN) to directly derive the inversion operator f-1 so that the velocity structure can be obtained without knowing the forward operator f. We build a convolutional neural network with an encoder-decoder structure to model the correspondence from seismic data to subsurface velocity structures. Furthermore, we employ the conditional random field (CRF) on top of the CNN to generate structural predictions by modeling the interactions between different locations on the velocity model. Our numerical examples using synthetic seismic reflection data show that the propose CNN-CRF model significantly improve the accuracy of the velocity inversion while the computational time is reduced.},
  archiveprefix = {arXiv},
  arxivid       = {1811.07875},
  booktitle     = {arXiv},
  doi           = {10.1109/TCI.2019.2956866},
  eprint        = {1811.07875},
  groups        = {Inverse problems, Ultrasound and wave imaging},
  issn          = {23318422},
  keywords      = {Conditional Random Field, Convolutional Neural Network, Electrical Engineering and Systems Science - Signa, Folder - FWI, Full-Waveform Inversion, Inversion},
  language      = {en},
  mendeley-tags = {Electrical Engineering and Systems Science - Signa,Folder - FWI},
  number        = {10},
  pages         = {e0205390},
  shorttitle    = {InversionNet},
  url           = {http://arxiv.org/abs/1811.07875 http://dx.plos.org/10.1371/journal.pone.0205390},
  volume        = {13},
}

@Article{Han2017,
  author   = {Han, Xiao},
  journal  = {Medical Physics},
  title    = {{MR-based synthetic CT generation using a deep convolutional neural network method}},
  year     = {2017},
  issn     = {00942405},
  month    = {apr},
  number   = {4},
  pages    = {1408--1419},
  volume   = {44},
  abstract = {Purpose: Interests have been rapidly growing in the field of radiotherapy to replace CT with magnetic resonance imaging (MRI), due to superior soft tissue contrast offered by MRI and the desire to reduce unnecessary radiation dose. MR-only radiotherapy also simplifies clinical workflow and avoids uncertainties in aligning MR with CT. Methods, however, are needed to derive CT-equivalent representations, often known as synthetic CT (sCT), from patient MR images for dose calculation and DRR-based patient positioning. Synthetic CT estimation is also important for PET attenuation correction in hybrid PET-MR systems. We propose in this work a novel deep convolutional neural network (DCNN) method for sCT generation and evaluate its performance on a set of brain tumor patient images.
Methods: The proposed method builds upon recent developments of deep learning and convolutional neural networks in the computer vision literature. The proposed DCNN model has 27 convolutional layers interleaved with pooling and unpooling layers and 35 million free parameters, which can be trained to learn a direct end-to-end mapping from MR images to their corresponding CTs. Training such a large model on our limited data is made possible through the principle of transfer learning and by initializing model weights from a pretrained model. Eighteen brain tumor patients with both CT and T1-weighted MR images are used as experimental data and a sixfold cross-validation study is performed. Each sCT generated is compared against the real CT image of the same patient on a voxel-by-voxel basis. Comparison is also made with respect to an atlas-based approach that involves deformable atlas registration and patch-based atlas fusion.
Results: The proposed DCNN method produced a mean absolute error (MAE) below 85 HU for 13 of the 18 test subjects. The overall average MAE was 84.8 {\AE} 17.3 HU for all subjects, which was found to be significantly better than the average MAE of 94.5 {\AE} 17.8 HU for the atlas-based method. The DCNN method also provided significantly better accuracy when being evaluated using two other metrics: the mean squared error (188.6 {\AE} 33.7 versus 198.3 {\AE} 33.0) and the Pearson correlation coefficient(0.906 {\AE} 0.03 versus 0.896 {\AE} 0.03). Although training a DCNN model can be slow, training only need be done once. Applying a trained model to generate a complete sCT volume for each new patient MR image only took 9 s, which was much faster than the atlas-based approach.
Conclusions: A DCNN model method was developed, and shown to be able to produce highly accurate sCT estimations from conventional, single-sequence MR images in near real time. Quantitative results also showed that the proposed method competed favorably with an atlas-based method, in terms of both accuracy and computation speed at test time. Further validation on dose computation accuracy and on a larger patient cohort is warranted. Extensions of the method are also possible to further improve accuracy or to handle multi-sequence MR images. {\textcopyright} 2017 American Association of Physicists in Medicine [https://doi.org/10.1002/mp.12155]},
  doi      = {10.1002/mp.12155},
  groups   = {img 2 img translation},
  keywords = {MRI, convolutional neural network, deep learning, radiation therapy, synthetic CT},
  language = {en},
  pmid     = {28192624},
  url      = {http://doi.wiley.com/10.1002/mp.12155},
}

@Article{Jin2017,
  author        = {Jin, Kyong Hwan and McCann, Michael T. and Froustey, Emmanuel and Unser, Michael},
  journal       = {IEEE Transactions on Image Processing},
  title         = {{Deep Convolutional Neural Network for Inverse Problems in Imaging}},
  year          = {2017},
  issn          = {1057-7149},
  month         = {sep},
  number        = {9},
  pages         = {4509--4522},
  volume        = {26},
  abstract      = {In this paper, we propose a novel deep convolutional neural network (CNN)-based algorithm for solving ill-posed inverse problems. Regularized iterative algorithms have emerged as the standard approach to ill-posed inverse problems in the past few decades. These methods produce excellent results, but can be challenging to deploy in practice due to factors including the high computational cost of the forward and adjoint operators and the difficulty of hyperparameter selection. The starting point of this paper is the observation that unrolled iterative methods have the form of a CNN (filtering followed by pointwise nonlinearity) when the normal operator (H*H, where H* is the adjoint of the forward imaging operator, H) of the forward model is a convolution. Based on this observation, we propose using direct inversion followed by a CNN to solve normal-convolutional inverse problems. The direct inversion encapsulates the physical model of the system, but leads to artifacts when the problem is ill posed; the CNN combines multiresolution decomposition and residual learning in order to learn to remove these artifacts while preserving image structure. We demonstrate the performance of the proposed network in sparse-view reconstruction (down to 50 views) on parallel beam X-ray computed tomography in synthetic phantoms as well as in real experimental sinograms. The proposed network outperforms total variation-regularized iterative reconstruction for the more realistic phantoms and requires less than a second to reconstruct a 512 × 512 image on the GPU.},
  archiveprefix = {arXiv},
  arxivid       = {arXiv:1611.03679v1},
  doi           = {10.1109/TIP.2017.2713099},
  eprint        = {arXiv:1611.03679v1},
  file          = {:home/antonio/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Jin et al. - 2016 - Deep Convolutional Neural Network for Inverse Problems in Imaging.pdf:pdf},
  groups        = {Inverse problems},
  keywords      = {CNN, Computed tomography, Convolution, GPU, Image reconstruction, Image restoration, Inverse problems, Iterative methods, Neural networks, adjoint operators, biomedical imaging, biomedical signal processing, computed tomography, computerised tomography, deep convolutional neural network, direct inversion, feedforward neural nets, forward model, forward operators, hyperparameter selection, ill-posed inverse problems, image reconstruction, image resolution, image structure, iterative methods, learning (artificial intelligence), magnetic resonance imaging, medical image processing, multiresolution decomposition, normal-convolutional inverse problems, parallel beam X-ray computed tomography, reconstruction algorithms, regularized iterative algorithms, residual learning, synthetic phantoms, tomography, total variation-regularized iterative reconstructi},
  mendeley-tags = {CNN,Computed tomography,Convolution,GPU,Image reconstruction,Image restoration,Inverse problems,Iterative methods,Neural networks,adjoint operators,biomedical imaging,biomedical signal processing,computed tomography,computerised tomography,deep convolutional neural network,direct inversion,feedforward neural nets,forward model,forward operators,hyperparameter selection,ill-posed inverse problems,image reconstruction,image resolution,image structure,iterative methods,learning (artificial intelligence),magnetic resonance imaging,medical image processing,multiresolution decomposition,normal-convolutional inverse problems,parallel beam X-ray computed tomography,reconstruction algorithms,regularized iterative algorithms,residual learning,synthetic phantoms,tomography,total variation-regularized iterative reconstructi},
  pmid          = {28641250},
}

@Article{Chen2020,
  author        = {Chen, Zhen and Xiu, Dongbin},
  journal       = {arXiv},
  title         = {{On generalized residue network for deep learning of unknown dynamical systems}},
  year          = {2020},
  issn          = {23318422},
  month         = {jan},
  pages         = {1--19},
  abstract      = {We present a general numerical approach for learning unknown dynamical systems using deep neural networks (DNNs). Our method is built upon recent studies that identified the residue network (ResNet) as an effective neural network structure. In this paper, we present a generalized ResNet framework and broadly define residue as the discrepancy between observation data and prediction made by another model, which can be an existing coarse model or reduced-order model. In this case, the generalized ResNet serves as a model correction to the existing model and recovers the unresolved dynamics. When an existing coarse model is not available, we present numerical strategies for fast creation of coarse models, to be used in conjunction with the generalized ResNet. These coarse models are constructed using the same data set and thus do not require additional resources. The generalized ResNet is capable of learning the underlying unknown equations and producing predictions with accuracy higher than the standard ResNet structure. This is demonstrated via several numerical examples, including long-term prediction of a chaotic system.},
  archiveprefix = {arXiv},
  arxivid       = {2002.02528},
  eprint        = {2002.02528},
  file          = {:home/antonio/Documents/bibliography/files/Chen, Xiu - 2020 - On generalized residue network for deep learning of unknown dynamical systems.pdf:pdf},
  groups        = {Dynamics and control},
  keywords      = {Computer Science - Machine Learning, Deep neural network, Governing equation discovery, Mathematics - Dynamical Systems, Mathematics - Numerical Analysis, Model correction, Residual network, Statistics - Machine Learning, deep neural network, governing equation discovery, model cor-, residual network},
  language      = {en},
  mendeley-tags = {Computer Science - Machine Learning,Mathematics - Dynamical Systems,Mathematics - Numerical Analysis,Statistics - Machine Learning},
  url           = {http://arxiv.org/abs/2002.02528},
}

@Article{Schlemper2018,
  author        = {Schlemper, Jo and Caballero, Jose and Hajnal, Joseph V. and Price, Anthony N. and Rueckert, Daniel},
  journal       = {IEEE Transactions on Medical Imaging},
  title         = {{A Deep Cascade of Convolutional Neural Networks for Dynamic MR Image Reconstruction}},
  year          = {2018},
  issn          = {1558254X},
  number        = {2},
  pages         = {491--503},
  volume        = {37},
  abstract      = {Inspired by recent advances in deep learning, we propose a framework for reconstructing dynamic sequences of 2-D cardiac magnetic resonance (MR) images from undersampled data using a deep cascade of convolutional neural networks (CNNs) to accelerate the data acquisition process. In particular, we address the case where data are acquired using aggressive Cartesian undersampling. First, we show that when each 2-D image frame is reconstructed independently, the proposed method outperforms state-of-the-art 2-D compressed sensing approaches, such as dictionary learning-based MR image reconstruction, in terms of reconstruction error and reconstruction speed. Second, when reconstructing the frames of the sequences jointly, we demonstrate that CNNs can learn spatio-temporal correlations efficiently by combining convolution and data sharing approaches. We show that the proposed method consistently outperforms state-of-the-art methods and is capable of preserving anatomical structure more faithfully up to 11-fold undersampling. Moreover, reconstruction is very fast: each complete dynamic sequence can be reconstructed in less than 10 s and, for the 2-D case, each image frame can be reconstructed in 23 ms, enabling real-time applications.},
  archiveprefix = {arXiv},
  arxivid       = {1704.02422},
  doi           = {10.1109/TMI.2017.2760978},
  eprint        = {1704.02422},
  file          = {:home/antonio/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Schlemper et al. - 2017 - A Deep Cascade of Convolutional Neural Networks for Dynamic MR Image Reconstruction.pdf:pdf;:home/antonio/Documents/bibliography/files/Schlemper et al. - 2018 - A Deep Cascade of Convolutional Neural Networks for Dynamic MR Image Reconstruction.pdf:pdf;:home/antonio/Documents/bibliography/files/Schlemper et al. - 2018 - A Deep Cascade of Convolutional Neural Networks for Dynamic MR Image Reconstruction(2).pdf:pdf},
  groups        = {Inverse problems},
  keywords      = {Deep learning, compressed sensing, convolutional neural network, dynamic magnetic resonance imaging, image reconstruction},
  pmid          = {29035212},
}

{B.~D.~Van~Veen1988,
abstract = {In this paper we introduce a new speckle tracking method that is based on the standard time-domain cross correlation strain estimation (TDE). We call this method time-domain cross-correlation with prior estimates (TDPE), because it uses prior displacement estimates of neighboring windows to speed up computation. TDPE has all the advantages of TDE, but is much faster. Simulations, as well as experiments with phantoms and tissue, indicate that TDPE is capable of reliably estimating tissue displacement and strain over a large range of displacements in real time.},
author = {B.$\sim$D.$\sim$Van$\sim$Veen and K.$\sim$M.$\sim$Buckley},
doi = {10.1109/TBME.2006.881780},
isbn = {0740-7467},
issn = {0018-9294, 1558-2531},
journal = {IEEE ASSP Magazine},
keywords = {Folder - Classical beamforming},
language = {en},
mendeley-tags = {Folder - Classical beamforming},
month = {oct},
number = {10},
pages = {4--24},
title = {{Beamforming: A Versatile Approach to Spatial Filtering}},
url = {http://ieeexplore.ieee.org/document/1703750/},
year = {1988}
}

@InProceedings{Besson2016,
  author        = {Besson, Adrien and Carrillo, Rafael E. and Bernard, Olivier and Wiaux, Yves and Thiran, Jean Philippe},
  booktitle     = {Proceedings - International Conference on Image Processing, ICIP},
  title         = {{Compressed delay-and-sum beamforming for ultrafast ultrasound imaging}},
  year          = {2016},
  number        = {10},
  pages         = {2509--2513},
  volume        = {2016-Augus},
  abstract      = {The theory of compressed sensing (CS) leverages upon structure of signals in order to reduce the number of samples needed to reconstruct a signal, compared to the Nyquist rate. Although CS approaches have been proposed for ultrasound (US) imaging with promising results, practical implementations are hard to achieve due to the impossibility to mimic random sampling on a US probe and to the high memory requirements of the measurement model. In this paper, we propose a CS framework for US imaging based on an easily implementable acquisition scheme and on a delay-and-sum measurement model.},
  doi           = {10.1109/ICIP.2016.7532811},
  groups        = {Classical US imaging},
  isbn          = {9781467399616},
  issn          = {15224880},
  keywords      = {Beamforming, Compressed sensing, Folder - Beamforming special, Folder - Correlation approaches, Folder - Side and grating lobes reduction, Ultrasound plane wave imaging},
  language      = {en},
  mendeley-tags = {Folder - Beamforming special,Folder - Correlation approaches,Folder - Side and grating lobes reduction},
  url           = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7532811},
}

@Article{,
  author        = {and Yang Gao},
  title         = {Perfect absorbing layers for wave scattering problems and related topics},
  pages         = {155},
  abstract      = {We compare recommenders based solely on low rank approximations of the rating matrix. The key diﬃculty lies in the sparseness of the known ratings within the matrix that cause expactation maximization algorithms converge very slow. Among the prior publicly known attempts for this problem a gradient boosting approach proved most successful in spite of the fact that the resulting vectors are nonorthogonal and prone to numeric errors. We systematically explore expectation maximization methods based both on the Lanczos algorithm and power iteration; novel in this paper is the eﬃcient handling of the dense estimate matrix used as input to a next iteration. We also compare sequence transformation methods to speed up convergence.},
  doi           = {10.32657/10356/137391},
  groups        = {Helmholtz and wave algorithms},
  keywords      = {Folder - problem_statement},
  language      = {en},
  mendeley-tags = {Folder - problem_statement},
}

@InProceedings{Jaderberg2015,
  author        = {Jaderberg, Max and Simonyan, Karen and Zisserman, Andrew and Kavukcuoglu, Koray},
  booktitle     = {Advances in Neural Information Processing Systems},
  title         = {{Spatial transformer networks}},
  year          = {2015},
  month         = {jun},
  number        = {Imi},
  pages         = {2017--2025},
  volume        = {2015-Janua},
  abstract      = {Convolutional Neural Networks define an exceptionally powerful class of models, but are still limited by the lack of ability to be spatially invariant to the input data in a computationally and parameter efficient manner.In this work we introduce a new learnable module, the Spatial Transformer, which explicitly allows the spatial manipulation of data within the network. This differentiable module can be inserted into existing convolutional architectures, giving neural networks the ability to actively spatially transform feature maps, conditional on the feature map itself, without any extra training supervision or modification to the optimisation process. We show that the use of spatial transformers results in models which learn invariance to translation, scale, rotation and more generic warping, resulting in state-of-the-art performance on several benchmarks, and for a number of classes of transformations.},
  archiveprefix = {arXiv},
  arxivid       = {1506.02025},
  eprint        = {1506.02025},
  groups        = {Attention},
  issn          = {10495258},
  keywords      = {- bapes, Computer Science - Computer Vision and Pattern Rec, Folder - 1D Doppler, adaptive spectral analysis, spectral},
  language      = {en},
  mendeley-tags = {- bapes,Computer Science - Computer Vision and Pattern Rec,Folder - 1D Doppler,adaptive spectral analysis,spectral},
  url           = {http://arxiv.org/abs/1506.02025},
}

@Article{Lediju2011,
  author        = {Lediju, Muyinatu A. and Trahey, Gregg E. and Byram, Brett C. and Dahl, Jeremy J.},
  journal       = {IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
  title         = {{Short-lag spatial coherence of backscattered echoes: Imaging characteristics}},
  year          = {2011},
  issn          = {08853010},
  month         = {may},
  number        = {7},
  pages         = {1377--1388},
  volume        = {58},
  abstract      = {Conventional ultrasound images are formed by delay-and-sum beamforming of the backscattered echoes received by individual elements of the transducer aperture. Although the delay-and-sum beamformer is well suited for ultrasound image formation, it is corrupted by speckle noise and challenged by acoustic clutter and phase aberration. We propose an alternative method of imaging utilizing the short-lag spatial coherence (SLSC) of the backscattered echoes. Compared with matched B-mode images, SLSC images demonstrate superior SNR and contrast-to-noise ratio in simulated and experimental speckle-generating phantom targets, but are shown to be challenged by limited point target conspicuity. Matched B-mode and SLSC images of a human thyroid are presented. The challenges and opportunities of real-time implementation of SLSC imaging are discussed. {\textcopyright} 2011 IEEE.},
  doi           = {10.1109/TUFFC.2011.1957},
  groups        = {Classical US imaging},
  keywords      = {Folder - Correlation approaches},
  language      = {en},
  mendeley-tags = {Folder - Correlation approaches},
  pmid          = {21768022},
  url           = {https://www.cambridge.org/core/product/identifier/S0962492919000059/type/journal_article},
}

@Book{Rubakov2009,
  author        = {Rubakov, Valery},
  publisher     = {Princeton University Press},
  title         = {{Classical Theory of Gauge Fields}},
  year          = {2009},
  address       = {Princeton, N.J},
  isbn          = {9780691059273},
  abstract      = {Based on a highly regarded lecture course at Moscow State University, this is a clear and systematic introduction to gauge field theory. It is unique in providing the means to master gauge field theory prior to the advanced study of quantum mechanics. Though gauge field theory is typically included in courses on quantum field theory, many of its ideas and results can be understood at the classical or semi-classical level. Accordingly, this book is organized so that its early chapters require no special knowledge of quantum mechanics. Aspects of gauge field theory relying on quantum mechanics are introduced only later and in a graduated fashion--making the text ideal for students studying gauge field theory and quantum mechanics simultaneously. The book begins with the basic concepts on which gauge field theory is built. It introduces gauge-invariant Lagrangians and describes the spectra of linear perturbations, including perturbations above nontrivial ground states. The second part focuses on the construction and interpretation of classical solutions that exist entirely due to the nonlinearity of field equations: solitons, bounces, instantons, and sphalerons. The third section considers some of the interesting effects that appear due to interactions of fermions with topological scalar and gauge fields. Mathematical digressions and numerous problems are included throughout. An appendix sketches the role of instantons as saddle points of Euclidean functional integral and related topics. Perfectly suited as an advanced undergraduate or beginning graduate text, this book is an excellent starting point for anyone seeking to understand gauge fields. {\textcopyright} 2002 by Princeton University Press. All Rights Reserved.},
  booktitle     = {Classical Theory of Gauge Fields},
  doi           = {10.1515/9781400825097},
  file          = {:home/antonio/Documents/bibliography/files/Rubakov - 2009 - Classical Theory of Gauge Fields.pdf:pdf},
  groups        = {Books},
  keywords      = {Gauge fields (Physics)},
  language      = {en},
  mendeley-tags = {Gauge fields (Physics)},
  pages         = {1--444},
}

@InProceedings{Mao2017,
  author        = {Mao, Xudong and Li, Qing and Xie, Haoran and Lau, Raymond Y.K. and Wang, Zhen and Smolley, Stephen Paul},
  booktitle     = {Proceedings of the IEEE International Conference on Computer Vision},
  title         = {{Least Squares Generative Adversarial Networks}},
  year          = {2017},
  number        = {November},
  pages         = {2813--2821},
  volume        = {2017-Octob},
  abstract      = {Unsupervised learning with generative adversarial networks (GANs) has proven hugely successful. Regular GANs hypothesize the discriminator as a classifier with the sigmoid cross entropy loss function. However, we found that this loss function may lead to the vanishing gradients problem during the learning process. To overcome such a problem, we propose in this paper the Least Squares Generative Adversarial Networks (LSGANs) which adopt the least squares loss function for the discriminator. We show that minimizing the objective function of LSGAN yields minimizing the Pearson X2 divergence. There are two benefits of LSGANs over regular GANs. First, LSGANs are able to generate higher quality images than regular GANs. Second, LSGANs perform more stable during the learning process. We evaluate LSGANs on LSUN and CIFAR-10 datasets and the experimental results show that the images generated by LSGANs are of better quality than the ones generated by regular GANs. We also conduct two comparison experiments between LSGANs and regular GANs to illustrate the stability of LSGANs.},
  archiveprefix = {arXiv},
  arxivid       = {1611.04076},
  doi           = {10.1109/ICCV.2017.304},
  eprint        = {1611.04076},
  groups        = {GANs},
  isbn          = {9781538610329},
  issn          = {15505499},
  keywords      = {Astrophysics - Cosmology and Nongalactic Astrophys, Computer Science - Computer Vision and Pattern Rec, Computer Science - Machine Learning, Folder - Classical beamforming, Physics - Data Analysis- Statistics and Probabilit, Statistics - Computation, Statistics - Machine Learning},
  language      = {en},
  mendeley-tags = {Astrophysics - Cosmology and Nongalactic Astrophys,Computer Science - Computer Vision and Pattern Rec,Computer Science - Machine Learning,Folder - Classical beamforming,Physics - Data Analysis- Statistics and Probabilit,Statistics - Computation,Statistics - Machine Learning},
  url           = {http://arxiv.org/abs/1611.04076 http://arxiv.org/abs/1901.04454},
}

@Misc{Tom2017,
  author        = {Tom, Francis and Sheet, Debdoot},
  month         = {dec},
  title         = {{Simulating patho-realistic ultrasound images using deep generative networks with adversarial learning}},
  year          = {2017},
  abstract      = {Ultrasound imaging makes use of backscattering of waves during their interaction with scatterers present in biological tissues. Simulation of synthetic ultrasound images is a challenging problem on account of inability to accurately model various factors of which some include intra-/inter scanline interference, transducer to surface coupling, artifacts on transducer elements, inhomogeneous shadowing and nonlinear attenuation. Current approaches typically solve wave space equations making them computationally expensive and slow to operate. We propose a generative adversarial network (GAN) inspired approach for fast simulation of patho-realistic ultrasound images. We apply the framework to intravascular ultrasound (IVUS) simulation. A stage 0 simulation performed using pseudo B-mode ultrasound image simulator yields speckle mapping of a digitally defined phantom. The stage I GAN subsequently refines them to preserve tissue specific speckle intensities. The stage II GAN further refines them to generate high resolution images with patho-realistic speckle profiles. We evaluate patho-realism of simulated images with a visual Turing test indicating an equivocal confusion in discriminating simulated from real. We also quantify the shift in tissue specific intensity distributions of the real and simulated images to prove their similarity.},
  booktitle     = {arXiv},
  groups        = {Ultrasound and wave imaging},
  issn          = {23318422},
  keywords      = {Adversarial learning, Computer Science - Computer Vision and Pattern Rec, Deep convolutional neural network, Generative adversarial network, Intravascular ultrasound, Ultrasound simulation},
  language      = {en},
  mendeley-tags = {Computer Science - Computer Vision and Pattern Rec},
  pages         = {1080--1084},
  publisher     = {IEEE},
  url           = {http://arxiv.org/abs/1712.07881},
}

@Article{Gammelmark2014,
  author        = {Gammelmark, Kim L{\o}kke and Jensen, J{\o}rgen Arendt},
  journal       = {IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
  title         = {{2-D tissue motion compensation of synthetic transmit aperture images}},
  year          = {2014},
  issn          = {08853010},
  number        = {4},
  pages         = {594--610},
  volume        = {61},
  abstract      = {Synthetic transmit aperture (STA) imaging is susceptible to tissue motion because it uses summation of low-resolution images to create the displayed high-resolution image. A method for 2-D tissue motion correction in STA imaging is presented. It utilizes the correlation between highresolution images recorded using the same emission sequence. The velocity and direction of the motion are found by cross correlating short high-resolution lines beamformed along selected angles. The motion acquisition is interleaved with the regular B-mode emissions in STA imaging, and the motion compensation is performed by tracking each pixel in the reconstructed image using the estimated velocity and direction. The method is evaluated using simulations, and phantom and in vivo experiments. In phantoms, a tissue velocity of 15 cm/s at a 45° angle was estimated with relative bias and standard deviation of -6.9% and 5.4%; the direction was estimated with relative bias and standard deviation of -8.4% and 6.6%. The contrast resolution in the corrected image was -0.65% lower than the reference image. Abdominal in vivo experiments with induced transducer motion demonstrate that severe tissue motion can be compensated for, and that doing so yields a significant increase in image quality. {\textcopyright} 1986-2012 IEEE.},
  doi           = {10.1109/TUFFC.2014.2948},
  groups        = {Motion},
  keywords      = {Finite element method, Folder - problem_statement, Helmholtz equation, Motion compensation, Perfectly matched layer, Time-harmonic scattering, contrast agents, contrast enhanced ultrasound, motion compensation, neovascularization},
  language      = {en},
  mendeley-tags = {Folder - problem_statement,Motion compensation,contrast agents,contrast enhanced ultrasound,motion compensation,neovascularization},
  url           = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6822987 https://linkinghub.elsevier.com/retrieve/pii/S0021999106004487},
}

@Article{Lusch2018,
  author        = {Lusch, Bethany and Kutz, J. Nathan and Brunton, Steven L.},
  journal       = {Nature Communications},
  title         = {{Deep learning for universal linear embeddings of nonlinear dynamics}},
  year          = {2018},
  issn          = {20411723},
  month         = {dec},
  number        = {1},
  pages         = {4950},
  volume        = {9},
  abstract      = {Identifying coordinate transformations that make strongly nonlinear dynamics approximately linear has the potential to enable nonlinear prediction, estimation, and control using linear theory. The Koopman operator is a leading data-driven embedding, and its eigenfunctions provide intrinsic coordinates that globally linearize the dynamics. However, identifying and representing these eigenfunctions has proven challenging. This work leverages deep learning to discover representations of Koopman eigenfunctions from data. Our network is parsimonious and interpretable by construction, embedding the dynamics on a low-dimensional manifold. We identify nonlinear coordinates on which the dynamics are globally linear using a modified auto-encoder. We also generalize Koopman representations to include a ubiquitous class of systems with continuous spectra. Our framework parametrizes the continuous frequency using an auxiliary network, enabling a compact and efficient embedding, while connecting our models to decades of asymptotics. Thus, we benefit from the power of deep learning, while retaining the physical interpretability of Koopman embeddings.},
  archiveprefix = {arXiv},
  arxivid       = {1712.09707},
  doi           = {10.1038/s41467-018-07210-0},
  eprint        = {1712.09707},
  file          = {:home/antonio/Documents/bibliography/files/Lusch, Kutz, Brunton - 2018 - Deep learning for universal linear embeddings of nonlinear dynamics.pdf:pdf},
  groups        = {Latent},
  language      = {en},
  pmid          = {30470743},
  url           = {http://www.nature.com/articles/s41467-018-07210-0},
}

@Article{Matrone2015,
  author        = {Matrone, Giulia and Savoia, Alessandro Stuart and Caliano, Giosue and Magenes, Giovanni},
  journal       = {IEEE Transactions on Medical Imaging},
  title         = {{The delay multiply and sum beamforming algorithm in ultrasound B-mode medical imaging}},
  year          = {2015},
  issn          = {1558254X},
  month         = {aug},
  number        = {4},
  pages         = {940--949},
  volume        = {34},
  abstract      = {Most of ultrasound medical imaging systems currently on the market implement standard Delay and Sum (DAS) beamforming to form B-mode images. However, image resolution and contrast achievable with DAS are limited by the aperture size and by the operating frequency. For this reason, different beamformers have been presented in the literature that are mainly based on adaptive algorithms, which allow achieving higher performance at the cost of an increased computational complexity. In this paper, we propose the use of an alternative nonlinear beamforming algorithm for medical ultrasound imaging, which is called Delay Multiply and Sum (DMAS) and that was originally conceived for a RADAR microwave system for breast cancer detection. We modify the DMAS beamformer and test its performance on both simulated and experimentally collected linear-scan data, by comparing the Point Spread Functions, beampatterns, synthetic phantom and in vivo carotid artery images obtained with standard DAS and with the proposed algorithm. Results show that the DMAS beamformer outperforms DAS in both simulated and experimental trials and that the main improvement brought about by this new method is a significantly higher contrast resolution (i.e., narrower main lobe and lower side lobes), which turns out into an increased dynamic range and better quality of B-mode images.},
  doi           = {10.1109/TMI.2014.2371235},
  groups        = {Classical US imaging},
  keywords      = {Beamforming, Folder - Beamforming special, Folder - Contrast agents doppler, contrast resolution, delay multiply and sum, ultrasound medical imaging},
  language      = {en},
  mendeley-tags = {Folder - Beamforming special,Folder - Contrast agents doppler},
  pmid          = {25420256},
  url           = {http://link.springer.com/10.1007/s11517-008-0423-y},
}

@Article{Ahmed2016,
  author        = {Ahmed, Rifat and Arfin, Rishad and Rubel, Monir Hossan and Islam, Kazi Khairul and Jia, Congxian and Metaxas, Dimitris and Garra, Brian S. and Alam, S. Kaisar},
  journal       = {Ultrasonics},
  title         = {{Comparison of windowing effects on elastography images: Simulation, phantom and in vivo studies}},
  year          = {2016},
  issn          = {0041624X},
  month         = {dec},
  pages         = {140--153},
  volume        = {66},
  abstract      = {In this paper, we have evaluated the use of smooth windows for ultrasound elastography. In ultrasound elastography, local tissue strain is estimated using operations such as cross-correlation on local segments of RF data. In this process, local data segments are selected by multiplying the RF data by a rectangular window. Such data truncation causes non-ideal spectral behavior, which can be mitigated by using smooth windows. Accordingly, we hypothesize that the use of smooth windows may improve the elastographic signal-to-noise ratio (SNRe) and contrast-to-noise ratio (CNRe) of strain images. The effects of using smooth windows have not been fully characterized for time-domain strain estimators. Thus, we have compared the elastographic performance of rectangular, Hanning, Gaussian, and Chebyshev windows used in conjunction with cross-correlation based algorithm and adaptive stretching algorithm using finite element method (FEM) simulation, experimental phantom, and in vivo data. Smooth windows are found to improve the SNRe by up to 3.94 for FEM data and by up to 1.76 for phantom data which represent 76% and 60.52% improvements, respectively. CNRe improves by up to 12.23 for FEM simulated data and by up to 4.28 for phantom data which represent 213.07% and 248.2% improvements, respectively. Mean structural similarity (MSSIM) was used for assessing the image perceptual quality and smooth windows improved it by up to 0.22 (85.98% improvement) for simulated data. We have evaluated these parameters at 1-6% applied strains for the experimental phantom and at 1%, 2%, 4%, 6%, 8%, and 12% applied strains for FEM simulation. We observed a maximum deterioration in axial resolution of 0.375 mm (which is on the order of the wavelength, 0.3 mm) due to smooth windows. "Salt-and-pepper" noise from false-peak errors has also been reduced. Smooth windows increased the lesion-to-background contrast (by increasing the CNRe by 213.07%) of a low contrast lesion (10-dB). For the in vivo cases, use of smooth windows resulted in better depiction of lesions, which is important for lesion classification. In this work, we have used an ATL Ultramark 9 scanner with an L10-5 (7.5 MHz) probe for the phantom experiment and a Sonix SP500 scanner with an L14-5/38 probe (10 MHz) for in vivo data collection.},
  doi           = {10.1016/j.ultras.2015.11.001},
  groups        = {Classical US imaging},
  keywords      = {Computer Science - Machine Learning, Data window, Elastography, Electrical Engineering and Systems Science - Image, Physics - Geophysics, Spectral leakage, Statistics - Machine Learning, Strain, Ultrasound},
  language      = {en},
  mendeley-tags = {Computer Science - Machine Learning,Data window,Elastography,Electrical Engineering and Systems Science - Image,Physics - Geophysics,Spectral leakage,Statistics - Machine Learning,Strain,Ultrasound},
  pmid          = {26647169},
  url           = {http://dx.doi.org/10.1016/j.ultras.2015.11.001 http://arxiv.org/abs/1909.06473},
}

@Article{Mattheakis2019,
  author        = {Mattheakis, M. and Protopapas, P. and Sondak, D. and {Di Giovanni}, M. and Kaxiras, E.},
  journal       = {arXiv},
  title         = {{Physical Symmetries Embedded in Neural Networks}},
  year          = {2019},
  issn          = {23318422},
  month         = {jan},
  pages         = {1--16},
  abstract      = {Neural networks are a central technique in machine learning. Recent years have seen a wave of interest in applying neural networks to physical systems for which the governing dynamics are known and expressed through differential equations. Two fundamental challenges facing the development of neural networks in physics applications is their lack of interpretability and their physics-agnostic design. The focus of the present work is to embed physical constraints into the structure of the neural network to address the second fundamental challenge. By constraining tunable parameters (such as weights and biases) and adding special layers to the network, the desired constraints are guaranteed to be satisfied without the need for explicit regularization terms. This is demonstrated on supervised and unsupervised networks for two basic symmetries: even/odd symmetry of a function and energy conservation. In the supervised case, the network with embedded constraints is shown to perform well on regression problems while simultaneously obeying the desired constraints whereas a traditional network fits the data but violates the underlying constraints. Finally, a new unsupervised neural network is proposed that guarantees energy conservation through an embedded symplectic structure. The symplectic neural network is used to solve a system of energy-conserving differential equations and outperforms an unsupervised, non-symplectic neural network.},
  archiveprefix = {arXiv},
  arxivid       = {1904.08991},
  eprint        = {1904.08991},
  file          = {:home/antonio/Documents/bibliography/files/Mattheakis et al. - 2019 - Physical Symmetries Embedded in Neural Networks.pdf:pdf},
  groups        = {Representation, architectures and DL layers},
  keywords      = {Computer Science - Machine Learning, Constraints, Differential equations, Energy conservation, Physics - Computational Physics, constraints, differential equations, energy conservation},
  language      = {en},
  mendeley-tags = {Computer Science - Machine Learning,Physics - Computational Physics},
  url           = {http://arxiv.org/abs/1904.08991},
}

@Article{Haber2018,
  author        = {Haber, Eldad and Ruthotto, Lars},
  journal       = {Inverse Problems},
  title         = {{Stable architectures for deep neural networks}},
  year          = {2018},
  issn          = {13616420},
  number        = {1},
  pages         = {1--22},
  volume        = {34},
  abstract      = {Deep neural networks have become invaluable tools for supervised machine learning, e.g. classification of text or images. While often offering superior results over traditional techniques and successfully expressing complicated patterns in data, deep architectures are known to be challenging to design and train such that they generalize well to new data. Critical issues with deep architectures are numerical instabilities in derivative-based learning algorithms commonly called exploding or vanishing gradients. In this paper, we propose new forward propagation techniques inspired by systems of ordinary differential equations (ODE) that overcome this challenge and lead to well-posed learning problems for arbitrarily deep networks. The backbone of our approach is our interpretation of deep learning as a parameter estimation problem of nonlinear dynamical systems. Given this formulation, we analyze stability and well-posedness of deep learning and use this new understanding to develop new network architectures. We relate the exploding and vanishing gradient phenomenon to the stability of the discrete ODE and present several strategies for stabilizing deep learning for very deep networks. While our new architectures restrict the solution space, several numerical experiments show their competitiveness with state-of-the-art networks.},
  archiveprefix = {arXiv},
  arxivid       = {1705.03341},
  doi           = {10.1088/1361-6420/aa9a90},
  eprint        = {1705.03341},
  file          = {:home/antonio/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Haber, Ruthotto - 2017 - Stable Architectures for Deep Neural Networks.pdf:pdf;:home/antonio/Documents/bibliography/files/Haber, Ruthotto - 2018 - Stable architectures for deep neural networks.pdf:pdf},
  groups        = {Representation, architectures and DL layers},
  keywords      = {PDE-constrained optimization, deep neural networks, dynamic inverse problems, image classification, machine learning, optimization, parameter estimation, pde-constrained},
  publisher     = {IOP Publishing},
}

@Article{Bertocchi2018,
  author        = {Bertocchi, C. and Chouzenoux, E. and Corbineau, M. C. and Pesquet, J. C. and Prato, M.},
  journal       = {arXiv},
  title         = {{Deep unfolding of a proximal interior point method for image restoration}},
  year          = {2018},
  issn          = {23318422},
  month         = {dec},
  pages         = {5},
  abstract      = {Variational methods are widely applied to ill-posed inverse problems for they have the ability to embed prior knowledge about the solution. However, the level of performance of these methods significantly depends on a set of parameters, which can be estimated through computationally expensive and time-consuming methods. In contrast, deep learning offers very generic and efficient architectures, at the expense of explainability, since it is often used as a black-box, without any fine control over its output. Deep unfolding provides a convenient approach to combine variational-based and deep learning approaches. Starting from a variational formulation for image restoration, we develop iRestNet, a neural network architecture obtained by unfolding a proximal interior point algorithm. Hard constraints, encoding desirable properties for the restored image, are incorporated into the network thanks to a logarithmic barrier, while the barrier parameter, the stepsize, and the penalization weight are learned by the network. We derive explicit expressions for the gradient of the proximity operator for various choices of constraints, which allows training iRestNet with gradient descent and backpropagation. In addition, we provide theoretical results regarding the stability of the network for a common inverse problem example. Numerical experiments on image deblurring problems show that the proposed approach compares favorably with both state-of-the-art variational and machine learning methods in terms of image quality.},
  archiveprefix = {arXiv},
  arxivid       = {1812.04276},
  eprint        = {1812.04276},
  groups        = {Inverse problems},
  keywords      = {Computer Science - Machine Learning, Deep unfolding, Image restoration, Interior point method, Mathematics - Optimization and Control, Neural network, Proximal algorithms, Regularization},
  language      = {en},
  mendeley-tags = {Computer Science - Machine Learning,Mathematics - Optimization and Control},
  url           = {http://arxiv.org/abs/1812.04276},
}

@Misc{Prokopenko2019,
  author        = {Prokopenko, Denis and Stadelmann, Jo{\"{e}}l Valentin and Schulz, Heinrich and Renisch, Steffen and Dylov, Dmitry V.},
  title         = {{Synthetic CT generation from MRI using improved DualGAN}},
  year          = {2019},
  abstract      = {Synthetic CT image generation from MRI scan is necessary to create radiotherapy plans without the need of co-registered MRI and CT scans. The chosen baseline adversarial model with cycle consistency permits unpaired image-to-image translation. Perceptual loss function term and coordinate convolutional layer were added to improve the quality of translated images. The proposed architecture was tested on paired MRI-CT dataset, where the synthetic CTs were compared to corresponding original CT images. The MAE between the synthetic CT images and the real CT scans is 61 HU computed inside of the true CTs body shape.},
  archiveprefix = {arXiv},
  arxivid       = {1909.08942},
  booktitle     = {arXiv},
  eprint        = {1909.08942},
  groups        = {GANs, img 2 img translation},
  issn          = {23318422},
  keywords      = {Computed Tomography, Deep Learning, Machine Learning, Magnetic Resonance Imaging, Radiology},
  language      = {en},
  pages         = {5},
}

@Article{Robertson2018,
  author    = {Robertson, James and Urban, Jillian and Stitzel, Joel and Treeby, Bradley E.},
  journal   = {Physics in Medicine and Biology},
  title     = {{The effects of image homogenisation on simulated transcranial ultrasound propagation}},
  year      = {2018},
  issn      = {13616560},
  month     = {jul},
  number    = {14},
  pages     = {145014},
  volume    = {63},
  abstract  = {Transcranial transmission of ultrasound is increasingly used in a variety of clinical and research applications, including high intensity ablation, opening the blood brain barrier, and neural stimulation. Numerical simulations of ultrasound propagation in the head are used to enable effective transcranial focusing and predict intracranial fields. Such simulations require maps of the acoustic properties of the head, which can be derived from clinical CT images. However, the spatial resolution of these images is typically coarser than the scale of heterogeneities within the skull bone, which are known to exert a major influence on ultrasound propagation. In the present work, the impact of image related homogenisation on transcranial transmission from a single element transducer is examined using a dataset of co-registered clinical resolution CT and micro-CT images of skull sections. Reference acoustic property maps are derived from micro-CT images of cortical bone tissue. The influence of imaging resolution is examined by progressively downsampling the segmented acoustic property maps, and through comparison with maps derived from co-registered clinical CT images. The influence of different methods of segmenting the bone volume from the clinical CT images, and for resampling the clinical and micro-CT data are also examined. Image related homogenisation is demonstrated to have a substantial effect on the transcranial transmission of ultrasound, resulting in underestimations of simulated transmission loss and time-of flight. Effects on time-of flight are due to the loss of the internal scattering microstructure of the skull, while changes in transmitted ultrasound amplitude are due to both loss of microstructure and other smoothing effects. Inflating the simulated attenuation coefficient of the skull layer reduces the error in transmitted pressure amplitude to around 40%, however this is unable to correct fully for errors in time of flight and the pressure distribution of the transmitted field.},
  doi       = {10.1088/1361-6560/aacc33},
  file      = {:home/antonio/Documents/bibliography/files/Robertson et al. - 2018 - The effects of image homogenisation on simulated transcranial ultrasound propagation.pdf:pdf},
  groups    = {Experimental},
  keywords  = {acoustic simulation, co-registered CT data, numerical methods, pseudospectral methods, transcranial ultrasound},
  language  = {en},
  pmid      = {29897047},
  publisher = {IOP Publishing},
  url       = {https://iopscience.iop.org/article/10.1088/1361-6560/aacc33},
}

@Article{Stanziola2018,
  author        = {Stanziola, Antonio and Leow, Chee Hau and Bazigou, Eleni and Weinberg, Peter D. and Tang, Meng Xing},
  journal       = {IEEE Transactions on Medical Imaging},
  title         = {{ASAP: Super-Contrast Vasculature Imaging Using Coherence Analysis and High Frame-Rate Contrast Enhanced Ultrasound}},
  year          = {2018},
  issn          = {1558254X},
  number        = {8},
  pages         = {1847--1856},
  volume        = {37},
  abstract      = {The very high frame rate afforded by ultrafast ultrasound, combined with microbubble contrast agents, opens new opportunities for imaging tissue microvasculature. However, new imaging paradigms are required to obtain superior image quality from the large amount of acquired data while allowing real-time implementation. In this paper, we report a technique-acoustic sub-aperture processing (ASAP)-capable of generating very high contrast/signal-to-noise ratio (SNR) images of macro-and microvessels, with similar computational complexity to classical power Doppler (PD) imaging. In ASAP, the received data are split into subgroups. The reconstructed data from each subgroup are temporally correlated over frames to generate the final image. As signals in subgroups are correlated but the noise is not, this substantially reduces the noise floor compared to PD. Using a clinical imaging probe, the method is shown to visualize vessels down to 200$\mu$m with a SNR of 10 dB higher than PD and to resolve microvascular flow/perfusion information in rabbit kidneys noninvasively in vivo at multiple centimeter depths. With careful filter design, the technique also allows the estimation of flow direction and the separation of fast flow from tissue perfusion. ASAP can readily be implemented into hardware/firmware for real-time imaging and can be applied to contrast enhanced and potentially noncontrast imaging and 3-D imaging.},
  doi           = {10.1109/TMI.2018.2798158},
  groups        = {Classical US imaging},
  isbn          = {978-3-319-02584-1},
  keywords      = {SNR, Ultrasound, biomedical ultrasonics, blood vessels, classical power Doppler imaging, coherence, coherence analysis, contrast, high-contrast signal-to-noise ratio, image enhancement, imaging paradigms, in vivo, kidney, macroand microvessels, medical image processing, microbubble contrast agents, microbubbles, microvascular flow, noise floor, perfusion information, real-time imaging, real-time implementation, reconstructed data, super-contrast vasculature imaging, superior image quality, technique-acoustic subaperture processing-capable, tissue microvasculature, tissue perfusion, ultrafast ultrasound, ultrasonic imaging, vascular imaging},
  mendeley-tags = {SNR,Ultrasound,biomedical ultrasonics,blood vessels,classical power Doppler imaging,coherence,coherence analysis,contrast,high-contrast signal-to-noise ratio,image enhancement,imaging paradigms,in vivo,kidney,macroand microvessels,medical image processing,microbubble contrast agents,microbubbles,microvascular flow,noise floor,perfusion information,real-time imaging,real-time implementation,reconstructed data,super-contrast vasculature imaging,superior image quality,technique-acoustic subaperture processing-capable,tissue microvasculature,tissue perfusion,ultrafast ultrasound,ultrasonic imaging,vascular imaging},
  pmid          = {29994061},
  url           = {http://link.springer.com/10.1007/978-3-319-02585-8},
}

@Article{Kaelbling2017,
  author = {Kaelbling, Leslie Pack},
  title  = {{Generalization in Deep Learning}},
  year   = {2017},
  file   = {:home/antonio/Documents/bibliography/files/Kaelbling - Unknown - Generalization in Deep Learning.pdf:pdf;:home/antonio/Documents/bibliography/files/Kaelbling - 2017 - Generalization in Deep Learning.pdf:pdf},
  groups = {General deep learning},
}

@Article{Ta2014,
  author        = {Ta, Casey N. and Eghtedari, Mohammad and Mattrey, Robert F. and Kono, Yuko and Kummel, Andrew C.},
  journal       = {Investigative Radiology},
  title         = {{2-Tier in-plane motion correction and out-of-plane motion filtering for contrast-enhanced ultrasound}},
  year          = {2014},
  issn          = {15360210},
  number        = {11},
  pages         = {707--719},
  volume        = {49},
  abstract      = {Objectives: Contrast-enhanced ultrasound (CEUS) cines of focal liver lesions (FLLs) can be quantitatively analyzed to measure tumor perfusion on a pixelby-pixel basis for diagnostic indication. However, CEUS cines acquired freehand and during free breathing cause nonuniform in-plane and out-of-plane motion from frame to frame. These motions create fluctuations in the time-intensity curves (TICs), reducing the accuracy of quantitative measurements. Out-of-plane motion cannot be corrected by image registration in 2-dimensional CEUS and degrades the quality of in-plane motion correction (IPMC). A 2-tier IPMC strategy and adaptive out-of-plane motion filter (OPMF) are proposed to provide a stable correction of nonuniform motion to reduce the impact of motion on quantitative analyses. Materials and Methods: A total of 22 cines of FLLs were imaged with dual B-mode and contrast specific imaging to acquire a 3-minute TIC. B-mode images were analyzed for motion, and the motion correction was applied to both B-mode and contrast images. For IPMC, the main reference frame was automatically selected for each cine, and subreference frames were selected in each respiratory cycle and sequentially registered toward the main reference frame. All other frames were sequentially registered toward the local subreference frame. Four OPMFs were developed and tested: subsample normalized correlation (NC), subsample sum of absolute differences, mean frame NC, and histogram. The frames that were most dissimilar to the OPMF reference frame using 1 of the 4 above criteria in each respiratory cycle were adaptively removed by thresholding against the low-pass filter of the similarity curve. Out-of-plane motion filter was quantitatively evaluated by an out-ofplane motion metric (OPMM) that measured normalized variance in the high-pass filtered TIC within the tumor region-of-interest with low OPMM being the goal. Results for IPMC and OPMF were qualitatively evaluated by 2 blinded observers who ranked the motion in the cines before and after various combinations of motion correction steps. Results: Quantitative measurements showed that 2-tier IPMC and OPMF improved imaging stability. With IPMC, the NC B-mode metric increased from 0.504 ± 0.149 to 0.585 ± 0.145 over all cines (P < 0.001). Two-tier IPMC also produced better fits on the contrast-specific TIC than industry standard IPMC techniques did (P < 0.02). In-plane motion correction and OPMF were shown to improve goodness of fit for pixel-by-pixel analysis (P < 0.001). Outof-plane motion filter reduced variance in the contrast-specific signal as shown by a median decrease of 49.8% in the OPMM. Two-tier IPMC and OPMF were also shown to qualitatively reduce motion. Observers consistently ranked cines with IPMC higher than the same cine before IPMC (P < 0.001) as well as ranked cines with OPMF higher than when they were uncorrected. Conclusion: The 2-tier sequential IPMC and adaptive OPMF significantly reduced motion in 3-minute CEUS cines of FLLs, thereby overcoming the challenges of drift and irregular breathing motion in long cines. The 2-tier IPMC strategy provided stable motion correction tolerant of out-of-plane motion throughout the cine by sequentially registering subreference frames that bypassed the motion cycles, thereby overcoming the lack of a nearly stationary reference point in long cines. Out-of-plane motion filter reduced apparent motion by adaptively removing frames imaged off-plane from the automatically selected OPMF reference frame, thereby tolerating nonuniform breathing motion. Selection of the best OPMF by minimizing OPMM effectively reduced motion under a wide variety of motion patterns applicable to clinical CEUS. These semiautomated processes only required user input for region-of-interest selection and can improve the accuracy of quantitative perfusion measurements.},
  doi           = {10.1097/RLI.0000000000000074},
  groups        = {Classical US imaging},
  keywords      = {00, 00 y 00, 2013, 22, 2d ultrasound, Contrast-enhanced ultrasound, Free breathing, Image registration, Motion correction, after revision, and accepted for publication, ceus, contrast-enhanced ultrasound, focal liver lesions, free breathing, image, invest radiol 2014, motion compensation, motion correction, mrf, perfusion imaging, received for publication may, registration},
  mendeley-tags = {00,00 y 00,2013,22,2d ultrasound,after revision,and accepted for publication,ceus,contrast-enhanced ultrasound,focal liver lesions,free breathing,image,invest radiol 2014,motion compensation,motion correction,mrf,perfusion imaging,received for publication may,registration},
  pmid          = {24901545},
  url           = {http://www.ncbi.nlm.nih.gov/pubmed/24901545},
}

@Article{Viola2008,
  author        = {Viola, Francesco and Ellis, Michael A. and Walker, William F.},
  journal       = {IEEE Transactions on Medical Imaging},
  title         = {{Time-domain optimized near-field estimator for ultrasound imaging: Initial development and results}},
  year          = {2008},
  issn          = {02780062},
  number        = {1},
  pages         = {99--110},
  volume        = {27},
  abstract      = {For nearly four decades, adaptive beamforming (ABF) algorithms have been applied in RADAR and SONAR signal processing. These algorithms reduce the contribution of undesired offaxis signals while maintaining a desired response along a specific look direction. Typically, higher resolution and contrast is attainable using adaptive beamforming at the price of an increased computational load. In this paper, we describe a novel ABF designed for medical ultrasound, named the Time-domain Optimized Nearfield Estimator (TONE). We performed a series of simulations using synthetic ultrasound data to test the performance of this algorithm and compared it to conventional, data independent, delay and sum beamforming (CBF) method. We also performed experiments using a Philips SONOS 5500 phased array imaging system. CBF was applied using the default parameters of the Philips scanner, whereas TONE was applied on per channel, unfocused data using an unfocused transmit beam. TONE images were reconstructed at a sampling of 67 $\mu$m laterally and 19 $\mu$m axially. The results obtained for a series of five 20-$\mu$m wires in a water tank show a significant improvement in spatial resolution when compared to CBF. We also analyzed the performance of TONE as a function of speed of sound errors and array sparsity, finding it robust to both. {\textcopyright} 2007 IEEE.},
  doi           = {10.1109/TMI.2007.903579},
  groups        = {Classical US imaging},
  keywords      = {Beamforming, Folder - Beamforming special, Image reconstruction, Ultrasound imaging, colorectal tumor, hepatoma, hsv, immunotherapy, oncolytic therapy},
  mendeley-tags = {Folder - Beamforming special,colorectal tumor,hepatoma,hsv,immunotherapy,oncolytic therapy},
  pmid          = {18270066},
}

@Misc{Bradbury2018,
  author = {Bradbury, James and Frostig, Roy and Hawkins, Peter and Johnson, Matthew James and Leary, Chris and Maclaurin, Dougal and Necula, George and Paszke, Adam and VanderPlas, Jake and Wanderman-Milne, Skye and Zhang, Qiao},
  title  = {{{JAX}: composable transformations of {P}ython+{N}um{P}y programs}},
  year   = {2018},
  groups = {Differentiable programming and simulation},
  url    = {http://github.com/google/jax},
}

@Article{Kidger2020,
  author        = {Kidger, Patrick and Chen, Ricky T.Q. and Lyons, Terry},
  journal       = {arXiv},
  title         = {{Hey, that's not an ODE}},
  year          = {2020},
  issn          = {23318422},
  number        = {2018},
  pages         = {1--11},
  abstract      = {Neural differential equations may be trained by backpropagating gradients via the adjoint method, which is another differential equation typically solved using an adaptive-step-size numerical differential equation solver. A proposed step is accepted if its error, relative to some norm, is sufficiently small; else it is rejected, the step is shrunk, and the process is repeated. Here, we demonstrate that the particular structure of the adjoint equations makes the usual choices of norm (such as L2) unnecessarily stringent. By replacing it with a more appropriate (semi)norm, fewer steps are unnecessarily rejected and the backpropagation is made faster. This requires only minor code modifications. Experiments on a wide range of tasks—including time series, generative modeling, and physical control—demonstrate a median improvement of 40% fewer function evaluations. On some problems we see as much as 62% fewer function evaluations, so that the overall training time is roughly halved.},
  archiveprefix = {arXiv},
  arxivid       = {arXiv:2009.09457v1},
  eprint        = {arXiv:2009.09457v1},
  file          = {:home/antonio/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kidger, Chen, Lyons - 2020 - Hey, that's not an ODE.pdf:pdf},
  groups        = {Normalizing flows},
}

@Article{2012,
  journal       = {IEEE Transactions on Signal Processing},
  title         = {{Learning beamforming in ultrasound imaging}},
  year          = {2012},
  issn          = {1053587X},
  number        = {9},
  pages         = {19},
  volume        = {60},
  abstract      = {Medical ultrasound (US) is a widespread imaging modality owing its popularity to cost efﬁciency, portability, speed, and lack of harmful ionizing radiation. In this paper, we demonstrate that replacing the traditional ultrasound processing pipeline with a data-driven, learnable counterpart leads to signiﬁcant improvement in image quality. Moreover, we demonstrate that greater improvement can be achieved through a learning-based design of the transmitted beam patterns simultaneously with learning an image reconstruction pipeline. We evaluate our method on an in-vivo ﬁrst-harmonic cardiac ultrasound dataset acquired from volunteers and demonstrate the signiﬁcance of the learned pipeline and transmit beam patterns on the image quality when compared to standard transmit and receive beamformers used in high frame-rate US imaging. We believe that the presented methodology provides a fundamentally different perspective on the classical problem of ultrasound beam pattern design.},
  doi           = {10.1109/TSP.2012.2200891},
  groups        = {Classical US imaging},
  keywords      = {Array processing, Folder - Beamforming special, Xampling, beamforming, compressed sensing (CS), finite rate of innovation (FRI), ultrasound},
  language      = {en},
  mendeley-tags = {Array processing,Folder - Beamforming special,Xampling,beamforming,compressed sensing (CS),finite rate of innovation (FRI),ultrasound},
}

@Article{Pitocchi2020,
  author    = {Pitocchi, Jonathan and Wirix-Speetjens, Roel and van Lenthe, G. Harry and P{\'{e}}rez, Mar{\'{i}}a {\'{A}}ngeles},
  journal   = {Computer Methods in Biomechanics and Biomedical Engineering},
  title     = {{Integration of cortical thickness data in a statistical shape model of the scapula}},
  year      = {2020},
  issn      = {14768259},
  number    = {10},
  pages     = {642--648},
  volume    = {23},
  abstract  = {Knowledge about bone morphology and bone quality of the scapula throughout the population is fundamental in the design of shoulder implants. In particular, regions with the best bone stock (cortical bone) are taken into account when planning the supporting screws, aiming for an optimal fixation. As an alternative to manual measurements, statistical shape models (SSMs) have been commonly used to describe shape variability within a population. However, explicitly including cortical thickness information in an SSM of the scapula still remains a challenge. Therefore, the goal of this study is to combine scapular bone shape and cortex morphology in an SSM. First, a method to estimate cortical thickness, based on HU (Hounsfield Unit) profile analysis, was developed and validated. Then, based on the manual segmentations of 32 healthy scapulae, a statistical shape model including cortical information was created and evaluated. Generalization, specificity and compactness were calculated in order to assess the quality of the SSM. The average cortical thickness of the SSM was 2.0 ± 0.63 mm. Generalization, specificity and compactness performances confirmed that the combined SSM was able to capture the bone quality changes in the population. In this work we integrated information on the cortical thickness in an SSM for the scapula. From the results we conclude that this methodology is a valuable tool for automatically generating a large population of scapulae and deducing statistics on the cortex. Hence, this SSM can be useful to automate implant design and screw placement in shoulder arthroplasty.},
  doi       = {10.1080/10255842.2020.1757082},
  file      = {:home/antonio/Documents/bibliography/files/Pitocchi et al. - 2020 - Integration of cortical thickness data in a statistical shape model of the scapula.pdf:pdf},
  groups    = {Computer Vision},
  keywords  = {Statistical shape model, cortical thickness, implant design, population analysis, reverse shoulder arthroplasty, scapula},
  pmid      = {32364819},
  publisher = {Taylor & Francis},
  url       = {https://doi.org/10.1080/10255842.2020.1757082},
}

@Book{Louv1984,
  author    = {Louv, William C.},
  title     = {{Adaptive filtering}},
  year      = {1984},
  isbn      = {9783030290566},
  number    = {4},
  volume    = {26},
  abstract  = {The extension of Kalman filtering to the case of unknown variances is known as adaptive filtering. Duncan and Horn's (1972) representation of the Kalman time-series model is exploited to derive variance-component estimates from the standpoint of regression analysis. Specifically, the MINQUE of Rao (1970) and the AUE of Horn, Horn, and Duncan (1975) are applied. These estimates are then used to formulate adaptive filters. The adaptive filters are applied to simulated data, and their performance is compared to the method of Carew and Belanger (1973). {\textcopyright} 1984 Taylor & Francis Group, LLC.},
  booktitle = {Technometrics},
  doi       = {10.1080/00401706.1984.10487993},
  file      = {:home/antonio/Documents/bibliography/files/Louv - 1984 - Adaptive filtering.pdf:pdf},
  issn      = {15372723},
  keywords  = {Adaptive filter, Kalman filter, Variance-component estimation},
  pages     = {399--409},
}

@Article{Jacot2018,
  author   = {Jacot, Arthur and Gabriel, Franck and Hongler, Clement},
  journal  = {arXiv},
  title    = {{Neural tangent kernel: Convergence and generalization in neural networks}},
  year     = {2018},
  issn     = {23318422},
  number   = {4},
  abstract = {At initialization, artificial neural networks (ANNs) are equivalent to Gaussian processes in the infinite-width limit (14; 11), thus connecting them to kernel methods. We prove that the evolution of an ANN during training can also be described by a kernel: During gradient descent on the parameters of an ANN, the network function f_ (which maps input vectors to output vectors) follows the kernel gradient of the functional cost (which is convex, in contrast to the parameter cost) w.r.t. a new kernel: The Neural Tangent Kernel (NTK). This kernel is central to describe the generalization features of ANNs. While the NTK is random at initialization and varies during training, in the infinite-width limit it converges to an explicit limiting kernel and it stays constant during training. This makes it possible to study the training of ANNs in function space instead of parameter space. Convergence of the training can then be related to the positive-definiteness of the limiting NTK. We prove the positive-definiteness of the limiting NTK when the data is supported on the sphere and the non-linearity is non-polynomial. We then focus on the setting of least-squares regression and show that in the infinitewidth limit, the network function f_ follows a linear differential equation during training. The convergence is fastest along the largest kernel principal components of the input data with respect to the NTK, hence suggesting a theoretical motivation for early stopping. Finally we study the NTK numerically, observe its behavior for wide networks, and compare it to the infinite-width limit.},
  file     = {:home/antonio/Documents/bibliography/files/Jacot, Gabriel, Hongler - 2018 - Neural tangent kernel Convergence and generalization in neural networks.pdf:pdf},
  groups   = {General deep learning},
}

@Article{Bench2020,
  author        = {Bench, Ciaran and Hauptmann, Andreas and Cox, Ben},
  journal       = {arXiv},
  title         = {{Towards accurate quantitative photoacoustic imaging: learning vascular blood oxygen saturation in 3D}},
  year          = {2020},
  issn          = {23318422},
  number        = {August},
  pages         = {1--17},
  volume        = {25},
  abstract      = {Significance: 2D fully convolutional neural networks have been shown capable of producing maps of sO2 from 2D simulated images of simple tissue models. However, their potential to produce accurate estimates in vivo is uncertain as they are limited by the 2D nature of the training data when the problem is inherently 3D, and they have not been tested with realistic images. Aim: To demonstrate the capability of deep neural networks to process whole 3D images and output 3D maps of vascular sO2 from realistic tissue models/images. Approach: Two separate fully convolutional neural networks were trained to produce 3D maps of vascular blood oxygen saturation and vessel positions from multiwavelength simulated images of tissue models. Results: The mean of the absolute difference between the true mean vessel sO2 and the network output for 40 examples was 4.4% and the standard deviation was 4.5%. Conclusions: 3D fully convolutional networks were shown capable of producing accurate sO2 maps using the full extent of spatial information contained within 3D images generated under conditions mimicking real imaging scenarios. This work demonstrates that networks can cope with some of the confounding effects present in real images such as limited-view artefacts, and have the potential to produce accurate estimates in vivo.},
  archiveprefix = {arXiv},
  arxivid       = {2005.01089},
  doi           = {10.1117/1.JBO.25.8.085003},
  eprint        = {2005.01089},
  file          = {:home/antonio/Documents/bibliography/files/Bench, Hauptmann, Cox - 2020 - Towards accurate quantitative photoacoustic imaging learning vascular blood oxygen saturation in 3D.pdf:pdf},
  groups        = {Ultrasound and wave imaging},
  keywords      = {Deep Learning, Machine Learning, Oxygen saturation, Photoacoustics, Quantitative photoacoustics, SO2},
}

@article{Wise2019,
abstract = {{\textcopyright} 2019 Author(s). Accurately representing acoustic source distributions is an important part of ultrasound simulation. This is challenging for grid-based collocation methods when such distributions do not coincide with the grid points, for instance when the source is a curved, two-dimensional surface embedded in a three-dimensional domain. Typically, grid points close to the source surface are defined as source points, but this can result in "staircasing" and substantial errors in the resulting acoustic fields. This paper describes a technique for accurately representing arbitrary source distributions within Fourier collocation methods. The method works by applying a discrete, band-limiting convolution operator to the continuous source distribution, after which source grid weights can be generated. This allows arbitrarily shaped sources, for example, focused bowls and circular pistons, to be defined on the grid without staircasing errors. The technique is examined through simulations of a range of ultrasound sources, and comparisons with analytical solutions show excellent accuracy and convergence rates. Extensions of the technique are also discussed, including application to initial value problems, distributed sensors, and moving sources.},
author = {Wise, Elliott S. and Cox, B. T. and Jaros, Jiri and Treeby, Bradley E.},
doi = {10.1121/1.5116132},
file = {:home/antonio/Documents/bibliography/files/Wise et al. - 2019 - Representing arbitrary acoustic source and sensor distributions in Fourier collocation methods.pdf:pdf},
issn = {0001-4966},
journal = {The Journal of the Acoustical Society of America},
number = {1},
pages = {278--288},
pmid = {31370581},
publisher = {Acoustical Society of America},
title = {{Representing arbitrary acoustic source and sensor distributions in Fourier collocation methods}},
volume = {146},
year = {2019}
}

@article{Serban2017,
abstract = {Sequential data often possesses hierarchical structures with complex dependencies between sub-sequences, such as found between the utterances in a dialogue. To model these dependen-cies in a generative framework, we propose a neural network-based generative architecture, with stochastic latent variables that span a variable number of time steps. We apply the pro-posed model to the task of dialogue response generation and compare it with other recent neural-network architectures. We evaluate the model performance through a human evaluation study. The experiments demonstrate that our model improves upon recently proposed models and that the latent variables facilitate both the generation of meaningful, long and diverse responses and maintaining dialogue state.},
author = {Serban, Iulian Vlad and Sordoni, Alessandro and Charlin, Laurent and Pineau, Joelle and Courville, Aaron and Bengio, Yoshua},
file = {:home/antonio/Documents/bibliography/files/Serban et al. - 2017 - A Hierarchical Latent Variable Encoder-Decoder Model for Generating Dialogues.pdf:pdf},
keywords = {Natural Language Processing and Machine Learning},
pages = {3295--3301},
title = {{A Hierarchical Latent Variable Encoder-Decoder Model for Generating Dialogues}},
year = {2017}
}

@article{Meng2021,
abstract = {Focused ultrasound (FUS) is a disruptive medical technology, and its implementation in the clinic represents the culmination of decades of research. Lying at the convergence of physics, engineering, imaging, biology and neuroscience, FUS offers the ability to non-invasively and precisely intervene in key circuits that drive common and challenging brain conditions. The actions of FUS in the brain take many forms, ranging from transient blood–brain barrier opening and neuromodulation to permanent thermoablation. Over the past 5 years, we have seen a dramatic expansion of indications for and experience with FUS in humans, with a resultant exponential increase in academic and public interest in the technology. Applications now span the clinical spectrum in neurological and psychiatric diseases, with insights still emerging from preclinical models and human trials. In this Review, we provide a comprehensive overview of therapeutic ultrasound and its current and emerging indications in the brain. We examine the potential impact of FUS on the landscape of brain therapies as well as the challenges facing further advancement and broader adoption of this promising minimally invasive therapeutic alternative.},
author = {Meng, Ying and Hynynen, Kullervo and Lipsman, Nir},
doi = {10.1038/s41582-020-00418-z},
file = {:home/antonio/Documents/bibliography/files/Meng, Hynynen, Lipsman - 2021 - Applications of focused ultrasound in the brain from thermoablation to drug delivery.pdf:pdf},
isbn = {4158202000},
issn = {17594766},
journal = {Nature Reviews Neurology},
number = {1},
pages = {7--22},
pmid = {33106619},
publisher = {Springer US},
title = {{Applications of focused ultrasound in the brain: from thermoablation to drug delivery}},
url = {http://dx.doi.org/10.1038/s41582-020-00418-z},
volume = {17},
year = {2021}
}

@Article{Pueschel2008,
  author        = {P{\"{u}}schel, Markus and Moura, Jos{\'{e}} M.F.},
  journal       = {IEEE Transactions on Signal Processing},
  title         = {{Algebraic signal processing theory: 1-D space}},
  year          = {2008},
  issn          = {1053587X},
  number        = {8 I},
  pages         = {3586--3599},
  volume        = {56},
  abstract      = {In our paper titled "Algebraic Signal Processing Theory: Foundation and 1-D Time"appearing in this issue of the IEEE Transactions on Signal Processin, we presented the algebraic signal processing theory, an axiomatic and general framework for linear signal processing. The basic concept in this theory is the signal model defined as the triple (A,M $\phi$), where A is a chosen algebra of filters, M an associated A-module of signals, and $\Phi$ is a generalization of the z-transform. Each signal model has its own associated set of basic SP concepts, including filtering, spectrum, and Fourier transform. Examples include infinite and finite discrete time where these notions take their well-known forms. In this paper, we use the algebraic theory to develop infinite and finite space signal models. These models are based on a symmetric space shift operator, which is distinct from the standard time shift. We present the space signal processing concepts of filtering or convolution, "z-transform,"spectrum, and Fourier transform. For finite length space signals, we obtain 16 variants of space models, which have the 16 discrete cosine and sine transforms (DCTs/DSTs) as Fourier transforms. Using this novel derivation, we provide missing signal processing concepts associated with the DCTs/DSTs, establish them as precise analogs to the DFT, get deep insight into their origin, and enable the easy derivation of many of their properties including their fast algorithms. {\textcopyright} 2008 IEEE.},
  archiveprefix = {arXiv},
  arxivid       = {arXiv:cs/0612077v2},
  doi           = {10.1109/TSP.2008.925259},
  eprint        = {0612077v2},
  file          = {:home/antonio/Documents/bibliography/files/P{\"{u}}schel, Moura - 2008 - Algebraic signal processing theory 1-D space.pdf:pdf},
  keywords      = {Algebra, boundary condition, Chebyshev polynomials, Convolution, Discrete cosine transform (DCT), Discrete sine transform (DST), Fourier transform, Module, Representation theory, Shift, Signal extension, Signal model},
  primaryclass  = {arXiv:cs},
}

@article{Heydari2020,
abstract = {The emergence of Generative Adversarial Network (GAN)-based single-image super-resolution (SISR) has allowed for finer textures in the super-resolved images, thus making them seem realistic to humans. However, GANbased models may depend on extensive high-quality data and are known to be very costly and unstable to train. On the other hand, Variational Autoencoders (VAEs) have inherent mathematical properties, and they are relatively cheap and stable to train; but VAEs produce blurry images that prevent them from being used for super-resolution. In this paper, we propose a first of its kind SISR method that takes advantage of a selfevaluating Variational Autoencoder (IntroVAE). Our network, called SRVAE, judges the quality of generated high-resolution (HR) images with the target images in an adversarial manner, which allows for high perceptual image generation. First, the encoder and the decoder of our introVAE-based method learn the manifold of HR images. In parallel, another encoder and decoder are simultaneously learning the reconstruction of the lowresolution (LR) images. Next, reconstructed LR images are fed to the encoder of the HR network to learn a mapping from LR images to corresponding HR versions. Using the encoder as a discriminator allows SRVAE to be a fast single-stream framework that performs super-resolution through generating photo-realistic images. Moreover, SRVAE has the same training stability and "nice" latent manifold structure as of VAEs, while playing a max-min adversarial game between the generator and the encoder like GANs. Our experiments show that our super-resolved images are comparable to the state-of-the-art GAN-based super-resolution.},
author = {Heydari, A. Ali and Mehmood, Asif},
doi = {10.1117/12.2559808},
file = {:home/antonio/Documents/bibliography/files/Heydari, Mehmood - 2020 - SRVAE super resolution using variational autoencoders.pdf:pdf},
isbn = {9781510635777},
issn = {1996756X},
number = {April 2020},
pages = {30},
title = {{SRVAE: super resolution using variational autoencoders}},
year = {2020}
}

@article{Larroza2019,
abstract = {Synthetic computed tomography (CT) images derived from magnetic resonance images (MRI) are of interest for radiotherapy planning and positron emission tomography (PET) attenuation correction. In recent years, deep learning implementations have demonstrated improvement over atlas-based and segmentation-based methods. Nevertheless, several open questions remain to be addressed, such as which is the best of MRI sequences and neural network architectures. In this work, we compared the performance of different combinations of two common MRI sequences (T1-and T2-weighted), and three state-of-the-art neural networks designed for medical image processing (Vnet, HighRes3dNet and ScaleNet). The experiments were conducted on brain datasets from a public database. Our results suggest that T1 images perform better than T2, but the results further improve when combining both sequences. The lowest mean average error over the entire head (MAE = 101.76 ± 10.4 HU) was achieved combining T1 and T2 scans with HighRes3dNet. All tested deep learning models achieved significantly lower MAE (p < 0.01) than a well-known atlas-based method.},
author = {Larroza, Andres and Moliner, Laura and Alvarez-Gomez, Juan M. and Oliver, Sandra and Espinos-Morato, Hector and Vergara-DIaz, Marina and Rodriguez-Alvarez, Maria J.},
doi = {10.1109/NSS/MIC42101.2019.9060051},
file = {:home/antonio/Documents/bibliography/files/Larroza et al. - 2019 - Deep learning for MRI-based CT synthesis A comparison of MRI sequences and neural network architectures.pdf:pdf},
isbn = {9781728141640},
journal = {2019 IEEE Nuclear Science Symposium and Medical Imaging Conference, NSS/MIC 2019},
pages = {2019--2022},
title = {{Deep learning for MRI-based CT synthesis: A comparison of MRI sequences and neural network architectures}},
year = {2019}
}

@Article{Song2020,
  author        = {Song, Chao and Alkhalifah, Tariq and bin Waheed, Umair},
  journal       = {arXiv},
  title         = {{Solving the acoustic VTI wave equation using physics-informed neural networks}},
  year          = {2020},
  issn          = {23318422},
  abstract      = {Frequency-domain wavefield solutions corresponding to the anisotropic acoustic wave equations can be used to describe the anisotropic nature of the earth. To solve a frequency-domain wave equation, we often need to invert the impedance matrix. This results in a dramatic increase in computational cost as the model size increases. It is even a bigger challenge for anisotropic media, where the impedance matrix is far more complex. To address this issue, we use the emerging paradigm of physics-informed neural networks (PINNs) to obtain wavefield solutions for an acoustic wave equation for transversely isotropic (TI) media with a vertical axis of symmetry (VTI). PINNs utilize the concept of automatic differentiation to calculate its partial derivatives. Thus, we use the wave equation as a loss function to train a neural network to provide functional solutions to form of the acoustic VTI wave equation. Instead of predicting the pressure wavefields directly, we solve for the scattered pressure wavefields to avoid dealing with the point source singularity. We use the spatial coordinates as input data to the network, which outputs the real and imaginary parts of the scattered wavefields and auxiliary function. After training a deep neural network (NN), we can evaluate the wavefield at any point in space instantly using this trained NN. We demonstrate these features on a simple anomaly model and a layered model. Additional tests on a modified 3D Overthrust model and a model with irregular topography also show the effectiveness of the proposed method.},
  archiveprefix = {arXiv},
  arxivid       = {2008.01865},
  eprint        = {2008.01865},
  file          = {:home/antonio/Documents/bibliography/files/Song, Alkhalifah, Waheed - 2020 - Solving the acoustic VTI wave equation using physics-informed neural networks.pdf:pdf},
  keywords      = {Acoustic wave equation modeling, Frequency domain, Physics-informed neural network, VTI media},
}

@article{Richardson2020,
abstract = {We present a generic image-to-image translation framework, Pixel2Style2Pixel (pSp). Our pSp framework is based on a novel encoder network that directly generates a series of style vectors which are fed into a pretrained StyleGAN generator, forming the extended W+ latent space. We first show that our encoder can directly embed real images into W+, with no additional optimization. We further introduce a dedicated identity loss which is shown to achieve improved performance in the reconstruction of an input image. We demonstrate pSp to be a simple architecture that, by leveraging a well-trained, fixed generator network, can be easily applied on a wide-range of image-to-image translation tasks. Solving these tasks through the style representation results in a global approach that does not rely on a local pixel-to-pixel correspondence and further supports multi-modal synthesis via the resampling of styles. Notably, we demonstrate that pSp can be trained to align a face image to a frontal pose without any labeled data, generate multi-modal results for ambiguous tasks such as conditional face generation from segmentation maps, and construct high-resolution images from corresponding low-resolution images.},
archivePrefix = {arXiv},
arxivId = {2008.00951},
author = {Richardson, Elad and Alaluf, Yuval and Patashnik, Or and Nitzan, Yotam and Azar, Yaniv and Shapiro, Stav and Cohen-Or, Daniel},
eprint = {2008.00951},
file = {:home/antonio/Documents/bibliography/files/Richardson et al. - 2020 - Encoding in Style a StyleGAN Encoder for Image-to-Image Translation.pdf:pdf},
issn = {23318422},
journal = {arXiv},
title = {{Encoding in Style: a StyleGAN Encoder for Image-to-Image Translation}},
year = {2020}
}

@Article{ParadaMayorga2020,
  author        = {Parada-Mayorga, Alejandro and Ribeiro, Alejandro},
  journal       = {arXiv},
  title         = {{Algebraic neural networks: Stability to deformations}},
  year          = {2020},
  issn          = {23318422},
  pages         = {1--13},
  abstract      = {In this work we study the stability of algebraic neural networks (AlgNNs) with commutative algebras which unify CNNs and GNNs under the umbrella of algebraic signal processing. An AlgNN is a stacked layered structure where each layer is conformed by an algebra A, a vector space M and a homomorphism $\rho$: A → End(M), where End(M) is the set of endomorphims of M. Signals in each layer are modeled as elements of M and are processed by elements of End(M) defined according to the structure of A via $\rho$. This framework provides a general scenario that covers several types of neural network architectures where formal convolution operators are being used. We obtain stability conditions regarding to perturbations which are defined as distortions of $\rho$, reaching general results whose particular cases are consistent with recent findings in the literature for CNNs and GNNs. We consider conditions on the domain of the homomorphisms in the algebra that lead to stable operators. Interestingly, we found that these conditions are related to the uniform boundedness of the Fr{\'{e}}chet derivative of a function p: End(M) → End(M) that maps the images of the generators of A on End(M) into a power series representation that defines the filtering of elements in M. Additionally, our results show that stability is universal to convolutional architectures whose algebraic signal model uses the same algebra.},
  archiveprefix = {arXiv},
  arxivid       = {2009.01433},
  eprint        = {2009.01433},
  file          = {:home/antonio/Documents/bibliography/files/Parada-Mayorga, Ribeiro - 2020 - Algebraic neural networks Stability to deformations.pdf:pdf},
  keywords      = {Algebraic Neural Networks, Algebraic signal processing, Convolutional neural networks (CNNs), Fr{\'{e}}chet differentiability, Graph neural networks (GNNs), Representation theory of algebras, Stability},
}

@article{Daniel2020,
abstract = {The recently introduced introspective variational autoencoder (IntroVAE) exhibits outstanding image generations, and allows for amortized inference using an image encoder. The main idea in IntroVAE is to train a VAE adversarially, using the VAE encoder to discriminate between generated and real data samples. However, the original IntroVAE loss function relied on a particular hinge-loss formulation that is very hard to stabilize in practice, and its theoretical convergence analysis ignored important terms in the loss. In this work, we take a step towards better understanding of the IntroVAE model, its practical implementation, and its applications. We propose the SoftIntroVAE, a modified IntroVAE that replaces the hinge-loss terms with a smooth exponential loss on generated samples. This change significantly improves training stability, and also enables theoretical analysis of the complete algorithm. Interestingly, we show that the IntroVAE converges to a distribution that minimizes a sum of KL distance from the data distribution and an entropy term. We discuss the implications of this result, and demonstrate that it induces competitive image generation and reconstruction. Finally, we describe two applications of Soft-IntroVAE to unsupervised image translation and out-of-distribution detection, and demonstrate compelling results. Code and additional information is available on the project website - https://taldatech.github.io/soft-introvae-web.},
archivePrefix = {arXiv},
arxivId = {2012.13253},
author = {Daniel, Tal and Tamar, Aviv},
eprint = {2012.13253},
file = {:home/antonio/Documents/bibliography/files/Daniel, Tamar - 2020 - Soft-IntroVAE Analyzing and improving the introspective variational autoencoder.pdf:pdf},
issn = {23318422},
journal = {arXiv},
title = {{Soft-IntroVAE: Analyzing and improving the introspective variational autoencoder}},
year = {2020}
}

@article{Plumerault2020,
abstract = {Among the wide variety of image generative models, two models stand out: Variational Auto Encoders (VAE) and Generative Adversarial Networks (GAN). GANs can produce realistic images, but they suffer from mode collapse and do not provide simple ways to get the latent representation of an image. On the other hand, VAEs do not have these problems, but they often generate images less realistic than GANs. In this article, we explain that this lack of realism is partially due to a common underestimation of the natural image manifold dimensionality. To solve this issue we introduce a new framework that combines VAE and GAN in a novel and complementary way to produce an auto-encoding model that keeps VAEs properties while generating images of GAN-quality. We evaluate our approach both qualitatively and quantitatively on five image datasets.},
archivePrefix = {arXiv},
arxivId = {2012.11551},
author = {Plumerault, Antoine and Borgne, Herv{\'{e}} Le and Hudelot, C{\'{e}}line},
eprint = {2012.11551},
file = {:home/antonio/Documents/bibliography/files/Plumerault, Borgne, Hudelot - 2020 - AVAE Adversarial Variational Auto Encoder.pdf:pdf},
number = {January},
pages = {1--16},
title = {{AVAE: Adversarial Variational Auto Encoder}},
url = {http://arxiv.org/abs/2012.11551},
year = {2020}
}

@article{Treeby2019,
author = {Treeby, Bradley E.},
doi = {10.1121/at.2019.15.2.36},
file = {:home/antonio/Documents/bibliography/files/Treeby - 2019 - From Biology to Bytes Predicting the Path of Ultrasound Waves Through the Human Body.pdf:pdf},
issn = {15570215},
journal = {Acoustics Today},
number = {2},
pages = {36},
title = {{From Biology to Bytes: Predicting the Path of Ultrasound Waves Through the Human Body}},
volume = {15},
year = {2019}
}

@article{Lucas2019,
abstract = {Posterior collapse in Variational Autoencoders (VAEs) arises when the variational posterior distribution closely matches the prior for a subset of latent variables. This paper presents a simple and intuitive explanation for posterior collapse through the analysis of linear VAEs and their direct correspondence with Probabilistic PCA (pPCA). We explain how posterior collapse may occur in pPCA due to local maxima in the log marginal likelihood. Unexpectedly, we prove that the ELBO objective for the linear VAE does not introduce additional spurious local maxima relative to log marginal likelihood. We show further that training a linear VAE with exact variational inference recovers an identifiable global maximum corresponding to the principal component directions. Empirically, we find that our linear analysis is predictive even for high-capacity, non-linear VAEs and helps explain the relationship between the observation noise, local maxima, and posterior collapse in deep Gaussian VAEs.},
archivePrefix = {arXiv},
arxivId = {1911.02469},
author = {Lucas, James and Tucker, George and Grosse, Roger and Norouzi, Mohammad},
eprint = {1911.02469},
file = {:home/antonio/Documents/bibliography/files/Lucas et al. - 2019 - Don't blame the ELBO! A linear vae perspective on posterior collapse.pdf:pdf},
issn = {23318422},
journal = {arXiv},
number = {NeurIPS},
title = {{Don't blame the ELBO! A linear vae perspective on posterior collapse}},
year = {2019}
}

@article{Lu2019,
abstract = {While it is widely known that neural networks are universal approximators of continuous functions, a less known and perhaps more powerful result is that a neural network with a single hidden layer can approximate accurately any nonlinear continuous operator [5]. This universal approximation theorem is suggestive of the potential application of neural networks in learning nonlinear operators from data. However, the theorem guarantees only a small approximation error for a sufficient large network, and does not consider the important optimization and generalization errors. To realize this theorem in practice, we propose deep operator networks (DeepONets) to learn operators accurately and efficiently from a relatively small dataset. A DeepONet consists of two sub-networks, one for encoding the input function at a fixed number of sensors xi, i = 1, . . ., m (branch net), and another for encoding the locations for the output functions (trunk net). We perform systematic simulations for identifying two types of operators, i.e., dynamic systems and partial differential equations, and demonstrate that DeepONet significantly reduces the generalization error compared to the fully-connected networks. We also derive theoretically the dependence of the approximation error in terms of the number of sensors (where the input function is defined) as well as the input function type, and we verify the theorem with computational results. More importantly, we observe high-order error convergence in our computational tests, namely polynomial rates (from half order to fourth order) and even exponential convergence with respect to the training dataset size.},
archivePrefix = {arXiv},
arxivId = {1910.03193},
author = {Lu, Lu and Jin, Pengzhan and Karniadakis, George Em},
eprint = {1910.03193},
file = {:home/antonio/Documents/bibliography/files/Lu, Jin, Karniadakis - 2019 - DeepONet Learning nonlinear operators for identifying differential equations based on the universal approx.pdf:pdf},
issn = {23318422},
journal = {arXiv},
pages = {1--22},
title = {{DeepONet: Learning nonlinear operators for identifying differential equations based on the universal approximation theorem of operators}},
year = {2019}
}

@Article{Monga2019,
  author        = {Monga, Vishal and Li, Yuelong and Eldar, Yonina C.},
  journal       = {arXiv},
  title         = {{Algorithm unrolling: Interpretable, efficient deep learning for signal and image processing}},
  year          = {2019},
  issn          = {23318422},
  abstract      = {Deep neural networks provide unprecedented performance gains in many real world problems in signal and image processing. Despite these gains, future development and practical deployment of deep networks is hindered by their blackbox nature, i.e., lack of interpretability, and by the need for very large training sets. An emerging technique called algorithm unrolling or unfolding offers promise in eliminating these issues by providing a concrete and systematic connection between iterative algorithms that are used widely in signal processing and deep neural networks. Unrolling methods were first proposed to develop fast neural network approximations for sparse coding. More recently, this direction has attracted enormous attention and is rapidly growing both in theoretic investigations and practical applications. The growing popularity of unrolled deep networks is due in part to their potential in developing efficient, high-performance and yet interpretable network architectures from reasonable size training sets. In this article, we review algorithm unrolling for signal and image processing. We extensively cover popular techniques for algorithm unrolling in various domains of signal and image processing including imaging, vision and recognition, and speech processing. By reviewing previous works, we reveal the connections between iterative algorithms and neural networks and present recent theoretical results. Finally, we provide a discussion on current limitations of unrolling and suggest possible future research directions.},
  archiveprefix = {arXiv},
  arxivid       = {1912.10557},
  doi           = {10.1109/MSP.2020.3016905},
  eprint        = {1912.10557},
  file          = {:home/antonio/Documents/bibliography/files/Monga, Li, Eldar - 2019 - Algorithm unrolling Interpretable, efficient deep learning for signal and image processing.pdf:pdf},
  keywords      = {Algorithm unrolling, Deep learning, Image reconstruction, Interpretable networks, Neural networks, Unfolding},
}

@article{Aubry2003,
abstract = {Developing minimally invasive brain surgery by high-intensity focused ultrasound beams is of great interest in cancer therapy. However, the skull induces strong aberrations both in phase and amplitude, resulting in a severe degradation of the beam shape. Thus, an efficient brain tumor therapy would require an adaptive focusing, taking into account the effects of the skull. In this paper, we will show that the acoustic properties of the skull can be deduced from high resolution CT scans and used to achieve a noninvasive adaptive focusing. Simulations have been performed with a full 3-D finite differences code, taking into account all the heterogeneities inside the skull. The set of signals to be emitted in order to focus through the skull can thus be computed. The complete adaptive focusing procedure based on prior CT scans has been experimentally validated. This could have promising applications in brain tumor hyperthermia but also in transcranial ultrasonic imaging.},
author = {Aubry, J.-F. and Tanter, M. and Pernot, M. and Thomas, J.-L. and Fink, M.},
doi = {10.1121/1.1529663},
file = {:home/antonio/Documents/bibliography/files/Aubry et al. - 2003 - Experimental demonstration of noninvasive transskull adaptive focusing based on prior computed tomography scans.pdf:pdf},
issn = {0001-4966},
journal = {The Journal of the Acoustical Society of America},
number = {1},
pages = {84--93},
pmid = {12558249},
title = {{Experimental demonstration of noninvasive transskull adaptive focusing based on prior computed tomography scans}},
volume = {113},
year = {2003}
}

@article{Such2019,
abstract = {This paper investigates the intriguing question of whether we can create learning algorithms that automatically generate training data, learning environments, and curricula in order to help AI agents rapidly learn. We show that such algorithms are possible via Generative Teaching Networks (GTNs), a general approach that is, in theory, applicable to supervised, unsupervised, and reinforcement learning, although our experiments only focus on the supervised case. GTNs are deep neural networks that generate data and/or training environments that a learner (e.g. a freshly initialized neural network) trains on for a few SGD steps before being tested on a target task. We then differentiate through the entire learning process via meta-gradients to update the GTN parameters to improve performance on the target task. GTNs have the beneficial property that they can theoretically generate any type of data or training environment, making their potential impact large. This paper introduces GTNs, discusses their potential, and showcases that they can substantially accelerate learning. We also demonstrate a practical and exciting application of GTNs: accelerating the evaluation of candidate architectures for neural architecture search (NAS), which is rate-limited by such evaluations, enabling massive speed-ups in NAS. GTN-NAS improves the NAS state of the art, finding higher performing architectures when controlling for the search proposal mechanism. GTN-NAS also is competitive with the overall state of the art approaches, which achieve top performance while using orders of magnitude less computation than typical NAS methods. Speculating forward, GTNs may represent a first step toward the ambitious goal of algorithms that generate their own training data and, in doing so, open a variety of interesting new research questions and directions.},
archivePrefix = {arXiv},
arxivId = {1912.07768},
author = {Such, Felipe Petroski and Rawal, Aditya and Lehman, Joel and Stanley, Kenneth O. and Clune, Jeff},
eprint = {1912.07768},
file = {:home/antonio/Documents/bibliography/files/Such et al. - 2019 - Generative Teaching Networks Accelerating neural architecture search by learning to generate synthetic training dat.pdf:pdf},
issn = {23318422},
journal = {arXiv},
pages = {1--26},
title = {{Generative Teaching Networks: Accelerating neural architecture search by learning to generate synthetic training data}},
year = {2019}
}

@article{Zhu2020,
abstract = {Imaging Earth structure or seismic sources from seismic data involves minimizing a target misfit function, and is commonly solved through gradient-based optimization. The adjointstate method has been developed to compute the gradient efficiently; however, its implementation can be time-consuming and difficult. We develop a general seismic inversion framework to calculate gradients using reverse-mode automatic differentiation. The central idea is that adjoint-state methods and reverse-mode automatic differentiation are mathematically equivalent. The mapping between numerical PDE simulation and deep learning allows us to build a seismic inverse modeling library, ADSeismic, based on deep learning frameworks, which supports high performance reverse-mode automatic differentiation on CPUs and GPUs. We demonstrate the performance of ADSeismic on inverse problems related to velocity model estimation, rupture imaging, earthquake location, and source time function retrieval. ADSeismic has the potential to solve a wide variety of inverse modeling applications within a unified framework.},
archivePrefix = {arXiv},
arxivId = {2003.06027},
author = {Zhu, Weiqiang and Xu, Kailai and Darve, Eric and Beroza, Gregory C.},
eprint = {2003.06027},
file = {:home/antonio/Documents/bibliography/files/Zhu et al. - 2020 - A general approach to seismic inversion with automatic differentiation.pdf:pdf},
issn = {23318422},
journal = {arXiv},
pages = {1--21},
title = {{A general approach to seismic inversion with automatic differentiation}},
year = {2020}
}

@article{Smidt2020,
abstract = {Curie's principle states that “when effects show certain asymmetry, this asymmetry must be found in the causes that gave rise to them”. We demonstrate that symmetry equivariant neural networks uphold Curie's principle and this property can be used to uncover symmetry breaking order parameters necessary to make input and output data symmetrically compatible. We prove these properties mathematically and demonstrate them numerically by training a Euclidean symmetry equivariant neural network to learn symmetry breaking input to deform a square into a rectangle.},
archivePrefix = {arXiv},
arxivId = {2007.02005},
author = {Smidt, Tess E. and Geiger, Mario and Miller, Benjamin Kurt},
doi = {10.1103/physrevresearch.3.l012002},
eprint = {2007.02005},
file = {:home/antonio/Documents/bibliography/files/Smidt, Geiger, Miller - 2020 - Finding Symmetry Breaking Order Parameters with Euclidean Neural Networks.pdf:pdf},
issn = {23318422},
journal = {arXiv},
pages = {2--7},
title = {{Finding Symmetry Breaking Order Parameters with Euclidean Neural Networks}},
year = {2020}
}

@article{Moseley2020,
abstract = {We investigate the use of Physics-Informed Neural Networks (PINNs) for solving the wave equation. Whilst PINNs have been successfully applied across many physical systems, the wave equation presents unique challenges due to the multi-scale, propagating and oscillatory nature of its solutions, and it is unclear how well they perform in this setting. We use a deep neural network to learn solutions of the wave equation, using the wave equation and a boundary condition as direct constraints in the loss function when training the network. We test the approach by solving the 2D acoustic wave equation for spatially-varying velocity models of increasing complexity, including homogeneous, layered and Earth-realistic models, and find the network is able to accurately simulate the wavefield across these cases. By using the physics constraint in the loss function the network is able to solve for the wavefield far outside of its boundary training data, offering a way to reduce the generalisation issues of existing deep learning approaches. We extend the approach for the Earth-realistic case by conditioning the network on the source location and find that it is able to generalise over this initial condition, removing the need to retrain the network for each solution. In contrast to traditional numerical simulation this approach is very efficient when computing arbitrary space-time points in the wavefield, as once trained the network carries out inference in a single step without needing to compute the entire wavefield. We discuss the potential applications, limitations and further research directions of this work.},
archivePrefix = {arXiv},
arxivId = {2006.11894},
author = {Moseley, B. and Markham, A. and Nissen-Meyer, T.},
eprint = {2006.11894},
file = {:home/antonio/Documents/bibliography/files/Moseley, Markham, Nissen-Meyer - 2020 - Solving the wave equation with physics-informed deep learning.pdf:pdf},
issn = {23318422},
journal = {arXiv},
title = {{Solving the wave equation with physics-informed deep learning}},
year = {2020}
}

@Article{Lunz2020,
  author   = {Lunz, Sebastian and Hauptmann, Andreas and Tarvainen, Tanja and Schonlieb, Carola Bibiane and Arridge, Simon},
  journal  = {arXiv},
  title    = {{On learned operator correction}},
  year     = {2020},
  issn     = {23318422},
  number   = {1},
  pages    = {92--127},
  volume   = {14},
  abstract = {We discuss the possibility to learn a data-driven explicit model correction for inverse problems and whether such a model correction can be used within a variational framework to obtain regularised reconstructions. This paper discusses the conceptual difficulty to learn such a forward model correction and proceeds to present a possible solution as forward-backward correction that explicitly corrects in both data and solution spaces. We then derive conditions under which solutions to the variational problem with a learned correction converge to solutions obtained with the correct operator. The proposed approach is evaluated on an application to limited view photoacoustic tomography and compared to the established framework of Bayesian approximation error method.},
  file     = {:home/antonio/Documents/bibliography/files/Lunz et al. - 2020 - On learned operator correction.pdf:pdf},
  keywords = {deep learning, inverse problems, model correction, operator learning, photoa-, variational methods},
}

@article{Ober2009,
author = {Ober, Curtis C and Collis, S Scott and Waanders, Bart Van Bloemen and Laboratories, Sandia National and Marcinkovich, Carey and Upstream, Exxonmobil},
file = {:home/antonio/Documents/bibliography/files/Ober et al. - 2009 - Method of Manufactured Solutions for the Acoustic Wave Equation SEG Houston 2009 International Exposition and Annua.pdf:pdf},
pages = {3615--3619},
title = {{Method of Manufactured Solutions for the Acoustic Wave Equation SEG Houston 2009 International Exposition and Annual Meeting SEG Houston 2009 International Exposition and Annual Meeting}},
year = {2009}
}

@article{Kingma2014,
abstract = {The ever-increasing size of modern data sets combined with the difficulty of obtaining label information has made semi-supervised learning one of the problems of significant practical importance in modern data analysis. We revisit the approach to semi-supervised learning with generative models and develop new models that allow for effective generalisation from small labelled data sets to large unlabelled ones. Generative approaches have thus far been either inflexible, inefficient or non-scalable. We show that deep generative models and approximate Bayesian inference exploiting recent advances in variational methods can be used to provide significant improvements, making generative approaches highly competitive for semi-supervised learning.},
archivePrefix = {arXiv},
arxivId = {1406.5298},
author = {Kingma, Diederik P. and Rezende, Danilo J. and Mohamed, Shakir and Welling, Max},
eprint = {1406.5298},
file = {:home/antonio/Documents/bibliography/files/Kingma et al. - 2014 - Semi-supervised learning with deep generative models.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
number = {January},
pages = {3581--3589},
title = {{Semi-supervised learning with deep generative models}},
volume = {4},
year = {2014}
}

@article{Ghose2020,
abstract = {The variational autoencoder is a well defined deep generative model that utilizes an encoder-decoder framework where an encoding neural network outputs a non-deterministic code for reconstructing an input. The encoder achieves this by sampling from a distribution for every input, instead of outputting a deterministic code per input. The great advantage of this process is that it allows the use of the network as a generative model for sampling from the data distribution beyond provided samples for training. We show in this work that utilizing batch normalization as a source for non-determinism suffices to turn deterministic autoencoders into generative models on par with variational ones, so long as we add a suitable entropic regularization to the training objective.},
archivePrefix = {arXiv},
arxivId = {2002.10631},
author = {Ghose, Amur and Rashwan, Abdullah and Poupart, Pascal},
eprint = {2002.10631},
file = {:home/antonio/Documents/bibliography/files/Ghose, Rashwan, Poupart - 2020 - Batch norm with entropic regularization turns deterministic autoencoders into generative models.pdf:pdf},
issn = {23318422},
journal = {arXiv},
title = {{Batch norm with entropic regularization turns deterministic autoencoders into generative models}},
volume = {124},
year = {2020}
}

@Article{Wang2018,
  author        = {Wang, Hongqiao and Li, Jinglai},
  journal       = {Neural Computation},
  title         = {{Adaptive Gaussian process approximation for Bayesian inference with expensive likelihood functions}},
  year          = {2018},
  issn          = {1530888X},
  number        = {11},
  pages         = {3072--3094},
  volume        = {30},
  abstract      = {We consider Bayesian inference problems with computationally intensive likelihood functions. We propose a Gaussian process (GP)-based method to approximate the joint distribution of the unknown parameters and the data, built on recent work (Kandasamy, Schneider, & P{\'{o}}czos, 2015). In particular, we write the joint density approximately as a product of an approximate posterior density and an exponentiated GP surrogate. We then provide an adaptive algorithm to construct such an approximation, where an active learning method is used to choose the design points. With numerical examples, we illustrate that the proposed method has competitive performance against existing approaches for Bayesian computation.},
  archiveprefix = {arXiv},
  arxivid       = {1703.09930},
  doi           = {10.1162/neco_a_01127},
  eprint        = {1703.09930},
  file          = {:home/antonio/Documents/bibliography/files/Wang, Li - 2018 - Adaptive Gaussian process approximation for Bayesian inference with expensive likelihood functions.pdf:pdf},
  keywords      = {active learning, bayesian inference, entropy, gaussian process, inverse},
  pmid          = {30216145},
}

@article{Rackauckas,
author = {Rackauckas, Chris},
file = {:home/antonio/Documents/bibliography/files/Rackauckas - Unknown - Universal Differential Equations for Scientific Machine Learning The major advances in machine learning were due.pdf:pdf},
title = {{Universal Differential Equations for Scientific Machine Learning The major advances in machine learning were due to encoding more structure into the model}}
}

@Article{Chen2019,
  author        = {Chen, Ricky T Q and Rubanova, Yulia and Bettencourt, Jesse and Duvenaud, David},
  journal       = {arXiv:1806.07366 [cs, stat]},
  title         = {{Neural Ordinary Differential Equations}},
  year          = {2019},
  month         = {dec},
  number        = {NeurIPS},
  abstract      = {We introduce a new family of deep neural network models. Instead of specifying a discrete sequence of hidden layers, we parameterize the derivative of the hidden state using a neural network. The output of the network is computed using a blackbox differential equation solver. These continuous-depth models have constant memory cost, adapt their evaluation strategy to each input, and can explicitly trade numerical precision for speed. We demonstrate these properties in continuous-depth residual networks and continuous-time latent variable models. We also construct continuous normalizing ﬂows, a generative model that can train by maximum likelihood, without partitioning or ordering the data dimensions. For training, we show how to scalably backpropagate through any ODE solver, without access to its internal operations. This allows end-to-end training of ODEs within larger models.},
  archiveprefix = {arXiv},
  arxivid       = {arXiv:1806.07366v4},
  eprint        = {arXiv:1806.07366v4},
  file          = {:home/antonio/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chen et al. - 2018 - Neural Ordinary Differential Equations.pdf:pdf},
  keywords      = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
  language      = {en},
  mendeley-tags = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  url           = {http://arxiv.org/abs/1806.07366},
}

@article{Ehrhardt2020,
author = {Ehrhardt, Sebastien},
file = {:home/antonio/Documents/bibliography/files/Ehrhardt - 2020 - LEARNING NEURAL PDE SOLVERS WITH CONVER- GENCE GUARANTEES.pdf:pdf},
number = {i},
pages = {1--13},
title = {{LEARNING NEURAL PDE SOLVERS WITH CONVER- GENCE GUARANTEES}},
year = {2020}
}

@article{Abdalla2019,
archivePrefix = {arXiv},
arxivId = {730481v3},
author = {Abdalla, Ali},
eprint = {730481v3},
file = {:home/antonio/Documents/bibliography/files/Abdalla - 2019 - a Ugmenting P Rotein N Etwork.pdf:pdf},
number = {2016},
pages = {1--8},
title = {{a Ugmenting P Rotein N Etwork}},
year = {2019}
}

@Article{Arridge2014,
  author    = {Arridge, S. R. and Betcke, M. M. and Harhanen, L.},
  journal   = {Inverse Problems},
  title     = {{Iterated preconditioned LSQR method for inverse problems on unstructured grids}},
  year      = {2014},
  issn      = {13616420},
  number    = {7},
  volume    = {30},
  abstract  = {This article presents a method for solving large-scale linear inverse imaging problems regularized with a nonlinear, edge-preserving penalty term such as total variation or the Perona-Malik technique. Our method is aimed at problems defined on unstructured meshes, where such regularizers naturally arise in unfactorized form as a stiffness matrix of an anisotropic diffusion operator and factorization is prohibitively expensive. In the proposed scheme, the nonlinearity is handled with lagged diffusivity fixed point iteration, which involves solving a large-scale linear least squares problem in each iteration. Because the convergence of Krylov methods for problems with discontinuities is notoriously slow, we propose to accelerate it by means of priorconditioning (Bayesian preconditioning). priorconditioning is a technique that, through transformation to the standard form, embeds the information contained in the prior (Bayesian interpretation of a regularizer) directly into the forward operator and thence into the solution space. We derive a factorization-free preconditioned LSQR algorithm (MLSQR), allowing implicit application of the preconditioner through efficient schemes such as multigrid. The resulting method is also matrix-free i.e. the forward map can be defined through its action on a vector. We illustrate the performance of the method on two numerical examples. Simple 1D-deblurring problem serves to visualize the discussion throughout the paper. The effectiveness of the proposed numerical scheme is demonstrated on a three-dimensional problem in fluorescence diffuse optical tomography with total variation regularization derived algebraic multigrid preconditioner, which is the type of large scale, unstructured mesh problem, requiring matrix-free and factorization-free approaches that motivated the work here. {\textcopyright} 2014 IOP Publishing Ltd.},
  doi       = {10.1088/0266-5611/30/7/075009},
  file      = {:home/antonio/Documents/bibliography/files/Arridge, Betcke, Harhanen - 2014 - Iterated preconditioned LSQR method for inverse problems on unstructured grids.pdf:pdf},
  keywords  = {Krylov methods, LSQR, ill-posed inverse problems, inhomogeneous diffusion, priorconditioning},
  publisher = {IOP Publishing},
}

@article{Bancel2021,
abstract = {Only one High Intensity Focused Ultrasound device has been clinically approved for transcranial brain surgery at the time of writing. The device operates within 650 kHz and 720 kHz and corrects the phase distortions induced by the skull of each patient using a multi-element phased array. Phase correction is estimated adaptively using a proprietary algorithm based on computed-tomography (CT) images of the patient's skull. In this paper, we assess the performance of the phase correction computed by the clinical device and compare it to (i) the correction obtained with a previously validated full-wave simulation algorithm using an open-source pseudo-spectral toolbox and (ii) a hydrophone-based correction performed invasively to measure the aberrations induced by the skull at 650 kHz. For the full-wave simulation, three different mappings between CT Hounsfield units and the longitudinal speed of sound inside the skull were tested. All methods are compared with the exact same setup thanks to transfer matrices acquired with the clinical system for N=5 skulls and T=2 different targets for each skull. We show that the clinical ray-tracing software and the full-wave simulation restore respectively 8415% and 8615% of the pressure obtained with hydrophone-based correction for targets located in central brain regions. On the second target (off-center), we also report that the performance of both algorithms degrades when the average incident angles of the acoustic beam at the skull surface increases. When incident angles are higher than 200, the restored pressure drops below 75% of the pressure restored with hydrophone-based correction.},
author = {Bancel, Thomas and Houdouin, Alexandre and Annic, Philippe and Rachmilevitch, Itay and Shapira, Yeruham and Tanter, Mickael and Aubry, Jean-Francois},
doi = {10.1109/TUFFC.2021.3063055},
file = {:home/antonio/Documents/bibliography/files/Bancel et al. - 2021 - Comparison between ray-tracing and full-wave simulation for transcranial ultrasound focusing on a clinical system.pdf:pdf},
issn = {1525-8955},
journal = {IEEE transactions on ultrasonics, ferroelectrics, and frequency control},
number = {c},
pmid = {33651688},
title = {{Comparison between ray-tracing and full-wave simulation for transcranial ultrasound focusing on a clinical system using the transfer matrix formalism.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/33651688},
volume = {PP},
year = {2021}
}

@Article{Cools2014,
  author   = {Cools, Siegfried and Reps, Bram and Vanroose, Wim},
  journal  = {Numerical Linear Algebra with Applications},
  title    = {{A new level-dependent coarse grid correction scheme for indefinite Helmholtz problems}},
  year     = {2014},
  issn     = {10991506},
  number   = {4},
  pages    = {513--533},
  volume   = {21},
  abstract = {In this paper, we construct and analyze a level-dependent coarse grid correction scheme for indefinite Helmholtz problems. This adapted multigrid (MG) method is capable of solving the Helmholtz equation on the finest grid using a series of MG cycles with a grid-dependent complex shift, leading to a stable correction scheme on all levels. It is rigorously shown that the adaptation of the complex shift throughout the MG cycle maintains the functionality of the two-grid correction scheme, as no smooth modes are amplified in or added to the error. In addition, a sufficiently smoothing relaxation scheme should be applied to ensure damping of the oscillatory error components. Numerical experiments on various benchmark problems show the method to be competitive with or even outperform the current state-of-the-art MG-preconditioned Krylov methods, for example, complex shifted Laplacian preconditioned flexible GMRES. {\textcopyright} 2013 John Wiley & Sons, Ltd.},
  doi      = {10.1002/nla.1895},
  keywords = {Complex shifted laplacian, Complex stretched grid, Helmholtz equation, Indefinite systems, Level-dependent correction scheme, Multigrid},
}

@Article{Papamakarios2018,
  author        = {Papamakarios, George and Pavlakou, Theo and Murray, Iain},
  journal       = {arXiv:1705.07057 [cs, stat]},
  title         = {{Masked Autoregressive Flow for Density Estimation}},
  year          = {2018},
  month         = {jun},
  number        = {Nips},
  abstract      = {Autoregressive models are among the best performing neural density estimators. We describe an approach for increasing the ﬂexibility of an autoregressive model, based on modelling the random numbers that the model uses internally when generating data. By constructing a stack of autoregressive models, each modelling the random numbers of the next model in the stack, we obtain a type of normalizing ﬂow suitable for density estimation, which we call Masked Autoregressive Flow. This type of ﬂow is closely related to Inverse Autoregressive Flow and is a generalization of Real NVP. Masked Autoregressive Flow achieves state-of-the-art performance in a range of general-purpose density estimation tasks.},
  file          = {:home/antonio/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Papamakarios, Pavlakou, Murray - 2017 - Masked Autoregressive Flow for Density Estimation.pdf:pdf},
  keywords      = {Computer Science - Machine Learning, Statistics - Machine Learning},
  language      = {en},
  mendeley-tags = {Computer Science - Machine Learning,Statistics - Machine Learning},
  url           = {http://arxiv.org/abs/1705.07057},
}

@Article{Sirignano2018,
  author        = {Sirignano, Justin and Spiliopoulos, Konstantinos},
  journal       = {Journal of Computational Physics},
  title         = {{DGM: A deep learning algorithm for solving partial differential equations}},
  year          = {2018},
  issn          = {10902716},
  number        = {Dms 1550918},
  pages         = {1339--1364},
  volume        = {375},
  abstract      = {High-dimensional PDEs have been a longstanding computational challenge. We propose to solve high-dimensional PDEs by approximating the solution with a deep neural network which is trained to satisfy the differential operator, initial condition, and boundary conditions. Our algorithm is meshfree, which is key since meshes become infeasible in higher dimensions. Instead of forming a mesh, the neural network is trained on batches of randomly sampled time and space points. The algorithm is tested on a class of high-dimensional free boundary PDEs, which we are able to accurately solve in up to 200 dimensions. The algorithm is also tested on a high-dimensional Hamilton–Jacobi–Bellman PDE and Burgers' equation. The deep learning algorithm approximates the general solution to the Burgers' equation for a continuum of different boundary conditions and physical conditions (which can be viewed as a high-dimensional space). We call the algorithm a “Deep Galerkin Method (DGM)” since it is similar in spirit to Galerkin methods, with the solution approximated by a neural network instead of a linear combination of basis functions. In addition, we prove a theorem regarding the approximation power of neural networks for a class of quasilinear parabolic PDEs.},
  archiveprefix = {arXiv},
  arxivid       = {1708.07469},
  doi           = {10.1016/j.jcp.2018.08.029},
  eprint        = {1708.07469},
  file          = {:home/antonio/Documents/bibliography/files/Sirignano, Spiliopoulos - 2018 - DGM A deep learning algorithm for solving partial differential equations.pdf:pdf;:home/antonio/Documents/bibliography/files/Sirignano, Spiliopoulos - 2018 - DGM A deep learning algorithm for solving partial differential equations(2).pdf:pdf},
  keywords      = {Deep learning, High-dimensional partial differential equations, Machine learning, Partial differential equations},
  publisher     = {Elsevier Inc.},
  url           = {https://doi.org/10.1016/j.jcp.2018.08.029},
}

@Article{ZepedaNunez2018,
  author   = {Zepeda-N{\'{u}}{\~{n}}ez, Leonardo and Scheuer, Adrien and Hewett, Russell J. and Demanet, Laurent},
  journal  = {arXiv},
  title    = {{The method of polarized traces for the 3D Helmholtz equation}},
  year     = {2018},
  issn     = {23318422},
  pages    = {1--54},
  abstract = {We present a fast solver for the 3D high-frequency Helmholtz equation in heterogeneous, constant density, acoustic media. The solver is based on the method of polarized traces, coupled with distributed linear algebra libraries and pipelining to obtain an empirical online runtime O(max(1, R/n)N log N) where N = n3 is the total number of degrees of freedom and R is the number of right-hand sides. Such a favorable scaling is a prerequisite for large-scale implementations of full waveform inversion (FWI) in frequency domain.},
  file     = {:home/antonio/Documents/bibliography/files/Zepeda-N{\'{u}}{\~{n}}ez et al. - 2018 - The method of polarized traces for the 3D Helmholtz equation.pdf:pdf},
}

@Article{Engquist2011,
  author   = {Engquist, Bjorn and Poulson, Jack and Ying, Lexing},
  journal  = {SEG Technical Program Expanded Abstracts},
  title    = {{Sweeping preconditioner for the 3D Helmholtz equation}},
  year     = {2011},
  issn     = {19494645},
  number   = {2},
  pages    = {1--27},
  volume   = {30},
  file     = {:home/antonio/Documents/bibliography/files/Engquist, Poulson, Ying - 2011 - Sweeping preconditioner for the 3D Helmholtz equation.pdf:pdf;:home/antonio/Documents/bibliography/files/Engquist, Poulson, Ying - 2011 - Sweeping preconditioner for the 3D Helmholtz equation(2).pdf:pdf;:home/antonio/Documents/bibliography/files/Engquist, Poulson, Ying - 2011 - Sweeping preconditioner for the 3D Helmholtz equation(3).pdf:pdf},
  keywords = {10, 100804644, 1137, 65f08, 65n22, 65n80, ams subject classifications, doi, factorization, green, helmholtz equation, high frequency waves, ldl t, multifrontal methods, optimal ordering, perfectly matched layers, preconditioners, s function},
}

@Article{Elman2002,
  author   = {Elman, Howard C. and Ernst, Oliver G. and O'Leary, Dianne P.},
  journal  = {SIAM Journal on Scientific Computing},
  title    = {{A multigrid method enhanced by Krylov subspace iteration for discrete Helmholtz equations}},
  year     = {2002},
  issn     = {10648275},
  number   = {4},
  pages    = {1291--1315},
  volume   = {23},
  abstract = {Standard multigrid algorithms have proven ineffective for the solution of discretizations of Helmholtz equations. In this work we modify the standard algorithm by adding GMRES iterations at coarse levels and as an outer iteration. We demonstrate the algorithm's effectiveness through theoretical analysis of a model problem and experimental results. In particular, we show thai the combined use of GMRES as a smoother and outer iteration produces an algorithm whose performance depends relatively mildly on wave number and is robust for normalized wave numbers as large as 200. For fixed wave numbers, it displays grid-independent convergence rates and has costs proportional to the number of unknowns.},
  doi      = {10.1137/S1064827501357190},
  file     = {:home/antonio/Documents/bibliography/files/Elman, Ernst, O'Leary - 2002 - A multigrid method enhanced by Krylov subspace iteration for discrete Helmholtz equations.pdf:pdf},
  keywords = {Helmholtz equation, Krylov subspace methods, Multigrid},
}

@Article{Gander2019,
  author        = {Gander, Martin J. and Zhang, Hui},
  journal       = {SIAM Review},
  title         = {{A class of iterative solvers for the Helmholtz equation: Factorizations, sweeping preconditioners, source transfer, single layer potentials, polarized traces, and optimized Schwarz methods}},
  year          = {2019},
  issn          = {00361445},
  number        = {1},
  pages         = {3--76},
  volume        = {61},
  abstract      = {Solving time-harmonic wave propagation problems by iterative methods is a difficult task, and over the last two decades an important research effort has gone into developing preconditioners for the simplest representative of such wave propagation problems, the Helmholtz equation. A specific class of these new preconditioners is considered here. They were developed by researchers with various backgrounds using formulations and notations that are very different, and all are among the most promising preconditioners for the Helmholtz equation. The goal of the present article is to show that this class of preconditioners is based on a common mathematical principle, and that they can all be formulated in the context of domain decomposition methods known as optimized Schwarz methods. This common formulation allows us to explain in detail how and why all these methods work. The domain decomposition formulation also allows us to avoid technicalities in the implementation description we give of these recent methods. The equivalence of these methods with optimized Schwarz methods translates at the discrete level into equivalence with approximate block LU decomposition preconditioners, and in each case we give the algebraic version, including a detailed description of the approximations used. While we choose to use the Helmholtz equation for which these methods were developed, our notation is completely general and the algorithms we give are written for an arbitrary second-order elliptic operator. The algebraic versions are even more general, assuming only a connectivity pattern in the discretization matrix. All the new methods studied here are based on sequential decomposition of the problem in space into a sequence of subproblems, and they have in their optimal form the property to lead to nilpotent iterations, like an exact block LU factorization. Using our domain decomposition formulation, we finally present an algorithm for two-dimensional decompositions, i.e., decompositions that contain cross points, which is still nilpotent in its optimal form. Its approximation is currently an active area of research, and it would have been difficult to discover such an algorithm without the domain decomposition framework.},
  archiveprefix = {arXiv},
  arxivid       = {1610.02270},
  doi           = {10.1137/16M109781X},
  eprint        = {1610.02270},
  file          = {:home/antonio/Documents/bibliography/files/Gander, Zhang - 2019 - A class of iterative solvers for the Helmholtz equation Factorizations, sweeping preconditioners, source transfer.pdf:pdf;:home/antonio/Downloads/sweeping.pdf:pdf},
  keywords      = {Factorization, Helmholtz, Iterative, Preconditioner, Schwarz, Sweeping},
}

@article{Erlangga2008,
abstract = {In this paper we survey the development of fast iterative solvers aimed at solving 2D/3D Helmholtz problems. In the first half of the paper, a survey on some recently developed methods is given. The second half of the paper focuses on the development of the shifted Laplacian preconditioner used to accelerate the convergence of Krylov subspace methods applied to the Helmholtz equation. Numerical examples are given for some difficult problems, which had not been solved iteratively before. {\textcopyright} 2007 CIMNE, Barcelona, Spain.},
author = {Erlangga, Yogi A.},
doi = {10.1007/s11831-007-9013-7},
file = {:home/antonio/Documents/bibliography/files/Erlangga - 2008 - Advances in iterative methods and preconditioners for the Helmholtz equation.pdf:pdf},
issn = {11343060},
journal = {Archives of Computational Methods in Engineering},
number = {1},
pages = {37--66},
title = {{Advances in iterative methods and preconditioners for the Helmholtz equation}},
volume = {15},
year = {2008}
}

@Article{Gordon2013,
  author    = {Gordon, Dan and Gordon, Rachel},
  journal   = {Journal of Computational and Applied Mathematics},
  title     = {{Robust and highly scalable parallel solution of the Helmholtz equation with large wave numbers}},
  year      = {2013},
  issn      = {03770427},
  number    = {1},
  pages     = {182--196},
  volume    = {237},
  abstract  = {Numerical solution of the Helmholtz equation is a challenging computational task, particularly when the wave number is large. For two-dimensional problems, direct methods provide satisfactory solutions, but large three-dimensional problems become unmanageable. In this work, the block-parallel CARP-CG algorithm [Parallel Computing 36, 2010] is applied to the Helmholtz equation with large wave numbers. The effectiveness of this algorithm is shown both theoretically and practically, with numerical experiments on two- and three-dimensional domains, including heterogeneous cases, and a wide range of wave numbers. A second-order finite difference discretization scheme is used, leading to a complex, nonsymmetric and indefinite linear system. CARP-CG is both robust and efficient on the tested problems. On a fixed grid, its scalability improves as the wave number increases. Additionally, when the number of grid points per wavelength is fixed, the number of iterations increases linearly with the wave number. Convergence rates for heterogeneous cases are similar to those of homogeneous cases. CARP-CG also outperforms, at all wave numbers, one of the leading methods, based on the shifted Laplacian preconditioner with a complex shift and solved with a multigrid. {\textcopyright} 2012 Elsevier B.V. All rights reserved.},
  doi       = {10.1016/j.cam.2012.07.024},
  file      = {:home/antonio/Documents/bibliography/files/Gordon, Gordon - 2013 - Robust and highly scalable parallel solution of the Helmholtz equation with large wave numbers.pdf:pdf},
  keywords  = {CARP-CG, Helmholtz equation, High frequency, Large wave numbers, Parallel processing, Partial differential equations},
  publisher = {Elsevier B.V.},
  url       = {http://dx.doi.org/10.1016/j.cam.2012.07.024},
}

@Article{Erlangga2006,
  author   = {Erlangga, Y. A. and Vuik, C. and Oosterlee, C. W.},
  journal  = {Applied Numerical Mathematics},
  title    = {{Comparison of multigrid and incomplete LU shifted-Laplace preconditioners for the inhomogeneous Helmholtz equation}},
  year     = {2006},
  issn     = {01689274},
  number   = {5},
  pages    = {648--666},
  volume   = {56},
  abstract = {Within the framework of shifted-Laplace preconditioners [Y.A. Erlangga, C. Vuik, C.W. Oosterlee, On a class of preconditioners for the Helmholtz equation, Appl. Numer. Math. 50 (2004) 409-425] for the Helmholtz equation, different methods for the approximation of the inverse of a complex-valued Helmholtz operator are discussed. The performance of the preconditioner for Helmholtz problems at high wavenumbers in heterogeneous media is evaluated. Comparison with other preconditioners from the literature is also presented. {\textcopyright} 2005 IMACS. Published by Elsevier B.V. All rights reserved.},
  doi      = {10.1016/j.apnum.2005.04.039},
  file     = {:home/antonio/Documents/bibliography/files/Erlangga, Vuik, Oosterlee - 2006 - Comparison of multigrid and incomplete LU shifted-Laplace preconditioners for the inhomogeneous Helmh.pdf:pdf},
  keywords = {Helmholtz equation, ILU, Krylov subspace methods, Multigrid, Shifted-Laplace preconditioner},
}

@Article{Chae2016,
  author        = {Chae, Minwoo and Walker, Stephen G.},
  title         = {{An EM based Iterative Method for Solving Large Sparse Linear Systems}},
  year          = {2016},
  number        = {1},
  pages         = {1--18},
  abstract      = {We propose a novel iterative algorithm for solving a large sparse linear system. The method is based on the EM algorithm. If the system has a unique solution, the algorithm guarantees convergence with a geometric rate. Otherwise, convergence to a minimal Kullback--Leibler divergence point is guaranteed. The algorithm is easy to code and competitive with other iterative algorithms.},
  archiveprefix = {arXiv},
  arxivid       = {1609.00670},
  doi           = {10.1080/03081087.2018.1498061},
  eprint        = {1609.00670},
  file          = {:home/antonio/Documents/bibliography/files/Chae, Walker - 2016 - An EM based Iterative Method for Solving Large Sparse Linear Systems.pdf:pdf},
  keywords      = {em algorithm, indefinite matrix, iterative method, kullback, leibler divergence, sparse linear system},
  url           = {http://arxiv.org/abs/1609.00670%0Ahttp://dx.doi.org/10.1080/03081087.2018.1498061},
}

@article{Rajeswaran2019,
abstract = {A core capability of intelligent systems is the ability to quickly learn new tasks by drawing on prior experience. Gradient (or optimization) based meta-learning has recently emerged as an effective approach for few-shot learning. In this formulation, meta-parameters are learned in the outer loop, while task-specific models are learned in the inner-loop, by using only a small amount of data from the current task. A key challenge in scaling these approaches is the need to differentiate through the inner loop learning process, which can impose considerable computational and memory burdens. By drawing upon implicit differentiation, we develop the implicit MAML algorithm, which depends only on the solution to the inner level optimization and not the path taken by the inner loop optimizer. This effectively decouples the meta-gradient computation from the choice of inner loop optimizer. As a result, our approach is agnostic to the choice of inner loop optimizer and can gracefully handle many gradient steps without vanishing gradients or memory constraints. Theoretically, we prove that implicit MAML can compute accurate meta-gradients with a memory footprint no more than that which is required to compute a single inner loop gradient and at no overall increase in the total computational cost. Experimentally, we show that these benefits of implicit MAML translate into empirical gains on few-shot image recognition benchmarks.},
archivePrefix = {arXiv},
arxivId = {1909.04630},
author = {Rajeswaran, Aravind and Finn, Chelsea and Kakade, Sham and Levine, Sergey},
eprint = {1909.04630},
file = {:home/antonio/Documents/bibliography/files/Rajeswaran et al. - 2019 - Meta-learning with implicit gradients.pdf:pdf},
issn = {23318422},
journal = {arXiv},
title = {{Meta-learning with implicit gradients}},
year = {2019}
}

@article{Huang2020,
abstract = {In this paper, we propose an approach to effectively accelerating the computation of continuous normalizing flow (CNF), which has been proven to be a powerful tool for the tasks such as variational inference and density estimation. The training time cost of CNF can be extremely high because the required number of function evaluations (NFE) for solving corresponding ordinary differential equations (ODE) is very large. We think that the high NFE results from large truncation errors of solving ODEs. To address the problem, we propose to add a regularization. The regularization penalizes the difference between the trajectory of the ODE and its fitted polynomial regression. The trajectory of ODE will approximate a polynomial function, and thus the truncation error will be smaller. Furthermore, we provide two proofs and claim that the additional regularization does not harm training quality. Experimental results show that our proposed method can result in 42.3% to 71.3% reduction of NFE on the task of density estimation, and 19.3% to 32.1% reduction of NFE on variational auto-encoder, while the testing losses are not affected at all.},
archivePrefix = {arXiv},
arxivId = {2012.04228},
author = {Huang, Han Hsien and Yeh, Mi Yen},
eprint = {2012.04228},
file = {:home/antonio/Documents/bibliography/files/Huang, Yeh - 2020 - Accelerating continuous normalizing flow with trajectory polynomial regularization.pdf:pdf},
issn = {23318422},
journal = {arXiv},
title = {{Accelerating continuous normalizing flow with trajectory polynomial regularization}},
volume = {1},
year = {2020}
}

@article{Chena,
author = {Chen, Hu and Zhang, Yi and Kalra, Mannudeep K and Lin, Feng and Chen, Yang and Liao, Peixo and Member, Senior and Wang, Ge},
file = {:home/antonio/Documents/bibliography/files/Chen et al. - Unknown - Low-Dose CT with a Residual Encoder-Decoder Convolutional Neural Network (RED-CNN).pdf:pdf},
title = {{Low-Dose CT with a Residual Encoder-Decoder Convolutional Neural Network (RED-CNN)}}
}

@Article{Ying2015a,
  author   = {Ying, Lexing},
  title    = {{APPROXIMATIONS OF INDEFINITE SYSTEMS ON PERIODIC Copyright {\textcopyright} by SIAM . Unauthorized reproduction of this article is prohibited . Copyright {\textcopyright} by SIAM . Unauthorized reproduction of this article is prohibited .}},
  year     = {2015},
  number   = {2},
  pages    = {459--471},
  volume   = {13},
  file     = {:home/antonio/Documents/bibliography/files/Ying - 2015 - APPROXIMATIONS OF INDEFINITE SYSTEMS ON PERIODIC Copyright {\textcopyright} by SIAM . Unauthorized reproduction of this article is proh.pdf:pdf},
  keywords = {65f08, 65f50, 65n22, ams subject classifications, helmholtz equation, imation, indefinite matrix, odinger equation, periodic structure, preconditioner, pseudospectral approx-, schr, sparse linear algebra},
}

@article{Kawaguchi2021a,
author = {Kawaguchi, Kenji},
file = {:home/antonio/Documents/bibliography/files/Kawaguchi - 2021 - A S IMPLE D EEP E QUILIBRIUM M ODEL C ONVERGES.pdf:pdf},
pages = {1--38},
title = {{A S IMPLE D EEP E QUILIBRIUM M ODEL C ONVERGES}},
year = {2021}
}

@article{Tancik2020a,
abstract = {We show that passing input points through a simple Fourier feature mapping enables a multilayer perceptron (MLP) to learn high-frequency functions in low-dimensional problem domains. These results shed light on recent advances in computer vision and graphics that achieve state-of-the-art results by using MLPs to represent complex 3D objects and scenes. Using tools from the neural tangent kernel (NTK) literature, we show that a standard MLP fails to learn high frequencies both in theory and in practice. To overcome this spectral bias, we use a Fourier feature mapping to transform the effective NTK into a stationary kernel with a tunable bandwidth. We suggest an approach for selecting problem-specific Fourier features that greatly improves the performance of MLPs for low-dimensional regression tasks relevant to the computer vision and graphics communities.},
archivePrefix = {arXiv},
arxivId = {2006.10739},
author = {Tancik, Matthew and Srinivasan, Pratul P. and Mildenhall, Ben and Fridovich-Keil, Sara and Raghavan, Nithin and Singhal, Utkarsh and Ramamoorthi, Ravi and Barron, Jonathan T. and Ng, Ren},
eprint = {2006.10739},
file = {:home/antonio/Documents/bibliography/files/Tancik et al. - 2020 - Fourier Features Let Networks Learn High Frequency Functions in Low Dimensional Domains.pdf:pdf},
issn = {23318422},
journal = {arXiv},
pages = {1--24},
title = {{Fourier Features Let Networks Learn High Frequency Functions in Low Dimensional Domains}},
year = {2020}
}

@article{Gander,
archivePrefix = {arXiv},
arxivId = {arXiv:1610.02270v3},
author = {Gander, Martin J and Zhang, H U I},
eprint = {arXiv:1610.02270v3},
file = {:home/antonio/Documents/bibliography/files/Gander, Zhang - Unknown - A class of iterative solvers for the helmholtz equation factorizations, sweeping preconditioners, source trans.pdf:pdf},
pages = {1--71},
title = {{A class of iterative solvers for the helmholtz equation: factorizations, sweeping preconditioners, source transfer, single layer potentials, polarized traces, and optimized schwarz methods}}
}

@article{Amos2016,
abstract = {This paper presents the input convex neural network architecture. These are scalar-valued (potentially deep) neural networks with constraints on the network parameters such that the output of the network is a convex function of (some of) the inputs. The networks allow for efficient inference via optimization over some inputs to the network given others, and can be applied to settings including structured prediction, data imputation, reinforcement learning, and others. In this paper we lay the basic groundwork for these models, proposing methods for inference, optimization and learning, and analyze their representational power. We show that many existing neural network architectures can be made input-convex with a minor modification, and develop specialized optimization algorithms tailored to this setting. Finally, we highlight the performance of the methods on multi-label prediction, image completion, and reinforcement learning problems, where we show improvement over the existing state of the art in many cases.},
archivePrefix = {arXiv},
arxivId = {1609.07152},
author = {Amos, Brandon and Xu, Lei and Kolter, J. Zico},
eprint = {1609.07152},
file = {:home/antonio/Documents/bibliography/files/Amos, Xu, Kolter - 2016 - Input Convex Neural Networks.pdf:pdf},
title = {{Input Convex Neural Networks}},
url = {http://arxiv.org/abs/1609.07152},
year = {2016}
}

@article{Meinhardt2017,
archivePrefix = {arXiv},
arxivId = {arXiv:1704.03488v2},
author = {Meinhardt, Tim},
eprint = {arXiv:1704.03488v2},
file = {:home/antonio/Documents/bibliography/files/Meinhardt - Unknown - Learning Proximal Operators Using Denoising Networks for Regularizing Inverse Imaging Problems.pdf:pdf;:home/antonio/Documents/bibliography/files/Meinhardt - 2017 - Learning Proximal Operators Using Denoising Networks for Regularizing Inverse Imaging Problems.pdf:pdf},
number = {October},
pages = {1781--1790},
title = {{Learning Proximal Operators : Using Denoising Networks for Regularizing Inverse Imaging Problems}},
year = {2017}
}

@Article{Hammernik2018,
  author        = {Hammernik, Kerstin and Klatzer, Teresa and Kobler, Erich and Recht, Michael P. and Sodickson, Daniel K. and Pock, Thomas and Knoll, Florian},
  journal       = {Magnetic Resonance in Medicine},
  title         = {{Learning a variational network for reconstruction of accelerated MRI data}},
  year          = {2018},
  issn          = {15222594},
  number        = {6},
  pages         = {3055--3071},
  volume        = {79},
  abstract      = {Purpose: To allow fast and high-quality reconstruction of clinical accelerated multi-coil MR data by learning a variational network that combines the mathematical structure of variational models with deep learning. Theory and Methods: Generalized compressed sensing reconstruction formulated as a variational model is embedded in an unrolled gradient descent scheme. All parameters of this formulation, including the prior model defined by filter kernels and activation functions as well as the data term weights, are learned during an offline training procedure. The learned model can then be applied online to previously unseen data. Results: The variational network approach is evaluated on a clinical knee imaging protocol for different acceleration factors and sampling patterns using retrospectively and prospectively undersampled data. The variational network reconstructions outperform standard reconstruction algorithms, verified by quantitative error measures and a clinical reader study for regular sampling and acceleration factor 4. Conclusion: Variational network reconstructions preserve the natural appearance of MR images as well as pathologies that were not included in the training data set. Due to its high computational performance, that is, reconstruction time of 193 ms on a single graphics card, and the omission of parameter tuning once the network is trained, this new approach to image reconstruction can easily be integrated into clinical workflow. Magn Reson Med 79:3055–3071, 2018. {\textcopyright} 2017 International Society for Magnetic Resonance in Medicine.},
  archiveprefix = {arXiv},
  arxivid       = {1704.00447},
  doi           = {10.1002/mrm.26977},
  eprint        = {1704.00447},
  file          = {:home/antonio/Documents/bibliography/files/Hammernik et al. - Unknown - Learning a Variational Network for Reconstruction of Accelerated MRI Data.pdf:pdf;:home/antonio/Documents/bibliography/files/Hammernik et al. - 2018 - Learning a variational network for reconstruction of accelerated MRI data.pdf:pdf;:home/antonio/Documents/bibliography/files/Hammernik et al. - 2018 - Learning a variational network for reconstruction of accelerated MRI data(2).pdf:pdf;:home/antonio/Documents/bibliography/files/Hammernik et al. - 2018 - Learning a variational network for reconstruction of accelerated MRI data(3).pdf:pdf},
  keywords      = {accelerated MRI, compressed sensing, deep learning, image reconstruction, parallel imaging, variational network},
}

@misc{Hsieh2019,
abstract = {Partial differential equations (PDEs) are widely used across the physical and computational sciences. Decades of research and engineering went into designing fast iterative solution methods. Existing solvers are general purpose, but may be sub-optimal for specific classes of problems. In contrast to existing hand-crafted solutions, we propose an approach to learn a fast iterative solver tailored to a specific domain. We achieve this goal by learning to modify the updates of an existing solver using a deep neural network. Crucially, our approach is proven to preserve strong correctness and convergence guarantees. After training on a single geometry, our model generalizes to a wide variety of geometries and boundary conditions, and achieves 2-3 times speedup compared to state-of-the-art solvers.},
archivePrefix = {arXiv},
arxivId = {1906.01200},
author = {Hsieh, Jun Ting and Zhao, Shengjia and Eismann, Stephan and Mirabella, Lucia and Ermon, Stefano},
booktitle = {arXiv},
eprint = {1906.01200},
file = {:home/antonio/Documents/bibliography/files/Hsieh et al. - 2019 - Learning neural pde solvers with convergence guarantees.pdf:pdf},
issn = {23318422},
number = {i},
pages = {1--14},
title = {{Learning neural pde solvers with convergence guarantees}},
year = {2019}
}

@Article{Jiang,
  author        = {Jiang, Zhengyao and Xu, Dixing and Liang, Jinjun},
  title         = {{A Deep Reinforcement Learning Framework for the Financial Portfolio Management Problem}},
  pages         = {1--31},
  archiveprefix = {arXiv},
  arxivid       = {arXiv:1706.10059v2},
  eprint        = {arXiv:1706.10059v2},
  file          = {:home/antonio/Documents/bibliography/files/Jiang, Xu, Liang - Unknown - A Deep Reinforcement Learning Framework for the Financial Portfolio Management Problem.pdf:pdf},
  keywords      = {algorithmic trading, bitcoin, convolutional neural networks, cryptocur-, deep learning, long short-term memory, machine learning, portfolio management, quantitative finance, recurrent neural net-, reinforcement learning, rency, works},
}

@Misc{Arjovsky2017,
  author        = {Arjovsky, Martin and Chintala, Soumith and Bottou, L{\'{e}}on},
  month         = {dec},
  title         = {{Wasserstein GaN}},
  year          = {2017},
  abstract      = {We introduce a new algorithm named WGAN, an alternative to traditional GAN training. In this new model, we show that we can improve the stability of learning, get rid of problems like mode collapse, and provide meaningful learning curves useful for debugging and hyperparameter searches. Furthermore, we show that the corresponding optimization problem is sound, and provide extensive theoretical work highlighting the deep connections to other distances between distributions.},
  archiveprefix = {arXiv},
  arxivid       = {1701.07875},
  booktitle     = {arXiv},
  eprint        = {1701.07875},
  keywords      = {Computer Science - Machine Learning, Statistics - Machine Learning},
  language      = {en},
  mendeley-tags = {Computer Science - Machine Learning,Statistics - Machine Learning},
  number        = {2016},
  pages         = {156--163},
  url           = {http://arxiv.org/abs/1701.07875},
  volume        = {2},
}

@inproceedings{Metz2019,
abstract = {Deep learning has shown that learned functions can dramatically outperform hand-designed functions on perceptual tasks. Analogously, this suggests that learned optimizers may similarly outperform current hand-designed optimizers, especially for specific problems. However, learned optimizers are notoriously difficult to train and have yet to demonstrate wall-clock speedups over hand-designed optimizers, and thus are rarely used in practice. Typically, learned optimizers are trained by truncated backpropagation through an unrolled optimization process resulting in gradients that are either strongly biased (for short truncations) or have exploding norm (for long truncations). In this work we propose a training scheme which overcomes both of these difficulties, by dynamically weighting two unbiased gradient estimators for a variational loss on optimizer performance, allowing us to train neural networks to perform optimization of a specific task faster than tuned first-order methods. We demonstrate these results on problems where our learned optimizer trains convolutional networks faster in wall-clock time compared to tuned first-order methods and with an improvement in test loss.},
archivePrefix = {arXiv},
arxivId = {1810.10180},
author = {Metz, Luke and Maheswaranathan, Niru and Nixon, Jeremy and {Daniel Freeman}, C. and Sohl-Dickstein, Jascha},
booktitle = {36th International Conference on Machine Learning, ICML 2019},
eprint = {1810.10180},
isbn = {9781510886988},
language = {en},
pages = {8016--8035},
title = {{Understanding and correcting pathologies in the training of learned optimizers}},
volume = {2019-June},
year = {2019}
}

@InProceedings{Arora2018,
  author        = {Arora, Raman and Basu, Amitabh and Mianjy, Poorya and Mukherjee, Anirbit},
  booktitle     = {6th International Conference on Learning Representations, ICLR 2018 - Conference Track Proceedings},
  title         = {{Understanding deep neural networks with rectified linear units}},
  year          = {2018},
  month         = {feb},
  abstract      = {In this paper we investigate the family of functions representable by deep neural networks (DNN) with rectified linear units (ReLU). We give an algorithm to train a ReLU DNN with one hidden layer to global optimality with runtime polynomial in the data size albeit exponential in the input dimension. Further, we improve on the known lower bounds on size (from exponential to super exponential) for approximating a ReLU deep net function by a shallower ReLU net. Our gap theorems hold for smoothly parametrized families of “hard” functions, contrary to countable, discrete families known in the literature. An example consequence of our gap theorems is the following: for every natural number k there exists a function representable by a ReLU DNN with k2 hidden layers and total size k3, such that any ReLU DNN with at most k hidden layers will require at least 21 kk+1 − 1 total nodes. Finally, for the family of Rn → R DNNs with ReLU activations, we show a new lowerbound on the number of affine pieces, which is larger than previous constructions in certain regimes of the network architecture and most distinctively our lowerbound is demonstrated by an explicit construction of a smoothly parameterized family of functions attaining this scaling. Our construction utilizes the theory of zonotopes from polyhedral theory.},
  archiveprefix = {arXiv},
  arxivid       = {1611.01491},
  eprint        = {1611.01491},
  keywords      = {Computer Science - Artificial Intelligence, Computer Science - Computational Complexity, Computer Science - Machine Learning, Condensed Matter - Disordered Systems and Neural N, Statistics - Machine Learning},
  language      = {en},
  mendeley-tags = {Computer Science - Artificial Intelligence,Computer Science - Computational Complexity,Computer Science - Machine Learning,Condensed Matter - Disordered Systems and Neural N,Statistics - Machine Learning},
  url           = {http://arxiv.org/abs/1611.01491},
}

@misc{Zhong2020,
abstract = {In this work, we introduce Dissipative SymODEN, a deep learning architecture which can infer the dynamics of a physical system with dissipation from observed state trajectories. To improve prediction accuracy while reducing network size, Dissipative SymODEN encodes the port-Hamiltonian dynamics with energy dissipation and external input into the design of its computation graph and learns the dynamics in a structured way. The learned model, by revealing key aspects of the system, such as the inertia, dissipation, and potential energy, paves the way for energy-based controllers.},
archivePrefix = {arXiv},
arxivId = {2002.08860},
author = {Zhong, Yaofeng Desmond and Dey, Biswadip and Chakraborty, Amit},
booktitle = {arXiv},
eprint = {2002.08860},
issn = {23318422},
language = {en},
pages = {6},
title = {{Dissipative symoden: Encoding hamiltonian dynamics with dissipation and control into deep learning}},
year = {2020}
}

@article{Minka2005,
abstract = {This paper presents a unifying view of message-passing algorithms, as methods to approximate a complex Bayesian network by a simpler network with minimum information divergence. In this view, the difference between mean-field methods and belief propagation is not the amount of structure they model, but only the measure of loss they minimize (`exclusive' versus `inclusive' Kullback-Leibler divergence). In each case, message-passing arises by minimizing a localized version of the divergence, local to each factor. By examining these divergence measures, we can intuit the types of solution they prefer (symmetry-breaking, for example) and their suitability for different tasks. Furthermore, by considering a wider variety of divergence measures (such as alpha-divergences), we can achieve different complexity and performance goals.},
author = {Minka, Thomas P},
issn = {0735-0015},
journal = {Microsoft Research Technical Report},
language = {en},
number = {MSR-TR-2005-173},
pages = {17},
title = {{Divergence measures and message passing}},
year = {2005}
}

@Article{Lam2006,
  author        = {Lam, Chunwei J. and Singer, Andrew C.},
  journal       = {IEEE Transactions on Signal Processing},
  title         = {{Bayesian beamforming for DOA uncertainty: Theory and implementation}},
  year          = {2006},
  issn          = {1053587X},
  number        = {11},
  pages         = {4435--4445},
  volume        = {54},
  abstract      = {A Bayesian approach to adaptive narrowband beamforming for uncertain source direction-of-arrival (DOA) is presented. The DOA is modeled as a random variable with prior statistics that describe its level of uncertainty. The Bayesian beamformer is the corresponding minimum mean-square error (MMSE) estimator, which can be viewed as a mixture of directional beamformers combined according to the posterior distribution of the DOA given the data. Under a deterministic DOA, the mean-square error (MSE) of the Bayesian beamformer becomes as low as that of the directional beamformer equipped with the DOA candidate in the prior set that is the closest to the true DOA at exponential rate, where closeness is defined in the Kullback-Leibler sense. Two efficient algorithms using a uniform linear array (ULA) are presented. The first method utilizes the efficiency of the fast Fourier transform (FFT) to compute the posterior distribution on a large number of DOA candidates. The second method approximates the posterior distribution by a Gaussian distribution, which leads to a directional beamformer incorporated with a particular spreading matrix and an adjusted DOA. Numerical simulations show that the proposed beamformer outperforms other related blind or robust beamforming algorithms over a wide range of signal-to-noise ratios (SNRs). {\textcopyright} 2006 IEEE.},
  doi           = {10.1109/TSP.2006.880257},
  groups        = {Classical US imaging},
  keywords      = {Adaptive beamforming, Bayesian model, Direction-of-arrival (DOA) uncertainty, Folder - BSS and acoustic source localization, Minimum mean-square error (MMSE) estimation},
  mendeley-tags = {Adaptive beamforming,Bayesian model,Direction-of-arrival (DOA) uncertainty,Folder - BSS and acoustic source localization,Minimum mean-square error (MMSE) estimation},
}

@Article{BarSinai2019,
  author        = {Bar-Sinai, Yohai and Hoyer, Stephan and Hickey, Jason and Brenner, Michael P.},
  journal       = {Proceedings of the National Academy of Sciences of the United States of America},
  title         = {{Learning data-driven discretizations for partial differential equations}},
  year          = {2019},
  issn          = {10916490},
  month         = {jul},
  number        = {31},
  pages         = {15344--15349},
  volume        = {116},
  abstract      = {The numerical solution of partial differential equations (PDEs) is challenging because of the need to resolve spatiotemporal features over wide length- and timescales. Often, it is computationally intractable to resolve the finest features in the solution. The only recourse is to use approximate coarse-grained representations, which aim to accurately represent long-wavelength dynamics while properly accounting for unresolved small-scale physics. Deriving such coarse-grained equations is notoriously difficult and often ad hoc. Here we introduce data-driven discretization, a method for learning optimized approximations to PDEs based on actual solutions to the known underlying equations. Our approach uses neural networks to estimate spatial derivatives, which are optimized end to end to best satisfy the equations on a low-resolution grid. The resulting numerical methods are remarkably accurate, allowing us to integrate in time a collection of nonlinear equations in 1 spatial dimension at resolutions 4× to 8× coarser than is possible with standard finite-difference methods.},
  archiveprefix = {arXiv},
  arxivid       = {1808.04930},
  doi           = {10.1073/pnas.1814058116},
  eprint        = {1808.04930},
  file          = {:home/antonio/Documents/bibliography/files/Unknown - Unknown - Learning data-driven discretizations for partial differential equations.pdf:pdf},
  keywords      = {Coarse graining, Computational physics, Machine learning, coarse graining, computational physics, machine learning},
  language      = {en},
  mendeley-tags = {coarse graining,computational physics,machine learning},
  pmid          = {31311866},
  url           = {https://www.pnas.org/content/early/2019/07/15/1814058116},
}

@article{Qin2009,
abstract = {Microbubble contrast agents and the associated imaging systems have developed over the past 25 years, originating with manually-agitated fluids introduced for intra-coronary injection. Over this period, stabilizing shells and low diffusivity gas materials have been incorporated in microbubbles, extending stability in vitro and in vivo. Simultaneously, the interaction of these small gas bubbles with ultrasonic waves has been extensively studied, resulting in models for oscillation and increasingly sophisticated imaging strategies. Early studies recognized that echoes from microbubbles contained frequencies that are multiples of the microbubble resonance frequency. Although individual microbubble contrast agents cannot be resolved - given that their diameter is on the order of microns - nonlinear echoes from these agents are used to map regions of perfused tissue and to estimate the local microvascular flow rate. Such strategies overcome a fundamental limitation of previous ultrasound blood flow strategies; the previous Doppler-based strategies are insensitive to capillary flow. Further, the insonation of resonant bubbles results in interesting physical phenomena that have been widely studied for use in drug and gene delivery. Ultrasound pressure can enhance gas diffusion, rapidly fragment the agent into a set of smaller bubbles or displace the microbubble to a blood vessel wall. Insonation of a microbubble can also produce liquid jets and local shear stress that alter biological membranes and facilitate transport. In this review, we focus on the physical aspects of these agents, exploring microbubble imaging modes, models for microbubble oscillation and the interaction of the microbubble with the endothelium. {\textcopyright} 2009 Institute of Physics and Engineering in Medicine.},
author = {Qin, Shengping and Caskey, Charles F. and Ferrara, Katherine W.},
doi = {10.1088/0031-9155/54/6/R01},
issn = {00319155},
journal = {Physics in Medicine and Biology},
keywords = {Folder - Contrast agent physics},
language = {en},
mendeley-tags = {Folder - Contrast agent physics},
month = {mar},
number = {6},
pages = {R27--R57},
pmid = {19229096},
shorttitle = {Ultrasound contrast microbubbles in imaging and th},
title = {{Ultrasound contrast microbubbles in imaging and therapy: Physical principles and engineering}},
url = {http://stacks.iop.org/0031-9155/54/i=6/a=R01?key=crossref.747f537e4cc42fed007c7f0875ec5880},
volume = {54},
year = {2009}
}

@book{Bruna2013,
author = {Bruna, Joaquim and Cuf{\'{i}}, Juli{\`{a}}},
booktitle = {Complex Analysis},
doi = {10.4171/111},
title = {{Complex Analysis}},
year = {2013}
}

@Article{Garcia2013,
  author        = {Garcia, Damien and {Le Tarnec}, Louis and Muth, St{\'{e}}phan and Montagnon, Emmanuel and Por{\'{e}}e, Jonathan and Cloutier, Guy},
  journal       = {IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
  title         = {{Stolt's f-k migration for plane wave ultrasound imaging}},
  year          = {2013},
  issn          = {08853010},
  month         = {sep},
  number        = {9},
  pages         = {1853--1867},
  volume        = {60},
  abstract      = {Ultrafast ultrasound is an emerging modality that offers new perspectives and opportunities in medical imaging. Plane wave imaging (PWI) allows one to attain very high frame rates by transmission of planar ultrasound wavefronts. As a plane wave reaches a given scatterer, the latter becomes a secondary source emitting upward spherical waves and creating a diffraction hyperbola in the received RF signals. To produce an image of the scatterers, all the hyperbolas must be migrated back to their apexes. To perform beamforming of plane wave echo RFs and return high-quality images at high frame rates, we propose a new migration method carried out in the frequency-wavenumber (f-k) domain. The f-k migration for PWI has been adapted from the Stolt migration for seismic imaging. This migration technique is based on the exploding reflector model (ERM), which consists in assuming that all the scatterers explode in concert and become acoustic sources. The classical ERM model, however, is not appropriate for PWI. We showed that the ERM can be made suitable for PWI by a spatial transformation of the hyperbolic traces present in the RF data. In vitro experiments were performed to outline the advantages of PWI with Stolt's f-k migration over the conventional delay-and-sum (DAS) approach. The Stolt's f-k migration was also compared with the Fourier-based method developed by J.-Y. Lu. Our findings show that multi-angle compounded f-k migrated images are of quality similar to those obtained with a stateof- the-art dynamic focusing mode. This remained true even with a very small number of steering angles, thus ensuring a highly competitive frame rate. In addition, the new FFT-based f-k migration provides comparable or better contrast-to-noise ratio and lateral resolution than the Lu's and DAS migration schemes. Matlab codes for the Stolt's f-k migration for PWI are provided. {\textcopyright} 1986-2012 IEEE.},
  doi           = {10.1109/TUFFC.2013.2771},
  groups        = {Classical US imaging},
  keywords      = {Folder - Classical beamforming},
  language      = {en},
  mendeley-tags = {Folder - Classical beamforming},
  pmid          = {24626107},
  url           = {http://ieeexplore.ieee.org/document/6587395/},
}

@Article{Erlangga2006a,
  author   = {Erlangga, Y. A. and Oosterlee, C. W. and Vuik, C.},
  journal  = {SIAM Journal on Scientific Computing},
  title    = {{A novel multigrid based preconditioner for heterogeneous Helmholtz problems}},
  year     = {2006},
  issn     = {10648275},
  month    = {jan},
  number   = {4},
  pages    = {1471--1492},
  volume   = {27},
  abstract = {An iterative solution method, in the form of a preconditioner for a Krylov subspace method, is presented for the Helmholtz equation. The preconditioner is based on a Helmholtz-type differential operator with a complex term. A multigrid iteration is used for approximately inverting the preconditioner. The choice of multigrid components for the corresponding preconditioning matrix with a complex diagonal is validated with Fourier analysis. Multigrid analysis results are verified by numerical experiments. High wavenumber Helmholtz problems in heterogeneous media are solved indicating the performance of the preconditioner. {\textcopyright} 2006 Society for Industrial and Applied Mathematics.},
  doi      = {10.1137/040615195},
  file     = {:home/antonio/Documents/bibliography/files/Erlangga, Oosterlee, Vuik - 2006 - A novel multigrid based preconditioner for heterogeneous Helmholtz problems.pdf:pdf},
  keywords = {Complex multigrid preconditioner, Fourier analysis, Helmholtz equation, Nonconstant high wavenumber},
  language = {en},
  url      = {http://epubs.siam.org/doi/10.1137/040615195},
}

@InProceedings{Sasso2005,
  author        = {Sasso, Magali and Cohen-Bacrie, Claude},
  booktitle     = {ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
  title         = {{Medical ultrasound imaging using the fully adaptive beamformer}},
  year          = {2005},
  pages         = {ii--489},
  publisher     = {IEEE},
  volume        = {II},
  abstract      = {Medical ultrasound beamformingis conventionally done using a classical delay-and-sum operation. This simplest beam-forming suffers from drawbacks. Indeed, in phased array imaging the beamformed radio-frequency signal is often polluted with off-axis energies. In this paper, we investigate the use of an adaptive beamforming approach widely used in array processing, the fully adaptive beamformer, to reduce the bright off-axis energies contribution. We show that the fully adaptive beamformer cannot be applied to medical ultrasound as it was initially derived since medical ultrasonic medium produces coherent or highly correlated signals and the algorithm fails to work within this context. The spatial smoothing preprocessing is introduced which allows the fully adaptive beamformer to operate. A complementary preprocessing that uses the received data obtained using consecutive transmission lines further improve the performances. Very promising results as for the application of adaptive array processing techniques in medical ultrasound are obtained. {\textcopyright} 2005 IEEE.},
  doi           = {10.1109/ICASSP.2005.1415448},
  groups        = {Classical US imaging},
  isbn          = {0780388747},
  issn          = {15206149},
  keywords      = {Folder - Adaptive beamforming},
  mendeley-tags = {Folder - Adaptive beamforming},
}

@Article{2008,
  journal    = {Choice Reviews Online},
  title      = {{Introduction to classical mechanics: with problems and solutions}},
  year       = {2008},
  issn       = {0009-4978},
  month      = {nov},
  number     = {03},
  pages      = {46--1544--46--1544},
  volume     = {46},
  abstract   = {This textbook covers all the standard introductory topics in classical mechanics, including Newton's laws, oscillations, energy, momentum, angular momentum, planetary motion, and special relativity. It also explores more advanced topics, such as normal modes, the Lagrangian method, gyroscopic motion, fictitious forces, 4-vectors, and general relativity. It contains more than 250 problems with detailed solutions so students can easily check their understanding of the topic. There are also over 350 unworked exercises which are ideal for homework assignments. Password protected solutions are available to instructors at www.cambridge.org/9780521876223. The vast number of problems alone makes it an ideal supplementary text for all levels of undergraduate physics courses in classical mechanics. Remarks are scattered throughout the text, discussing issues that are often glossed over in other textbooks, and it is thoroughly illustrated with more than 600 figures to help demonstrate key concepts.},
  doi        = {10.5860/choice.46-1544},
  language   = {en},
  shorttitle = {Introduction to classical mechanics},
  url        = {http://choicereviews.org/review/10.5860/CHOICE.46-1544},
}

@inproceedings{Aghamiry2020,
abstract = {Wavefield Reconstruction Inversion (WRI) extends the linear regime of Full Waveform Inversion (FWI) by relaxing the wave equation with a feedback term to the data during wavefield simulation before updating the subsurface model by minimizing the source residuals this relaxation generates. Wavefield reconstruction and parameter estimation are efficiently nested with the alternating-direction method of multipliers (ADMM), leading to the so-called iteratively-refined WRI (IR-WRI). Capitalizing on the bilinearity of the wave equation, the alternating-direction strategy recasts the parameter estimation as a linear subproblem, which can be easily regularized with bound constraints and nonsmooth regularizations in the ADMM framework. Although the promise of regularized IR-WRI to image large-contrast media has been shown, the robustness of the parameter estimation subproblem can be further improved by phase retrieval during the early stages of IR-WRI, that is when the phase of the reconstructed wavefields is inaccurate in the deep part of the velocity model. Then, the velocity model inferred from phase retrieval at low frequencies is used as initial model for the subsequent steps of classical IR-WRI. This new workflow successfully reconstructs the BP salt model from a sparse fixed-spread acquisition using a 3 Hz starting frequency and a homogeneous initial velocity model.},
address = {San Antonio, Texas},
author = {Aghamiry, H. S. and Gholami, A. and Operto, S.},
booktitle = {SEG International Exposition and Annual Meeting 2019},
doi = {10.1190/segam2019-3216189.1},
language = {en},
month = {aug},
pages = {1526--1530},
publisher = {Society of Exploration Geophysicists},
title = {{Robust ADMM-based wavefield reconstruction inversion with phase retrieval}},
url = {https://library.seg.org/doi/10.1190/segam2019-3216189.1},
year = {2020}
}

@Article{Butts2001,
  author        = {Butts, Carter},
  journal       = {Computational & Mathematical Organization Theory},
  title         = {{Structure and Interpretation of Classical Mechanics}},
  year          = {2001},
  issn          = {1381-298X},
  number        = {4},
  pages         = {339--342},
  volume        = {7},
  abstract      = {The MIT Press; 2001, ISBN 0262194554},
  address       = {Cambridge, Massachusetts},
  doi           = {10.1023/A:1013458301432},
  edition       = {Second edi},
  isbn          = {978-0-262-02896-7},
  keywords      = {Mechanics, analytical dynamics, computational mechanics, computational physics, computer science, stochastic interpretation, time evolution},
  language      = {en},
  mendeley-tags = {Mechanics},
  publisher     = {The MIT Press},
}

@Article{Ito2015,
  author        = {Ito, Koichi and Noro, Kazumasa and Yanagisawa, Yukari and Sakamoto, Maya and Mori, Shiro and Shiga, Kiyoto and Kodama, Tetsuya and Aoki, Takafumi},
  journal       = {Ultrasound in Medicine and Biology},
  title         = {{High-Accuracy Ultrasound Contrast Agent Detection Method for Diagnostic Ultrasound Imaging Systems}},
  year          = {2015},
  issn          = {1879291X},
  number        = {12},
  pages         = {3120--3130},
  volume        = {41},
  abstract      = {An accurate method for detecting contrast agents using diagnostic ultrasound imaging systems is proposed. Contrast agents, such as microbubbles, passing through a blood vessel during ultrasound imaging are detected as blinking signals in the temporal axis, because their intensity value is constantly in motion. Ultrasound contrast agents are detected by evaluating the intensity variation of a pixel in the temporal axis. Conventional methods are based on simple subtraction of ultrasound images to detect ultrasound contrast agents. Even if the subject moves only slightly, a conventional detection method will introduce significant error. In contrast, the proposed technique employs spatiotemporal analysis of the pixel intensity variation over several frames. Experiments visualizing blood vessels in the mouse tail illustrated that the proposed method performs efficiently compared with conventional approaches. We also report that the new technique is useful for observing temporal changes in microvessel density in subiliac lymph nodes containing tumors. The results are compared with those of contrast-enhanced computed tomography.},
  doi           = {10.1016/j.ultrasmedbio.2015.07.032},
  keywords      = {Computer-aided diagnosis, Medical image, Ultrasound, Ultrasound contrast agent, Vessel density},
  mendeley-tags = {Computer-aided diagnosis,Medical image,Ultrasound,Ultrasound contrast agent,Vessel density},
  pmid          = {26411669},
  url           = {http://www.sciencedirect.com/science/article/pii/S0301562915004809},
}

@article{Thomson1897,
author = {Thomson, L},
pages = {1--65},
title = {{Elementi di Fisica Nucleare Parte 1 : Radioattivit{\`{a}} , Collisioni e Modelli nucleari Introduzione storica}},
year = {1897}
}

@Misc{Zhang2017a,
  author        = {Zhang, Cheng and B{\"{u}}tepage, Judith and Kjellstr{\"{o}}m, Hedvig and Mandt, Stephan},
  month         = {nov},
  title         = {{Advances in variational inference}},
  year          = {2017},
  abstract      = {Many modern unsupervised or semi-supervised machine learning algorithms rely on Bayesian probabilistic models. These models are usually intractable and thus require approximate inference. Variational inference (VI) lets us approximate a high-dimensional Bayesian posterior with a simpler variational distribution by solving an optimization problem. This approach has been successfully applied to various models and large-scale applications. In this review, we give an overview of recent trends in variational inference. We first introduce standard mean field variational inference, then review recent advances focusing on the following aspects: (a) scalable VI, which includes stochastic approximations, (b) generic VI, which extends the applicability of VI to a large class of otherwise intractable models, such as non-conjugate models, (c) accurate VI, which includes variational models beyond the mean field approximation or with atypical divergences, and (d) amortized VI, which implements the inference over local latent variables with inference networks. Finally, we provide a summary of promising future research directions.},
  booktitle     = {arXiv},
  issn          = {23318422},
  keywords      = {Approximate bayesian inference, Computer Science - Machine Learning, Inference networks, Reparameterization gradients, Scalable inference, Statistics - Machine Learning, Structured variational approximations, Variational inference},
  language      = {en},
  mendeley-tags = {Computer Science - Machine Learning,Statistics - Machine Learning},
  url           = {http://arxiv.org/abs/1711.05597},
}

@Article{Nilsen2010,
  author        = {Nilsen, Carl Inge and Holm, Sverre},
  journal       = {IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
  title         = {{Wiener beamforming and the coherence factor in ultrasound imaging}},
  year          = {2010},
  issn          = {08853010},
  number        = {6},
  pages         = {1329--1346},
  volume        = {57},
  abstract      = {The coherence factor (CF) is used for aberration correction and sidelobe suppression in ultrasound imaging. Unfortunately, it suffers from artifacts when the SNR is low. We show how the CF can be interpreted as an implementation of the Wiener postfilter for a delay-and-sum beamformer. In addition, we show that a minimum-variance, distortionlessresponse beamformer followed by CF weighting can be interpreted as an implementation of the Wiener beamformer. These interpretations provide us with a theoretical framework for analyzing and improving CF-based methods. We use this theory to develop more robust implementations for both the Wiener postfilter and beamformer. The performance of these implementations is shown on simulated and real data. {\textcopyright} 2006 IEEE.},
  doi           = {10.1109/TUFFC.2010.1553},
  groups        = {Classical US imaging},
  keywords      = {Folder - Adaptive beamforming},
  mendeley-tags = {Folder - Adaptive beamforming},
  pmid          = {20529709},
}

@InProceedings{Stanziola2015,
  author        = {Stanziola, Antonio and Cheung, Wing Keung and Eckersley, Robert and Tang, Meng Xing},
  booktitle     = {Proceedings - International Symposium on Biomedical Imaging},
  title         = {{Motion correction in contrast-enhanced ultrasound scans of carotid atherosclerotic plaques}},
  year          = {2015},
  pages         = {1093--1096},
  volume        = {2015-July},
  abstract      = {Contrast Enhanced Ultrasound has shown great potential in detecting vulnerable atherosclerotic plaques, but an effective motion correction crucial for identifying relevant plaque features is still lacking. In this article, a semi-automated algorithm capable of non-rigidly registering contrast enhanced ultrasound scans of the carotid artery is proposed, employing information about the lumen and its deformation at different phases of the cardiac cycle, in order to segment the lumen and improve the registration process. The proposed registration is compared to state of the art algorithms. Significant improvements can be achieved, especially in the regions within and surrounding the plaques. A 77% reduction has been reported in grayscale variability for a stationary scatter, compared to reference algorithms.},
  doi           = {10.1109/ISBI.2015.7164062},
  isbn          = {9781479923748},
  issn          = {19458452},
  keywords      = {Contrast agent quantification, Image registration, Ultrasound, [carotid, carotid, contrast, pulse inversion, registration, ultrasound, vulnerable plaques},
  mendeley-tags = {Contrast agent quantification,Image registration,Ultrasound,[carotid,contrast,pulse inversion,registration},
  url           = {http://ieeexplore.ieee.org/document/7164062/},
}

@article{Jensen2003,
abstract = {A new method for directional velocity estimation is presented. The method uses beamformation along the flow direction to generate data in which the correct velocity magnitude can be directly estimated from the shift in position of the received consecutive signals. The shift is found by cross-correlating the beamformed lines. The approach can find the velocity in any direction, including transverse to the traditionally emitted ultrasound beam. The velocity estimation is studied through extensive simulations using Field H. A 128-element, 7-MHz linear array is used. A parabolic velocity profile with a peak velocity of 0.5 m/s is simulated for different beam-to-flow angles and for different emit foci. At 45degrees the relative standard deviation over the profile is 1.6% for a transmit focus at 40 mm. At 90degrees the approach gave a relative standard deviation of 6.6% with a transmit focus of 80 mm, when using 8 pulse-echo lines and stationary echo canceling. Pulsatile flow in the femoral artery was also simulated using Womersley's flow model. A purely transverse flow profile could be obtained with a relative standard deviation of less than 10% over the whole cardiac cycle using 8 pulse emissions for each imaging direction, which is sufficient to show clinically relevant transverse color flow images.},
author = {Jensen, J{\o}rgen A},
journal = {IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
number = {7},
pages = {857--872},
title = {{Focusing Along the Flow Direction I : Theory and Simulation}},
volume = {50},
year = {2003}
}

@article{Yu2018,
abstract = {Traditional ultrasound imaging techniques are limited in spatial resolution to visualize angiogenic vasa vasorum that is considered as an important marker for atherosclerotic plaque progression and vulnerability. The recently introduced super-resolution imaging technique based on microbubble center localization has shown potential to achieve unprecedented high spatial resolution beyond the acoustic diffraction limit. However, a major drawback of the current super-resolution imaging approach is low temporal resolution because it requires a large number of imaging frames. In this study, a new imaging sequence and signal processing approach for super-resolution ultrasound imaging are presented to improve temporal resolution by employing deconvolution and spatio-temporal-interframe-correlation based data acquisition. In vivo feasibility of the developed technology is demonstrated and evaluated in imaging vasa vasorum in the rabbit atherosclerosis model. The proposed method not only identifies a tiny vessel with a diameter of 41 $\mu$m, 5 times higher spatial resolution than the acoustic diffraction limit at 7.7 MHz, but also significantly improves temporal resolution that allows for imaging vessels over cardiac motion.},
author = {Yu, Jaesok and Lavery, Linda and Kim, Kang},
doi = {10.1038/s41598-018-32235-2},
issn = {20452322},
journal = {Scientific Reports},
keywords = {Folder - Beamforming special},
language = {en},
mendeley-tags = {Folder - Beamforming special},
month = {dec},
number = {1},
pmid = {30224779},
title = {{Super-resolution ultrasound imaging method for microvasculature in vivo with a high temporal accuracy}},
url = {http://www.nature.com/articles/s41598-018-32235-2},
volume = {8},
year = {2018}
}

@InProceedings{Gueth2010,
  author    = {Gueth, Pierre and Blanchard, R{\'{e}}my and Liebgott, Herv{\'{e}} and Basset, Olivier},
  booktitle = {Proceedings - IEEE Ultrasonics Symposium},
  title     = {{Improved resolution for ultrasound Fourier imaging}},
  year      = {2010},
  pages     = {1735--1738},
  publisher = {IEEE},
  abstract  = {Ultrasound Fourier imaging was first initiated by Jian-yu Lu during the90's. Using this method, one can compute an ultrasound image using a singleemission, allowing a very high frame rate (up to 10000 frames per second). Themain limitation of this method is the presence of geometrical artifacts, whichtend to reduce the image resolution. In this study, we propose to use steeredplane waves in reception instead of spherical waves as in [1]. This helpssampling the non-null part of the ultrasound spectrum with finer resolution,while reducing the presence of artifacts. A plane wave is emitted.Back-scattered signals are measured using multiple steered plane waves. Thosesignals 1D spectrum contain spatial information merged to create the 2Dultrasound image spectrum. Due to axial modulation, this 2D spectrum features 2symmetric lobes. The image resolution increases when using plane waves insteadof spherical waves because the sampling of these lobes is easier. The PSF sizeis measured both in simulation and experimentally for each method. Forconventional imaging technique, this size is 155 by 311m in axial and transversedirections. Standard Fourier imaging leads to a size of 156 by 279m. With ourspectral imaging, this size is 154m in axial direction and 252m in transversedirection. Using steered plane wave in a Fourier imaging framework increases thebeamformed image resolution, especially in the transverse direction whencompared to other beamforming methods. {\textcopyright} 2010 IEEE.},
  doi       = {10.1109/ULTSYM.2010.5935714},
  isbn      = {9781457703829},
  issn      = {10510117},
  keywords  = {Fourier beamforming, resolution, spectral beamforming, ultrasound},
}

@article{Radar2010,
author = {compressive sensing applied to Radar, On},
journal = {Signal Processing},
keywords = {Folder - Generic Signal Processing},
mendeley-tags = {Folder - Generic Signal Processing},
number = {5},
pages = {1402--1414},
title = {{On compressive sensing applied to radar}},
volume = {90},
year = {2010}
}

@article{Aghamiry2019,
abstract = {Full-waveform inversion (FWI) is an iterative nonlinear waveform matching procedure subject to wave-equation constraint. FWI is highly nonlinear when the wave-equation constraint is enforced at each iteration. To mitigate nonlinearity, wavefield-reconstruction inversion (WRI) expands the search space by relaxing the wave-equation constraint with a penalty method. The pitfall of this approach resides in the tuning of the penalty parameter because increasing values should be used to foster data fitting during early iterations while progressively enforcing the wave-equation constraint during late iterations. However, large values of the penalty parameter lead to ill-conditioned problems. Here, this tuning issue is solved by replacing the penalty method by an augmented Lagrangian method equipped with operator splitting (iteratively refined WRI [IR-WRI]). It is shown that IR-WRI is similar to a penalty method in which data and sources are updated at each iteration by the running sum of the data and source residuals of previous iterations. Moreover, the alternating direction strategy exploits the bilinearity of the wave-equation constraint to linearize the subsurface model estimation around the reconstructed wavefield. Accordingly, the original nonlinear FWI is decomposed into a sequence of two linear subproblems, the optimization variable of one subproblem being passed as a passive variable for the next subproblem. The convergence of WRI and IR-WRI is first compared with a simple transmission experiment, which lies in the linear regime of FWI. Under the same conditions, IR-WRI converges to a more accurate minimizer with a smaller number of iterations than WRI. More realistic case studies performed with the Marmousi II and the BP salt models indicate the resilience of IR-WRI to cycle skipping and noise, as well as its ability to reconstruct with high-fidelity, large-contrast salt bodies and subsalt structures starting the inversion from crude initial models and a 3 Hz starting frequency.},
archivePrefix = {arXiv},
arxivId = {1809.00891},
author = {Aghamiry, Hossein S. and Gholami, Ali and Operto, St{\'{e}}phane},
doi = {10.1190/geo2018-0093.1},
eprint = {1809.00891},
issn = {19422156},
journal = {Geophysics},
keywords = {Mathematics - Optimization and Control},
language = {en},
mendeley-tags = {Mathematics - Optimization and Control},
month = {jan},
number = {1},
pages = {R139--R162},
title = {{Improving full-waveform inversion by wavefield reconstruction with the alternating direction method of multipliers}},
url = {http://arxiv.org/abs/1809.00891},
volume = {84},
year = {2019}
}

@book{Bertsekas2019,
abstract = {This book explores the common boundary between optimal control and artificial intelligence, as it relates to reinforcement learning and simulation-based neural network methods. These are popular fields with many applications, which can provide approximate solutions to challenging sequential decision problems and large-scale dynamic programming (DP). The aim of the book is to organize coherently the broad mosaic of methods in these fields, which have a solid analytical and logical foundation, and have also proved successful in practice--back cover. 1. Exact Dynamic Programming -- 2. Approximation in Value Space -- 3. Parametric Approximation -- 4. Infinite Horizon Dynamic Programming -- 5. Infinite Horizon Reinforcement Learning -- 6. Aggregation.},
author = {Bertsekas, Dimitri P.},
isbn = {1886529396},
keywords = {Folder - RL and Dynamic Programming},
language = {en},
mendeley-tags = {Folder - RL and Dynamic Programming},
pages = {373},
title = {{Reinforcement learning and optimal control}},
year = {2019}
}

@misc{Zhu2017,
abstract = {Image-to-image translation is a class of vision and graphics problems where the goal is to learn the mapping between an input image and an output image using a training set of aligned image pairs. However, for many tasks, paired training data will not be available. We present an approach for learning to translate an image from a source domain X to a target domain Y in the absence of paired examples. Our goal is to learn a mapping G: X → Y such that the distribution of images from G(X) is indistinguishable from the distribution Y using an adversarial loss. Because this mapping is highly under-constrained, we couple it with an inverse mapping F: Y → X and introduce a cycle consistency loss to enforce F(G(X)) ≈ X (and vice versa). Qualitative results are presented on several tasks where paired training data does not exist, including collection style transfer, object transfiguration, season transfer, photo enhancement, etc. Quantitative comparisons against several prior methods demonstrate the superiority of our approach.},
author = {Zhu, Jun Yan and Park, Taesung and Isola, Phillip and Efros, Alexei A.},
booktitle = {arXiv},
issn = {23318422},
keywords = {Computer Science - Computer Vision and Pattern Rec},
language = {en},
mendeley-tags = {Computer Science - Computer Vision and Pattern Rec},
month = {nov},
title = {{Unpaired image-to-image translation using cycle-consistent adversarial networks}},
url = {http://arxiv.org/abs/1703.10593},
year = {2017}
}

@article{Frost1972,
abstract = {A constrained least mean-squares algorithm has been derived which is capable of adjusting an array of sensors in real time to respond to a signal coming from a desired direction while discriminating against noises coming from other directions. Analysis and computer simulations confirm that the algorithm is able to iteratively adapt variable weights on the taps of the sensor array to minimize noise power in the array output. A set of linear equality constraints on the weights maintains a chosen frequency characteristic for the array in the direction of interest. The array problem would be a classical constrained least-mean-squares problem except that the signal and noise statistics are assumed unknown a priori. A geometrical presentation shows that the algorithm is able to maintain the constraints and prevent the accumulation of quantization errors in a digital implementation. Copyright {\textcopyright} 1972 by The Institute of Electrical and Electronics Engineers, Inc.},
author = {Frost, Otis Lamont},
doi = {10.1109/PROC.1972.8817},
issn = {15582256},
journal = {Proceedings of the IEEE},
keywords = {Folder - Adaptive beamforming},
mendeley-tags = {Folder - Adaptive beamforming},
number = {8},
pages = {926--935},
title = {{An Algorithm for Linearly Constrained Adaptive Array Processing}},
volume = {60},
year = {1972}
}

@inproceedings{Goos1980,
author = {Goos, G. and Hartmanis, J.},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-662-19161-3},
issn = {16113349},
language = {en},
pages = {i},
title = {{Lecture notes in computer science}},
volume = {106},
year = {1980}
}

@Article{Hedenqvist2002,
  author        = {Hedenqvist, P. and Orr, H. E. and Roughan, J. V. and Antunes, L. M. and Flecknell, P. A.},
  journal       = {Veterinary Anaesthesia and Analgesia},
  title         = {{Anaesthesia with ketamine/medetomidine in the rabbit: Influence of route of administration and the effect of combination with butorphanol}},
  year          = {2002},
  issn          = {14672995},
  number        = {1},
  pages         = {14--19},
  volume        = {29},
  abstract      = {Objective To compare the characteristics of anaesthesia induced with ketamine/medetomidine administered by the subcutaneous and intramuscular routes and to assess the effects of the addition of butorphanol to this combination. Study design Prospective randomised study. Animals Six female New Zealand White rabbits. Methods Rabbits were given one of four combinations of ketamine and medetomidine (K/M) either subcutaneously (SC) or intramuscularly (IM) on four successive occasions with a 7-day interval between treatments. The dose combinations were; 15/0.25mgkg−1 SC; 15/0.25mgkg−1 IM; 15/0.5mgkg−1 SC, and 15/0.25mgkg−1 together with 0.4mgkg−1 butorphanol (K/M/B) SC. The effects of anaesthesia on arterial blood gas values and cardiovascular variables were recorded at predetermined time points. Toe and ear pinch reflexes were judged to determine the duration of surgical anaesthesia. Loss of the righting reflex was used to measure the duration of sleep time. Analyses used repeated measures analysis of variance. Results All groups lost the righting reflex and ear pinch response. Three animals in the groups that received K/M alone lost their toe pinch reflex, whereas four lost this reflex when given K/M/B. Time of onset of loss of the righting, toe and ear pinch reflexes did not differ significantly among the groups. The higher dose combination of medetomidine with ketamine and the combination of K/M/B produced a greater duration of loss of the ear pinch response than the lower dose of K/M administered by either route. No significant differences were found among the groups in the duration of loss of the toe pinch reflex. All animals developed a moderate bradycardia (mean heart rate <166beatsminute−1) and moderate hypoxaemia (mean PaO2<6.0kPa). Animals given butorphanol showed the greatest reduction in respiratory rate (31±13breathsminute−1, p<0.05) but this was not reflected in any significant differences in arterial PCO2, PO2 or pH among the groups. Conclusions Administration of K/M by the SC route produced equivalent effects in comparison to intramuscular administration. The addition of butorphanol increased the duration of anaesthesia, but produced a slight increase in the degree of respiratory depression. All dose rates resulted in hypoxaemia so oxygen should be administered when these combinations are used in rabbits. Clinical relevance Subcutaneous administration is both technically simpler and may cause less discomfort to the animal than IM injection, and so is preferred. The combination of K/M with butorphanol has relatively minor effects on the depth and duration of anaesthesia, so offers little advantage to the use of K/M alone. {\textcopyright} 2017 Wiley. All rights reserved.},
  doi           = {10.1046/j.1467-2987.2001.00058.x},
  keywords      = {Anaesthesia, Butorphanol, Ketamine, Medetomidine, Rabbit},
  mendeley-tags = {Anaesthesia,Butorphanol,Ketamine,Medetomidine,Rabbit},
}

@phdthesis{Petterson2010,
abstract = {The Teager Energy Operator is a nonlinear operator defined for both continuous and discrete time signals. In this thesis we define different versions and extensions of the one-dimensional operator, and then look at the properties and positivity of the operator. Its connection to Volterra systems is explained. The Teager Energy Operator is used for demodulation of AM-FM signals, and we look at how this can be done using the operator and nonlinear methods (Hilbert transform, Prony's, Modified covariance, etc). As the Teager Energy Operator is sensitive to noise, the multiband demodulation technique is introduced to refine the estimates. The performance of linear and nonlinear differentiators is investigated. An application to speech analysis is shown, using a multiband method to locate formants in speech. Finally, a performance comparison in different levels of noise is done.},
author = {Petterson},
booktitle = {Signal Processing},
isbn = {8273681335},
number = {May},
pages = {121},
title = {{Toeplitz Covariance Matrix Estimation for Adaptive Beamforming and Ultrasound Imaging}},
url = {https://www.duo.uio.no/bitstream/handle/10852/34156/Michael_Pettersson.pdf%0Ahttp://folk.uio.no/eivindkv/ek-thesis-2003-05-12-final-2.pdf},
volume = {9120},
year = {2010}
}

@misc{Greydanus2019,
abstract = {Even though neural networks enjoy widespread use, they still struggle to learn the basic laws of physics. How might we endow them with better inductive biases? In this paper, we draw inspiration from Hamiltonian mechanics to train models that learn and respect exact conservation laws in an unsupervised manner. We evaluate our models on problems where conservation of energy is important, including the two-body problem and pixel observations of a pendulum. Our model trains faster and generalizes better than a regular neural network. An interesting side effect is that our model is perfectly reversible in time.},
archivePrefix = {arXiv},
arxivId = {1906.01563},
author = {Greydanus, Sam and Dzamba, Misko and Yosinski, Jason},
booktitle = {arXiv},
eprint = {1906.01563},
issn = {23318422},
keywords = {Computer Science - Neural and Evolutionary Computi},
language = {en},
mendeley-tags = {Computer Science - Neural and Evolutionary Computi},
month = {jun},
title = {{Hamiltonian neural networks}},
url = {http://arxiv.org/abs/1906.01563},
year = {2019}
}

@Misc{VanDenOord2018,
  author        = {{Van Den Oord}, Aaron and Li, Yazhe and Vinyals, Oriol},
  month         = {jul},
  title         = {{Representation learning with contrastive predictive coding}},
  year          = {2018},
  abstract      = {While supervised learning has enabled great progress in many applications, unsupervised learning has not seen such widespread adoption, and remains an important and challenging endeavor for artificial intelligence. In this work, we propose a universal unsupervised learning approach to extract useful representations from high-dimensional data, which we call Contrastive Predictive Coding. The key insight of our model is to learn such representations by predicting the future in latent space by using powerful autoregressive models. We use a probabilistic contrastive loss which induces the latent space to capture information that is maximally useful to predict future samples. It also makes the model tractable by using negative sampling. While most prior work has focused on evaluating representations for a particular modality, we demonstrate that our approach is able to learn useful representations achieving strong performance on four distinct domains: speech, images, text and reinforcement learning in 3D environments.},
  archiveprefix = {arXiv},
  arxivid       = {1807.03748},
  booktitle     = {arXiv},
  eprint        = {1807.03748},
  issn          = {23318422},
  keywords      = {Computer Science - Machine Learning, Statistics - Machine Learning},
  language      = {en},
  mendeley-tags = {Computer Science - Machine Learning,Statistics - Machine Learning},
  url           = {http://arxiv.org/abs/1807.03748},
}

@article{Jensen1996,
abstract = {A program for the simulation of ultrasound systems is presented. It is based on the Tupholme-Stepanishen method, and is fast because of the use of a far-field approximation. Any kind of transducer geometry and excitation can be simulated, and both pulse-echo and continuous wave fields can-be calculated for both transmit and pulse-echo. Dynamic apodization and focusing are handled through time lines, and different focusing schemes can be simulated. The versatility of the program is ensured by interfacing it to Matlab. All routines are called directly from Matlab, and all Matlab features can be used. This makes it possible to simulate all types of ultrasound imaging systems.},
author = {Jensen, J{\o}rgen Arendt},
doi = {papers2://publication/uuid/6C8DF1DC-B55C-49BB-9E4A-5BF6EFE51E67},
issn = {01400118},
journal = {Medical and Biological Engineering and Computing},
keywords = {Folder - Simulations},
mendeley-tags = {Folder - Simulations},
number = {SUPPL. 1},
pages = {351--352},
title = {{FIELD: A program for simulating ultrasound systems}},
volume = {34},
year = {1996}
}

@article{Stanziola2017,
author = {Stanziola, Antonio and Tang, Meng-Xing},
journal = {Proceedings of the 21st European Symposium on Ultrasound Contrast Imaging, Rotterdam},
keywords = {Folder - Correlation approaches},
mendeley-tags = {Folder - Correlation approaches},
pages = {1--14},
title = {{Super contrast imaging using high frame-rate CEUS and spatial and temporal signal processing}},
year = {2017}
}

@Book{Szabo2004,
  author        = {Szabo, Thomas L.},
  title         = {{Diagnostic ultrasound imaging inside out}},
  year          = {2004},
  isbn          = {0126801452},
  abstract      = {Diagnostic Ultrasound Imaging provides a comprehensive introduction to and a state-of-the-art review of the essential science and signal processing principles of diagnostic ultrasound. The progressive organization of the material serves beginners in medical ultrasound science and graduate students as well as design engineers, medical physicists, researchers, clinical collaborators, and the curious. This it the most comprehensive and extensive work available on the core science and workings of advanced digital imaging systems, exploring the subject in a unified, consistent and interrelated manner. From its antecedents to the modern day use and prospects for the future, this it the most up-to-date text on the subject. Diagnostic Ultrasound Imaging provides in-depth overviews on the following major aspects of diagnostic ultrasound: absorption in tissues; acoustical and electrical measurements; beamforming, focusing, and imaging; bioeffects and ultrasound safety; digital imaging systems and terminology; Doppler and Doppler imaging; nonlinear propagation, beams and harmonic imaging; scattering and propagation through realistic tissues; and tissue characterization. {\textcopyright} 2004 Elsevier Inc. All rights reserved.},
  booktitle     = {Diagnostic Ultrasound Imaging: Inside Out},
  doi           = {10.1055/s-2005-861725},
  file          = {:home/antonio/Documents/bibliography/files/Unknown - Unknown - Diagnostic ultrasound imaging inside out.pdf:pdf},
  issn          = {0172-4614},
  keywords      = {Folder - General US},
  mendeley-tags = {Folder - General US},
  pages         = {1--549},
  url           = {https://books.google.co.kr/books?id=wTYTAAAAQBAJ},
}

@article{Lockwood1996,
abstract = {A method for reducing the number of elements in a 2-D array while minimizing degradation of the beam forming properties is described. The method relies on selecting a different arrangement of elements when the array is transmitting energy and when the array is receiving energy. The transmit and receive aperture functions are chosen to minimize the difference between the effective aperture of the sparse array and the effective aperture of a desired dense array. In a companion paper [1], the design of sparse linear arrays using the effective aperture method was described. Here, we extend this method to the design of 2D arrays. Comparisons of the radiation patterns of a dense 2-D array and sparse 2-D arrays with random and periodic element spacing are given. Using the effective aperture method, we show that the number of elements in a 64 x 64 2-D array can be reduced by more than six times, and the elements in a 128 x 128 array can be reduced by more than 12 times, with little effect on the beam forming properties of the arrays. {\textcopyright} 1996 IEEE.},
author = {Lockwood, Geoffrey R. and {Stuart Foster}, F.},
doi = {10.1109/58.484458},
issn = {08853010},
journal = {IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
number = {1},
pages = {15--19},
title = {{Optimizing the radiation pattern of sparse periodic two-dimensional arrays}},
volume = {43},
year = {1996}
}

@Article{Druskin2018,
  author        = {Druskin, Vladimir and Mamonov, Alexander V. and Zaslavsky, Mikhail},
  journal       = {SIAM Journal on Imaging Sciences},
  title         = {{A nonlinear method for imaging with acoustic waves via reduced order model backprojection}},
  year          = {2018},
  issn          = {19364954},
  month         = {jan},
  number        = {1},
  pages         = {164--196},
  volume        = {11},
  abstract      = {We introduce a novel nonlinear imaging method for the acoustic wave equation based on data-driven model order reduction. The objective is to image the discontinuities of the acoustic velocity, a coefficient of the scalar wave equation from the discretely sampled time domain data measured at an array of transducers that can act as both sources and receivers. We treat the wave equation along with transducer functionals as a dynamical system. A reduced order model (ROM) for the propagator of such a system can be computed so that it interpolates exactly the measured time domain data. The resulting ROM is an orthogonal projection of the propagator on the subspace of the snapshots of solutions of the acoustic wave equation. While the wave field snapshots are unknown, the projection ROM can be computed entirely from the measured data; thus we refer to such ROM as data-driven. The image is obtained by backprojecting the ROM. Since the basis functions for the projection subspace are not known, we replace them with the ones computed for a known smooth kinematic velocity model. A crucial step of ROM construction is an implicit orthogonalization of solution snapshots. It is a nonlinear procedure that differentiates our approach from the conventional linear imaging methods (Kirchhoff migration and reverse time migration—RTM). It resolves all dynamical behavior captured by the data, so the error from the imperfect knowledge of the velocity model is purely kinematic. This allows for almost complete removal of multiple reflection artifacts, while simultaneously improving the resolution in the range direction compared to conventional RTM.},
  archiveprefix = {arXiv},
  arxivid       = {1704.06974},
  doi           = {10.1137/17M1133580},
  eprint        = {1704.06974},
  keywords      = {Acoustic, Block cholesky decomposition, Data-driven reduced order model, Gram-schmidt orthogonalization, Imaging, Krylov subspace, Migration, Model reduction, Seismic, Wave equation},
  language      = {en},
  url           = {https://epubs.siam.org/doi/10.1137/17M1133580},
}

@article{Horner1984,
abstract = {From image processing work, we know that the phase information is significantly more important than amplitude information in preserving the features of a visual scene. Is the same true in the case of a matched filter? From previous work [J. L. Horner, Appl. Opt. 21, 4511 (1982)], we know that a pure phase correlation filter can have an optical efficiency of 100% in an optical correlation system. We examine this relationship between phase and amplitude in the case of alphanumeric characters, with and without noise, using a computer simulation. We compare the phase-only and amplitude-only filters to the classical matched filter using the criteria of discrimination, correlation peak, and optical efficiency. Three-dimensional plots of the autocorrelation and cross-correlation functions are presented and discussed.},
author = {Horner, Joseph L. and Gianino, Peter D.},
doi = {10.1364/ao.23.000812},
issn = {0003-6935},
journal = {Applied Optics},
number = {6},
pages = {812},
title = {{Phase-only matched filtering}},
volume = {23},
year = {1984}
}

@article{Cheng2006,
abstract = {East three-dimensional (3-D) ultrasound imaging is a technical challenge. Previously, a high-frame rate (HFR) imaging theory was developed in which a pulsed plane wave was used in transmission, and limited-diffraction array beam weightings were applied to received echo signals to produce a spatial Fourier transform of object function for 3-D image reconstruction. In this paper, the theory is extended to include explicitly various transmission schemes such as multiple limited-diffraction array beams and steered plane waves. A relationship between the limited-diffraction array beam weighting of received echo signals and a 2-D Fourier transform of the same signals over a transducer aperture is established. To verify the extended theory, computer simulations, in vitro experiments on phantoms, and in vivo experiments on the human kidney and heart were performed. Results show that image resolution and contrast are increased over a large field of view as more and more limited-diffraction array beams with different parameters or plane waves steered at different angles are used in transmissions. Thus, the method provides a continuous compromise between image quality and image frame rate that is inversely proportional to the number of transmissions used to obtain a single frame of image. From both simulations and experiments, the extended theory holds a great promise for future HFR 3-D imaging. {\textcopyright} 2006 IEEE.},
author = {Cheng, Jiqi and Lu, Jian Yu},
doi = {10.1109/TUFFC.2006.1632680},
issn = {08853010},
journal = {IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
keywords = {Folder - HFR US},
mendeley-tags = {Folder - HFR US},
number = {5},
pages = {880--899},
pmid = {16764444},
title = {{Extended high-frame rate imaging method with limited-diffraction beams}},
volume = {53},
year = {2006}
}

@Article{Tibshirani2013,
  author        = {Tibshirani, Ryan J.},
  journal       = {Electronic Journal of Statistics},
  title         = {{The lasso problem and uniqueness}},
  year          = {2013},
  issn          = {19357524},
  number        = {1},
  pages         = {1456--1490},
  volume        = {7},
  abstract      = {The lasso is a popular tool for sparse linear regression, especially for problems in which the number of variables p exceeds the number of observations n. But when p > n, the lasso criterion is not strictly convex, and hence it may not have a unique minimizer. An important question is: when is the lasso solution well-defined (unique)? We review results from the literature, which show that if the predictor variables are drawn from a continuous probability distribution, then there is a unique lasso solution with probability one, regardless of the sizes of n and p. We also show that this result extends easily to ℓ1 penalized minimization problems over a wide range of loss functions. A second important question is: how can we manage the case of non-uniqueness in lasso solutions? In light of the aforementioned result, this case really only arises when some of the predictor variables are discrete, or when some post-processing has been performed on continuous predictor measurements. Though we certainly cannot claim to provide a complete answer to such a broad question, we do present progress towards understanding some aspects of non-uniqueness. First, we extend the LARS algorithm for computing the lasso solution path to cover the non-unique case, so that this path algorithm works for any predictor matrix. Next, we derive a simple method for computing the component-wise uncertainty in lasso solutions of any given problem instance, based on linear programming. Finally, we review results from the literature on some of the unifying properties of lasso solutions, and also point out particular forms of solutions that have distinctive properties.},
  archiveprefix = {arXiv},
  arxivid       = {1206.0313},
  doi           = {10.1214/13-EJS815},
  eprint        = {1206.0313},
  keywords      = {High-dimensional, LARS, Lasso, Uniqueness},
  mendeley-tags = {High-dimensional,LARS,Lasso,Uniqueness},
}

@Article{Carroll1970,
  author  = {J.D., Carroll and J.J., Chang},
  journal = {Psychometrika},
  title   = {{Analysis of individual differences in multidimensional scaling via an N-way generalization of "Eckart-Young" decomposition}},
  year    = {1970},
  number  = {3},
  pages   = {283--319},
  volume  = {35},
}

@InProceedings{Imbault2016,
  author        = {Imbault, M. and Serroune, H. and Gennisson, Jl and Tanter, M. and Chauvet, D. and Capelle, L. and Lehericy, S.},
  booktitle     = {IEEE International Ultrasonics Symposium, IUS},
  title         = {{Functional ultrasound imaging of the human brain activity: An intraoperative pilot study for cortical functional mapping}},
  year          = {2016},
  pages         = {8--11},
  volume        = {2016-Novem},
  abstract      = {A wide spectrum of methods is used to image brain activation in vivo, such as functional MRI (fMRI) or positron emission tomography. Both techniques have excellent depth penetration but do not provide good spatial nor temporal resolution. By contrast, ultrasound imaging achieves good spatiotemporal resolution in depth, but until now its poor sensitivity has limited its use to the imaging of major vessels. Functional ultrasound (fUS) derived from the key concept of ultrafast imaging (up to 20 000 frames/s) [1] overcomes this limitation. fUS enables high spatiotemporal resolution imaging of microvasculature dynamics in response to brain activation and was previously validated in rodents [2]. We aim to demonstrate that fUS could find activation maps accurately during brain surgery in humans without requiring electrocortical stimulation mapping (ESM). A clinical study including 10 patients with brain lesion is undertaken, with both fMRI and ESM as gold standard. Patients underwent fMRI before surgery, data were intraoperatively used for ultrasound probe positioning on a targeted functional area using a neuronavigation system (Brainlab AG, Feldkirchen, Germany) and probe location was also confirmed by ESM. A sterilized linear probe driven by an ultrafast ultrasound scanner (Aixplorer, Supersonic Imagine, France) was placed directly on the brain after skull opening. Patients, awake during this part of their surgery, were asked to perform a specific task (motor, sensory or language). fUS imaging with a 6000 Hz frame rate determines regions of brain activity based on the cerebral blood volume (CBV) increase due to neurovascular coupling. This first pilot study demonstrates the ability of fUS imaging to map with a high signal-to-noise ratio (SNR) the stimulus-based neuronal activation in depth in real time during brain surgery. Such technique could be extremely useful for neurosurgeons to improve their surgery and therefore patient quality of life.},
  doi           = {10.1109/ULTSYM.2016.7728505},
  isbn          = {9781467398978},
  issn          = {19485727},
  keywords      = {Folder - HFR US, brain, cortical mapping, functional, intraoperative, ultrasound},
  mendeley-tags = {Folder - HFR US,brain,functional,intraoperative,ultrasound},
}

@Article{Burshtein2016,
  author        = {Burshtein, Amir and Birk, Michael and Chernyakova, Tanya and Eilam, Alon and Kempinski, Arcady and Eldar, Yonina C.},
  journal       = {IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
  title         = {{Sub-Nyquist Sampling and Fourier Domain Beamforming in Volumetric Ultrasound Imaging}},
  year          = {2016},
  issn          = {08853010},
  number        = {5},
  pages         = {703--716},
  volume        = {63},
  abstract      = {A key step in ultrasound image formation is digital beamforming of signals sampled by several transducer elements placed upon an array. High-resolution digital beamforming introduces the demand for sampling rates significantly higher than the signals' Nyquist rate, which greatly increases the volume of data that must be transmitted from the system's front end. In 3-D ultrasound imaging, 2-D transducer arrays rather than 1-D arrays are used, and more scan lines are needed. This implies that the amount of sampled data is vastly increased with respect to 2-D imaging. In this work, we show that a considerable reduction in data rate can be achieved by applying the ideas of Xampling and frequency domain beamforming (FDBF), leading to a sub-Nyquist sampling rate, which uses only a portion of the bandwidth of the ultrasound signals to reconstruct the image. We extend previous work on FDBF for 2-D ultrasound imaging to accommodate the geometry imposed by volumetric scanning and a 2-D grid of transducer elements. High image quality from low-rate samples is demonstrated by simulation of a phantom image composed of several small reflectors. Our technique is then applied to raw data of a heart ventricle phantom obtained by a commercial 3-D ultrasound system. We show that by performing 3-D beamforming in the frequency domain, sub-Nyquist sampling and low processing rate are achievable, while maintaining adequate image quality.},
  archiveprefix = {arXiv},
  arxivid       = {1508.04893},
  doi           = {10.1109/TUFFC.2016.2535280},
  eprint        = {1508.04893},
  keywords      = {Array processing, beamforming, compressed sensing (CS), ultrasound},
  mendeley-tags = {Array processing,beamforming,compressed sensing (CS),ultrasound},
  pmid          = {26930678},
}

@article{Ebbini1989,
abstract = {A new method for computing array element amplitude and phase distributions for direct synthesis of multiple-focus field patterns using ultrasonic phased arrays is shown to be capable of producing desired field levels at a set of control points in the treatment volume. The complex pressure at any of these control points can be chosen to produce the desired power deposition at that point, including reducing the field level to avoid potential hot spots, thus providing a powerful tool for hyperthermia treatment planning. The method also allows the complex excitation vector to be weighted to reduce the dynamic range of the driving signals without disturbing the relative field levels at the control points allowing near maximum power transfer from the array into the treatment volume. {\textcopyright} 1989 IEEE},
author = {Ebbini, Emad S. and Cain, Charles A.},
doi = {10.1109/58.31798},
issn = {08853010},
journal = {IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
keywords = {Folder - General US},
language = {en},
mendeley-tags = {Folder - General US},
month = {sep},
number = {5},
pages = {540--548},
shorttitle = {Multiple-focus ultrasound phased-array pattern syn},
title = {{Multiple-Focus Ultrasound Phased-Array Pattern Synthesis: Optimal Driving-Signal Distributions for Hyperthermia}},
url = {http://ieeexplore.ieee.org/document/31798/},
volume = {36},
year = {1989}
}

@Article{Kim2019a,
  author        = {Kim, Byungsoo and Azevedo, Vinicius C. and Thuerey, Nils and Kim, Theodore and Gross, Markus and Solenthaler, Barbara},
  journal       = {Computer Graphics Forum},
  title         = {{Deep Fluids: A Generative Network for Parameterized Fluid Simulations}},
  year          = {2019},
  issn          = {14678659},
  month         = {may},
  number        = {2},
  pages         = {59--70},
  volume        = {38},
  abstract      = {This paper presents a novel generative model to synthesize fluid simulations from a set of reduced parameters. A convolutional neural network is trained on a collection of discrete, parameterizable fluid simulation velocity fields. Due to the capability of deep learning architectures to learn representative features of the data, our generative model is able to accurately approximate the training data set, while providing plausible interpolated in-betweens. The proposed generative model is optimized for fluids by a novel loss function that guarantees divergence-free velocity fields at all times. In addition, we demonstrate that we can handle complex parameterizations in reduced spaces, and advance simulations in time by integrating in the latent space with a second network. Our method models a wide variety of fluid behaviors, thus enabling applications such as fast construction of simulations, interpolation of fluids with different parameters, time re-sampling, latent space simulations, and compression of fluid simulation data. Reconstructed velocity fields are generated up to 700× faster than re-simulating the data with the underlying CPU solver, while achieving compression rates of up to 1300×.},
  archiveprefix = {arXiv},
  arxivid       = {1806.02071},
  doi           = {10.1111/cgf.13619},
  eprint        = {1806.02071},
  keywords      = {CCS Concepts, Computer Science - Graphics, Computer Science - Machine Learning, Neural networks, Physics - Computational Physics, Physics - Fluid Dynamics, Statistics - Machine Learning, • Computing methodologies → Physical simulation},
  language      = {en},
  mendeley-tags = {Computer Science - Graphics,Computer Science - Machine Learning,Physics - Computational Physics,Physics - Fluid Dynamics,Statistics - Machine Learning},
  shorttitle    = {Deep Fluids},
  url           = {http://arxiv.org/abs/1806.02071},
}

@misc{Goodfellow2016,
abstract = {This report summarizes the tutorial presented by the author at NIPS 2016 on generative adversarial networks (GANs). The tutorial describes: (1) Why generative modeling is a topic worth studying, (2) how generative models work, and how GANs compare to other generative models, (3) the details of how GANs work, (4) research frontiers in GANs, and (5) state-of-the-art image models that combine GANs with other methods. Finally, the tutorial contains three exercises for readers to complete, and the solutions to these exercises.},
archivePrefix = {arXiv},
arxivId = {1701.00160},
author = {Goodfellow, Ian},
booktitle = {arXiv},
eprint = {1701.00160},
issn = {23318422},
keywords = {Computer Science - Machine Learning},
language = {en},
mendeley-tags = {Computer Science - Machine Learning},
month = {dec},
shorttitle = {NIPS 2016 Tutorial},
title = {{NIPS 2016 tutorial: Generative adversarial networks}},
url = {http://arxiv.org/abs/1701.00160},
year = {2016}
}

@article{Harmanci2000,
abstract = {For many years, the popular minimum variance (MV) adaptive beamformer has been well known for not having been derived as a maximum likelihood (ML) estimator. This paper demonstrates that by use of a judicious decomposition of the signal and noise, the log-likelihood function of source location is, in fact, directly proportional to the adaptive MV beamformer output power. In the proposed model, the measurement consists of an unknown temporal signal whose spatial wavefront is known as a function of its unknown location, which is embedded in complex Gaussian noise with unknown but positive definite covariance. Further, in cases where the available observation time is insufficient, a constrained ML estimator is derived here that is closely related to MV beamforming with a diagonally loaded data covariance matrix estimate. The performance of the constrained ML estimator compares favorably with robust MV techniques, giving slightly better root-mean-square error (RMSE) angle-of-arrival estimation of a plane-wave signal in interference. More importantly, however, the fact that such optimal ML techniques are closely related to conventional robust MV methods, such as diagonal loading, lends theoretical justification to the use of these practical approaches.},
archivePrefix = {arXiv},
arxivId = {1701.00160},
author = {Harmanci, Kerem and Tabrikian, Joseph and Krolik, Jeffrey L.},
doi = {10.1109/78.815474},
eprint = {1701.00160},
issn = {1053587X},
journal = {IEEE Transactions on Signal Processing},
keywords = {Folder - BSS and acoustic source localization},
mendeley-tags = {Folder - BSS and acoustic source localization},
number = {1},
pages = {1--12},
title = {{Relationships between adaptive minimum variance beamforming and optimal source localization}},
volume = {48},
year = {2000}
}

@InProceedings{Johnson2016,
  author        = {Johnson, Justin and Alahi, Alexandre and Fei-Fei, Li},
  booktitle     = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  title         = {{Perceptual losses for real-time style transfer and super-resolution}},
  year          = {2016},
  month         = {mar},
  pages         = {694--711},
  volume        = {9906 LNCS},
  abstract      = {We consider image transformation problems, where an input image is transformed into an output image. Recent methods for such problems typically train feed-forward convolutional neural networks using a per-pixel loss between the output and ground-truth images. Parallel work has shown that high-quality images can be generated by defining and optimizing perceptual loss functions based on high-level features extracted from pretrained networks. We combine the benefits of both approaches, and propose the use of perceptual loss functions for training feed-forward networks for image transformation tasks. We show results on image style transfer, where a feed-forward network is trained to solve the optimization problem proposed by Gatys et al. in real-time. Compared to the optimization-based method, our network gives similar qualitative results but is three orders of magnitude faster. We also experiment with single-image super-resolution, where replacing a per-pixel loss with a perceptual loss gives visually pleasing results.},
  archiveprefix = {arXiv},
  arxivid       = {1603.08155},
  doi           = {10.1007/978-3-319-46475-6_43},
  eprint        = {1603.08155},
  isbn          = {9783319464749},
  issn          = {16113349},
  keywords      = {Computer Science - Computer Vision and Pattern Rec, Computer Science - Machine Learning, Deep learning, Style transfer, Super-resolution},
  language      = {en},
  mendeley-tags = {Computer Science - Computer Vision and Pattern Rec,Computer Science - Machine Learning},
  url           = {http://arxiv.org/abs/1603.08155},
}

@Article{Fischer2015,
  author        = {Fischer, Philipp and Dosovitskiy, Alexey and Fischery, Philipp and Ilg, Eddy and Hausser, Philip and Hazirbas, Caner and Golkov, Vladimir and Smagt, Patrick Van Der and Cremers, Daniel and Brox, Thomas},
  journal       = {Proceedings of the IEEE International Conference on Computer Vision},
  title         = {{FlowNet: Learning optical flow with convolutional networks}},
  year          = {2015},
  month         = {apr},
  pages         = {2758--2766},
  abstract      = {Convolutional neural networks (CNNs) have recently been very successful in a variety of computer vision tasks, especially on those linked to recognition. Optical flow estimation has not been among the tasks where CNNs were successful. In this paper we construct appropriate CNNs which are capable of solving the optical flow estimation problem as a supervised learning task. We propose and compare two architectures: a generic architecture and another one including a layer that correlates feature vectors at different image locations. Since existing ground truth data sets are not sufficiently large to train a CNN, we generate a synthetic Flying Chairs dataset. We show that networks trained on this unrealistic data still geeralinze very well to existing datasets such as Sintel and KITTI, achieving competitive accuracy at frame rates of 5 to 10 fps.},
  keywords      = {Computer Science - Computer Vision and Pattern Rec, Computer Science - Machine Learning, I.2.6, I.4.8},
  language      = {en},
  mendeley-tags = {Computer Science - Computer Vision and Pattern Rec,Computer Science - Machine Learning,I.2.6,I.4.8},
  shorttitle    = {FlowNet},
  url           = {http://arxiv.org/abs/1504.06852},
}

@article{Jeong2000,
abstract = {Focusing is widely used to increase the resolution in medirtil ultraenntul imaging systems. Focusing increases signal levfils returning from tho mainlobc direction and decreases tlioso from Hidololie direction;;. The stdelobes, wlien not comph{\^{i}}l.ely canceled, deteriorate the resulting image resolution. This paper proposes n method of improving tlio resolution by scaling the received signal according to tho ratio between the mainlobe and the aidolobe levels computed in the frequency domain by tho use of Fourier transform. The proposed method is verified hy computer simulation and experiment and is shown to bo highly effective in narrowing tVm mainloliti width und decreasing the sidolobe levels at tllo same time. {\textcopyright} 2000 IEEE.},
author = {Jeong, Mok Kun},
doi = {10.1109/58.842066},
issn = {08853010},
journal = {IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
keywords = {Folder - Side and grating lobes reduction},
mendeley-tags = {Folder - Side and grating lobes reduction},
number = {3},
pages = {759--763},
title = {{A fourier transform-based sidelobo reduction method in ultrasound imaging}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23838363},
volume = {47},
year = {2000}
}

@Article{Odelson2006,
  author        = {Odelson, Brian J. and Rajamani, Murali R. and Rawlings, James B.},
  journal       = {Automatica},
  title         = {{A new autocovariance least-squares method for estimating noise covariances}},
  year          = {2006},
  issn          = {00051098},
  month         = {feb},
  number        = {2},
  pages         = {303--308},
  volume        = {42},
  abstract      = {Industrial implementation of model-based control methods, such as model predictive control, is often complicated by the lack of knowledge about the disturbances entering the system. In this paper, we present a new method (constrained ALS) to estimate the variances of the disturbances entering the process using routine operating data. A variety of methods have been proposed to solve this problem. Of note, we compare ALS to the classic approach presented in Mehra [(1970). On the identification of variances and adaptive Kalman filtering. IEEE Transactions on Automatic Control, 15(12), 175-184]. This classic method, and those based on it, use a three-step procedure to compute the covariances. The method presented in this paper is a one-step procedure, which yields covariance estimates with lower variance on all examples tested. The formulation used in this paper provides necessary and sufficient conditions for uniqueness of the estimated covariances, previously not available in the literature. We show that the estimated covariances are unbiased and converge to the true values with increasing sample size. The proposed method also guarantees positive semidefinite covariance estimates by adding constraints to the ALS problem. The resulting convex program can be solved efficiently. {\textcopyright} 2005 Elsevier Ltd. All rights reserved.},
  doi           = {10.1016/j.automatica.2005.09.006},
  keywords      = {Adaptive Kalman filter, Covariance estimation, Folder - Generic Signal Processing, Optimal estimation, Semidefinite programming, State estimation},
  language      = {en},
  mendeley-tags = {Folder - Generic Signal Processing},
  url           = {https://linkinghub.elsevier.com/retrieve/pii/S0005109805003262},
}

@InProceedings{Combettes2014,
  author        = {Combettes, P. L. and Condat, L. and Pesquet, J. C. and Vu, B. C.},
  booktitle     = {2014 IEEE International Conference on Image Processing, ICIP 2014},
  title         = {{A forward-backward view of some primal-dual optimization methods in image recovery}},
  year          = {2014},
  address       = {Paris, France},
  month         = {oct},
  pages         = {4141--4145},
  publisher     = {IEEE},
  abstract      = {A wide array of image recovery problems can be abstracted into the problem of minimizing a sum of composite convex functions in a Hilbert space. To solve such problems, primal-dual proximal approaches have been developed which provide efficient solutions to large-scale optimization problems. The objective of this paper is to show that a number of existing algorithms can be derived from a general form of the forward-backward algorithm applied in a suitable product space. Our approach also allows us to develop useful extensions of existing algorithms by introducing a variable metric. An illustration to image restoration is provided.},
  archiveprefix = {arXiv},
  arxivid       = {1406.5439},
  doi           = {10.1109/ICIP.2014.7025841},
  eprint        = {1406.5439},
  isbn          = {9781479957514},
  keywords      = {convex optimization, duality, image recovery, parallel computing, proximal algorithm, variational methods},
  language      = {en},
  url           = {http://ieeexplore.ieee.org/document/7025841/},
}

@Misc{Zhang2019,
  author        = {Zhang, Haimiao and Dong, Bin},
  month         = {jun},
  title         = {{A Review on Deep Learning in Medical Image Reconstruction ∗}},
  year          = {2019},
  abstract      = {Medical imaging is crucial in modern clinics to provide guidance to the diagnosis and treatment of diseases. Medical image reconstruction is one of the most fundamental and important components of medical imaging, whose major objective is to acquire high-quality medical images for clinical usage at the minimal cost and risk to the patients. Mathematical models in medical image reconstruction or, more generally, image restoration in computer vision, have been playing a prominent role. Earlier mathematical models are mostly designed by human knowledge or hypothesis on the image to be reconstructed, and we shall call these models handcrafted models. Later, handcrafted plus data-driven modeling started to emerge which still mostly relies on human designs, while part of the model is learned from the observed data. More recently, as more data and computation resources are made available, deep learning based models (or deep models) pushed the data-driven modeling to the extreme where the models are mostly based on learning with minimal human designs. Both handcrafted and data-driven modeling have their own advantages and disadvantages. Typical handcrafted models are well interpretable with solid theoretical supports on the robustness, recoverability, complexity, etc., whereas they may not be flexible and sophisticated enough to fully leverage large data sets. Data-driven models, especially deep models, on the other hand, are generally much more flexible and effective in extracting useful information from large data sets, while they are currently still in lack of theoretical foundations. Therefore, one of the major research trends in medical imaging is to combine handcrafted modeling with deep modeling so that we can enjoy benefits from both approaches. The major part of this article is to provide a conceptual review of some recent works on deep modeling from the unrolling dynamics viewpoint. This viewpoint stimulates new designs of neural network architectures with inspirations from optimization algorithms and numerical differential equations. Given the popularity of deep modeling, there are still vast remaining challenges in the field, as well as opportunities which we shall discuss at the end of this article. 60H10, 92C55, 93C15, 94A08},
  booktitle     = {arXiv},
  issn          = {23318422},
  keywords      = {60H10- 92C55- 93C15- 94A08, Computer Science - Computer Vision and Pattern Rec, Computer Science - Machine Learning, Deep learning, Deep modeling, Electrical Engineering and Systems Science - Image, Handcrafted modeling, Image reconstruction, Medical imaging, Physics - Medical Physics, Unrolling dynamics},
  language      = {en},
  mendeley-tags = {60H10- 92C55- 93C15- 94A08,Computer Science - Computer Vision and Pattern Rec,Computer Science - Machine Learning,Electrical Engineering and Systems Science - Image,Physics - Medical Physics},
  url           = {http://arxiv.org/abs/1906.10643},
}

@InProceedings{Carrillo2015,
  author        = {Carrillo, Rafael E. and Besson, Adrien and Zhang, Miaomiao and Friboulet, Denis and Wiaux, Yves and Thiran, Jean Philippe and Bernard, Olivier},
  booktitle     = {2015 IEEE International Ultrasonics Symposium, IUS 2015},
  title         = {{A Sparse regularization approach for ultrafast ultrasound imaging}},
  year          = {2015},
  pages         = {1--4},
  publisher     = {IEEE},
  abstract      = {Ultrafast imaging based on plane-wave (PW) insonification is an active area of research due to its capability of reaching high frame rates. Several approaches have been proposed either based on either of Fourier-domain reconstruction or on delay-and-sum (DAS) reconstruction. Using a single PW, these techniques achieve low quality, in terms of resolution and contrast, compared to the classic DAS method with focused beams. To overcome this drawback, compounding of several steered PWs is needed, which currently decreases the high frame rate limit that could be reached by such techniques. Based on a compressed sensing (CS) framework, we propose a new method that allows the reconstruction of high quality ultrasound (US) images from only 1 PW at the expense of augmenting the computational complexity at the reconstruction.},
  doi           = {10.1109/ULTSYM.2015.0184},
  isbn          = {9781479981823},
  keywords      = {Compressed sensing, Folder - Beamforming special, Fourier imaging, Plane wave, Sparsity, Ultrafast imaging},
  mendeley-tags = {Folder - Beamforming special},
}

@misc{Wu2018a,
abstract = {We propose a deep generative Markov State Model (DeepGenMSM) learning framework for inference of metastable dynamical systems and prediction of trajectories. After unsupervised training on time series data, the model contains (i) a probabilistic encoder that maps from high-dimensional configuration space to a small-sized vector indicating the membership to metastable (long-lived) states, (ii) a Markov chain that governs the transitions between metastable states and facilitates analysis of the long-time dynamics, and (iii) a generative part that samples the conditional distribution of configurations in the next time step. The model can be operated in a recursive fashion to generate trajectories to predict the system evolution from a defined starting state and propose new configurations. The DeepGenMSM is demonstrated to provide accurate estimates of the long-time kinetics and generate valid distributions for molecular dynamics (MD) benchmark systems. Remarkably, we show that DeepGenMSMs are able to make long time-steps in molecular configuration space and generate physically realistic structures in regions that were not seen in training data.},
author = {Wu, Hao and Mardt, Andreas and Pasquali, Luca and No{\'{e}}, Frank},
booktitle = {arXiv},
issn = {23318422},
language = {en},
pages = {10},
title = {{Deep generative markov state models}},
year = {2018}
}

@Article{Matsuoka1995,
  author   = {Matsuoka, Kiyotoshi and Ohoya, Masahiro and Kawamoto, Mitsuru},
  journal  = {Neural Networks},
  title    = {{A neural net for blind separation of nonstationary signals}},
  year     = {1995},
  issn     = {08936080},
  number   = {3},
  pages    = {411--419},
  volume   = {8},
  abstract = {This paper proposes a neural network that recovers some original random signals from their linear mixtures observed by the same number of sensors. The network acquires the function with a learning process without using any particular information about the statistical properties of the sources and the coefficients of the linear transformation, except the fact that the source signals are statistically independent and nonstationary. The learning rule for the network's parameters is derived from the steepest descent minimization of a time-dependent cost function that takes the minimum only when the network outputs are uncorrelated with each other. {\textcopyright} 1995.},
  doi      = {10.1016/0893-6080(94)00083-X},
  keywords = {Anti-Hebbian learning, Blind separation, Nonstationary signals, Self-organization},
}

@article{Plesset1949,
abstract = {{Three regimes of liquid flow over a body are defined, namely: (a) noncavitating flow; (b) cavitating flow with a relatively small number of cavitation bubbles in the field of !}ow; and (L) cavitating flow with a single large cavity about the body. The assumption is made that, for the second regime of flow, the pressure coefficient in the flow field is no different from that in the noncavitating flow. On this basis, the equation of motion for the growth and collapse of a cavitation bubble containing vapor is derived and applied to experimental observations on such bubbles. The limitations of this equation of motion are pointed out, and include the effect of the finite rate of evaporation and condensation, and compressibility of vapor and liquid. A brief discussion of the role of "nuclei" in the liquid in the rate of formation of cavitation bubbles is also given},
author = {Plesset, Milton},
issn = {0021-8936},
journal = {Journal of Applied Mechanics},
keywords = {Folder - Contrast agent physics},
mendeley-tags = {Folder - Contrast agent physics},
pages = {277--282},
title = {{The dynamics of cavitation bubbles}},
volume = {16},
year = {1949}
}

@InProceedings{Bernard2014,
  author        = {Bernard, Olivier and Zhang, Miaomiao and Varray, Francois and Gueth, Pierre and Thiran, Jean Philippe and Liebgott, Herv{\'{e}} and Friboulet, Denis},
  booktitle     = {IEEE International Ultrasonics Symposium, IUS},
  title         = {{Ultrasound Fourier slice imaging: A novel approach for ultrafast imaging technique}},
  year          = {2014},
  address       = {Chicago, IL, USA},
  month         = {sep},
  pages         = {129--132},
  publisher     = {IEEE},
  abstract      = {Ultrafast imaging based on plane-wave (PW) has become an intense area of research thanks to its capability of reaching frame rate higher than a thousand of frames per second. Several proposed approaches are based on Fourier-domain reconstruction. In these techniques, the Fourier transform of the received echoes is projected to the k-space corresponding to the Fourier transform of the object function. For one emitted PW, N lines along the kz axis direction are reconstructed in the k-space. We propose in this study a new acquisition scheme which allows acquiring the non-null part of the ultrasound spectrum with finer resolution. We show that this strategy allows obtaining images with slightly better lateral resolution and higher contrast-to-noise ratio (CNR) when compared to other Fourier-based techniques.},
  doi           = {10.1109/ULTSYM.2014.0033},
  isbn          = {9781479970490},
  issn          = {19485727},
  keywords      = {Folder - Classical beamforming, Fourier imaging, Plane wave, Ultrafast imaging},
  language      = {en},
  mendeley-tags = {Folder - Classical beamforming},
  shorttitle    = {Ultrasound Fourier slice imaging},
  url           = {http://ieeexplore.ieee.org/document/6932218/},
}

@Misc{Wu2018b,
  author        = {Wu, Fangfang and Dong, Weisheng and Shi, Guangming and Li, Xin},
  month         = {jul},
  title         = {{Learning hybrid sparsity prior for image restoration: Where deep learning meets sparse coding}},
  year          = {2018},
  abstract      = {State-of-the-art approaches toward image restoration can be classified into model-based and learning-based. The former - best represented by sparse coding techniques - strive to exploit intrinsic prior knowledge about the unknown high-resolution images; while the latter - popularized by recently developed deep learning techniques - leverage external image prior from some training dataset. It is natural to explore their middle ground and pursue a hybrid image prior capable of achieving the best in both worlds. In this paper, we propose a systematic approach of achieving this goal called Structured Analysis Sparse Coding (SASC). Specifically, a structured sparse prior is learned from extrinsic training data via a deep convolutional neural network (in a similar way to previous learning-based approaches); meantime another structured sparse prior is internally estimated from the input observation image (similar to previous model-based approaches). Two structured sparse priors will then be combined to produce a hybrid prior incorporating the knowledge from both domains. To manage the computational complexity, we have developed a novel framework of implementing hybrid structured sparse coding processes by deep convolutional neural networks. Experimental results show that the proposed hybrid image restoration method performs comparably with and often better than the current state-of-the-art techniques.},
  archiveprefix = {arXiv},
  arxivid       = {1807.06920},
  booktitle     = {arXiv},
  eprint        = {1807.06920},
  issn          = {23318422},
  keywords      = {Computer Science - Computer Vision and Pattern Rec, Deep convolutional neural networks, Electrical Engineering and Systems Science - Image, Hybrid prior learning, Image restoration, Structured analysis sparse coding},
  language      = {en},
  mendeley-tags = {Computer Science - Computer Vision and Pattern Rec,Electrical Engineering and Systems Science - Image},
  shorttitle    = {Learning Hybrid Sparsity Prior for Image Restorati},
  url           = {http://arxiv.org/abs/1807.06920},
}

@inproceedings{Maragoudakis2000,
author = {Maragoudakis, Michael E.},
booktitle = {General Pharmacology: Vascular System},
doi = {10.1016/S0306-3623(01)00111-2},
issn = {03063623},
number = {5},
pages = {225--226},
pmid = {11888676},
title = {{Angiogenesis in health and disease}},
volume = {35},
year = {2000}
}

@Article{Tiran2015,
  author        = {Tiran, Elodie and Deffieux, Thomas and Correia, Mafalda and Maresca, David and Osmanski, Bruno Felix and Sieu, Lim Anna and Bergel, Antoine and Cohen, Ivan and Pernot, Mathieu and Tanter, Mickael},
  journal       = {Physics in Medicine and Biology},
  title         = {{Multiplane wave imaging increases signal-to-noise ratio in ultrafast ultrasound imaging}},
  year          = {2015},
  issn          = {13616560},
  number        = {21},
  pages         = {8549--8566},
  volume        = {60},
  abstract      = {Ultrafast imaging using plane or diverging waves has recently enabled new ultrasound imaging modes with improved sensitivity and very high frame rates. Some of these new imaging modalities include shear wave elastography, ultrafast Doppler, ultrafast contrast-enhanced imaging and functional ultrasound imaging. Even though ultrafast imaging already encounters clinical success, increasing even more its penetration depth and signal-to-noise ratio for dedicated applications would be valuable. Ultrafast imaging relies on the coherent compounding of backscattered echoes resulting from successive tilted plane waves emissions; this produces high-resolution ultrasound images with a trade-off between final frame rate, contrast and resolution. In this work, we introduce multiplane wave imaging, a new method that strongly improves ultrafast images signal-to-noise ratio by virtually increasing the emission signal amplitude without compromising the frame rate. This method relies on the successive transmissions of multiple plane waves with differently coded amplitudes and emission angles in a single transmit event. Data from each single plane wave of increased amplitude can then be obtained, by recombining the received data of successive events with the proper coefficients. The benefits of multiplane wave for B-mode, shear wave elastography and ultrafast Doppler imaging are experimentally demonstrated. Multiplane wave with 4 plane waves emissions yields a 5.8 ± 0.5 dB increase in signal-to-noise ratio and approximately 10 mm in penetration in a calibrated ultrasound phantom (0.7 d MHz-1 cm-1). In shear wave elastography, the same multiplane wave configuration yields a 2.07 ± 0.05 fold reduction of the particle velocity standard deviation and a two-fold reduction of the shear wave velocity maps standard deviation. In functional ultrasound imaging, the mapping of cerebral blood volume results in a 3 to 6 dB increase of the contrast-to-noise ratio in deep structures of the rodent brain.},
  doi           = {10.1088/0031-9155/60/21/8549},
  keywords      = {B-mode, Doppler imaging, Folder - HFR US, Ultrasound imaging, frame rate, shear wave elastography, signal-to-noise ratio, ultrafast imaging},
  mendeley-tags = {Folder - HFR US},
  pmid          = {26487501},
  url           = {http://dx.doi.org/10.1088/0031-9155/60/21/8549},
}

@inproceedings{Holfort2009,
abstract = {This paper suggests a framework for utilizing adaptive, data-dependent apodization weights on both the receiving and transmitting aperture for Synthetic Aperture (SA) ultrasound imaging. The suggested approach is based on the Minimum Variance (MV) beamformer and consists of two steps. A set of uniquely designed receive apodization weights are applied to pre-summed element data forming a set of adaptively weighted images; these are in SA literature conventionally referred to as low-resolution images. The adaptive transmit apodization is obtained by applying MV across the full set of single emission images before summation. The method is investigated using simulated SA ultrasound data obtained using Field II. Data of 13 point targets distributed at depths from 40 mm to 70 mm, and a 5.5 MHz, 64-element linear array transducer have been used. The investigation has shown that the introduction of adaptive apodization weights on the transmitting aperture provides a main-lobe reduction (estimated at -30 dB) by a factor of 1.8 compared to the method using adaptive apodization weights on the receiving aperture only.},
address = {Rome},
author = {Holfort, Iben Kraglund and Austeng, Andreas and Synnev{\aa}g, Johan Fredrik and Holm, Sverre and Gran, Fredrik and Jensen, J{\o}rgen Arendt},
booktitle = {Proceedings - IEEE Ultrasonics Symposium},
doi = {10.1109/ULTSYM.2009.5442035},
isbn = {9781424443895},
issn = {10510117},
keywords = {Folder - Adaptive beamforming},
language = {en},
mendeley-tags = {Folder - Adaptive beamforming},
month = {sep},
pages = {1--4},
publisher = {IEEE},
title = {{Adaptive receive and transmit apodization for synthetic aperture ultrasound imaging}},
url = {http://ieeexplore.ieee.org/document/5442035/},
year = {2009}
}

@article{Zhao2017,
abstract = {{\textcopyright} 2017 Acoustical Society of America. The coherence factor (CF) and Wiener postfilter methods have been proposed as effective approaches for reducing the output noise of the delay-and-sum (DAS) beamformer in ultrasound imaging. The theoretical framework between them was also established. However, past researches about the CF and Wiener postfilter methods mainly focused on the summation of an array signal. This paper analyzes the CF and Wiener postfilter in the synthetic aperture (SA) imaging mode, where two-dimensional echo data are recorded. Different CF definitions in the SA imaging are first given and the corresponding Wiener postfilter methods are then proposed, including a Wiener postfilter especially for the SA imaging, named as Wiener SA . The performances of different CF and Wiener postfilter methods were evaluated on both simulated and experimental SA data. Results showed that the proposed Wiener SA outperformed the other Wiener postfilters in reducing the sidelobe noise level. It obtained the highest contrast ratio among the Wiener postfilter methods, which was even higher than some of the CF methods. Meanwhile it could benefit a much higher contrast-to-noise ratio than those CF methods with further suppression of incoherent noises. Consequently, the Wiener SA is believed to be a promising approach in enhancing the SA image quality.},
author = {Zhao, Jinxin and Wang, Yuanyuan and Guo, Wei and Yu, Jinhua},
doi = {10.1121/1.4979053},
issn = {0001-4966},
journal = {The Journal of the Acoustical Society of America},
keywords = {Folder - Correlation approaches},
mendeley-tags = {Folder - Correlation approaches},
number = {3},
pages = {2177--2190},
pmid = {28372122},
title = {{Coherence factor and Wiener postfilter in synthetic aperture ultrasound imaging}},
url = {http://aip.scitation.org/doi/10.1121/1.4979053},
volume = {141},
year = {2017}
}

@article{Delannoy1979,
abstract = {In acoustics, the analysis of pressure distribution in a field of surface sources is most frequently performed using the assumption that the source constitutes a part of an infinite planar rigid baffle (Rayleigh's approximation). However, in many practical cases of ultrasonic echography, assumption of a soft pressure-release baffle (the Rayleigh-Sommerfeld approximation) or of free-field conditions (the Kirchhoff approximation) seemed to be better matched to real conditions. A theoretical survey of the planar baffles problem is given in this paper, and its practical aspects in acoustic source radiation are discussed. Some experiments, showing the influence of different boundary conditions onto radiation patterns, verify the theoretical predictions.},
author = {Delannoy, B. and Lasota, H. and Bruneel, C. and Torguet, R. and Bridoux, E.},
doi = {10.1063/1.326656},
issn = {00218979},
journal = {Journal of Applied Physics},
month = {aug},
number = {8},
pages = {5189--5195},
title = {{The infinite planar baffles problem in acoustic radiation and its experimental verification}},
url = {https://aip.scitation.org/doi/10.1063/1.326656},
volume = {50},
year = {1979}
}

@article{Li1999,
author = {Li, J S Jimmy and Turley, Mike D E and Division, Surveillance Systems},
number = {1},
pages = {22--25},
title = {{BEAMFORMING FOR HIGH FREQUENCY RADAR}},
year = {1999}
}

@InProceedings{Zhe2007,
  author    = {Zhe, Wang and Slabaugh, Greg and Unal, Gozde and Tong, Fang},
  booktitle = {2007 4th IEEE International Symposium on Biomedical Imaging: From Nano to Macro - Proceedings},
  title     = {{Registration of ultrasound images using an information-theoretic feature detector}},
  year      = {2007},
  pages     = {736--739},
  publisher = {IEEE},
  abstract  = {In this paper, we present a new method for ultrasound image registration. For each image to be registered, our method first applies an ultrasound-specific information-theoretic feature detector, which is based on statistical modeling of speckle and provides a feature image that robustly delineates important edges in the image. These feature images are then registered using differential equations, the solution of which provides a locally optimal transformation that brings the images into alignment. We describe our method and present experimental results demonstrating its effectiveness, particularly for low contrast, speckled images. Furthermore, we compare our method to standard gradient-based techniques, which we show are more susceptible to misregistration. {\textcopyright} 2007 IEEE.},
  doi       = {10.1109/ISBI.2007.356957},
  isbn      = {1424406722},
  keywords  = {Biomedical image processing, Image registration, Information theory},
}

@article{Kruizinga2012,
abstract = {Beamforming of plane-wave ultrasound echo signals in the Fourier domain provides fast and accurate image reconstruction. Conventional implementations perform a k-space interpolation from the uniform sampled grid to a nonuniform acoustic dispersion grid. In this paper, we demonstrate that this step can be replaced by a nonuniform Fourier transform. We study the performance of the nonuniform fast Fourier transform (NUFFT) in terms of signal-to-noise ratio and computational cost, and show that the NUFFT offers an advantage in the trade-off between speed and accuracy, compared with other frequency-domain beamforming strategies. {\textcopyright} 2012 IEEE.},
author = {Kruizinga, Pieter and Mastik, Frits and {De Jong}, Nico and {Van Der Steen}, Antonius and {Van Soest}, Gijs},
doi = {10.1109/TUFFC.2012.2509},
issn = {08853010},
journal = {IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
keywords = {Folder - Classical beamforming},
language = {en},
mendeley-tags = {Folder - Classical beamforming},
month = {dec},
number = {12},
pages = {2684--2691},
pmid = {23221217},
title = {{Plane-wave ultrasound beamforming using a nonuniform fast fourier transform}},
url = {http://ieeexplore.ieee.org/document/6373791/},
volume = {59},
year = {2012}
}

@article{AliEslami2018,
abstract = {Scene representation—the process of converting visual sensory data into concise descriptions—is a requirement for intelligent behavior. Recent work has shown that neural networks excel at this task when provided with large, labeled datasets. However, removing the reliance on human labeling remains an important open problem. To this end, we introduce the Generative Query Network (GQN), a framework within which machines learn to represent scenes using only their own sensors. The GQN takes as input images of a scene taken from different viewpoints, constructs an internal representation, and uses this representation to predict the appearance of that scene from previously unobserved viewpoints. The GQN demonstrates representation learning without human labels or domain knowledge, paving the way toward machines that autonomously learn to understand the world around them.},
author = {{Ali Eslami}, S. M. and Rezende, Danilo Jimenez and Besse, Frederic and Viola, Fabio and Morcos, Ari S. and Garnelo, Marta and Ruderman, Avraham and Rusu, Andrei A. and Danihelka, Ivo and Gregor, Karol and Reichert, David P. and Buesing, Lars and Weber, Theophane and Vinyals, Oriol and Rosenbaum, Dan and Rabinowitz, Neil and King, Helen and Hillier, Chloe and Botvinick, Matt and Wierstra, Daan and Kavukcuoglu, Koray and Hassabis, Demis},
doi = {10.1126/science.aar6170},
issn = {10959203},
journal = {Science},
language = {en},
month = {jun},
number = {6394},
pages = {1204--1210},
pmid = {29903970},
title = {{Neural scene representation and rendering}},
url = {https://www.sciencemag.org/lookup/doi/10.1126/science.aar6170},
volume = {360},
year = {2018}
}

@InProceedings{Holfort2007,
  author        = {Holfort, Iben Kraglund and Gran, Fredrik and Jensen, J{\o}rgen Arendt},
  booktitle     = {Proceedings - IEEE Ultrasonics Symposium},
  title         = {{Minimum variance beamforming for high frame-rate ultrasound imaging}},
  year          = {2007},
  number        = {3},
  pages         = {1541--1544},
  abstract      = {This paper investigates the application of adaptive beamforming in medical ultrasound imaging. A minimum variance (MV) approach for near-field beamforming of broadband data is proposed. The approach is implemented in the frequency domain, and it provides a set of adapted, complex apodization weights for each frequency sub-band. As opposed to the conventional, Delay and Sum (DS) beamformer, this approach is dependent on the specific data. The performance of the proposed MV beamformer is tested on simulated synthetic aperture (SA) ultrasound data, obtained using Field II. For the simulations, a 7 MHz, 128-element, phased array transducer with $\lambda$/2-spacing was used. Data is obtained using a single element as the transmitting aperture and all 128 elements as the receiving aperture. A full SA sequence consisting of 128 emissions was simulated by sliding the active transmitting element across the array. Data for 13 point targets and a circular cyst with a radius of 5 mm were simulated. The performance of the MV beamformer is compared to DS using boxcar weights and Hanning weights, and is quantified by the Full Width at Half Maximum (FWHM) and the peak-side-lobe level (PSL). Single emission {DS Boxcar, DS Hanning, MV} provide a PSL of {-16, -36, -49} dB and a FWHM of {0.79, 1.33, 0.08} mm = {3.59$\lambda$, 6.05$\lambda$, 0.36$\lambda$}. Using all 128 emissions, {DS Boxcar, DS Hanning, MV} provide a PSL of {-32,-49,-65} dB, and a FWHM of {0.63, 0.97, 0.08} mm = {2.86$\lambda$, 4.41$\lambda$, 0.36$\lambda$}. The contrast of the beamformed single emission responses of the circular cyst were calculated to {-18, -37, -40} dB. The simulations have shown that the frequency sub-band MV beamformer provides a significant increase in lateral resolution compared to DS, even when using considerably fewer emissions. An increase in resolution is seen when using only one single emission. Furthermore, it is seen that an increase of the number of emissions does not alter the FWHM. Thus, the MV beamformer introduces the possibility for high frame-rate imaging with increased resolution. {\textcopyright} 2007 IEEE.},
  doi           = {10.1109/ULTSYM.2007.388},
  isbn          = {1424413834},
  issn          = {10510117},
  keywords      = {Folder - Adaptive beamforming, P2B-12 Minimum Variance Beamforming for High Fram},
  mendeley-tags = {Folder - Adaptive beamforming,P2B-12 Minimum Variance Beamforming for High Fram},
}

@Article{Li2003,
  author        = {Li, Pai Chi and Li, Meng Lin},
  journal       = {IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
  title         = {{Adaptive imaging using the generalized coherence factor}},
  year          = {2003},
  issn          = {08853010},
  number        = {2},
  pages         = {128--141},
  volume        = {50},
  abstract      = {Sound-velocity inhomogeneities degrade both spatial and contrast resolutions. This paper proposes a new adaptive imaging technique t hat uses the generalized coherence factor (GCF) to reduce the focusing errors resulting from the sound-velocity inhomogeneities. The GCF is derived from the spatial spectrum of the received aperture data after proper receive delays have been applied. It is defined as the ratio of the spectral energy within a prespecified low-frequency range to the total energy. It is demonstrated that the low-frequency component of the spectrum corresponds to the coherent portion of the received data, and that the high-frequency component corresponds to the incoherent portion. Hence, the GCF reduces to the coherence factor defined in the literature if the prespecified low-frequency range is restricted to dc only. In addition, the GCF is also an index of the focusing quality and can be used as a weighting factor for the reconstructed image. The efficacy of the GCF technique is demonstrated for focusing errors resulting from the sound-velocity inhomogeneities. Simulations and real ultrasound data are used to evaluate the efficacy of the proposed GCF technique. The characteristics of the GCF. including the effects of the signal-to-noise ratio and the number of channels, are also discussed. The GCF technique also is compared with the correlation-based technique and the parallel adaptive receive compensation algorithm; the improvement in image quality obtained with the proposed technique rivals that of the latter technique. In the presence of a displaced phase screen, this proposed technique also outperforms the correlation-based technique. Computational complexity and implementation issues also are addressed.},
  doi           = {10.1109/TUFFC.2003.1182117},
  keywords      = {Folder - Adaptive beamforming, Folder - Correlation approaches},
  mendeley-tags = {Folder - Adaptive beamforming,Folder - Correlation approaches},
  pmid          = {12625586},
}

@Misc{Ruthotto2018,
  author        = {Ruthotto, Lars and Ruthotto, Lars and Haber, Eldad and Haber, Eldad},
  month         = {apr},
  title         = {{Deep neural networks motivated by partial differential equations}},
  year          = {2018},
  abstract      = {Partial differential equations (PDEs) are indispensable for modeling many physical phenomena and also commonly used for solving image processing tasks. In the latter area, PDE-based approaches interpret image data as discretizations of multivariate functions and the output of image processing algorithms as solutions to certain PDEs. Posing image processing problems in the in flnite dimensional setting provides powerful tools for their analysis and solution. Over the last few decades, the reinterpretation of classical image processing problems through the PDE lens has been creating multiple celebrated approaches that bene flt a vast area of tasks including image segmentation, denoising, registration, and reconstruction. In this paper, we establish a new PDE-interpretation of a class of deep convolutional neural networks (CNN) that are commonly used to learn from speech, image, and video data. Our interpretation includes convolution residual neural networks (ResNet), which are among the most promising approaches for tasks such as image classi flcation having improved the state-of-the-art performance in prestigious benchmark challenges. Despite their recent successes, deep ResNets still face some critical challenges associated with their design, immense computational costs and memory requirements, and lack of understanding of their reasoning. Guided by well-established PDE theory, we derive three new ResNet architectures that fall into two new classes: parabolic and hyperbolic CNNs. We demonstrate how PDE theory can provide new insights and algorithms for deep learning and demonstrate the competitiveness of three new CNN architectures using numerical experiments.},
  booktitle     = {arXiv},
  issn          = {23318422},
  keywords      = {65K10- 68T45, Computer Science - Machine Learning, Deep Neural Networks, Image Classi flcation, Machine Learning, Mathematics - Optimization and Control, PDE-Constrained Optimization, Partial Differential Equations, Statistics - Machine Learning},
  language      = {en},
  mendeley-tags = {65K10- 68T45,Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning},
  url           = {http://arxiv.org/abs/1804.04272},
}

@Misc{Odaibo2019,
  author        = {Odaibo, Stephen G.},
  month         = {jul},
  title         = {{Tutorial: Deriving the Standard Variational Autoencoder (VAE) Loss Function}},
  year          = {2019},
  abstract      = {In Bayesian machine learning, the posterior distribution is typically computationally intractable, hence variational inference is often required. In this approach, an evidence lower bound on the log likelihood of data is maximized during training. Variational Autoencoders (VAE) are one important example where variational inference is utilized. In this tutorial, we derive the variational lower bound loss function of the standard variational autoencoder. We do so in the instance of a gaussian latent prior and gaussian approximate posterior, under which assumptions the Kullback-Leibler term in the variational lower bound has a closed form solution. We derive essentially everything we use along the way; everything from Bayes' theorem to the Kullback-Leibler divergence.},
  archiveprefix = {arXiv},
  arxivid       = {1907.08956},
  booktitle     = {arXiv},
  eprint        = {1907.08956},
  issn          = {23318422},
  keywords      = {Computer Science - Machine Learning, Statistics - Machine Learning},
  language      = {en},
  mendeley-tags = {Computer Science - Machine Learning,Statistics - Machine Learning},
  shorttitle    = {Tutorial},
  url           = {http://arxiv.org/abs/1907.08956},
}

@inproceedings{Moubark2016,
abstract = {FDMAS has been successfully used in microwave imaging for breast cancer detection. FDMAS gained its popularity due to its capability to produce results faster than any other adaptive beamforming technique such as minimum variance (MV) which requires higher computational complexity. The average computational time for single point spread function (PSF) at 40 mm depth for FDMAS is 87 times faster than MV. The new beamforming technique has been tested on PSF and cyst phantoms experimentally with the ultrasound array research platform version 2 (UARP II) using a 3-8 MHz 128 element clinical transducer. FDMAS is able to improve both imaging contrast and spatial resolution as compared to DAS. The wire phantom main lobes lateral resolution improved in FDMAS by 40.4% with square pulse excitation signal when compared to DAS. Meanwhile the contrast ratio (CR) obtained for an anechoic cyst located at 15 mm depth for PWI with DAS and FDMAS are -6.2 dB and -14.9 dB respectively. The ability to reduce noise from off axis with auto-correlation operation in FDMAS pave the way to display the B-mode image with high dynamic range. However, the contrast to noise ratio (CNR) measured at same cyst location for FDMAS give less reading compared to DAS. Nevertheless, this drawback can be compensated by applying compound plane wave imaging (CPWI) technique on FDMAS. In overall the new FDMAS beamforming technique outperforms DAS in laboratory experiments by narrowing its main lobes and increases the image contrast without sacrificing its frame rates.},
author = {Moubark, Asraf Mohamed and Alomari, Zainab and Harput, Sevan and Cowell, David M.J. and Freear, Steven},
booktitle = {IEEE International Ultrasonics Symposium, IUS},
doi = {10.1109/ULTSYM.2016.7728678},
isbn = {9781467398978},
issn = {19485727},
keywords = {Folder - Beamforming special},
mendeley-tags = {Folder - Beamforming special},
number = {2},
pages = {2--5},
title = {{Enhancement of contrast and resolution of B-mode plane wave imaging (PWI) with non-linear filtered delay multiply and sum (FDMAS) beamforming}},
volume = {2016-Novem},
year = {2016}
}

@Article{Besson2018,
  author        = {Besson, Adrien and Perdios, Dimitris and Martinez, Florian and Chen, Zhouye and Carrillo, Rafael E. and Arditi, Marcel and Wiaux, Yves and Thiran, Jean Philippe},
  journal       = {IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
  title         = {{Ultrafast Ultrasound Imaging as an Inverse Problem: Matrix-Free Sparse Image Reconstruction}},
  year          = {2018},
  issn          = {08853010},
  month         = {mar},
  number        = {3},
  pages         = {339--355},
  volume        = {65},
  abstract      = {Conventional ultrasound (US) image reconstruction methods rely on delay-and-sum (DAS) beamforming, which is a relatively poor solution to the image reconstruction problem. An alternative to DAS consists in using iterative techniques, which require both an accurate measurement model and a strong prior on the image under scrutiny. Toward this goal, much effort has been deployed in formulating models for US imaging, which usually require a large amount of memory to store the matrix coefficients. We present two different techniques, which take advantage of fast and matrix-free formulations derived for the measurement model and its adjoint, and rely on sparsity of US images in well-chosen models. Sparse regularization is used for enhanced image reconstruction. Compressed beamforming exploits the compressed sensing framework to restore high-quality images from fewer raw data than state-of-the-art approaches. Using simulated data and in vivo experimental acquisitions, we show that the proposed approach is three orders of magnitude faster than non-DAS state-of-the-art methods, with comparable or better image quality.},
  doi           = {10.1109/TUFFC.2017.2768583},
  keywords      = {Beamforming, Folder - Beamforming special, compressed sensing (CS), sparse regularization (SR), ultrafast ultrasound (US) imaging},
  language      = {en},
  mendeley-tags = {Folder - Beamforming special},
  pmid          = {29505404},
  shorttitle    = {Ultrafast Ultrasound Imaging as an Inverse Problem},
  url           = {https://ieeexplore.ieee.org/document/8091286/},
}

@article{Holfort2009a,
abstract = {A minimum variance (MV) approach for nearfield beamforming of broadband data is proposed. The approach is implemented in the frequency domain, and it provides a set of adapted, complex apodization weights for each frequency subband. The performance of the proposed MV beamformer is tested on simulated data obtained using Field II. The method is validated using synthetic aperture data and data obtained from a plane wave emission. Data for 13 point targets and a circular cyst with a radius of 5 mm are simulated. The performance of the MV beamformer is compared with delay-andsum (DS) using boxcar weights and Hanning weights and is quantified by the full width at half maximum (FWHM) and the peak-side-lobe level (PSL). Single emission {DS boxcar, DS Hanning, MV} provide a PSL of {-16, -36, -49} dB and a FWHM of {0.79, 1.33, 0.08} mm. Using all 128 emissions, {DS boxcar, DS Hanning, MV} provides a PSL of {-32, -49, -65} dB, and a FWHM of {0.63, 0.97, 0.08} mm. The contrast of the beamformed single emission responses of the circular cyst was calculated as {-18, -37, -40} dB. The simulations have shown that the frequency subband MV beamformer provides a significant increase in lateral resolution compared with DS, even when using considerably fewer emissions. An increase in resolution is seen when using only one single emission. Furthermore, the effect of steering vector errors is investigated. The steering vector errors are investigated by applying an error of the sound speed estimate to the ultrasound data. As the error increases, it is seen that the MV beamformer is not as robust compared with the DS beamformer with boxcar and Hanning weights. Nevertheless, it is noted that the DS does not outperform the MV beamformer. For errors of 2% and 4% of the correct value, the FWHM are {0.81, 1.25, 0.34} mm and {0.89, 1.44, 0.46} mm, respectively. {\textcopyright} 2006 IEEE.},
author = {Holfort, Iben Kraglund and Gran, Fredrik and J{\o}ensen, Jorgen Arendt},
doi = {10.1109/TUFFC.2009.1040},
issn = {08853010},
journal = {IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
keywords = {Folder - Adaptive beamforming},
mendeley-tags = {Folder - Adaptive beamforming},
number = {2},
pages = {314--325},
pmid = {19251518},
title = {{Broadband minimum variance beamforming for ultrasound imaging}},
volume = {56},
year = {2009}
}

@article{Schmidt2005,
abstract = {This project surveys and examines optimization ap- proaches proposed for parameter estimation in Least Squares linear regression models with an L1 penalty on the regression coefficients. We first review linear regres- sion and regularization, and both motivate and formalize this problem. We then give a detailed analysis of 8 of the varied approaches that have been proposed for optimiz- ing this objective, 4 focusing on constrained formulations and 4 focusing on the unconstrained formulation. We then briefly survey closely related work on the orthogonal design case, approximate optimization, regularization parameter estimation, other loss functions, active application areas, and properties of L1 regularization. Illustrative implemen- tations of each of these 8 methods are included with this document as a web resource.},
author = {Schmidt, Mark},
journal = {Optimization},
number = {December},
pages = {230--238},
title = {{Least Squares Optimization with L1-Norm Regularization}},
url = {http://people.cs.ubc.ca/ schmidtm/Software/lasso.pdf http://people.cs.ubc.ca/$\sim$schmidtm/Software/lasso.pdf},
volume = {98},
year = {2005}
}

@InProceedings{Du2008,
  author        = {Du, Lin and Yardibi, Tarik and Li, Jian and Stoica, Petre},
  booktitle     = {Conference Record - Asilomar Conference on Signals, Systems and Computers},
  title         = {{Review of user parameter-free robust adaptive beamforming algorithms}},
  year          = {2008},
  pages         = {363--367},
  publisher     = {IEEE},
  abstract      = {This paper provides a comprehensive review of user parameter-free robust adaptive beamforming algorithms, including ridge regression Capon beamformers (RRCBs), the mid-way (MW) algorithm, the shrinkage based approaches, and iterative beamforming algorithms, namely the iterative adaptive approach (IAA), maximum likelihood based IAA (IAA-ML) and M-SBL (multi-snapshot sparse Bayesian learning). The purpose of these algorithms is to mitigate the negative effects of model errors on the standard Capon beamformer (SCB). We provide a thorough evaluation of these methods under various scenarios and give insights into which algorithm is the best choice under which circumstances. {\textcopyright} 2008 IEEE.},
  doi           = {10.1109/ACSSC.2008.5074426},
  isbn          = {9781424429417},
  issn          = {10586393},
  keywords      = {Array processing, Beamforming, Diagonal loading, Folder - Adaptive beamforming, User parameter-free},
  mendeley-tags = {Folder - Adaptive beamforming},
}

@Article{Stride2003,
  author        = {Stride, E. and Saffari, N.},
  journal       = {Proceedings of the Institution of Mechanical Engineers, Part H: Journal of Engineering in Medicine},
  title         = {{Microbubble ultrasound contrast agents: A review}},
  year          = {2003},
  issn          = {09544119},
  number        = {6},
  pages         = {429--447},
  volume        = {217},
  abstract      = {The superior scattering properties of gas bubbles compared with blood cells have made microbubble ultrasound contrast agents important tools in ultrasound diagnosis. Over the past 2 years they have become the focus of a wide and rapidly expanding field of research, with their benefits being repeatedly demonstrated, both in ultrasound image enhancement, and more recently in drug and gene delivery applications. However, despite considerable investigation, their behaviour is by no means fully understood and, while no definite evidence of harmful effects has been obtained, there remain some concerns as to their safety. In this review the existing theoretical and experimental evidence is examined in order to clarify the extent to which contrast agents are currently understood and to identify areas for future research. In particular the disparity between the conditions considered in theoretical models and those encountered both in vitro, and more importantly in vivo is discussed, together with the controversy regarding the risk of harmful bio-effects.},
  doi           = {10.1243/09544110360729072},
  keywords      = {Folder - Contrast agent physics, Microbubble ultrasound contrast agents},
  mendeley-tags = {Folder - Contrast agent physics},
  pmid          = {14702981},
}

@article{Burckhardt1978,
abstract = {Ultrasound images obtained with a simple linear or sector scan show a granular appearance, called “speckle.” This speckle is analyzed. The reduction in speckle that can be obtained with a compound scan with maximum amplitude writing is computed. The reduction in speckle is almost as large as can be obtained with averaging. It depends on the number of independent amplitude values that are measured. The condition for the independence of two amplitude values is derived, and thus a limit is given for the possible reduction in speckle. Copyright {\textcopyright} 1977 by The Institute of Electrical and Electronics Engineers, Inc.},
author = {Burckhardt, Christoph B.},
doi = {10.1109/T-SU.1978.30978},
issn = {00189537},
journal = {IEEE Transactions on Sonics and Ultrasonics},
keywords = {ultrasound},
mendeley-tags = {ultrasound},
number = {1},
pages = {1--6},
title = {{Speckle in Ultrasound B-Mode Scans}},
volume = {25},
year = {1978}
}

@Article{Chan2015,
  author        = {Chan, Tsung Han and Jia, Kui and Gao, Shenghua and Lu, Jiwen and Zeng, Zinan and Ma, Yi},
  journal       = {IEEE Transactions on Image Processing},
  title         = {{PCANet: A Simple Deep Learning Baseline for Image Classification?}},
  year          = {2015},
  issn          = {10577149},
  month         = {dec},
  number        = {12},
  pages         = {5017--5032},
  volume        = {24},
  abstract      = {In this paper, we propose a very simple deep learning network for image classification that is based on very basic data processing components: 1) cascaded principal component analysis (PCA); 2) binary hashing; and 3) blockwise histograms. In the proposed architecture, the PCA is employed to learn multistage filter banks. This is followed by simple binary hashing and block histograms for indexing and pooling. This architecture is thus called the PCA network (PCANet) and can be extremely easily and efficiently designed and learned. For comparison and to provide a better understanding, we also introduce and study two simple variations of PCANet: 1) RandNet and 2) LDANet. They share the same topology as PCANet, but their cascaded filters are either randomly selected or learned from linear discriminant analysis. We have extensively tested these basic networks on many benchmark visual data sets for different tasks, including Labeled Faces in the Wild (LFW) for face verification; the MultiPIE, Extended Yale B, AR, Facial Recognition Technology (FERET) data sets for face recognition; and MNIST for hand-written digit recognition. Surprisingly, for all tasks, such a seemingly naive PCANet model is on par with the state-of-the-art features either prefixed, highly hand-crafted, or carefully learned [by deep neural networks (DNNs)]. Even more surprisingly, the model sets new records for many classification tasks on the Extended Yale B, AR, and FERET data sets and on MNIST variations. Additional experiments on other public data sets also demonstrate the potential of PCANet to serve as a simple but highly competitive baseline for texture classification and object recognition.},
  archiveprefix = {arXiv},
  arxivid       = {1404.3606},
  doi           = {10.1109/TIP.2015.2475625},
  eprint        = {1404.3606},
  keywords      = {Computer Science - Computer Vision and Pattern Rec, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computi, Convolution Neural Network, Deep Learning, Face Recognition, Handwritten Digit Recognition, LDA Network, Object Classification, PCA Network, Random Network},
  language      = {en},
  mendeley-tags = {Computer Science - Computer Vision and Pattern Rec,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computi},
  shorttitle    = {PCANet},
  url           = {http://arxiv.org/abs/1404.3606},
}

@Book{2017,
  publisher  = {Springer International Publishing},
  title      = {{Spectral and High Order Methods for Partial Differential Equations ICOSAHOM 2016: Selected Papers from the ICOSAHOM conference, June 27-July 1, 2016, Rio de Janeiro, Brazil}},
  year       = {2017},
  address    = {Cham},
  isbn       = {978-3-319-65869-8 978-3-319-65870-4},
  series     = {Lecture Notes in Computational Science and Engineering},
  volume     = {119},
  language   = {en},
  shorttitle = {Spectral and High Order Methods for Partial Differ},
  url        = {http://link.springer.com/10.1007/978-3-319-65870-4},
}

@Misc{Turco2020,
  author     = {Turco, Simona and Frinking, Peter and Wildeboer, Rogier and Arditi, Marcel and Wijkstra, Hessel and Lindner, Jonathan R. and Mischi, Massimo},
  month      = {mar},
  title      = {{Contrast-Enhanced Ultrasound Quantification: From Kinetic Modeling to Machine Learning}},
  year       = {2020},
  abstract   = {Ultrasound contrast agents (UCAs) have opened up immense diagnostic possibilities by combined use of indicator dilution principles and dynamic contrast-enhanced ultrasound (DCE-US) imaging. UCAs are microbubbles encapsulated in a biocompatible shell. With a rheology comparable to that of red blood cells, UCAs provide an intravascular indicator for functional imaging of the (micro)vasculature by quantitative DCE-US. Several models of the UCA intravascular kinetics have been proposed to provide functional quantitative maps, aiding diagnosis of different pathological conditions. This article is a comprehensive review of the available methods for quantitative DCE-US imaging based on temporal, spatial and spatiotemporal analysis of the UCA kinetics. The recent introduction of novel UCAs that are targeted to specific vascular receptors has advanced DCE-US to a molecular imaging modality. In parallel, new kinetic models of increased complexity have been developed. The extraction of multiple quantitative maps, reflecting complementary variables of the underlying physiological processes, requires an integrative approach to their interpretation. A probabilistic framework based on emerging machine-learning methods represents nowadays the ultimate approach, improving the diagnostic accuracy of DCE-US imaging by optimal combination of the extracted complementary information. The current value and future perspective of all these advances are critically discussed.},
  booktitle  = {Ultrasound in Medicine and Biology},
  doi        = {10.1016/j.ultrasmedbio.2019.11.008},
  issn       = {1879291X},
  keywords   = {Contrast-enhanced ultrasound, Indicator dilution theory, Kinetic modeling, Machine learning, Molecular ultrasound, Multiparametric ultrasound, Quantitative ultrasound, Spatiotemporal analysis, Time–intensity curves, Ultrasound contrast agents},
  language   = {en},
  number     = {3},
  pages      = {518--543},
  pmid       = {31924424},
  shorttitle = {Contrast-Enhanced Ultrasound Quantification},
  url        = {https://linkinghub.elsevier.com/retrieve/pii/S030156291931590X},
  volume     = {46},
}

@article{Budini2016,
abstract = {The standard central limit theorem with a Gaussian attractor for the sum of independent random variables may lose its validity in the presence of strong correlations between the added random contributions. Here, we study this problem for similar interchangeable globally correlated random variables. Under these conditions, a hierarchical set of equations is derived for the conditional transition probabilities. This result allows us to define different classes of memory mechanisms that depend on a symmetric way on all involved variables. Depending on the correlation mechanisms and statistics of the single variables, the corresponding sums are characterized by distinct probability densities. For a class of urn models it is also possible to characterize their domain of attraction, which, as in the standard case, is parametrized by the probability density of each random variable. Symmetric and asymmetric q-Gaussian attractors (q<1) arise in a particular two-state case of these urn models.},
archivePrefix = {arXiv},
arxivId = {1603.07314},
author = {Budini, Adri{\'{a}}n A.},
doi = {10.1103/PhysRevE.93.062114},
eprint = {1603.07314},
issn = {24700053},
journal = {Physical Review E},
number = {6},
pages = {1--16},
title = {{Central limit theorem for a class of globally correlated random variables}},
url = {http://arxiv.org/abs/1603.07314},
volume = {93},
year = {2016}
}

@book{VanTrees2002,
abstract = {《信息技术和电气工程学科国际知名教材中译本系列{\textperiodcentered}最优阵列处理技术》内容非常丰富，既包含了经典的阵列设计和空时随机过程分析的理论，了然近十年来在自适应阵列处理领域内自适应波束形成，波达方向估计（DOA）和空间谱估计方面的各种新的理论、算法和技术。作者结合多年的教学和撰写教材的经验，在内容选材上做到结构完整，脉络清晰。作者在每一章后面都为读者精心提供了很多习题。这些习题一方面可以帮助读者加强对基本概念的理解，另一方面也可以帮助读者开拓视野，了解相关问题的进一步研究方向。阵列信号处理是近30年以来迅速发展的一个领域，在雷达、声纳、通信、电子对抗、地震信号处理、语音信号处理、射电天文等领域得到广泛应用，并逐渐成为众多应用领域中的核心技术和主要发展方向——如雷达中的相控阵技术、通信中的智能天线阵列技术，电子圣训的超分辨率测向技术以及语音信号处理中的麦克风阵列技术等。},
address = {New York},
author = {{Van Trees}, Harry L.},
booktitle = {Optimum Array Processing},
doi = {10.1002/0471221104},
isbn = {978-0-471-09390-9},
language = {en},
pages = {1443},
publisher = {Wiley},
series = {Detection, estimation, and modulation theory / Harry L. Van Trees},
title = {{Optimum Array Processing}},
year = {2002}
}

@Article{Yoon2019,
  author        = {Yoon, Yeo Hun and Khan, Shujaat and Huh, Jaeyoung and Ye, Jong Chul},
  journal       = {IEEE Transactions on Medical Imaging},
  title         = {{Efficient B-Mode Ultrasound Image Reconstruction From Sub-Sampled RF Data Using Deep Learning}},
  year          = {2019},
  issn          = {1558254X},
  month         = {feb},
  number        = {2},
  pages         = {325--336},
  volume        = {38},
  abstract      = {In portable, 3-D, and ultra-fast ultrasound imaging systems, there is an increasing demand for the reconstruction of high-quality images from a limited number of radio-frequency (RF) measurements due to receiver (Rx) or transmit (Xmit) event sub-sampling. However, due to the presence of side lobe artifacts from RF sub-sampling, the standard beamformer often produces blurry images with less contrast, which are unsuitable for diagnostic purposes. Existing compressed sensing approaches often require either hardware changes or computationally expensive algorithms, but their quality improvements are limited. To address this problem, in this paper, we propose a novel deep learning approach that directly interpolates the missing RF data by utilizing redundancy in the Rx-Xmit plane. Our extensive experimental results using sub-sampled RF data from a multi-line acquisition B-mode system confirm that the proposed method can effectively reduce the data rate without sacrificing the image quality.},
  archiveprefix = {arXiv},
  arxivid       = {1712.06096},
  doi           = {10.1109/TMI.2018.2864821},
  eprint        = {1712.06096},
  keywords      = {B-mode, B-mode ultrasound image reconstruction, Hankel matrix, Image reconstruction, Imaging, Machine learning, Neural networks, Radio frequency, Redundancy, Ultrasonic imaging, Ultrasound imaging, biomedical ultrasonics, blurry images, compressed sensing approaches, deep learning, deep learning approach, high-quality images, image quality, image reconstruction, learning (artificial intelligence), medical image processing, multi-line acquisition, multiline acquisition B-mode system, radio-frequency measurements, ultra-fast ultrasound imaging systems},
  mendeley-tags = {B-mode,B-mode ultrasound image reconstruction,Hankel matrix,Image reconstruction,Imaging,Machine learning,Neural networks,Radio frequency,Redundancy,Ultrasonic imaging,Ultrasound imaging,biomedical ultrasonics,blurry images,compressed sensing approaches,deep learning,deep learning approach,high-quality images,image quality,image reconstruction,learning (artificial intelligence),medical image processing,multi-line acquisition,multiline acquisition B-mode system,radio-frequency measurements,ultra-fast ultrasound imaging systems},
  pmid          = {30106712},
}

@Article{Synnevaag2007,
  author        = {Synnev{\aa}g, Jnhan Fredrik and Austeng, Andreas and Holm, Sverre},
  journal       = {IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
  title         = {{Adaptive beamforming applied to medical ultrasound imaging}},
  year          = {2007},
  issn          = {08853010},
  number        = {8},
  pages         = {1606--1613},
  volume        = {54},
  abstract      = {We have applied the minimum variance (MV) adaptive beamformer to medical ultrasound imaging and shown significant improvement in image quality compared to delay-and-sum (DAS). We demonstrate reduced mainlobe width and suppression of sidelobes on both simulated and experimental RF data of closely spaced wire targets, which gives potential contrast and resolution enhancement in medical images. The method is applied to experimental RF data from a heart phantom, in which we show increased resolution and improved definition of the ventricular walls. A potential weakness of adaptive beamformers is sensitivity to errors in the assumed wavefleld parameters. We look at two ways to increase robustness of the proposed method; spatial smoothing and diagonal loading. We show that both are controlled by a single parameter that can move the performance from that of a MV beamformer to that of a DAS beamformer. We evaluate the sensitivity to velocity errors and show that reliable amplitude estimates are achieved while the mainlobe width and sidelobe levels are still significantly lower than for the conventional beamformer. {\textcopyright} 2007 IEEE.},
  doi           = {10.1109/TUFFC.2007.431},
  keywords      = {Computer-Assisted, Folder - Adaptive beamforming, Heart, Humans, Image Enhancement/*methods, Image Processing, Imaging, Phantoms, Sensitivity and Specificity, Signal Processing, Ultrasonography/*methods},
  mendeley-tags = {Computer-Assisted,Folder - Adaptive beamforming,Heart,Humans,Image Enhancement/*methods,Image Processing,Imaging,Phantoms,Sensitivity and Specificity,Signal Processing,Ultrasonography/*methods},
  pmid          = {17703664},
  url           = {http://www.ncbi.nlm.nih.gov/pubmed/17703664},
}

@article{Mace2013,
abstract = {Hemodynamic changes in the brain are often used as surrogates of neuronal activity to infer the loci of brain activity. A major limitation of conventional Doppler ultrasound for the imaging of these changes is that it is not sensitive enough to detect the blood flow in small vessels where the major part of the hemodynamic response occurs. Here, we present a $\mu$Doppler ultrasound method able to detect and map the cerebral blood volume (CBV) over the entire brain with an important increase in sensitivity. This method is based on imaging the brain at an ultrafast frame rate (1 kHz) using compounded plane wave emissions. A theoretical model demonstrates that the gain in sensitivity of the $\mu$Doppler method is due to the combination of 1) the high signal-to-noise ratio of the gray scale images, resulting from the synthetic compounding of backscattered echoes; and 2) the extensive signal averaging enabled by the high temporal sampling of ultrafast frame rates. This $\mu$Doppler imaging is performed in vivo on trepanned rats without the use of contrast agents. The resulting images reveal detailed maps of the rat brain vascularization with an acquisition time as short as 320 ms per slice. This new method is the basis for a real-time functional ultrasound (fUS) imaging of the brain. {\textcopyright} 1986-2012 IEEE.},
author = {Mace, Emilie and Montaldo, Gabriel and Osmanski, Bruno Felix and Cohen, Ivan and Fink, Mathias and Tanter, Mickael},
doi = {10.1109/TUFFC.2013.2592},
issn = {08853010},
journal = {IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
keywords = {Folder - HFR US},
mendeley-tags = {Folder - HFR US},
number = {3},
pages = {492--506},
pmid = {23475916},
title = {{Functional ultrasound imaging of the brain: Theory and basic principles}},
volume = {60},
year = {2013}
}

@inproceedings{Gehrke2008,
abstract = {Pulse-echo ultrasound signal formation can be simulated by numerical emulation of the process chain: emit signal - electromechanical emit transformation - wave propagation and scattering - electromechanical receive transformation - receive signal. The simulation software Field II is indented for simulation of linear ultrasound systems. We present an extension to Field II that enables the inclusion of nonlinear oscillations of ultrasound contrast agent bubbles into the simulation. An example is given for contrast agent enhanced imaging of a virtual vessel phantom probed by a linear array transducer.},
author = {Gehrke, Tobias and Overhoff, Heinrich M.},
booktitle = {Informatik aktuell},
doi = {10.1007/978-3-540-78640-5_13},
isbn = {9783540786399},
issn = {1431472X},
pages = {62--66},
title = {{Simulation of contrast agent enhanced ultrasound imaging based on field II}},
year = {2008}
}

@Article{RigoPassarin2018,
  author   = {{Rigo Passarin}, Thiago Alberto and {W{\"{u}}st Zibetti}, Marcelo Victor and {Rodrigues Pipa}, Daniel},
  journal  = {Sensors (Basel, Switzerland)},
  title    = {{Sparse Ultrasound Imaging via Manifold Low-Rank Approximation and Non-Convex Greedy Pursuit}},
  year     = {2018},
  issn     = {14248220},
  month    = {nov},
  number   = {12},
  volume   = {18},
  abstract = {Model-based image reconstruction has improved contrast and spatial resolution in imaging applications such as magnetic resonance imaging and emission computed tomography. However, these methods have not succeeded in pulse-echo applications like ultrasound imaging due to the typical assumption of a finite grid of possible scatterer locations in a medium⁻an assumption that does not reflect the continuous nature of real world objects and creates a problem known as off-grid deviation. To cope with this problem, we present a method of dictionary expansion and constrained reconstruction that approximates the continuous manifold of all possible scatterer locations within a region of interest. The expanded dictionary is created using a highly coherent sampling of the region of interest, followed by a rank reduction procedure. We develop a greedy algorithm, based on the Orthogonal Matching Pursuit, that uses a correlation-based non-convex constraint set that allows for the division of the region of interest into cells of any size. To evaluate the performance of the method, we present results of two-dimensional ultrasound imaging with simulated data in a nondestructive testing application. Our method succeeds in the reconstructions of sparse images from noisy measurements, providing higher accuracy than previous approaches based on regular discrete models.},
  doi      = {10.3390/s18124097},
  keywords = {dictionary, inverse problems, manifolds, nondestructive testing, rank reduction, ultrasound},
  pmid     = {30477106},
  url      = {https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6308998/},
}

@article{RueckertDHayesCHillDLGLeachMOHawkesDJ.1999,
abstract = {In this paper we present a new approach for the nonrigid registration of contrast-enhanced breast MRI. A hierarchical transformation model of the motion of the breast has been developed. The global motion of the breast is modeled by an affine transformation while the local breast motion is described by a free-form deformation (FFD) based on B-splines. Normalized mutual information is used as a voxel-based similarity measure which is insensitive to intensity changes as a result of the contrast enhancement. Registration is achieved by minimizing a cost function, which represents a combination of the cost associated with the smoothness of the transformation and the cost associated with the image similarity. The algorithm has been applied to the fully automated registration of three-dimensional (3-D) breast MRI in volunteers and patients. In particular, we have compared the results of the proposed nonrigid registration algorithm to those obtained using rigid and affine registration techniques. The results clearly indicate that the nonrigid registration algorithm is much better able to recover the motion and deformation of the breast than rigid or affine registration algorithms.},
author = {{Rueckert D Hayes C, Hill DLG, Leach MO, Hawkes DJ.}, Sonoda L I},
journal = {IEEE Transactions on Medical Imaging},
number = {8},
pages = {18:712--21},
title = {{Nonrigid registration using free-form deformations: application to breast MR images.}},
volume = {18},
year = {1999}
}

@Article{Lattari2019,
  author        = {Lattari, Francesco and Leon, Borja Gonzalez and Asaro, Francesco and Rucci, Alessio and Prati, Claudio and Matteucci, Matteo},
  journal       = {Remote Sensing},
  title         = {{Deep learning for SAR image despeckling}},
  year          = {2019},
  issn          = {20724292},
  month         = {jan},
  number        = {13},
  pages         = {1532},
  volume        = {11},
  abstract      = {Speckle filtering is an unavoidable step when dealing with applications that involve amplitude or intensity images acquired by coherent systems, such as Synthetic Aperture Radar (SAR). Speckle is a target-dependent phenomenon; thus, its estimation and reduction require the individuation of specific properties of the image features. Speckle filtering is one of the most prominent topics in the SAR image processing research community, who has first tackled this issue using handcrafted feature-based filters. Even if classical algorithms have slowly and progressively achieved better and better performance, the more recent Convolutional-Neural-Networks (CNNs) have proven to be a promising alternative, in the light of the outstanding capabilities in efficiently learning task-specific filters. Currently, only simplistic CNN architectures have been exploited for the speckle filtering task. While these architectures outperform classical algorithms, they still show some weakness in the texture preservation. In this work, a deep encoder-decoder CNN architecture, focused in the specific context of SAR images, is proposed in order to enhance speckle filtering capabilities alongside texture preservation. This objective has been addressed through the adaptation of the U-Net CNN, which has been modified and optimized accordingly. This architecture allows for the extraction of features at different scales, and it is capable of producing detailed reconstructions through its system of skip connections. In this work, a two-phase learning strategy is adopted, by first pre-training the model on a synthetic dataset and by adapting the learned network to the real SAR image domain through a fast fine-tuning procedure. During the fine-tuning phase, a modified version of the total variation (TV) regularization was introduced to improve the network performance when dealing with real SAR data. Finally, experiments were carried out on simulated and real data to compare the performance of the proposed method with respect to the state-of-the-art methodologies.},
  doi           = {10.3390/rs11131532},
  keywords      = {Deep learning, Despeckling, SAR image, deep learning, despeckling},
  language      = {en},
  mendeley-tags = {SAR image,deep learning,despeckling},
  url           = {https://www.mdpi.com/2072-4292/11/13/1532},
}

@InProceedings{Besson2016a,
  author        = {Besson, Adrien and Carrillo, Rafael E. and Perdios, Dimitris and Arditi, Marcel and Bernard, Olivier and Wiaux, Yves and Thiran, Jean Philippe},
  booktitle     = {IEEE International Ultrasonics Symposium, IUS},
  title         = {{A compressed beamforming framework for ultrafast ultrasound imaging}},
  year          = {2016},
  address       = {Tours, France},
  month         = {sep},
  pages         = {1--4},
  publisher     = {IEEE},
  volume        = {2016-Novem},
  abstract      = {Classical beamforming methods, based on Delay-And-Sum (DAS) require an extensive number of samples and delay calculations to obtain high-quality images. Compressed Beamforming (CB) proposes an alternative to DAS, based on compressed sensing, which aims at reducing the data rate. However, proposed CB approaches induce a computationally heavy measurement model that hampers their attractiveness for iterative image reconstruction. In this paper, a CB framework, applicable to either radio-frequency or in-phase quadrature data and for both plane wave and diverging wave compounding, is described. The proposed framework exploits a computationally light measurement model which leads to tractable reconstruction. It solves a convex problem and assumes sparsity in a waveletbased model to achieve high-quality image reconstruction from measurements acquired with only few transducer elements.},
  doi           = {10.1109/ULTSYM.2016.7728743},
  isbn          = {9781467398978},
  issn          = {19485727},
  keywords      = {Beamforming, Compressed sensing, Diverging wave, Folder - Beamforming special, Plane wave, Sparsity, Ultrafast imaging},
  language      = {en},
  mendeley-tags = {Folder - Beamforming special},
  url           = {http://ieeexplore.ieee.org/document/7728743/},
}

@Article{Kamilov2016,
  author        = {Kamilov, Ulugbek S. and Liu, Dehong and Mansour, Hassan and Boufounos, Petros T.},
  journal       = {IEEE Signal Processing Letters},
  title         = {{A Recursive Born Approach to Nonlinear Inverse Scattering}},
  year          = {2016},
  issn          = {10709908},
  month         = {aug},
  number        = {8},
  pages         = {1052--1056},
  volume        = {23},
  abstract      = {The iterative Born approximation (IBA) is a well-known method for describing waves scattered by semitransparent objects. In this letter, we present a novel nonlinear inverse scattering method that combines IBA with an edge-preserving total variation regularizer. The proposed method is obtained by relating iterations of IBA to layers of an artificial multilayer neural network and developing a corresponding error backpropagation algorithm for efficiently estimating the permittivity of the object. Simulations illustrate that, by accounting for multiple scattering, the method successfully recovers the permittivity distribution where the traditional linear inverse scattering fails.},
  archiveprefix = {arXiv},
  arxivid       = {1603.03768},
  doi           = {10.1109/LSP.2016.2579647},
  eprint        = {1603.03768},
  keywords      = {Computer Science - Machine Learning, Folder - Beamforming special, Inverse scattering, Physics - Optics, error backpropagation, neural networks, sparse recovery, total variation regularization},
  language      = {en},
  mendeley-tags = {Computer Science - Machine Learning,Folder - Beamforming special,Physics - Optics},
  url           = {http://arxiv.org/abs/1603.03768},
}

@Misc{Khan2019,
  author        = {Khan, Shujaat and Huh, Jaeyoung and Ye, Jong Chul},
  month         = {jan},
  title         = {{Universal deep beamformer for variable rate ultrasound imaging}},
  year          = {2019},
  abstract      = {Ultrasound (US) imaging is based on the time-reversal principle, in which individual channel RF measurements are back-propagated and accumulated to form an image after applying specific delays. While this time reversal is usually implemented as a delay-and-sum (DAS) beamformer, the image quality quickly degrades as the number of measurement channels decreases. To address this problem, various types of adaptive beamforming techniques have been proposed using predefined models of the signals. Unfortunately, the performance of these adaptive beamforming approaches degrade when the underlying model is not sufficiently accurate. Here, we demonstrate for the first time that a single universal deep beamformer trained using a purely data-driven way can generate significantly improved images over widely varying aperture and channel subsampling patterns. In particular, we design an end-to-end deep learning framework that can directly process sub-sampled RF data acquired at different subsampling rate and detector configuration to generate high quality ultrasound images using a single beamformer. Experimental results using B-mode focused ultrasound confirm the efficacy of the proposed methods.},
  archiveprefix = {arXiv},
  arxivid       = {1901.01706},
  booktitle     = {arXiv},
  eprint        = {1901.01706},
  issn          = {23318422},
  keywords      = {Adaptive beamformer, B-mode, Beamforming, Capon beamformer, Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Rec, Computer Science - Machine Learning, Statistics - Machine Learning, Ultrasound imaging},
  language      = {en},
  mendeley-tags = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Rec,Computer Science - Machine Learning,Statistics - Machine Learning},
  url           = {http://arxiv.org/abs/1901.01706},
}

@inproceedings{ODonnell1990,
abstract = {A method for multiple beam formation in the near field using phase rotation (i.e., Fourier inversion) is presented. This method, if used in conjunction with a digital beamformer described by M. O'Donnell et al. (IEEE 1990 Ultrasonics Sym. Proc., vol. 3, pp. 1499-1502), can produce multiple simultaneous beams of high precision with little increase in the complexity of the beamformer. This method combines dynamic focusing along a single beam with range-independent spatial Fourier processing to generate a set of high-quality simultaneous receive beams in the neighborhood of the dynamically focused beam. This system produces images of comparable quality to conventional beamformers but at twice the frame rate.},
author = {O'Donnell, M.},
booktitle = {Ultrasonics Symposium Proceedings},
doi = {10.1109/ULTSYM.1990.171615},
issn = {00905607},
pages = {1495--1498},
title = {{Efficient parallel receive beam forming for phased array imaging using phase rotation}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=171615},
volume = {3},
year = {1990}
}

@misc{Cichocki2015,
abstract = {The widespread use of multisensor technology and the emergence of big data sets have highlighted the limitations of standard flat-view matrix models and the necessity to move toward more versatile data analysis tools. We show that higher-order tensors (i.e., multiway arrays) enable such a fundamental paradigm shift toward models that are essentially polynomial, the uniqueness of which, unlike the matrix methods, is guaranteed under very mild and natural conditions. Benefiting from the power of multilinear algebra as their mathematical backbone, data analysis techniques using tensor decompositions are shown to have great flexibility in the choice of constraints which match data properties and extract more general latent components in the data than matrix-based methods.},
archivePrefix = {arXiv},
arxivId = {1403.4462},
author = {Cichocki, Andrzej and Mandic, Danilo and {De Lathauwer}, Lieven and Zhou, Guoxu and Zhao, Qibin and Caiafa, Cesar and Phan, Huy Anh},
booktitle = {IEEE Signal Processing Magazine},
doi = {10.1109/MSP.2013.2297439},
eprint = {1403.4462},
issn = {10535888},
language = {en},
month = {mar},
number = {2},
pages = {145--163},
shorttitle = {Tensor Decompositions for Signal Processing Applic},
title = {{Tensor decompositions for signal processing applications: From two-way to multiway component analysis}},
url = {http://ieeexplore.ieee.org/document/7038247/},
volume = {32},
year = {2015}
}

@article{Walker1998,
abstract = {-K-space is a frequency domain description of imaging systems and targets that can be used to gain insight into image formation. Although originally proposed in ultrasound for the analysis of experiments involving anisotropic scattering and for the design of acoustic tomography systems, it is particularly useful for the analysis of pulse echo ultrasonic imaging systems. This paper presents analytical and conceptual techniques for estimating the kspace representation of pulse echo imaging systems with arbitrary transmit and receive array geometries and apodizations. Simple graphical methods of estimating the first and second order statistics of speckle are presented. Examples are presented that utilize k-space to gain insight regarding the performance of spatial and frequency compounding and to describe the impact of synthetic receive aperture geometry on beamforming and speckle statistics. The Van Cittert-Zernike theorem is presented in k-space, and techniques for improving echo coherence are discussed. {\textcopyright} 1998 IEEE.},
author = {Walker, William F. and Trahey, Gregg E.},
doi = {10.1109/58.677599},
issn = {08853010},
journal = {IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
keywords = {Folder - Classical beamforming},
mendeley-tags = {Folder - Classical beamforming},
number = {3},
pages = {541--558},
title = {{The application of K-space in pulse echo ultrasound}},
volume = {45},
year = {1998}
}

@Article{Demi2013,
  author        = {Demi, Libertario and Viti, Jacopo and Kusters, Hlieneke and Guidi, Francesco and Tortoli, Piero and Mischi, Massimo},
  journal       = {IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
  title         = {{Implementation of parallel transmit beamforming using orthogonal frequency division multiplexing-achievable resolution and interbeam interference}},
  year          = {2013},
  issn          = {08853010},
  number        = {11},
  pages         = {2310--2320},
  volume        = {60},
  abstract      = {The speed of sound in the human body limits the achievable data acquisition rate of pulsed ultrasound scanners. To overcome this limitation, parallel beamforming techniques are used in ultrasound 2-D and 3-D imaging systems. Different parallel beamforming approaches have been proposed. They may be grouped into two major categories: parallel beamforming in reception and parallel beamforming in transmission. The first category is not optimal for harmonic imaging; the second category may be more easily applied to harmonic imaging. However, inter-beam interference represents an issue. To overcome these shortcomings and exploit the benefit of combining harmonic imaging and high data acquisition rate, a new approach has been recently presented which relies on orthogonal frequency division multiplexing (OFDM) to perform parallel beamforming in transmission. In this paper, parallel transmit beamforming using OFDM is implemented for the first time on an ultrasound scanner. An advanced open platform for ultrasound research is used to investigate the axial resolution and interbeam interference achievable with parallel transmit beamforming using OFDM. Both fundamental and second-harmonic imaging modalities have been considered. Results show that, for fundamental imaging, axial resolution in the order of 2 mm can be achieved in combination with interbeam interference in the order of-30 dB. For second-harmonic imaging, axial resolution in the order of 1 mm can be achieved in combination with interbeam interference in the order of-35 dB. {\textcopyright} 2013 IEEE.},
  doi           = {10.1109/TUFFC.2013.6644735},
  groups        = {Classical US imaging},
  keywords      = {Computer-Assisted, Imaging, Models, Phantoms, Signal Processing, Theoretical, Transducers, Ultrasonography, Ultrasonography: instrumentation, Ultrasonography: methods},
  mendeley-tags = {Computer-Assisted,Imaging,Models,Phantoms,Signal Processing,Theoretical,Transducers,Ultrasonography,Ultrasonography: instrumentation,Ultrasonography: methods},
  pmid          = {24158287},
  url           = {http://www.ncbi.nlm.nih.gov/pubmed/24158287},
}

@inproceedings{Simeoni2019,
abstract = {We propose a recurrent neural-network for real-time reconstruction of acoustic camera spherical maps. The network, dubbed DeepWave, is both physically and algorithmically motivated: its recurrent architecture mimics iterative solvers from convex optimisation, and its parsimonious parametrisation is based on the natural structure of acoustic imaging problems. Each network layer applies successive filtering, biasing and activation steps to its input, which can be interpreted as generalised deblurring and sparsification steps. To comply with the irregular geometry of spherical maps, filtering operations are implemented efficiently by means of graph signal processing techniques. Unlike commonly-used imaging network architectures, DeepWave is moreover capable of directly processing the complex-valued raw microphone correlations, learning how to optimally back-project these into a spherical map. We propose moreover a smart physically-inspired initialisation scheme that attains much faster training and higher performance than random initialisation. Our real-data experiments show DeepWave has similar computational speed to the state-of-the-art delay-and-sum imager with vastly superior resolution. While developed primarily for acoustic cameras, DeepWave could easily be adapted to neighbouring signal processing fields, such as radio astronomy, radar and sonar.},
author = {Simeoni, Matthieu and Kashani, Sepand and Hurley, Paul and Vetterli, Martin},
booktitle = {Advances in Neural Information Processing Systems},
issn = {10495258},
language = {en},
pages = {13},
title = {{DeepWave: A recurrent neural-network for real-time acoustic imaging}},
volume = {32},
year = {2019}
}

@InProceedings{Bera2015,
  author    = {Bera, Deep and Bosch, Johan G. and {De Jong}, Nico and Vos, Hendrik J.},
  booktitle = {2015 IEEE International Ultrasonics Symposium, IUS 2015},
  title     = {{Synthetic Aperture Sequential Beamforming for phased array imaging}},
  year      = {2015},
  pages     = {1--4},
  publisher = {IEEE},
  abstract  = {Synthetic Aperture Sequential Beamforming (SASB) is adapted for phased array ultrasound imaging. The primary advantage of using SASB is an improved lateral resolution without storing the raw channel data which can be realized on ultrasound systems with a relatively simple frontend. The performance of the beamforming technique is evaluated with simulations in Field II and by off-line processing of phantom data using a commercial ultrasound scanner. Results show that the lateral resolution improved by 20% in comparison to conventional dynamic receive beamforming.},
  doi       = {10.1109/ULTSYM.2015.0499},
  isbn      = {9781479981823},
  keywords  = {Phased array imaging, Sequential beamforming, Synthetic Aperture},
}

@incollection{Jensen1996a,
abstract = {Pulsed wave ultrasound systems can be used for determining blood's velocity non-invasively in the body. A region of interest is selected, and the received signal is range gated to measure data from the region. One complex sample value is acquired for each pulse emission after complex demodulation of the received signal. The time evolution and distribution of velocity can then be found by using samples from a number of pulse-echo lines. Making a short-time Fourier transform of the data reveals the velocity distribution in the range gate over time.Such systems are called Doppler ultrasound systems implying that they use the classical Doppler effect. The velocity is typically on the order of 0.5 to 1 m/s giving a relative shift of 2 to 4 kHz of the center frequency of the received spectrum for a 3 MHz transducer. Finding such a shift is impossible since the unknown frequency shift from attenuation in tissue can be tens of kilohertz. Some recent reviews and articles state that the Doppler effect is used, and contradictory and wrong results and erroneous system diagrams arise from this assumption. Research done in the last fifteen years has revealed that it is the movement of the scatterers between pulse emissions, that is used for finding the velocity. This finding gives new insight into the role of the complex demodulation stage, and shows that this can be replaced by a matched filter and quadrature RF sampling. A derivation of this result is presented in this paper, and it reveals how the bandwidth of the pulse and the number of pulse emissions affect the result. The final equation for the received signal is quite complicated, and a simplified interpretation is therefore also given. This readily reveals the influence from transducer bandwidth, attenuation, non-linear effects, classical Doppler effect, and scattering.},
author = {Jensen, J{\o}rgen Arendt},
booktitle = {Acoustical Imaging},
doi = {10.1007/978-1-4419-8772-3_61},
pages = {377--384},
title = {{An Analysis of Pulsed Wave Ultrasound Systems for Blood Velocity Estimation}},
url = {http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.41.7592},
volume = {22},
year = {1996}
}

@Article{Gedalyahu2010,
  author        = {Gedalyahu, Kfir and Eldar, Yonina C.},
  journal       = {IEEE Transactions on Signal Processing},
  title         = {{Time-delay estimation from low-rate samples: A union of subspaces approach}},
  year          = {2010},
  issn          = {1053587X},
  number        = {6},
  pages         = {3017--3031},
  volume        = {58},
  abstract      = {Time-delay estimation arises in many applications in which a multipath medium has to be identified from pulses transmitted through the channel. Previous methods for time delay recovery either operate on the analog received signal, or require sampling at the Nyquist rate of the transmitted pulse. In this paper, we develop a unified approach to time delay estimation from low-rate samples. This problem can be formulated in the broader context of sampling over an infinite union of subspaces. Although sampling over unions of subspaces has been receiving growing interest, previous results either focus on unions of finite-dimensional subspaces, or finite unions. The framework we develop here leads to perfect recovery of the multipath delays from samples of the channel output at the lowest possible rate, even in the presence of overlapping transmitted pulses, and allows for a variety of different sampling methods. The sampling rate depends only on the number of multipath components and the transmission rate, but not on the bandwidth of the probing signal. This result can be viewed as a sampling theorem over an infinite union of infinite dimensional subspaces. By properly manipulating the low-rate samples, we show that the time delays can be recovered using the well-known ESPRIT algorithm. Combining results from sampling theory with those obtained in the context of direction of arrival estimation, we develop sufficient conditions on the transmitted pulse and the sampling functions in order to ensure perfect recovery of the channel parameters at the minimal possible rate. {\textcopyright} 2010 IEEE.},
  archiveprefix = {arXiv},
  arxivid       = {0905.2429},
  doi           = {10.1109/TSP.2010.2044253},
  eprint        = {0905.2429},
  keywords      = {Folder - Generic Signal Processing, Sub-Nyquist sampling, Time-delay estimation, Union of subspaces},
  mendeley-tags = {Folder - Generic Signal Processing},
}

@Article{Ingold1912,
  author        = {Ingold, Louis},
  journal       = {Transactions of the American Mathematical Society},
  title         = {{Functional Differential Geometry}},
  year          = {1912},
  issn          = {00029947},
  number        = {3},
  pages         = {319},
  volume        = {13},
  abstract      = {Differential geometry is deceptively simple. It is surprisingly easyto get the right answer with unclear and informal symbol manipulation.To address this problem we use computer programs to communicate aprecise understanding of the computations in differential geometry.Expressing the methods of differential geometry in a computer languageforces them to be unambiguous and computationally effective. The taskof formulating a method as a computer-executable program and debuggingthat program is a powerful exercise in the learning process. Also,once formalized procedurally, a mathematical idea becomes a tool thatcan be used directly to compute results.},
  address       = {Cambridge, MA},
  doi           = {10.2307/1988759},
  isbn          = {978-0-262-01934-7},
  keywords      = {Functional differential equations, Geometry- Differential, Mathematical physics},
  language      = {en},
  mendeley-tags = {Functional differential equations,Geometry- Differential,Mathematical physics},
  publisher     = {The MIT Press},
}

@techreport{David2017,
author = {David, Guillaume},
language = {en},
pages = {218},
title = {{Time-domain Compressive Beamforming for Medical Ultrasound Imaging}},
year = {2017}
}

@article{Gao2019,
abstract = {Better understanding of large-scale brain dynamics with functional magnetic resonance imaging (fMRI) data is a major goal of modern neuroscience. In this work, we propose a novel hierarchical manifold learning framework for time-synchronized fMRI data for elucidating brain dynamics. Our framework—labelled 2-step diffusion maps (2sDM)—is based on diffusion maps, a nonlinear dimensionality reduction method. First, 2sDM learns the manifold of fMRI data for each individual separately and then learns a low-dimensional group-level embedding by integrating individual information. We also propose a method for out-of-sample extension within our hierarchical framework. Using 2sDM, we constructed a single manifold structure based on 6 different task-based fMRI (tfMRI) runs. Results on the tfMRI data show a clear manifold structure with four distinct clusters, or brain states. We extended this to embedding resting-state fMRI (rsfMRI) data by first synchronizing across individuals using an optimal orthogonal transformation. The rsfMRI data from the same individuals cleanly embedded onto the four clusters, suggesting that rsfMRI is a collection of different brains states. Overall, our results highlight 2sDM as a powerful method to understand brain dynamics and show that tfMRI and rsfMRI data share representative brain states.},
author = {Gao, Siyuan and Mishne, Gal and Scheinost, Dustin},
isbn = {978-3-030-20350-4},
issn = {0302-9743},
language = {en},
pages = {631--643},
shorttitle = {Information Processing in Medical Imaging},
title = {{Information Processing in Medical Imaging, 26th International Conference, IPMI 2019, Hong Kong, China, June 2–7, 2019, Proceedings}},
year = {2019}
}

@Misc{KATRUTSA2017,
  author        = {KATRUTSA, ALEXANDR and DAULBAEV, TALGAT and OSELEDETS, IVAN},
  month         = {nov},
  title         = {{Deep multigrid: Learning prolongation and restriction matrices}},
  year          = {2017},
  abstract      = {This paper proposes the method to optimize restriction and prolongation operators in the two-grid method. The proposed method is straightforwardly extended to the geometric multigrid method (GMM). GMM is used in solving discretized partial differential equation (PDE) and based on the restriction and prolongation operators. The operators are crucial for fast convergence of GMM, but they are unknown. To find them we propose a reformulation of the two-grid method in terms of a deep neural network with a specific architecture. This architecture is based on the idea that every operation in the two-grid method can be considered as a layer of a deep neural network. The parameters of layers correspond to the restriction and prolongation operators. Therefore, we state an optimization problem with respect to these operators and get optimal ones through backpropagation approach. To illustrate the performance of the proposed approach, we carry out experiments on the discretized Laplace equation, Helmholtz equation and singularly perturbed convection-diffusion equation and demonstrate that proposed approach gives operators, which lead to faster convergence.},
  archiveprefix = {arXiv},
  arxivid       = {1711.03825},
  booktitle     = {arXiv},
  eprint        = {1711.03825},
  groups        = {Acceleration},
  issn          = {23318422},
  keywords      = {Deep neural network, Geometric multigrid method, Helmholtz equation, Mathematics - Numerical Analysis, Poisson equation, Spectral radius minimization},
  language      = {en},
  mendeley-tags = {Mathematics - Numerical Analysis},
  shorttitle    = {Deep Multigrid},
  url           = {http://arxiv.org/abs/1711.03825},
}

@Article{Jensen2006,
  author        = {Jensen, J{\o}rgen Arendt and Nikolov, Svetoslav Ivanov and Gammelmark, Kim L{\o}kke and Pedersen, Morten H{\o}gholm},
  journal       = {Ultrasonics},
  title         = {{Synthetic aperture ultrasound imaging}},
  year          = {2006},
  issn          = {0041624X},
  number        = {SUPPL.},
  volume        = {44},
  abstract      = {The paper describes the use of synthetic aperture (SA) imaging in medical ultrasound. SA imaging is a radical break with today's commercial systems, where the image is acquired sequentially one image line at a time. This puts a strict limit on the frame rate and the possibility of acquiring a sufficient amount of data for high precision flow estimation. These constrictions can be lifted by employing SA imaging. Here data is acquired simultaneously from all directions over a number of emissions, and the full image can be reconstructed from this data. The paper demonstrates the many benefits of SA imaging. Due to the complete data set, it is possible to have both dynamic transmit and receive focusing to improve contrast and resolution. It is also possible to improve penetration depth by employing codes during ultrasound transmission. Data sets for vector flow imaging can be acquired using short imaging sequences, whereby both the correct velocity magnitude and angle can be estimated. A number of examples of both phantom and in vivo SA images will be presented measured by the experimental ultrasound scanner RASMUS to demonstrate the many benefits of SA imaging. {\textcopyright} 2006 Elsevier B.V. All rights reserved.},
  doi           = {10.1016/j.ultras.2006.07.017},
  keywords      = {Folder - HFR US, Synthetic aperture, Ultrasound imaging, Vector velocity estimation},
  mendeley-tags = {Folder - HFR US,Synthetic aperture,Ultrasound imaging,Vector velocity estimation},
  pmid          = {16959281},
}

@InProceedings{Schiffner2017,
  author        = {Schiffner, Martin and Schmitz, Georg},
  booktitle     = {IEEE International Ultrasonics Symposium, IUS},
  title         = {{Random incident sound waves for fast compressed pulse-echo ultrasound imaging}},
  year          = {2017},
  month         = {dec},
  abstract      = {Multiple research groups have recently innovated image recovery methods for fast pulse-echo ultrasound imaging (UI) that combine inverse scattering techniques with compressed sensing (CS). These methods alleviate the inherent tradeoff between the image quality and the image acquisition rate. The choice of the incident sound field is a crucial degree of freedom to implement the specific requirements of CS, e.g. incoherent measurements. Previous publications exclusively investigated steered plane waves (PWs). In this study, we leverage three types of random ultrasonic waves to better conform with the requirements of CS. This increases both the image quality and the speed of convergence.},
  doi           = {10.1109/ULTSYM.2017.8091509},
  isbn          = {9781538633830},
  issn          = {19485727},
  keywords      = {Folder - Beamforming special, Physics - Medical Physics},
  language      = {en},
  mendeley-tags = {Folder - Beamforming special,Physics - Medical Physics},
  url           = {http://arxiv.org/abs/1801.00205},
}

@Article{Caiafa2013,
  author        = {Caiafa, Cesar F. and Cichocki, Andrzej},
  journal       = {Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery},
  title         = {{Multidimensional compressed sensing and their applications}},
  year          = {2013},
  issn          = {19424787},
  number        = {6},
  pages         = {355--380},
  volume        = {3},
  abstract      = {Compressed sensing (CS) comprises a set of relatively new techniques that exploit the underlying structure of data sets allowing their reconstruction from compressed versions or incomplete information. CS reconstruction algorithms are essentially nonlinear, demanding heavy computation overhead and large storage memory, especially in the case of multidimensional signals. Excellent review papers discussing CS state-of-the-art theory and algorithms already exist in the literature, which mostly consider data sets in vector forms. In this paper, we give an overview of existing techniques with special focus on the treatment of multidimensional signals (tensors). We discuss recent trends that exploit the natural multidimensional structure of signals (tensors) achieving simple and efficient CS algorithms. The Kronecker structure of dictionaries is emphasized and its equivalence to the Tucker tensor decomposition is exploited allowing us to use tensor tools and models for CS. Several examples based on real world multidimensional signals are presented, illustrating common problems in signal processing such as the recovery of signals from compressed measurements for magnetic resonance imaging (MRI) signals or for hyper-spectral imaging, and the tensor completion problem (multidimensional inpainting). WIREs Data Mining Knowl Discov 2013, 3:355-380. doi: 10.1002/widm.1108 Conflict of interest: The authors have declared no conflicts of interest for this article. For further resources related to this article, please visit the WIREs website. {\textcopyright} 2013 John Wiley & Sons, Ltd.},
  doi           = {10.1002/widm.1108},
  keywords      = {Folder - Generic Signal Processing, compressed sensing, mul-, multidimensional signals, sparse representations, tensors, tiway arrays},
  mendeley-tags = {Folder - Generic Signal Processing,compressed sensing,mul-,multidimensional signals,sparse representations,tensors,tiway arrays},
  url           = {http://onlinelibrary.wiley.com/doi/10.1002/widm.1108/full},
}

@article{Asl2010,
abstract = {Recently, adaptive beamforming methods have been successfully applied to medical ultrasound imaging, resulting in significant improvement in image quality compared with non-adaptive delay-and-sum (DAS) beamformers. Most of the adaptive beamformers presented in the ultrasound imaging literature are based on the minimum variance (MV) beamformer which can significantly improve the imaging resolution, although their success in enhancing the contrast has not yet been satisfactory. It is desirable for the beamformer to improve the resolution and contrast at the same time. To this end, in this paper, we have applied the eigenspace-based MV (EIBMV) beamformer to medical ultrasound imaging and have shown a simultaneous improvement in imaging resolution and contrast. EIBMV beamformer utilizes the eigenstructure of the covariance matrix to enhance the performance of the MV beamformer. The weight vector of the EIBMV is found by projecting the MV weight vector onto a vector subspace constructed from the eigenstructure of the covariance matrix. Using EIBMV weights instead of the MV ones leads to reduced sidelobes and improved contrast, without compromising the high resolution of the MV beamformer. In addition, the proposed EIBMV beamformer presents a satisfactory robustness against data misalignment resulting from steering vector errors, outperforming the regularized MV beamformer. {\textcopyright} 2006 IEEE.},
author = {Asl, Babak Mohammadzadeh and Mahloojifar, Ali},
doi = {10.1109/TUFFC.2010.1706},
issn = {08853010},
journal = {IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
keywords = {Folder - Adaptive beamforming},
mendeley-tags = {Folder - Adaptive beamforming},
number = {11},
pages = {2381--2390},
pmid = {21041127},
title = {{Eigenspace-based minimum variance beamforming applied to medical ultrasound imaging}},
volume = {57},
year = {2010}
}

@Misc{Shahdoosti2017,
  author    = {Shahdoosti, Hamid Reza},
  title     = {{Robust non-local means filter for ultrasound image denoising}},
  year      = {2017},
  abstract  = {This paper introduces a new approach to non-local means image denoising. Instead of using all pixels located in the search window for estimating the value of a pixel, we identify the highly corrupted pixels and assign less weight to these pixels. This method is called robust non-local means. Numerical and subjective evaluations using ultrasound images show good performances of the proposed denoising method in recovering the shape of edges and important detailed components, in comparison to traditional ultrasound image denoising methods.},
  booktitle = {arXiv},
  issn      = {23318422},
  keywords  = {Corrupted pixels, Image denoising, Non-local means filter},
  language  = {en},
  pages     = {6},
}

@inproceedings{Wright2009,
abstract = {Principal component analysis is a fundamental operation in computational data analysis, with myriad applications ranging from web search to bioinformatics to computer vision and image analysis. However, its performance and applicability in real scenarios are limited by a lack of robustness to outlying or corrupted observations. This paper considers the idealized "robust principal component analysis" problem of recovering a low rank matrix A from corrupted observations D = A + E. Here, the corrupted entries E are unknown and the errors can be arbitrarily large (modeling grossly corrupted observations common in visual and bioinformatic data), but are assumed to be sparse. We prove that most matrices A can be efficiently and exactly recovered from most error sign-and-support patterns by solving a simple convex program, for which we give a fast and provably convergent algorithm. Our result holds even when the rank of A grows nearly proportionally (up to a logarithmic factor) to the dimensionality of the observation space and the number of errors E grows in proportion to the total number of entries in the matrix. A by-product of our analysis is the first proportional growth results for the related problem of completing a low-rank matrix from a small fraction of its entries. Simulations and real-data examples corroborate the theoretical results, and suggest potential applications in computer vision.},
author = {Wright, John and Peng, Yigang and Ma, Yi and Ganesh, Arvind and Rao, Shankar},
booktitle = {Advances in Neural Information Processing Systems 22 - Proceedings of the 2009 Conference},
isbn = {9781615679119},
language = {en},
pages = {2080--2088},
title = {{Robust principal component analysis: Exact recovery of corrupted low-rank matrices by convex optimization}},
year = {2009}
}

@Article{Vilkomerson2013,
  author        = {Vilkomerson, David and Ricci, Stefano and Tortoli, Piero},
  journal       = {IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
  title         = {{Finding the peak velocity in a flow from its doppler spectrum}},
  year          = {2013},
  issn          = {08853010},
  number        = {10},
  pages         = {2079--2088},
  volume        = {60},
  abstract      = {The signal backscattered by blood cells crossing a sample volume produces a Doppler power spectrum determined by the scatterers¿ velocity distribution. Because of intrinsic spectral broadening, the peak Doppler frequency observed does not correspond to the peak velocity in the flow. Several methods have been proposed for estimating the maximum velocity component-an important clinical parameter-but these methods are approximate, based on heuristic thresholds that can be inaccurate and strongly affected by noise. Reported here is a method of modeling the Doppler power spectrum of a flow, and from that model, determining what Doppler frequency on the descending slope of the power spectrum corresponds to the peak velocity in the insonated flow. It is shown that, for a fully insonated flow with a parabolic velocity distribution, the peak velocity corresponds to the Doppler frequency at the half-power point on that slope. The method is demonstrated to be robust with regard to the effects of noise and valid for a wide range of acquisition parameters. Experimental maximum velocity measurements on steady flows with rates between 100 and 300 mL/min (peak velocity range 6.6 cm/s to 19.9 cm/s) show a mean bias error that is smaller than 1%. {\textcopyright} 2013 IEEE.},
  doi           = {10.1109/TUFFC.2013.2798},
  groups        = {Classical US imaging},
  keywords      = {Folder - 1D Doppler},
  mendeley-tags = {Folder - 1D Doppler},
  pmid          = {24081256},
}

@Article{Tierney2017,
  author        = {Tierney, Jaime and Coolbaugh, Crystal and Towse, Theodore and Byram, Brett},
  journal       = {IEEE Transactions on Medical Imaging},
  title         = {{Adaptive clutter demodulation for non-contrast ultrasound perfusion imaging}},
  year          = {2017},
  issn          = {1558254X},
  number        = {9},
  pages         = {1979--1991},
  volume        = {36},
  abstract      = {Conventional Doppler ultrasound is useful for visualizing fast blood flow in large resolvable vessels. However, frame rate and tissue clutter caused by movement of the patient or sonographer make visualizing slow flow with ultrasound difficult. Patient and sonographer motion causes spectral broadening of the clutter signal, which limits ultrasound's sensitivity to velocities greater than 5-10 mm/s for typical clinical imaging frequencies. To address this, we propose a clutter filtering technique that may increase the sensitivity of Doppler measurements to at least as low as 0.52 mm/s. The proposed technique uses plane wave imaging and an adaptive frequency and amplitude demodulation scheme to decrease the bandwidth of tissue clutter. To test the performance of the adaptive demodulation method at suppressing tissue clutter bandwidths due to sonographer hand motion alone, six volunteer subjects acquired data from a stationary phantom. Additionally, to test in vivo feasibility, arterial occlusion and muscle contraction studies were performed to assess the efficiency of the proposed filter at preserving signals from blood velocities 2 mm/s or greater at a 7.8 MHz center frequency. The hand motion study resulted in initial average bandwidths of 175 Hz (8.60mm/s), which were decreased to 10.5 Hz (0.52 mm/s) at -60 dB using our approach. The in vivo power Doppler studies resulted in 4.73 dB and 4.80 dB dynamic ranges of the blood flow with the proposed filter and 0.15 dB and 0.16 dB dynamic ranges of the blood flow with a conventional 50 Hz high-pass filter for the occlusion and contraction studies, respectively.},
  doi           = {10.1109/TMI.2017.2714901},
  keywords      = {Folder - Adaptive Doppler, Perfusion, blood flow, clutter filter, power Doppler, ultrasound},
  mendeley-tags = {Folder - Adaptive Doppler,Perfusion,blood flow,clutter filter,power Doppler,ultrasound},
  pmid          = {28622670},
}

@Article{Cheung2017,
  author        = {Cheung, Wing Keung and Shah, Benoy N. and Stanziola, Antonio and Gujral, Dorothy M. and Chahal, Navtej S. and Cosgrove, David O. and Senior, Roxy and Tang, Meng Xing},
  journal       = {Ultrasound in Medicine and Biology},
  title         = {{Differential Intensity Projection for Visualisation and Quantification of Plaque Neovascularisation in Contrast-Enhanced Ultrasound Images of Carotid Arteries}},
  year          = {2017},
  issn          = {1879291X},
  number        = {4},
  pages         = {831--837},
  volume        = {43},
  abstract      = {Studies have reported that intraplaque neovascularisation (IPN) is closely correlated with plaque vulnerability. In this study, a new image processing approach, differential intensity projection (DIP), was developed to visualise and quantify IPN in contrast-enhanced non-linear ultrasound image sequences of carotid arteries. DIP used the difference between the local temporal maximum and the local temporal average signals to identify bubbles against tissue non-linear artefact and noise. The total absolute and relative areas occupied by bubbles within each plaque were calculated to quantify IPN. In vitro measurements on a laboratory phantom were made, followed by in vivo measurements in which 24 contrast-enhanced non-linear ultrasound image sequences of carotid arteries from 48 patients were selected and motion corrected. The results using DIP were compared with those obtained by maximum intensity projection (MIP) and visual assessment. The results indicated that DIP can significantly reduce non-linear propagation tissue artefacts and is much more specific in detecting bubble signals than MIP, being able to reveal microbubble signals that are buried in tissue artefacts in the corresponding MIP image. A good correlation was found between microvascular area (MVA) (r = 0.83, p < 0.001)/microvascular density (r = 0.77, p < 0.001) obtained using DIP and the corresponding expert visual grades, comparing favourably to r = 0.26 and 0.23 obtained using MIP on the same data. In conclusion, the proposed method exhibits great potential in quantification of IPN in contrast-enhanced ultrasound images of carotid arteries.},
  doi           = {10.1016/j.ultrasmedbio.2016.11.018},
  keywords      = {Carotid artery, Contrast-enhanced ultrasound, Folder - Contrast agents applications, Intraplaque neovascularisation, Non-linear tissue artefact, Perfusion quantification},
  mendeley-tags = {Carotid artery,Contrast-enhanced ultrasound,Folder - Contrast agents applications,Intraplaque neovascularisation,Non-linear tissue artefact,Perfusion quantification},
  pmid          = {28094067},
}

@Article{Song2017,
  author        = {Song, Pengfei and Manduca, Armando and Trzasko, Joshua D. and Chen, Shigao},
  journal       = {IEEE Transactions on Medical Imaging},
  title         = {{Ultrasound small vessel imaging with block-wise adaptive local clutter filtering}},
  year          = {2017},
  issn          = {1558254X},
  number        = {1},
  pages         = {251--262},
  volume        = {36},
  abstract      = {Robust clutter filtering is essential for ultrasound small vessel imaging. Eigen-based clutter filtering techniques have recently shown great improvement in clutter rejection over conventional clutter filters in small animals. However, for in vivo human imaging, eigen-based clutter filtering can be challenging due to the complex spatially-varying tissue and noise characteristics. To address this challenge, we present a novel block-wise adaptive singular value decomposition (SVD) based clutter filtering technique. The proposed method divides the global plane wave data into overlapped local spatial segments, within which tissue signals are assumed to be locally coherent and noise locally stationary. This, in turn, enables effective separation of tissue, blood and noise via SVD. For each block, the proposed method adaptively determines the singular value cutoff thresholds based on local data statistics. Processing results from each block are redundantly combined to improve both the signal-to-noise-ratio (SNR) and the contrast-to-noise-ratio (CNR) of the small vessel perfusion image. Experimental results show that the proposed method achieved more than two-fold increase in SNR and more than three-fold increase in CNR in dB scale over the conventional global SVD filtering technique for an in vivo human native kidney study. The proposed method also showed substantial improvement in suppression of the depth-dependent background noise and better rejection of near field tissue clutter. The effects of different processing block size and block overlap percentage were systematically investigated as well as the tradeoff between imaging quality and computational cost.},
  doi           = {10.1109/TMI.2016.2605819},
  keywords      = {Clutter filtering, Folder - Adaptive Doppler, plane wave imaging, singular value thresholding, small vessel imaging, ultrasound Dopplre},
  mendeley-tags = {Folder - Adaptive Doppler},
  pmid          = {27608455},
  url           = {http://ieeexplore.ieee.org/document/7559732/},
}

@Article{Evans2011,
  author        = {{D. H. Evans} and {J. A. Jensen} and {M. B. Nielsen}},
  journal       = {Interface Focus},
  title         = {{Ultrasonic colour Doppler imaging}},
  year          = {2011},
  number        = {4},
  pages         = {490--502},
  volume        = {1},
  keywords      = {BVE, Folder - 1D Doppler},
  mendeley-tags = {Folder - 1D Doppler},
}

@Article{Tortoli2010,
  author        = {Tortoli, Piero and Dallai, Alessandro and Boni, Enrico and Francalanci, Lorenzo and Ricci, Stefano},
  journal       = {Ultrasound in Medicine and Biology},
  title         = {{An Automatic Angle Tracking Procedure for Feasible Vector Doppler Blood Velocity Measurements}},
  year          = {2010},
  issn          = {03015629},
  number        = {3},
  pages         = {488--496},
  volume        = {36},
  abstract      = {Two-dimensional angle-independent blood velocity estimates typically combine the Doppler frequencies independently measured by two ultrasound beams with known interbeam angle. A different dual-beam approach was recently introduced in which one (reference) beam is used to identify the flow direction, and the second (measuring) beam directly estimates the true flow velocity at known beam-flow angle. In this paper, we present a procedure to automatically steer the two beams along optimal orientations so that the velocity magnitude can be measured. The operator only takes care of locating the Doppler sample volume in the region of interest and, through the extraction of appropriate parameters from the Doppler spectrum, the reference beam is automatically steered toward right orientation to the flow. The velocity magnitude is thus estimated by the measuring beam, which is automatically oriented with respect to the (known) flow direction at a suitable Doppler angle. The implementation of the new angle tracking method in the ULtrasound Advanced Open Platform (ULA-OP), connected to a linear array transducer, is reported. A series of experiments shows that the proposed method rapidly locks the flow direction and measures the velocity magnitude with low variability for a large range of initial probe orientations. In vitro tests conducted in both steady and pulsatile flow conditions produced coefficients of variability (CV) below 2.3% and 8.3%, respectively. The peak systolic velocities have also been measured in the common carotid arteries of 13 volunteers, with mean CV of 7%. (E-mail: piero.tortoli@unifi.it). {\textcopyright} 2010 World Federation for Ultrasound in Medicine & Biology.},
  doi           = {10.1016/j.ultrasmedbio.2009.11.004},
  keywords      = {Adult, Angle-dependence, Automation, Blood Flow Velocity, Blood velocity measurement, Cardiovascular, Cardiovascular: instrumenta, Carotid Artery, Carotid artery, Common, Common: ultrasonography, Diagnostic Techniques, Doppler, Dual-beam method, Folder - Vector doppler, Humans, Middle Aged, Reference Standards, Reproducibility, Ultrasonography, Ultrasound, Vector Doppler, Young Adult},
  mendeley-tags = {Adult,Automation,Blood Flow Velocity,Cardiovascular,Cardiovascular: instrumenta,Carotid Artery,Common,Common: ultrasonography,Diagnostic Techniques,Doppler,Folder - Vector doppler,Humans,Middle Aged,Reference Standards,Ultrasonography,Young Adult},
  pmid          = {20133036},
  url           = {http://www.ncbi.nlm.nih.gov/pubmed/20133036},
}

@inproceedings{Demi2015,
abstract = {Recently, a new acoustic marker for ultrasound contrast agents (UCAs) has been introduced. A cumulative phase delay (CPD) between the second harmonic and fundamental pressure wave field components is in fact observable for ultrasound propagating through UCAs. This phenomenon is absent in the case of tissue nonlinearity and is dependent on insonating pressure and frequency, UCA concentration, and propagation path length through UCAs. In this paper, ultrasound images based on this marker are presented. The ULA-OP research platform, in combination with a LA332 linear array probe (Esaote, Firenze Italy), were used to image a gelatin phantom containing a PVC plate (used as a reflector) and a cylindrical cavity measuring 7?mm in diameter (placed in between the observation point and the PVC plate). The cavity contained a 240?$\mu$L/L SonoVueO{\textregistered} UCA concentration. Two insonating frequencies (3?MHz and 2.5?MHz) were used to scan the gelatine phantom. A mechanical index MI = 0.07, measured in water at the cavity location with a HGL-0400 hydrophone (Onda, Sunnyvale, CA), was utilized. Processing the ultrasound signals backscattered from the plate, ultrasound images were generated in a tomographic fashion using the filtered back-projection method. As already observed in previous studies, significantly higher CPD values are measured when imaging at a frequency of 2.5?MHz, as compared to imaging at 3?MHz. In conclusion, these results confirm the applicability of the discussed CPD as a marker for contrast imaging. Comparison with standard contrast-enhanced ultrasound imaging modalities will be the focus of future work.},
author = {Demi, Libertario and {Van Sloun}, Ruud J.G. and Wijkstra, Hessel and Mischi, Massimo},
booktitle = {AIP Conference Proceedings},
doi = {10.1063/1.4934407},
isbn = {9780735413320},
issn = {15517616},
keywords = {Folder - Contrast agents detection},
mendeley-tags = {Folder - Contrast agents detection},
pages = {L23},
title = {{Cumulative phase delay imaging - A new contrast enhanced ultrasound modality}},
url = {http://dx.doi.org/10.1088/0031-9155/60/21/L23},
volume = {1685},
year = {2015}
}

@Article{Bjaerum2002,
  author        = {Bj{\ae}rum, Steinar and Torp, Hans and Kristoffersen, Kjell},
  journal       = {IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
  title         = {{Clutter filter design for ultrasound color flow imaging}},
  year          = {2002},
  issn          = {08853010},
  number        = {2},
  pages         = {204--216},
  volume        = {49},
  abstract      = {For ultrasound color flow images with high quality, it is important to suppress the clutter signals originating from stationary and slowly moving tissue sufficiently. Without sufficient clutter rejection, low velocity blood flow cannot be measured, and estimates of higher velocities will have a large bias. The small number of samples available (8 to 16) makes clutter filtering in color flow imaging a challenging problem. In this paper, we review and analyze three classes of filters: finite impulse response (FIR), infinite impulse response (IIR), and regression filters. The quality of the filters was assessed based on the frequency response, as well as on the bias and variance of a mean blood velocity estimator using an autocorrelation technique. For FIR filters, the frequency response was improved by allowing a non-linear phase response. By estimating the mean blood flow velocity from two vectors filtered in the forward and backward direction, respectively, the standard deviation was significantly lower with a minimum phase filter than with a linear phase filter. For IIR filters applied to short signals, the transient part of the output signal is important. We analyzed zero, step, and projection initialization, and found that projection initialization gave the best filters. For regression filters, polynomial basis functions provide effective clutter suppression. The best filters from each of the three classes gave comparable bias and variance of the mean blood velocity estimates. However, polynomial regression filters and projection-initialized IIR filters had a slightly better frequency response than could be obtained with FIR filters.},
  doi           = {10.1109/58.985705},
  keywords      = {Folder - 1D Doppler},
  mendeley-tags = {Folder - 1D Doppler},
  pmid          = {11885678},
}

@Article{Lindner2004,
  author        = {Lindner, Jonathan R.},
  journal       = {Nature Reviews Drug Discovery},
  title         = {{Microbubbles in medical imaging: Current applications and future directions}},
  year          = {2004},
  issn          = {14741776},
  number        = {6},
  pages         = {527--532},
  volume        = {3},
  abstract      = {Not all bubbles in the bloodstream are detrimental. During the past decade, contrast-enhanced ultrasound has evolved from a purely investigational tool to a routine diagnostic technique. This transformation has been facilitated by advances in the microbubble contrast agents and contrast-specific ultrasound imaging techniques. The ability to non-invasively image molecular events with targeted microbubbles is likely to be important for characterizing pathophysiology and for developing new therapeutic strategies in the treatment of cardiovascular and neoplastic diseases.},
  doi           = {10.1038/nrd1417},
  keywords      = {Animals, Diagnostic Imaging, Diagnostic Imaging: methods, Diagnostic Imaging: trends, Folder - Contrast agents applications, Forecasting, Humans, Microbubbles, Microbubbles: trends},
  mendeley-tags = {Animals,Diagnostic Imaging,Diagnostic Imaging: methods,Diagnostic Imaging: trends,Folder - Contrast agents applications,Forecasting,Humans,Microbubbles,Microbubbles: trends},
  pmid          = {15173842},
  url           = {http://dx.doi.org/10.1038/nrd1417},
}

@InProceedings{Ricci2010,
  author        = {Ricci, S. and Guidi, F. and Tortoli, P.},
  booktitle     = {Proceedings - IEEE Ultrasonics Symposium},
  title         = {{Velocity profile detection through adaptive spectral estimators}},
  year          = {2010},
  pages         = {57--60},
  abstract      = {The echoes backscattered from red blood cells moving in a vessel atdifferent depths, can be elaborated to obtain the so-called spectral profile,reporting the distribution of Doppler frequencies along the investigatingM-line. The typical processing is based on power spectral density estimationapplied to the slow-time samples gathered at each depth. The Welch estimator istypically employed, but it features a good spectral resolution only if theobservation window (OW) (i.e. data processed for a single estimate) is composedof at least 64-128 samples. Adaptive spectral estimators capable of producinggood resolution with reduced OWs, have recently been proposed for spectrogramcalculation. In this work we apply Capon and APES adaptive estimator to spectralprofile assessment, obtaining good profiles with short OWs. This result can beexploited for improving the temporal resolution and/or introducing multipleDoppler lines. Two examples are reported: in the first, the blood velocitydistribution during the fast systolic acceleration in carotid artery is detailedwith high temporal resolution; in the second, 4 spectral profiles aresimultaneously detected at different sites of the carotid bifurcation. {\textcopyright}2010 IEEE.},
  doi           = {10.1109/ULTSYM.2010.5935437},
  isbn          = {9781457703829},
  issn          = {10510117},
  keywords      = {APES Estimator, Adaptive Spectral Estimation, Folder - Adaptive Doppler, Minimum Variance Estimator, Spectral Doppler},
  mendeley-tags = {Folder - Adaptive Doppler},
  url           = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5935437},
}

@Article{Leow2015,
  author        = {Leow, Chee Hau and Bazigou, Eleni and Eckersley, Robert J. and Yu, Alfred C.H. and Weinberg, Peter D. and Tang, Meng Xing},
  journal       = {Ultrasound in Medicine and Biology},
  title         = {{Flow velocity mapping using contrast enhanced high-frame-rate plane wave ultrasound and image tracking: Methods and initial in vitro and in vivo evaluation}},
  year          = {2015},
  issn          = {1879291X},
  number        = {11},
  pages         = {2913--2925},
  volume        = {41},
  abstract      = {Ultrasound imaging is the most widely used method for visualising and quantifying blood flow in medical practice, but existing techniques have various limitations in terms of imaging sensitivity, field of view, flow angle dependence, and imaging depth. In this study, we developed an ultrasound imaging velocimetry approach capable of visualising and quantifying dynamic flow, by combining high-frame-rate plane wave ultrasound imaging, microbubble contrast agents, pulse inversion contrast imaging and speckle image tracking algorithms. The system was initially evaluated in vitro on both straight and carotid-mimicking vessels with steady and pulsatile flows and in vivo in the rabbit aorta. Colour and spectral Doppler measurements were also made. Initial flow mapping results were compared with theoretical prediction and reference Doppler measurements and indicate the potential of the new system as a highly sensitive, accurate, angle-independent and full field-of-view velocity mapping tool capable of tracking and quantifying fast and dynamic flows.},
  doi           = {10.1016/j.ultrasmedbio.2015.06.012},
  keywords      = {Atherosclerosis, Echo-particle image velocimetry, Flow, Folder - Contrast agents doppler, Image tracking, Microbubble contrast agents, Ultrafast ultrasound imaging, Ultrasound imaging velocimetry},
  mendeley-tags = {Atherosclerosis,Echo-particle image velocimetry,Flow,Folder - Contrast agents doppler,Image tracking,Microbubble contrast agents,Ultrafast ultrasound imaging,Ultrasound imaging velocimetry},
  pmid          = {26275971},
}

@article{Jayaweera,
abstract = {Ultrasound can cause microbubble destruction. We hypothesized that ultrasound induced microbubble destruction can be used to quantify myocardial blood flow. in viva experiments were performed where microbubbles were delivered as a constant infusion, and ultrasound examination was performed using different pulsing intervals from which microbubble velocity and microvascular cross-sectional area were calculated. The product of the two represents myocardial blood flow. Excellent correlations were found between ultrasound-derived flow and independent parameters of flow. This novel approach has the potential for measuring tissue perhtsion in any organ accessible to ultrasound.},
author = {Jayaweera, R and Kaul, Sanjiv and Wei, Kevin},
keywords = {Folder - Contrast agents detection},
language = {en},
mendeley-tags = {Folder - Contrast agents detection},
number = {8},
pages = {2177--2178},
title = {{Quantification of Myocardial Blood Flow Using Microbubbles}},
volume = {4}
}

@Misc{Toulemonde2018,
  author        = {Toulemonde, Matthieu E.G. and Corbett, Richard and Papadopoulou, Virginie and Chahal, Navtej and Li, Yuanwei and Leow, Chee Hau and Cosgrove, David O. and Eckersley, Robert J. and Duncan, Neill and Senior, Roxy and Tang, Meng Xing},
  title         = {{High Frame-Rate Contrast Echocardiography: In-Human Demonstration}},
  year          = {2018},
  booktitle     = {JACC: Cardiovascular Imaging},
  doi           = {10.1016/j.jcmg.2017.09.011},
  issn          = {18767591},
  keywords      = {Folder - Cardiac, Folder - Contrast agents applications},
  mendeley-tags = {Folder - Cardiac,Folder - Contrast agents applications},
  number        = {6},
  pages         = {923--924},
  pmid          = {29248652},
  url           = {https://doi.org/10.1016/j.jcmg.2017.09.011},
  volume        = {11},
}

@Misc{Porter2010,
  author        = {Porter, Thomas R. and Xie, Feng},
  month         = {feb},
  title         = {{Myocardial Perfusion Imaging With Contrast Ultrasound}},
  year          = {2010},
  abstract      = {This report reviews the development and clinical application of myocardial perfusion imaging with myocardial contrast echocardiography (MCE). This includes the development of microbubble formulations that permit the detection of left ventricular contrast from venous injection and the imaging techniques that have been invented to detect the transit of these microbubbles through the microcirculation. The methods used to quantify myocardial perfusion during a continuous infusion of microbubbles are described. A review of the clinical studies that have examined the clinical utility of myocardial perfusion imaging with MCE during rest and stress echocardiography is then presented. The limitations of MCE are also discussed. {\textcopyright} 2010 American College of Cardiology Foundation.},
  booktitle     = {JACC: Cardiovascular Imaging},
  doi           = {10.1016/j.jcmg.2009.09.024},
  issn          = {1936878X},
  keywords      = {Folder - Contrast agents applications, myocardial contrast echocardiography, ultrasound contrast},
  language      = {en},
  mendeley-tags = {Folder - Contrast agents applications},
  number        = {2},
  pages         = {176--187},
  pmid          = {20159645},
  url           = {http://linkinghub.elsevier.com/retrieve/pii/S1936878X09007943},
  volume        = {3},
}

@Article{TremblayDarveau2014,
  author        = {Tremblay-Darveau, Charles and Williams, Ross and Milot, Laurent and Bruce, Matthew and Burns, Peter N.},
  journal       = {IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
  title         = {{Combined perfusion and doppler imaging using plane-wave nonlinear detection and microbubble contrast agents}},
  year          = {2014},
  issn          = {08853010},
  number        = {12},
  pages         = {1988--2000},
  volume        = {61},
  abstract      = {Plane-wave imaging offers image acquisition rates at the pulse repetition frequency, effectively increasing the imaging frame rates by up to two orders of magnitude over conventional line-by-line imaging. This form of acquisition can be used to achieve very long ensemble lengths in nonlinear modes such as pulse inversion Doppler, which enables new imaging trade-offs that were previously unattainable. We first demonstrate in this paper that the coherence of microbubble signals under repeated exposure to acoustic pulses of low mechanical index can be as high as 204 ± 5 pulses, which is long enough to allow an accurate power Doppler measurement. We then show that external factors, such as tissue acceleration, restrict the detection of perfusion at the capillary level with linear Doppler, even if long Doppler ensembles are considered. Hence, perfusion at the capillary level can only be detected with ultrasound through combined microbubbles and Doppler imaging. Finally, plane-wave contrast-enhanced power and color Doppler are performed on a rabbit kidney in vivo as a proof of principle. We establish that long pulse-inversion Doppler sequences and conventional wall-filters can create an image that simultaneously resolves both the vascular morphology of veins and arteries, and perfusion at the capillary level with frame rates above 100 Hz.},
  doi           = {10.1109/TUFFC.2014.006573},
  keywords      = {Folder - 1D Doppler},
  mendeley-tags = {Folder - 1D Doppler},
  pmid          = {25474775},
}

@Article{Tortoli2001,
  author        = {Tortoli, Piero and Michelassi, Vittorio and Corsi, Massimo and Righi, Daniele and Takeuchi, Yasuhito},
  journal       = {Ultrasound in Medicine and Biology},
  title         = {{On the interaction between ultrasound and contrast agents during Doppler investigations}},
  year          = {2001},
  issn          = {03015629},
  month         = {sep},
  number        = {9},
  pages         = {1265--1273},
  volume        = {27},
  abstract      = {Knowledge of interaction mechanisms between ultrasound (US) and contrast agents (CA) suspended in blood is important for a correct interpretation of clinical investigation results. Experiments performed in different laboratories have shown that, as a consequence of primary radiation force, CA tend to move away from the US transducer. Accordingly, Doppler spectra produced by particles suspended in moving water turn out to be significantly altered from what is theoretically expected. The purpose of this paper is twofold. First, an original model describing the bubble dynamics as the outcome of the balance between US radiation force and fluid drag force is validated for the case in which bubbles are suspended in blood. The high fluid viscosity is shown to prevent significant bubble deviations from the unperturbed fluid streamlines so that, in large vessels, a residual spectral distortion may exist only at the highest intensity levels permitted by current regulations. Finally, the relative importance and differences between the effect of primary radiation force and streaming mechanisms that, in principle, could lead to similar effects, are discussed. Copyright {\textcopyright} 2001 World Federation for Ultrasound in Medicine & Biology.},
  doi           = {10.1016/S0301-5629(01)00426-4},
  keywords      = {Contrast agents, Doppler ultrasound, Folder - Contrast agents doppler, Radiation force, Spectral analysis, Streaming},
  mendeley-tags = {Contrast agents,Doppler ultrasound,Folder - Contrast agents doppler,Radiation force,Spectral analysis,Streaming},
  pmid          = {11597368},
  url           = {http://www.sciencedirect.com/science/article/pii/S0301562901004264},
}

@Article{Couture2009,
  author        = {Couture, Olivier and Bannouf, Souad and Montaldo, Gabriel and Aubry, Jean Fran{\c{c}}ois and Fink, Mathias and Tanter, Mickael},
  journal       = {Ultrasound in Medicine and Biology},
  title         = {{Ultrafast Imaging of Ultrasound Contrast Agents}},
  year          = {2009},
  issn          = {03015629},
  number        = {11},
  pages         = {1908--1916},
  volume        = {35},
  abstract      = {The disappearance of ultrasound contrast agents after disruption can provide useful information on their environment. However, in vivo acoustical imaging of this transient phenomenon, which has a duration on the order of milliseconds, requires high frame rates that are unattainable by conventional ultrasound scanners. In this article, ultrafast imaging is applied to microbubble tracking using a 128-element linear array and an elastography scanner. Contrast agents flowing in a wall-less tissue phantom are insonified with a high-intensity disruption pulse followed by a series of plane waves emitted at a 5 kHz PRF. A collection of compounded images depicting the evolution of microbubbles is obtained after the echoes are beamformed in silico. The backscattering of the microbubbles appears to increase in the first image after disruption (4 ms) and decrease following an exponential decay in the next hundred milliseconds. This microbubble dynamic depends on the length and amplitude of the high-intensity pulse. Furthermore, confined microbubbles are found to differ significantly from their free-flowing counterparts in their dissolution curves. The high temporal resolution provided by ultrafast imaging could help distinguish targeted microbubbles during molecular imaging. (E-mail: olicou@gmail.com). {\textcopyright} 2009 World Federation for Ultrasound in Medicine & Biology.},
  doi           = {10.1016/j.ultrasmedbio.2009.05.020},
  keywords      = {Disruption, Dissolution, Folder - Contrast agents detection, Microbubbles, Molecular imaging, Plane waves, Targeted contrast agents, Ultrafast},
  mendeley-tags = {Disruption,Dissolution,Folder - Contrast agents detection,Microbubbles,Molecular imaging,Plane waves,Targeted contrast agents,Ultrafast},
  pmid          = {19699026},
}

@Article{Ellegala2003,
  author        = {Ellegala, Dilantha B. and Leong-Poi, Howard and Carpenter, Joan E. and Klibanov, Alexander L. and Kaul, Sanjiv and Shaffrey, Mark E. and Sklenar, Jiri and Lindner, Jonathan R.},
  journal       = {Circulation},
  title         = {{Imaging tumor angiogenesis with contrast ultrasound and microbubbles targeted to $\alpha$v$\beta$3}},
  year          = {2003},
  issn          = {00097322},
  number        = {3},
  pages         = {336--341},
  volume        = {108},
  abstract      = {Background - Angiogenesis is a critical determinant of tumor growth and metastasis. We hypothesized that contrast-enhanced ultrasound (CEU) with microbubbles targeted to $\alpha$v-integrins expressed on the neovascular endothelium could be used to image angiogenesis. Methods and Results - Malignant gliomas were produced in 14 athymic rats by intracerebral implantation of U87MG human glioma cells. On day 14 or day 28 after implantation, CEU was performed with microbubbles targeted to $\alpha$v$\beta$3 by surface conjugation of echistatin. CEU perfusion imaging with nontargeted microbubbles was used to derive tumor microvascular blood volume and blood velocity. Vascular $\alpha$v-integrin expression was assessed by immunohistochemistry, and microbubble adhesion was characterized by confocal microscopy. Mean tumor size increased markedly from 14 to 28 days (2 ± 1 versus 35 ± 14 mm2, P < 0.001). Tumor blood volume increased by ≈35% from day 14 to day 28, whereas microvascular blood velocity decreased, especially at the central portions of the tumors. On confocal microscopy, $\alpha$v$\beta$3-targeted but not control microbubbles were retained preferentially within the tumor microcirculation. CEU signal from $\alpha$v$\beta$3-targeted microbubbles in tumors increased significantly from 14 to 28 days (1.7 ± 0.4 versus 3.3 ± 1.0 relative units, P < 0.05). CEU signal from $\alpha$v$\beta$3-targeted microbubbles was greatest at the periphery of tumors, where $\alpha$v-integrin expression was most prominent, and correlated well with tumor microvascular blood volume (r = 0.86). Conclusions - CEU with microbubbles targeted to $\alpha$v$\beta$3 can noninvasively detect early tumor angiogenesis. This technique, when coupled with changes in blood volume and velocity, may provide insights into the biology of tumor angiogenesis and be used for diagnostic applications.},
  doi           = {10.1161/01.CIR.0000080326.15367.0C},
  keywords      = {Angiogenesis, Cancer, Folder - Contrast agents applications, Ultrasound},
  mendeley-tags = {Angiogenesis,Cancer,Folder - Contrast agents applications,Ultrasound},
  pmid          = {12835208},
}

@Article{Tang2010,
  author        = {Tang, Meng Xing and Kamiyama, Naohisa and Eckersley, Robert J.},
  journal       = {Ultrasound in Medicine and Biology},
  title         = {{Effects of Nonlinear Propagation in Ultrasound Contrast Agent Imaging}},
  year          = {2010},
  issn          = {03015629},
  number        = {3},
  pages         = {459--466},
  volume        = {36},
  abstract      = {This paper investigates two types of nonlinear propagation and their effects on image intensity and contrast-to-tissue ratio (CTR) in contrast ultrasound images. Previous studies have shown that nonlinear propagation can occur when ultrasound travels through tissue and microbubble clouds, making tissue farther down the acoustic path appear brighter in pulse inversion (PI) images, thus reducing CTR. In this study, the effect of nonlinear propagation through tissue or microbubbles on PI image intensity and CTR are compared at low mechanical index. A combination of simulation and experiment with SonoVue microbubbles were performed using a microbubble dynamics model, a laboratory ultrasound system and a clinical prototype scanner. The results show that, close to the bubble resonance frequency, nonlinear propagation through a bubble cloud of a few centimeter thickness with a modest concentration (1:10000 dilution of SonoVue microbubbles) is much more significant than through tissue-mimicking material. Consequently, CTR in regions distal to the imaging probe is greatly reduced for nonlinear propagation through the bubble cloud, with as much as a 12-dB reduction compared with nonlinear propagation through tissue-mimicking material. Both types of nonlinear propagation cause only a small change in bubble PI signals at the bubble resonance frequency. When the driving frequency increases beyond bubble resonance, nonlinear propagation through bubbles is greatly reduced in absolute values. However because of a greater reduction in nonlinear scattering from bubbles at higher frequencies, the corresponding CTR is much lower than that at bubble resonance frequency. (E-mail: mengxing.tang@imperial.ac.uk). {\textcopyright} 2010 World Federation for Ultrasound in Medicine & Biology.},
  doi           = {10.1016/j.ultrasmedbio.2009.11.011},
  keywords      = {Contrast Media, Contrast agents, Folder - Contrast agents detection, Imaging, Imaging artefacts, Imaging: trends, Microbubbles, Nonlinear propagation, Perfusion quantification, Phantoms, Ultrasonics},
  mendeley-tags = {Contrast Media,Folder - Contrast agents detection,Imaging,Imaging: trends,Microbubbles,Phantoms,Ultrasonics},
  pmid          = {20133035},
  url           = {http://www.ncbi.nlm.nih.gov/pubmed/20133035},
}

@Article{Hershey2014,
  author        = {Hershey, John R. and Roux, Jonathan Le and Weninger, Felix},
  journal       = {arXiv:1409.2574 [cs, stat]},
  title         = {{Deep Unfolding: Model-Based Inspiration of Novel Deep Architectures}},
  year          = {2014},
  month         = {sep},
  abstract      = {Model-based methods and deep neural networks have both been tremendously successful paradigms in machine learning. In model-based methods, problem domain knowledge can be built into the constraints of the model, typically at the expense of difficulties during inference. In contrast, deterministic deep neural networks are constructed in such a way that inference is straightforward, but their architectures are generic and it is unclear how to incorporate knowledge. This work aims to obtain the advantages of both approaches. To do so, we start with a model-based approach and an associated inference algorithm, and \emph{unfold} the inference iterations as layers in a deep network. Rather than optimizing the original model, we \emph{untie} the model parameters across layers, in order to create a more powerful network. The resulting architecture can be trained discriminatively to perform accurate inference within a fixed network size. We show how this framework allows us to interpret conventional networks as mean-field inference in Markov random fields, and to obtain new architectures by instead using belief propagation as the inference algorithm. We then show its application to a non-negative matrix factorization model that incorporates the problem-domain knowledge that sound sources are additive. Deep unfolding of this model yields a new kind of non-negative deep neural network, that can be trained using a multiplicative backpropagation-style update algorithm. We present speech enhancement experiments showing that our approach is competitive with conventional neural networks despite using far fewer parameters.},
  archiveprefix = {arXiv},
  arxivid       = {1409.2574},
  eprint        = {1409.2574},
  keywords      = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computi, Statistics - Machine Learning},
  language      = {en},
  mendeley-tags = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computi,Statistics - Machine Learning},
  shorttitle    = {Deep Unfolding},
  url           = {http://arxiv.org/abs/1409.2574},
}

@Article{Ekroll2015,
  author        = {Ekroll, Ingvild K. and Voormolen, Marco M. and Standal, Oyvind K.V. and Rau, Jochen M. and Lovstakken, Lasse},
  journal       = {IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
  title         = {{Coherent compounding in doppler imaging}},
  year          = {2015},
  issn          = {08853010},
  month         = {sep},
  number        = {9},
  pages         = {1634--1643},
  volume        = {62},
  abstract      = {Coherent compounding can provide high frame rates and wide regions of interest for imaging of blood flow. However, motion will cause out-of-phase summation, potentially causing image degradation. In this work the impact of blood motion on SNR and the accuracy of Doppler velocity estimates are investigated. A simplified model for the compounded Doppler signal is proposed. The model is used to show that coherent compounding acts as a low-pass filter on the coherent compounding Doppler signal, resulting in negatively biased velocity estimates. Simulations and flow phantom experiments are used to quantify the bias and Doppler SNR for different velocities and beam-to-flow (BTF) angles. It is shown that the bias in the mean velocity increases with increasing beam-to-flow angle and/or blood velocity, whereas the SNR decreases; losses up to 4 dB were observed in the investigated scenarios. Further, a 2-D motion correction scheme is proposed based on multi-angle vector Doppler velocity estimates. For a velocity of 1.1 v<inf>Nyq</inf> and a BTF angle of 75°, the bias was reduced from 30% to less than 4% in simulations. The motion correction scheme was also applied to flow phantom and in vivo recordings, in both cases resulting in a substantially reduced mean velocity bias and an SNR less dependent on blood velocity and direction.},
  doi           = {10.1109/TUFFC.2015.007010},
  keywords      = {Blood, Charge coupled devices, Doppler effect, Folder - 1D Doppler, Frequency estimation, Phantoms, Signal to noise ratio},
  language      = {en},
  mendeley-tags = {Folder - 1D Doppler},
  pmid          = {26415126},
  url           = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7272462},
}

@Article{Luchies2018,
  author   = {Luchies, Adam C. and Byram, Brett C.},
  journal  = {IEEE Transactions on Medical Imaging},
  title    = {{Deep Neural Networks for Ultrasound Beamforming}},
  year     = {2018},
  issn     = {1558254X},
  month    = {sep},
  number   = {9},
  pages    = {2010--2021},
  volume   = {37},
  abstract = {We investigate the use of deep neural networks (DNNs) for suppressing off-axis scattering in ultrasound channel data. Our implementation operates in the frequency domain via the short-time Fourier transform. The inputs to the DNN consisted of the separated real and imaginary components (i.e. in-phase and quadrature components) observed across the aperture of the array, at a single frequency and for a single depth. Different networks were trained for different frequencies. The output had the same structure as the input and the real and imaginary components were combined as complex data before an inverse short-time Fourier transform was used to reconstruct channel data. Using simulation, physical phantom experiment, and in vivo scans from a human liver, we compared this DNN approach to standard delay-and-sum (DAS) beamforming and an adaptive imaging technique that uses the coherence factor. For a simulated point target, the side lobes when using the DNN approach were about 60 dB below those of standard DAS. For a simulated anechoic cyst, the DNN approach improved contrast ratio (CR) and contrast-to-noise (CNR) ratio by 8.8 dB and 0.3 dB, respectively, compared with DAS. For an anechoic cyst in a physical phantom, the DNN approach improved CR and CNR by 17.1 dB and 0.7 dB, respectively. For two in vivo scans, the DNN approach improved CR and CNR by 13.8 dB and 9.7 dB, respectively. We also explored methods for examining how the networks in this paper function.},
  doi      = {10.1109/TMI.2018.2809641},
  keywords = {Ultrasound imaging, beamforming, image contrast enhancement, neural networks, off-axis scattering},
  language = {en},
  pmid     = {29994441},
  url      = {https://ieeexplore.ieee.org/document/8302520/},
}

@Misc{JolicoeurMartineau2018,
  author        = {Jolicoeur-Martineau, Alexia},
  month         = {jul},
  title         = {{The relativistic discriminator: A key element missing from standard GAN}},
  year          = {2018},
  abstract      = {In standard generative adversarial network (SGAN), the discriminator D estimates the probability that the input data is real. The generator G is trained to increase the probability that fake data is real. We argue that it should also simultaneously decrease the probability that real data is real because 1) this would account for a priori knowledge that half of the data in the mini-batch is fake, 2) this would be observed with divergence minimization, and 3) in optimal settings, SGAN would be equivalent to integral probability metric (IPM) GANs. We show that this property can be induced by using a “relativistic discriminator” which estimate the probability that the given real data is more realistic than a randomly sampled fake data. We also present a variant in which the discriminator estimate the probability that the given real data is more realistic than fake data, on average. We generalize both approaches to non-standard GAN loss functions and we refer to them respectively as Relativistic GANs (RGANs) and Relativistic average GANs (RaGANs). We show that IPM-based GANs are a subset of RGANs which use the identity function. Empirically, we observe that 1) RGANs and RaGANs are significantly more stable and generate higher quality data samples than their non-relativistic counterparts, 2) Standard RaGAN with gradient penalty generate data of better quality than WGAN-GP while only requiring a single discriminator update per generator update (reducing the time taken for reaching the state-of-the-art by 400%), and 3) RaGANs are able to generate plausible high resolutions images (256x256) from a very small sample (N=2011), while GAN and LSGAN cannot; these images are of significantly better quality than the ones generated by WGAN-GP and SGAN with spectral normalization.},
  archiveprefix = {arXiv},
  arxivid       = {1807.00734},
  booktitle     = {arXiv},
  eprint        = {1807.00734},
  issn          = {23318422},
  keywords      = {Computer Science - Artificial Intelligence, Computer Science - Cryptography and Security, Computer Science - Machine Learning, Statistics - Machine Learning},
  language      = {en},
  mendeley-tags = {Computer Science - Artificial Intelligence,Computer Science - Cryptography and Security,Computer Science - Machine Learning,Statistics - Machine Learning},
  shorttitle    = {The relativistic discriminator},
  url           = {http://arxiv.org/abs/1807.00734},
}

@inproceedings{Nikolov2000,
abstract = {Previously we have presented a recursive beamforming algorithm for synthetic transmit aperture focusing. At every emission a beamformed low-resolution image is added to an existing high-resolution one, and the low-resolution image from the previous emission with the current active element is subtracted yielding a new frame at every pulse emission. In this paper the method is extended to blood velocity estimation, where a new Color Flow Mapping (CFM) image is created after every pulse emission. The underlying assumption is that the velocity is constant between two pulse emissions and the current estimates can therefore be used for compensation of the motion artifacts in the data acquired in the next emission. Two different transmit strategies are investigated in this paper: (a) using a single defocused active aperture in transmit, and (b) emitting with all active transmit sub-apertures at the same time using orthogonal spatial encoding signals. The method was applied on data recorded by an experimental system. The estimates of the blood velocity for both methods had a bias less than 3% and a standard deviation around 2% making them a feasible approach for blood velocity estimations.},
address = {San Juan, Puerto Rico},
author = {Nikolov, Svetoslav and Gammelmark, Kim and Jensen, J{\o}rgen},
booktitle = {Proceedings of the IEEE Ultrasonics Symposium},
doi = {10.1109/ultsym.2000.921602},
isbn = {978-0-7803-6365-6},
issn = {10510117},
language = {en},
pages = {1473--1477},
publisher = {IEEE},
title = {{Velocity estimation using recursive ultrasound imaging and spatially encoded signals}},
url = {http://ieeexplore.ieee.org/document/921602/},
volume = {2},
year = {2000}
}

@misc{Wang2018a,
abstract = {The Super-Resolution Generative Adversarial Network (SRGAN) [1] is a seminal work that is capable of generating realistic textures during single image super-resolution. However, the hallucinated details are often accompanied with unpleasant artifacts. To further enhance the visual quality, we thoroughly study three key components of SRGAN – network architecture, adversarial loss and perceptual loss, and improve each of them to derive an Enhanced SRGAN (ESRGAN). In particular, we introduce the Residual-in-Residual Dense Block (RRDB) without batch normalization as the basic network building unit. Moreover, we borrow the idea from relativistic GAN [2] to let the discriminator predict relative realness instead of the absolute value. Finally, we improve the perceptual loss by using the features before activation, which could provide stronger supervision for brightness consistency and texture recovery. Benefiting from these improvements, the proposed ESRGAN achieves consistently better visual quality with more realistic and natural textures than SRGAN and won the first place in the PIRM2018-SR Challenge1 [3]. The code is available at https://github.com/xinntao/ESRGAN.},
author = {Wang, Xintao and Yu, Ke and Wu, Shixiang and Gu, Jinjin and Liu, Yihao and Dong, Chao and Loy, Chen Change and Qiao, Yu and Tang, Xiaoou},
booktitle = {arXiv},
issn = {23318422},
keywords = {Computer Science - Computer Vision and Pattern Rec},
language = {en},
mendeley-tags = {Computer Science - Computer Vision and Pattern Rec},
month = {sep},
shorttitle = {ESRGAN},
title = {{ESRGAN: Enhanced super-resolution generative adversarial networks}},
url = {http://arxiv.org/abs/1809.00219},
year = {2018}
}

@inproceedings{Vincent2008,
abstract = {Previous work has shown that the difficulties in learning deep generative or discriminative models can be overcome by an initial unsupervised learning step that maps inputs to useful intermediate representations. We introduce and motivate a new training principle for unsupervised learning of a representation based on the idea of making the learned representations robust to partial corruption of the input pattern. This approach can be used to train autoencoders, and these denoising autoencoders can be stacked to initialize deep architectures. The algorithm can be motivated from a manifold learning and information theoretic perspective or from a generative model perspective. Comparative experiments clearly show the surprising advantage of corrupting the input of autoencoders on a pattern classification benchmark suite. Copyright 2008 by the author(s)/owner(s).},
address = {Helsinki, Finland},
author = {Vincent, Pascal and Larochelle, Hugo and Bengio, Yoshua and Manzagol, Pierre Antoine},
booktitle = {Proceedings of the 25th International Conference on Machine Learning},
doi = {10.1145/1390156.1390294},
isbn = {9781605582054},
language = {en},
pages = {1096--1103},
publisher = {ACM Press},
title = {{Extracting and composing robust features with denoising autoencoders}},
url = {http://portal.acm.org/citation.cfm?doid=1390156.1390294},
year = {2008}
}

@Misc{Garnelo2018,
  author        = {Garnelo, Marta and Schwarz, Jonathan and Rosenbaum, Dan and Viola, Fabio and Rezende, Danilo J. and {Ali Eslami}, S. M. and Teh, Yee Whye},
  month         = {jul},
  title         = {{Neural processes}},
  year          = {2018},
  abstract      = {A neural network (NN) is a parameterised function that can be tuned via gradient descent to approximate a labelled collection of data with high precision. A Gaussian process (GP), on the other hand, is a probabilistic model that defines a distribution over possible functions, and is updated in light of data via the rules of probabilistic inference. GPs are probabilistic, data-efficient and flexible, however they are also computationally intensive and thus limited in their applicability. We introduce a class of neural latent variable models which we call Neural Processes (NPs), combining the best of both worlds. Like GPs, NPs define distributions over functions, are capable of rapid adaptation to new observations, and can estimate the uncertainty in their predictions. Like NNs, NPs are computationally efficient during training and evaluation but also learn to adapt their priors to data. We demonstrate the performance of NPs on a range of learning tasks, including regression and optimisation, and compare and contrast with related models in the literature.},
  archiveprefix = {arXiv},
  arxivid       = {1807.01622},
  booktitle     = {arXiv},
  eprint        = {1807.01622},
  issn          = {23318422},
  keywords      = {Computer Science - Machine Learning, Statistics - Machine Learning},
  language      = {en},
  mendeley-tags = {Computer Science - Machine Learning,Statistics - Machine Learning},
  url           = {http://arxiv.org/abs/1807.01622},
}

@misc{Ito2018,
abstract = {In the present paper, we propose a novel sparse signal recovery algorithm called the Trainable Iterative Soft Thresholding Algorithm (TISTA). The proposed algorithm consists of two estimation units: a linear estimation unit and a minimum mean squared error (MMSE) estimator-based shrinkage unit. The estimated error variance required in the MMSE shrinkage unit is precisely estimated from a tentative estimate of the original signal. The remarkable feature of the proposed scheme is that TISTA includes adjustable variables that control step size and the error variance for the MMSE shrinkage. The variables are adjusted by standard deep learning techniques. The number of trainable variables of TISTA is nearly equal to the number of iteration rounds and is much smaller than that of known learnable sparse signal recovery algorithms. This feature leads to highly stable and fast training processes of TISTA. Computer experiments show that TISTA is applicable to various classes of sensing matrices such as Gaussian matrices, binary matrices, and matrices with large condition numbers. Numerical results also demonstrate that, in many cases, TISTA provides significantly faster convergence than AMP and the Learned ISTA and also outperforms OAMP in the NMSE performance.},
author = {Ito, Daisuke and Takabe, Satoshi and Wadayama, Tadashi},
booktitle = {arXiv},
issn = {23318422},
keywords = {Computer Science - Information Theory},
language = {en},
mendeley-tags = {Computer Science - Information Theory},
month = {jan},
title = {{Trainable ISTA for sparse signal recovery}},
url = {http://arxiv.org/abs/1801.01978},
year = {2018}
}

@misc{Boyd2010,
abstract = {Many problems of recent interest in statistics and machine learning can be posed in the framework of convex optimization. Due to the explosion in size and complexity of modern datasets, it is increasingly important to be able to solve problems with a very large number of features or training examples. As a result, both the decentralized collection or storage of these datasets as well as accompanying distributed solution methods are either necessary or at least highly desirable. In this review, we argue that the alternating direction method of multipliers is well suited to distributed convex optimization, and in particular to large-scale problems arising in statistics, machine learning, and related areas. The method was developed in the 1970s, with roots in the 1950s, and is equivalent or closely related to many other algorithms, such as dual decomposition, the method of multipliers, Douglas-Rachford splitting, Spingarn's method of partial inverses, Dykstra's alternating projections, Bregman iterative algorithms for ℓ1 problems, proximal methods, and thers. After briefly surveying the theory and history of the algorithm, we discuss applications to a wide variety of statistical and machine learning problems of recent interest, including the lasso, sparse logistic regression, basis pursuit, covariance selection, support vector machines, and many others. We also discuss general distributed optimization, extensions to the nonconvex setting, and efficient implementation, including some details on distributed MPI and Hadoop MapReduce implementations. {\textcopyright} 2011 S. Boyd, N. Parikh, E. Chu, B. Peleato and J. Eckstein.},
author = {Boyd, Stephen and Parikh, Neal and Chu, Eric and Peleato, Borja and Eckstein, Jonathan},
booktitle = {Foundations and Trends in Machine Learning},
doi = {10.1561/2200000016},
issn = {19358237},
language = {en},
number = {1},
pages = {1--122},
title = {{Distributed optimization and statistical learning via the alternating direction method of multipliers}},
url = {http://www.nowpublishers.com/article/Details/MAL-016},
volume = {3},
year = {2010}
}

@Article{Huang2019,
  author   = {Huang, Chengwu and Song, Pengfei and Gong, Ping and Trzasko, Joshua D. and Manduca, Armando and Chen, Shigao},
  journal  = {IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
  title    = {{Debiasing-based noise suppression for ultrafast ultrasound microvessel imaging}},
  year     = {2019},
  issn     = {15258955},
  number   = {8},
  pages    = {1281--1291},
  volume   = {66},
  abstract = {Ultrasound microvessel imaging (UMI) based on the combination of singular value decomposition (SVD) clutter filtering and ultrafast plane wave imaging has recently demonstrated significantly improved Doppler sensitivity, especially to small vessels that are invisible to conventional Doppler imaging. Practical implementation of UMI is hindered by the high computational cost associated with SVD and low blood signal-to-noise ratio (SNR) in deep regions of the tissue due to the lack of transmit focusing of plane waves. Concerning the high computational cost, an accelerated SVD clutter filtering method based on randomized SVD (rSVD) and randomized spatial downsampling (rSD) was recently proposed by our group, which showed the feasibility of real-time implementation of UMI. Concerning the low blood flow SNR in deep imaging regions, here we propose a noise suppression method based on noise debiasing that can be easily applied to the accelerated SVD method to bridge the gap between real-time implementation and high imaging quality. The proposed method experimentally measures the noise-induced bias by collecting the noise signal using the identical imaging sequence as regular UMI, but with the ultrasound transmission turned off. The estimated bias can then be subtracted from the original power Doppler (PD) image to obtain effective noise suppression. The feasibility of the proposed method was validated under different ultrasound imaging parameters [including transmitting voltages and time-gain compensation (TGC) settings] with a phantom experiment. The noise-debiased images showed an increase of up to 15.3 and 13.4 dB in SNR as compared to original PD images on the blood flow phantom and an in vivo human kidney data set, respectively. The proposed noise suppression method has negligible computational cost and can be conveniently combined with the previously proposed accelerated SVD clutter filtering technique to achieve high quality, real-time UMI imaging.},
  doi      = {10.1109/TUFFC.2019.2918180},
  keywords = {Noise suppression, power Doppler (PD), singular value decomposition (SVD), ultrafast ultrasound, ultrasound microvessel imaging (UMI)},
  language = {en},
  pmid     = {31135357},
  url      = {https://ieeexplore.ieee.org/document/8720262/},
}

@Misc{Yang2017,
  author        = {Yang, Yan and Sun, Jian and Li, Huibin and Xu, Zongben},
  month         = {jan},
  title         = {{ADMM-net: A deep learning approach for compressive sensing MRI}},
  year          = {2017},
  abstract      = {Compressive sensing (CS) is an effective approach for fast Magnetic Resonance Imaging (MRI). It aims at reconstructing MR images from a small number of under-sampled data in k-space, and accelerating the data acquisition in MRI. To improve the current MRI system in reconstruction accuracy and speed, in this paper, we propose two novel deep architectures, dubbed ADMM-Nets in basic and generalized versions. ADMM-Nets are defined over data flow graphs, which are derived from the iterative procedures in Alternating Direction Method of Multipliers (ADMM) algorithm for optimizing a general CS-based MRI model. They take the sampled k-space data as inputs and output reconstructed MR images. Moreover, we extend our network to cope with complex-valued MR images. In the training phase, all parameters of the nets, e.g., transforms, shrinkage functions, etc., are discriminatively trained end-to-end. In the testing phase, they have computational overhead similar to ADMM algorithm but use optimized parameters learned from the data for CS-based reconstruction task. We investigate different configurations in network structures and conduct extensive experiments on MR image reconstruction under different sampling rates. Due to the combination of the advantages in model-based approach and deep learning approach, the ADMM-Nets achieve state-of-the-art reconstruction accuracies with fast computational speed.},
  archiveprefix = {arXiv},
  arxivid       = {1705.06869},
  booktitle     = {arXiv},
  doi           = {10.1109/TUFFC.2013.2533},
  eprint        = {1705.06869},
  issn          = {23318422},
  keywords      = {ADMM, ADMM-Net, CS-MRI, Deep learning, Discriminative learning, Folder - Contrast agent physics},
  language      = {en},
  mendeley-tags = {Folder - Contrast agent physics},
  number        = {1},
  pages         = {7--20},
  pmid          = {23287909},
  url           = {http://ieeexplore.ieee.org/document/6396482/},
  volume        = {60},
}

@Misc{Chernyakova2018,
  author        = {Chernyakova, Tanya and Cohen, Dan and Shoham, Meged and Eldar, Yonina C.},
  month         = {jun},
  title         = {{iMAP beamforming for high quality high frame rate imaging}},
  year          = {2018},
  abstract      = {We present a statistical interpretation of beamforming to overcome limitations of standard delay-and-sum (DAS) processing. Both the interference and the signal of interest are viewed as random variables and the distribution of the signal of interest is exploited to maximize the a-posteriori distribution of the aperture signals. In this formulation the beamformer output is a maximum-a-posteriori (MAP) estimator of the signal of interest. We provide a closed form expression for the MAP beamformer and estimate the unknown distribution parameters from the available aperture data using an empirical Bayes approach. We propose a simple scheme that iterates between estimation of distribution parameters and computation of the MAP estimator of the signal of interest, leading to an iterative MAP (iMAP) beamformer. This results in a significant improvement of the contrast compared to DAS without severe increase in computational complexity or need for fine-tuning of parameters. By implementing iMAP on both simulated and experimental data, we show that only 13 transmissions are required to obtain contrast comparable to DAS with 75 plane-waves. The proposed method is compared to other interference suppression techniques such as coherence factor and scaled Wiener processing and shows improved contrast and better preserved speckle pattern.},
  booktitle     = {arXiv},
  issn          = {23318422},
  keywords      = {Computer Science - Information Theory, Folder - Beamforming special},
  language      = {en},
  mendeley-tags = {Computer Science - Information Theory,Folder - Beamforming special},
  url           = {http://arxiv.org/abs/1806.03526},
}

@inproceedings{Simpson1997,
abstract = {A novel technique for the selective detection of ultrasound contrast agents, called pulse inversion Doppler, has been developed. In this technique, a conventional Doppler pulse sequence is modified by inverting every second transmit pulse. Either conventional or harmonic Doppler processing is then performed on the received echoes. In the resulting Doppler spectra, Doppler shifts from linear and nonlinear scattering are separated into two distinct regions which can be analyzed separately or combined to estimate the ratio of nonlinear to linear scattering from a region of tissue. The maximum Doppler shift which can be detected is 1/2 the normal Nyquist limit. In vitro measurements comparing flowing agent and cellulose particles suggest that pulse inversion Doppler can provide 3 to 10 dB more agent to tissue contrast than harmonic imaging with similar pulses. Similar measurements suggest that broadband pulse inversion Doppler can provide up to 16 dB more contrast than broadband conventional Doppler.},
author = {Simpson, David Hope and Burns, Peter N.},
booktitle = {Proceedings of the IEEE Ultrasonics Symposium},
doi = {10.1109/ultsym.1997.663301},
issn = {10510117},
pages = {1597--1600},
publisher = {IEEE},
title = {{Pulse inversion Doppler: A new method for detecting nonlinear echoes from microbubble contrast agents}},
volume = {2},
year = {1997}
}

@InProceedings{Lu2006,
  author    = {Lu, Jian Yu and Wang, Jing},
  booktitle = {Proceedings - IEEE Ultrasonics Symposium},
  title     = {{Square-wave aperture weightings for reception beam forming in high frame rate imaging}},
  year      = {2006},
  pages     = {124--127},
  publisher = {IEEE},
  volume    = {1},
  abstract  = {Recently, the high frame rate (HFR) imaging method was extended to include multiple transmission beams such as steered plane waves and limited-diffraction array beams to improve image quality. In addition, limited-diffraction array beam transmissions have been approximated with square-wave aperture weightings so that only one or two transmitters are needed for three-dimensional imaging with a fully populated twodimensional array transducer, simplifying the transmission subsystem of an imager. In this paper, the square-wave aperture weightings are applied to reception beamforming to simplify the limited-diffraction array beam aperture weightings proposed previously, which allows the production of all spatial frequency components of analog echo signals in realtime over a transducer aperture by direct summation and subtraction of these signals for image reconstructions. This approach reduces the need of some high-speed digital circuits and can also be used as a realtime spatial spectrum analyzer to produce both amplitude and phase of the waves impinging on the surface of a receiver with simple electronics as long as the spatial Nyquist sampling criterion is satisfied. Both in vitro (on an ATS539 phantom) and in vivo (on the hearts and a kidney of volunteers) experiments were performed with a broadband phased array transducer of 2.5MHz center frequency, 128 elements, and 0.15mm pitch using a home-made generalpurpose HFR imaging system. A one-cycle, 2.5MHz sine wave pulse was used to excite the transducer with a pulse repetition period of about 187 microseconds. Results show that the quality of images reconstructed with the reception square-wave aperture weightings is very close to that of images reconstructed with the exact limited-diffraction array beam weightings or spatial Fourier transform on echo signals. The images reconstructed have over +/-45 degree field of view and an image frame rate of about 486/s is achieved for a depth of 120 mm.},
  doi       = {10.1109/ULTSYM.2006.44},
  isbn      = {1424402018},
  issn      = {10510117},
  keywords  = {Beamforming, HFR, High frame rate, Limited diffraction beams, Medical imaging, Spatial spectrum analyzer, Square-wave aperture weighting},
}

@Misc{Weinan2018,
  author        = {Weinan, E. and Han, Jiequn and Li, Qianxiao},
  month         = {jul},
  title         = {{A mean-field optimal control formulation of deep learning}},
  year          = {2018},
  abstract      = {Recent work linking deep neural networks and dynamical systems opened up new avenues to analyze deep learning. In particular, it is observed that new insights can be obtained by recasting deep learning as an optimal control problem on difference or differential equations. However, the mathematical aspects of such a formulation have not been systematically explored. This paper introduces the mathematical formulation of the population risk minimization problem in deep learning as a mean-field optimal control problem. Mirroring the development of classical optimal control, we state and prove optimality conditions of both the Hamilton-Jacobi-Bellman type and the Pontryagin type. These mean-field results reflect the probabilistic nature of the learning problem. In addition, by appealing to the mean-field Pontryagin's maximum principle, we establish some quantitative relationships between population and empirical learning problems. This serves to establish a mathematical foundation for investigating the algorithmic and theoretical connections between optimal control and deep learning.},
  booktitle     = {arXiv},
  issn          = {23318422},
  keywords      = {Computer Science - Machine Learning, Mathematics - Optimization and Control},
  language      = {en},
  mendeley-tags = {Computer Science - Machine Learning,Mathematics - Optimization and Control},
  url           = {http://arxiv.org/abs/1807.01083},
}

@InProceedings{Calliada1998,
  author        = {Calliada, Fabrizio and Campani, Rodolfo and Bottinelli, Olivia and Bozzini, Anna and Sommaruga, Maria Grazia},
  booktitle     = {European Journal of Radiology},
  title         = {{Ultrasound contrast agents: Basic principles}},
  year          = {1998},
  number        = {SUPPL. 2},
  pages         = {157--160},
  volume        = {27},
  abstract      = {Introduction. Ultrasonography lacked substances to be administered to patients to improve or increase the diagnostic yield, which is peculiar considering that contrast agents have long been used with all the other imaging techniques. Fortunately some contrast agents, most of them consisting in gas microbubbles, have been recently introduced for ultrasound imaging too: this review will focus on their history, behavior, current applications and future developments. Echocontrast agent research is in progress and many new agents are expected to be marketed this and next year, to be added to Leovist(TM) by Schering AG (Berlin, Germany), to enhance the ultrasound signal safely and effectively. No definitive conclusions can be drawn yet on the actual merits of each contrast agent, but all of them seem to be both effective and safe, meaning that their future success will depend on the relative cost-effectiveness and peculiarities. The basic principles of echocontrast agents. The microbubbles act as echo-enhancers by basically the same mechanism as that determining echo-scattering in all the other cases of diagnostic ultrasound, namely that the backscattering echo intensity is proportional to the change in acoustic impedance between the blood and the gas making the bubbles. The different acoustic impedance at this interface is very high and in fact all of the incident sound is reflected, even though not all of it will of course go back to the transducer. But the acoustic wave reflection, though nearly complete, would not be sufficient to determine a strong US enhancement because the microbubbles are very small and are sparse in the circulation. Moreover, reflectivity is proportional to the fourth power of a particle diameter but also directly proportional to the concentration of the particles themselves. Second harmonic imaging. As we said above, the microbubbles reached by an ultrasound signal resonate with a specific frequency depeding on microbubble diameter. However, the main resonance frequency is not the only resonance frequency of the bubble itself and multiple frequencies of the fundamental one are emitted, just like in a musical instrument. These harmonic frequencies have decreasing intensity, but the second frequency, known as the second harmonic, is still strong enough to be used for diagnostic purposes. The theoretical advantage of the harmonic over the fundamental frequency is that only contrast agent microbubbles resonate with harmonic frequencies, while adjacent tissues do not resonate, or else their harmonic resonation is very little. Thus, using a unit especially set to produce ultrasounds at a given frequency (3.5 MHz) and receive an ultrasound signal twice as powerful (7 MHz) it will be possible to show the contrast agent only, without any artifact from the surrounding anatomical structures, with a markedly improved signal-to-noise ratio. A similar effect to digital subtraction in angiography can thus be obtained, even though through a totally different process. Moreover, second harmonic imaging permits to show extremely small vessels (down to 40 $\mu$m) with very slow flow, which would be missed with a conventional method. B-mode imaging can also depict the microbubbles in the myocardium suppressing nearly all the artifacts from cardiac muscle motion. Recently a peculiar behavior of microbubbles has been observed which may permit contrast agent detection even in capillaries. This method is variously known as sonoscintigraphy, loss of correlation, stimulated acoustic emission and transient scattering. The contrast agent microbubbles reached by an ultrasound beam powerful enough explode producing a strong and very short backscatter echo which is read by the unit as a Doppler signal and results in a color pixel where the individual microbubble exploded. Conclusions. The microbubble contrast agents developed and introduced as safe and effective echo-enhancers in present-day clinical practice will open up new oppurtunities and result in an amazing revolution of ultrasonography as we know it now.},
  doi           = {10.1016/S0720-048X(98)00057-6},
  issn          = {0720048X},
  keywords      = {Folder - Contrast agent physics, Hand-made agents, Microbubbles, Ultrasound},
  mendeley-tags = {Folder - Contrast agent physics,Hand-made agents,Microbubbles,Ultrasound},
  pmid          = {9652516},
}

@Misc{Khan2019a,
  author        = {Khan, Shujaat and Huh, Jaeyoung and Ye, Jong Chul},
  month         = {apr},
  title         = {{Deep learning-based universal beamformer for ultrasound imaging}},
  year          = {2019},
  abstract      = {In ultrasound (US) imaging, individual channel RF measurements are back-propagated and accumulated to form an image after applying specific delays. While this time reversal is usually implemented using a hardware- or software-based delay-and-sum (DAS) beamformer, the performance of DAS decreases rapidly in situations where data acquisition is not ideal. Herein, for the first time, we demonstrate that a single data-driven adaptive beamformer designed as a deep neural network can generate high quality images robustly for various detector channel configurations and subsampling rates. The proposed deep beamformer is evaluated for two distinct acquisition schemes: focused ultrasound imaging and planewave imaging. Experimental results showed that the proposed deep beamformer exhibit significant performance gain for both focused and planar imaging schemes, in terms of contrast-to-noise ratio and structural similarity.},
  booktitle     = {arXiv},
  issn          = {23318422},
  keywords      = {Adaptive beamforming, Computer Science - Computer Vision and Pattern Rec, Computer Science - Machine Learning, Deep neural network, Electrical Engineering and Systems Science - Image, Statistics - Machine Learning, Ultrasound},
  language      = {en},
  mendeley-tags = {Computer Science - Computer Vision and Pattern Rec,Computer Science - Machine Learning,Electrical Engineering and Systems Science - Image,Statistics - Machine Learning},
  url           = {http://arxiv.org/abs/1904.02843},
}

@Article{Alberti2017,
  author        = {Alberti, Giovanni S. and Ammari, Habib and Romero, Francisco and Wintz, Timoth{\'{e}}e},
  journal       = {SIAM Journal on Applied Mathematics},
  title         = {{Mathematical analysis of ultrafast ultrasound imaging}},
  year          = {2017},
  issn          = {00361399},
  number        = {1},
  pages         = {1--25},
  volume        = {77},
  abstract      = {This paper provides a mathematical analysis of ultrafast ultrasound imaging. This newly emerging modality for biomedical imaging uses plane waves instead of focused waves in order to achieve very high frame rates. We derive the point spread function of the system in the Born approximation for wave propagation and study its properties. We consider dynamic data for blood ow imaging, and introduce a suitable random model for blood cells. We show that a singular value decomposition method can successfully remove the clutter signal by using the different spatial coherences of tissue and blood signals, thereby providing high-resolution images of blood vessels, even in cases when the clutter and blood speeds are comparable in magnitude. Several numerical simulations are presented to illustrate and validate the approach.},
  archiveprefix = {arXiv},
  arxivid       = {1604.04604},
  doi           = {10.1137/16M107102X},
  eprint        = {1604.04604},
  keywords      = {Blood ow imaging, Casorati matrix, Folder - HFR US, Singular value decomposition, Ultrafast ultrasound imaging, blood, casorati matrix, singular value decomposition, ultrafast ultrasound imaging},
  mendeley-tags = {Folder - HFR US,blood,casorati matrix,singular value decomposition,ultrafast ultrasound imaging},
  url           = {http://arxiv.org/abs/1604.04604},
}

@Misc{Lu2017,
  author        = {Lu, Yiping and Zhong, Aoxiao and Li, Quanzheng and Dong, Bin},
  month         = {mar},
  title         = {{Beyond finite layer neural networks: Bridging deep architectures and numerical differential equations}},
  year          = {2017},
  abstract      = {Deep neural networks have become the state-of-the-art models in numerous machine learning tasks. However, general guidance to network architecture design is still missing. In our work, we bridge deep neural network design with numerical differential equations. We show that many effective networks, such as ResNet, PolyNet, FractalNet and RevNet, can be interpreted as different numerical discretizations of differential equations. This finding brings us a brand new perspective on the design of effective deep architectures. We can take advantage of the rich knowledge in numerical analysis to guide us in designing new and potentially more effective deep networks. As an example, we propose a linear multi-step architecture (LM-architecture) which is inspired by the linear multistep method solving ordinary differential equations. The LM-architecture is an effective structure that can be used on any ResNet-like networks. In particular, we demonstrate that LM-ResNet and LM-ResNeXt (i.e. the networks obtained by applying the LM-architecture on ResNet and ResNeXt respectively) can achieve noticeably higher accuracy than ResNet and ResNeXt on both CIFAR and ImageNet with comparable numbers of trainable parameters. In particular, on both CIFAR and ImageNet, LM-ResNet/LM-ResNeXt can significantly compress (> 50%) the original networks while maintaining a similar performance. This can be explained mathematically using the concept of modified equation from numerical analysis. Last but not least, we also establish a connection between stochastic control and noise injection in the training process which helps to improve generalization of the networks. Furthermore, by relating stochastic training strategy with stochastic dynamic system, we can easily apply stochastic training to the networks with the LM-architecture. As an example, we introduced stochastic depth to LM-ResNet and achieve significant improvement over the original LM-ResNet on CIFAR10.},
  booktitle     = {arXiv},
  issn          = {23318422},
  keywords      = {Computer Science - Computer Vision and Pattern Rec, Computer Science - Machine Learning, Statistics - Machine Learning},
  language      = {en},
  mendeley-tags = {Computer Science - Computer Vision and Pattern Rec,Computer Science - Machine Learning,Statistics - Machine Learning},
  shorttitle    = {Beyond Finite Layer Neural Networks},
  url           = {http://arxiv.org/abs/1710.10121},
}

@incollection{Oosterlee2010,
abstract = {We present an iterative solution method for the discrete high wavenumber Helmholtz equation. The basic idea of the solution method, already presented in [18], is to develop a preconditioner which is based on a Helmholtz operator with a complex-valued shift, for a Krylov subspace iterative method. The preconditioner, which can be seen as a strongly damped wave equation in Fourier space, can be approximately inverted by a multigrid method.},
address = {Berlin, Heidelberg},
author = {Oosterlee, C. W. and Vuik, C. and Mulder, W. A. and Plessix, R. E.},
booktitle = {Lecture Notes in Computational Science and Engineering},
doi = {10.1007/978-3-642-03344-5_2},
isbn = {978-3-642-03343-8 978-3-642-03344-5},
issn = {14397358},
language = {en},
pages = {21--46},
publisher = {Springer Berlin Heidelberg},
title = {{Shifted-laplacian preconditioners for heterogeneous Helmholtz problems}},
url = {http://link.springer.com/10.1007/978-3-642-03344-5_2},
volume = {71},
year = {2010}
}

@Article{Groenvold2008,
  author        = {Gr{\o}nvold, Lars},
  journal       = {Norweigan University of Science and Technology},
  title         = {{Implementing Ultrasound Beamforming on the GPU using CUDA}},
  year          = {2008},
  number        = {May},
  pages         = {74},
  abstract      = {This thesis discusses the implementation of ultrasound beamforming on the GPU using CUDA. Fractional delay filters and the need for it when implement- ing beamforming is discussed. An introduction to CUDA programming is given as well as a study of the workings of the NVIDIA Tesla GPU(or G80). A number of suggestions for implementing beamforming on a GPU is presented as well as an actual implementation and an evaluation of it's performance.},
  keywords      = {Master's Thesis, NTNU},
  mendeley-tags = {Master's Thesis,NTNU},
}

@article{Asl2012,
abstract = {In recent years, adaptive beamforming methods have been successfully applied to medical ultrasound imaging, resulting in simultaneous improvement in imaging resolution and contrast. These improvements have been achieved at the expense of higher computational complexity, with respect to the conventional non-adaptive delay-and-sum (DAS) beamformer, in which computational complexity is proportional to the number of elements, O(M). The computational overhead results from the covariance matrix inversion needed for computation of the adaptive weights, the complexity of which is cubic with the subarray size, O(L 3). This is a computationally intensive procedure, which makes the implementation of adaptive beamformers less attractive in spite of their advantages. Considering that, in medical ultrasound applications, most of the energy is scattered from angles close to the steering angle, assuming spatial stationarity is a good approximation, allowing us to assume the Toeplitz structure for the estimated covariance matrix. Based on this idea, in this paper, we have applied the Toeplitz structure to the spatially smoothed covariance matrix by averaging the entries along all subdiagonals. Because the inverse of the resulting Toeplitz covariance matrix can be computed in O(L 2) operations, this technique results in a greatly reduced computational complexity. By using simulated and experimental RF datapoint targets as well as cyst phantomswe show that the proposed low-complexity adaptive beamformer significantly outperforms the DAS and its performance is comparable to that of the minimum variance beamformer, with reduced computational complexity. {\textcopyright} 2012 IEEE.},
author = {Asl, Babak Mohammadzadeh and Mahloojifar, Ali},
doi = {10.1109/TUFFC.2012.2244},
issn = {08853010},
journal = {IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
language = {en},
month = {apr},
number = {4},
pages = {660--667},
pmid = {22547277},
title = {{A low-complexity adaptive beamformer for ultrasound imaging using structured covariance matrix}},
url = {http://ieeexplore.ieee.org/document/6189173/},
volume = {59},
year = {2012}
}

@article{Anderson2000,
author = {Anderson, Martin E. and Trahey, Gregg E.},
journal = {Lecture notes},
keywords = {Folder - Classical beamforming},
mendeley-tags = {Folder - Classical beamforming},
pages = {63},
title = {{A seminar on k-space applied to medical ultrasound}},
year = {2000}
}

@Article{Ponnle2013,
  author   = {Ponnle, Akinlolu and Hasegawa, Hideyuki and Kanai, Hiroshi},
  journal  = {Ultrasound in Medicine and Biology},
  title    = {{Suppression of Grating Lobe Artifacts in Ultrasound Images Formed from Diverging Transmitting Beams by Modulation of Receiving Beams}},
  year     = {2013},
  issn     = {1879291X},
  month    = {apr},
  number   = {4},
  pages    = {681--691},
  volume   = {39},
  abstract = {In linear array transducers, owing to regular spacing of the array elements, grating lobes exist in transmission and reception. In ultrasonic imaging involving the use of diverging (unfocused) transmitting beams and steered receiving beams by linear transducer arrays, aperture apodization and spatial combination of steered receiving beams from multiple transmissions are not sufficient to suppress receive-grating lobe artifacts. To further suppress receive-grating lobe artifacts in reconstructed B-mode images, we propose a technique of modulating the receiving beams by a factor that is governed by the envelope of a corresponding signal, which is formed by filtering the receiving beam with a zero-phase low-pass filter with a cut-off frequency that is determined by the receiving beam steering angle. This technique suppressed receive-grating lobe artifacts without significant loss in spatial resolution in offline reconstructed B-mode images from simulation, phantom and in vivo imaging of the carotid artery. In a simulation of point scatterers, a relative reduction in grating lobe artifacts of 40 dB was realized in images from diverging beam scanning. {\textcopyright} 2013 World Federation for Ultrasound in Medicine & Biology.},
  doi      = {10.1016/j.ultrasmedbio.2012.10.019},
  groups   = {Classical US imaging},
  keywords = {Bidirectional filtering, Diverging transmitting beam, Modulated receiving beam, Receive-grating lobe, Zero-phase low-pass filter},
  language = {en},
  pmid     = {23415288},
  url      = {https://linkinghub.elsevier.com/retrieve/pii/S0301562912006680},
}

@Article{Wagner1983,
  author     = {Wagner, Robert F. and Smith, Stephen W. and Sandrik, John M. and Lopez, Hector},
  journal    = {IEEE Transactions on Sonics and Ultrasonics},
  title      = {{Statistics of Speckle in Ultrasound B-Scans}},
  year       = {1983},
  issn       = {00189537},
  number     = {3},
  pages      = {156--163},
  volume     = {30},
  abstract   = {In the ultrasound imaging process, the complex summation at the transducer face is assumed to be linear. The envelope detection process in B-scanning is a nonlinear step which yields essentially the magnitude of the complex field or voltage. (A square law detector, as in the analogous laser case, yields the square of the magnitude, i.e., the intensity, of the field.) It is shown that Rayleigh statistics govern the first-order behavior of the magnitude; and the autocorrelation of the resulting image speckle is obtained by the method of Middleton. The corresponding power spectrum follows immediately by Fourier transformation. Theoretical and experimentally determined autocorrelation functions and power spectra derived from B-scans of a scattering phantom containing many scatterers per resolution cell are presented. These functions lead naturally to the definition of the average speckle spot or cell size, and this in turn is comparable to the resolution cell. Each independent speckle serves as a degree of freedom that determines the number of samples of tissue available over a target. As the speckle cell size decreases this number increases in a manner predictable from the physical parameters of the cell size. However, it is found that the speckle cell is broadened, the degrees of freedom diminished, when the object structure is correlated. This yields the possibility of deducing information about the object structure from the second-order statistics of the speckle texture, in addition to that obtainable from the first-order statistics. Copyright {\textcopyright} 1983 by The Institute of Electrical and Electronics Engineers, Inc.},
  doi        = {10.1109/T-SU.1983.31404},
  readstatus = {read},
}

@Article{Lu1997,
  author        = {Lu, Jian Yu},
  journal       = {International Journal of Imaging Systems and Technology},
  title         = {{Limited diffraction array beams}},
  year          = {1997},
  issn          = {08999457},
  number        = {1},
  pages         = {126--136},
  volume        = {8},
  abstract      = {Limited diffraction beams have a large depth of field and could have many applications. In this article, new limited diffraction beams are developed. They are composed of multiple parallel beams and are thus called array beams. A broadband synthetic array experiment is used to produce these beams of a finite aperture, and results are in excellent agreement with theory over a large depth of field. In addition, potential applications of the new beams to real-time volumetric imaging and measurement of transverse velocity of blood flow are described. {\textcopyright} 1997 John Wiley & Sons, Inc.},
  doi           = {10.1002/(SICI)1098-1098(1997)8:1<126::AID-IMA14>3.0.CO;2-0},
  keywords      = {Bessel beams, Folder - HFR US, Limited diffraction beams, Real-time 2D and 3D imaging, Transverse Doppler effects, X waves},
  mendeley-tags = {Bessel beams,Folder - HFR US,Limited diffraction beams,Real-time 2D and 3D imaging,Transverse Doppler effects,X waves},
}

@InProceedings{Liu2015,
  author        = {Liu, Jing and He, Qiong and Luo, Jianwen},
  booktitle     = {2015 IEEE International Ultrasonics Symposium, IUS 2015},
  title         = {{Compressed sensing for synthetic transmit aperture}},
  year          = {2015},
  pages         = {1--4},
  publisher     = {IEEE},
  abstract      = {In this paper, the previously proposed compressed sensing based synthetic transmit aperture (CS-STA) was compared with synthetic transmit aperture (STA), multi-element synthetic transmit aperture (ME-STA) and the conventional focused mode in two different phantoms. The quantitative results of full width at half-maximum (FWHM) and contrast-to-noise ratio (CNR) demonstrated the merits of CS-STA. Besides, the results from two different phantoms verified the reproducibility of CS-STA. Moreover, the clinical potentials of CS-STA were presented through preliminary in-vivo studies on human bicipital muscle of arm and thyroid. At last, CS-STA is demonstrated to exhibit certain advantages through the comparison with coherent plane wave (CPW) compounding method.},
  doi           = {10.1109/ULTSYM.2015.0308},
  isbn          = {9781479981823},
  keywords      = {Folder - Beamforming special, compressed sensing, contrast, frame rate, resolution, synthetic transmit aperture},
  mendeley-tags = {Folder - Beamforming special},
}

@article{Tu2009,
abstract = {Experiments were performed to measure the dynamical response of individual SonoVue microbubbles subjected to pulsed ultrasound. Three commonly used bubble dynamic models (i.e., Hoff's, Sarkar's, and linearized Marmottant's models) were compared to determine the most appropriate model for fitting to the experimental data. The models were evaluated against published optical microscopy data. The comparison suggests that it is difficult to rank these models for lipid-shelled microbubbles undergoing small-amplitude oscillations, because under these conditions the shell parameters in these models are closely related. A linearized version of the Marmottant model was used to estimate the shell parameters (i.e., shear modulus and shear viscosity) of SonoVue microbubbles from the experimental light scattering data, as a function of ambient microbubble radius. The SonoVue microbubble shell elasticity and dilatational viscosity increase with ambient bubble radius, in agreement with previously published data. The results suggest that light scattering, used in conjunction with one of several popular bubble dynamics models, is effective at characterizing microbubble response and evaluating shell parameters.},
author = {Tu, Juan and Guan, Jingfeng and Qiu, Yuanyuan and Matula, Thomas J.},
doi = {10.1121/1.3242346},
issn = {0001-4966},
journal = {The Journal of the Acoustical Society of America},
keywords = {Folder - Contrast agent physics},
mendeley-tags = {Folder - Contrast agent physics},
number = {6},
pages = {2954--2962},
pmid = {20000908},
title = {{Estimating the shell parameters of SonoVue {\textregistered} microbubbles using light scattering}},
volume = {126},
year = {2009}
}

@InProceedings{Shin2013,
  author        = {Shin, Junseob and Yen, Jesse T.},
  booktitle     = {IEEE International Ultrasonics Symposium, IUS},
  title         = {{Clutter suppression using Phase Apodization with Cross-correlation in ultrasound imaging}},
  year          = {2013},
  pages         = {793--796},
  abstract      = {Dual Apodization with Cross-correlation (DAX) is a novel adaptive beamforming technique that utilizes two distinct receive apodizations in suppressing clutter to enhance ultrasound image contrast. Previous studies have shown that its performance in terms of contrast enhancement diminishes with increasing level of phase aberration and has a tendency to create image artifacts. In this work, we propose a modified version of DAX, known as Phase Apodization with Cross-correlation (PAX), which utilizes sinusoidal phase apodization to further enhance image quality. Our preliminary simulation and experimental results presented in this work showed that PAX performs in a more robust manner than DAX, especially with increased level of phase aberration, to further improve image contrast and reduce image artifacts. {\textcopyright} 2013 IEEE.},
  doi           = {10.1109/ULTSYM.2013.0204},
  groups        = {Classical US imaging},
  isbn          = {9781467356862},
  issn          = {19485719},
  keywords      = {Beamforming, Clutter suppression, Contrast enhancement, Dual apodiztion, Folder - Correlation approaches, Phase apodization, Phase grating},
  mendeley-tags = {Beamforming,Clutter suppression,Contrast enhancement,Dual apodiztion,Folder - Correlation approaches,Phase apodization,Phase grating},
}

@Article{Lin2017,
  author        = {Lin, Henry W. and Tegmark, Max and Rolnick, David},
  journal       = {Journal of Statistical Physics},
  title         = {{Why Does Deep and Cheap Learning Work So Well?}},
  year          = {2017},
  issn          = {00224715},
  month         = {sep},
  number        = {6},
  pages         = {1223--1247},
  volume        = {168},
  abstract      = {We show how the success of deep learning could depend not only on mathematics but also on physics: although well-known mathematical theorems guarantee that neural networks can approximate arbitrary functions well, the class of functions of practical interest can frequently be approximated through “cheap learning” with exponentially fewer parameters than generic ones. We explore how properties frequently encountered in physics such as symmetry, locality, compositionality, and polynomial log-probability translate into exceptionally simple neural networks. We further argue that when the statistical process generating the data is of a certain hierarchical form prevalent in physics and machine learning, a deep neural network can be more efficient than a shallow one. We formalize these claims using information theory and discuss the relation to the renormalization group. We prove various “no-flattening theorems” showing when efficient linear deep networks cannot be accurately approximated by shallow ones without efficiency loss; for example, we show that n variables cannot be multiplied using fewer than 2 n neurons in a single hidden layer.},
  archiveprefix = {arXiv},
  arxivid       = {1608.08225},
  doi           = {10.1007/s10955-017-1836-5},
  eprint        = {1608.08225},
  keywords      = {Artificial neural networks, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computi, Condensed Matter - Disordered Systems and Neural N, Deep learning, Statistical physics, Statistics - Machine Learning},
  language      = {en},
  mendeley-tags = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computi,Condensed Matter - Disordered Systems and Neural N,Statistics - Machine Learning},
  url           = {http://arxiv.org/abs/1608.08225},
}

@inproceedings{Tong1990,
abstract = {The mathematical formulation of the blind identification problem is presented. Various theoretical properties are discussed. The AMUSE algorithm is derived on the basis of the necessary condition of source identifiability and shown to have good performance and wide application.},
author = {Tong, L. and Soon, V. C. and Huang, Y. F. and Liu, R.},
booktitle = {Proceedings - IEEE International Symposium on Circuits and Systems},
doi = {10.1109/iscas.1990.111981},
issn = {02714310},
pages = {1784--1787},
publisher = {IEEE},
title = {{AMUSE: A new blind identification algorithm}},
volume = {3},
year = {1990}
}

@misc{Du2019,
abstract = {Energy based models (EBMs) are appealing due to their generality and simplicity in likelihood modeling, but have been traditionally difficult to train. We present techniques to scale MCMC based EBM training on continuous neural networks, and we show its success on the high-dimensional data domains of ImageNet32x32, ImageNet128x128, CIFAR-10, and robotic hand trajectories, achieving better samples than other likelihood models and nearing the performance of contemporary GAN approaches, while covering all modes of the data. We highlight some unique capabilities of implicit generation such as compositionality and corrupt image reconstruction and inpainting. Finally, we show that EBMs are useful models across a wide variety of tasks, achieving state-of-the-art out-of-distribution classification, adversarially robust classification, state-of-the-art continual online class learning, and coherent long term predicted trajectory rollouts.},
author = {Du, Yilun and Mordatch, Igor},
booktitle = {arXiv},
issn = {23318422},
language = {en},
pages = {11},
title = {{Implicit generation and modeling with energy-based models}},
year = {2019}
}

@Misc{Fotiadis2020,
  author        = {Fotiadis, Stathi and Pignatelli, Eduardo and Bharath, Anil A. and Valencia, Mario Lino and Cantwell, Chris D. and Storkey, Amos},
  month         = {feb},
  title         = {{Comparing recurrent and convolutional neural networks for predicting wave propagation}},
  year          = {2020},
  abstract      = {Dynamical systems can be modelled by partial differential equations and a need for their numerical solution appears in many areas of science and engineering. In this work, we investigate the performance of recurrent and convolutional deep neural network architectures to predict the propagation of surface waves governed by the Saint-Venant equations. We improve on the long-term prediction over previous methods while keeping the inference time at a fraction of numerical simulations. We also show that convolutional networks perform at least as well as recurrent networks in this task. Finally, we assess the generalisation capability of each network by extrapolating for longer times and in different physical settings.1},
  archiveprefix = {arXiv},
  arxivid       = {2002.08981},
  booktitle     = {arXiv},
  eprint        = {2002.08981},
  issn          = {23318422},
  keywords      = {Computer Science - Computer Vision and Pattern Rec, Computer Science - Machine Learning, Statistics - Machine Learning},
  language      = {en},
  mendeley-tags = {Computer Science - Computer Vision and Pattern Rec,Computer Science - Machine Learning,Statistics - Machine Learning},
  url           = {http://arxiv.org/abs/2002.08981},
}

@Misc{Ye2017,
  author        = {Ye, Jong Chul and Han, Yoseob and Cha, Eunju},
  month         = {jul},
  title         = {{Deep convolutional framelets: A general deep learning framework for inverse problems}},
  year          = {2017},
  abstract      = {Recently, deep learning approaches with various network architectures have achieved significant performance improvement over existing iterative reconstruction methods in various imaging problems. However, it is still unclear why these deep learning architectures work for specific inverse problems. Moreover, in contrast to the usual evolution of signal processing theory around the classical theories, the link between deep learning and the classical signal processing approaches such as wavelets, non-local processing, compressed sensing, etc, are not yet well understood. To address these issues, here we show that the long-searched-for missing link is the convolution framelets for representing a signal by convolving local and non-local bases. The convolution framelets was originally developed to generalize the theory of low-rank Hankel matrix approaches for inverse problems, and this paper further extends the idea so that we can obtain a deep neural network using multilayer convolution framelets with perfect reconstruction (PR) under rectilinear linear unit nonlinearity (ReLU). Our analysis also shows that the popular deep network components such as residual block, redundant filter channels, and concatenated ReLU (CReLU) do indeed help to achieve the PR, while the pooling and unpooling layers should be augmented with high-pass branches to meet the PR condition. Moreover, by changing the number of filter channels and bias, we can control the shrinkage behaviors of the neural network. This discovery reveals the limitations of many existing deep learning architectures for inverse problems, and leads us to propose a novel theory for deep convolutional framelets neural network. Using numerical experiments with various inverse problems, we demonstrated that our deep convolution framelets network shows consistent improvement over existing deep architectures. This discovery suggests that the success of deep learning is not from a magical power of a black-box, but rather comes from the power of a novel signal representation using non-local basis combined with data-driven local basis, which is indeed a natural extension of classical signal processing theory.},
  booktitle     = {arXiv},
  issn          = {23318422},
  keywords      = {Computer Science - Computer Vision and Pattern Rec, Computer Science - Information Theory, Computer Science - Machine Learning, Convolutional neural network, Deep learning, Framelets, Inverse problems, Perfect reconstruction condition, ReLU, Statistics - Machine Learning},
  language      = {en},
  mendeley-tags = {Computer Science - Computer Vision and Pattern Rec,Computer Science - Information Theory,Computer Science - Machine Learning,Statistics - Machine Learning},
  shorttitle    = {Deep Convolutional Framelets},
  url           = {http://arxiv.org/abs/1707.00372},
}

@Misc{Qin2019,
  author        = {Qin, Hong},
  month         = {dec},
  title         = {{Machine learning and serving of discrete field theories — when artificial intelligence meets the discrete universe}},
  year          = {2019},
  abstract      = {A method for machine learning and serving of discrete field theories in physics is developed. The learning algorithm trains a discrete field theory from a set of observational data on a spacetime lattice, and the serving algorithm uses the learned discrete field theory to predict new observations of the field for new boundary and initial conditions. The approach to learn discrete field theories overcomes the difficulties associated with learning continuous theories by artificial intelligence. The serving algorithm of discrete field theories belongs to the family of structure-preserving geometric algorithms, which have been proven to be superior to the conventional algorithms based on discretization of differential equations. The effectiveness of the method and algorithms developed is demonstrated using the examples of nonlinear oscillations and the Kepler problem. In particular, the learning algorithm learns a discrete field theory from a set of data of planetary orbits similar to what Kepler inherited from Tycho Brahe in 1601, and the serving algorithm correctly predicts other planetary orbits, including parabolic and hyperbolic escaping orbits, of the solar system without learning or knowing Newton's laws of motion and universal gravitation. The proposed algorithms are also applicable when effects of special relativity and general relativity are important. The illustrated advantages of discrete field theories relative to continuous theories in terms of machine learning compatibility are consistent with Bostrom's simulation hypothesis.},
  archiveprefix = {arXiv},
  arxivid       = {1910.10147},
  booktitle     = {arXiv},
  eprint        = {1910.10147},
  issn          = {23318422},
  keywords      = {Computer Science - Machine Learning, High Energy Physics - Lattice, Physics - Computational Physics},
  language      = {en},
  mendeley-tags = {Computer Science - Machine Learning,High Energy Physics - Lattice,Physics - Computational Physics},
  url           = {http://arxiv.org/abs/1910.10147},
}

@Article{Gross2011,
  author        = {Gross, David},
  journal       = {IEEE Transactions on Information Theory},
  title         = {{Recovering low-rank matrices from few coefficients in any basis}},
  year          = {2011},
  issn          = {00189448},
  month         = {mar},
  number        = {3},
  pages         = {1548--1566},
  volume        = {57},
  abstract      = {We present novel techniques for analyzing the problem of low-rank matrix recovery. The methods are both considerably simpler and more general than previous approaches. It is shown that an unknown n × n matrix of rank r can be efficiently reconstructed from only O(nr$\nu$ ln2 n) randomly sampled expansion coefficients with respect to any given matrix basis. The number $\nu$ quantifies the "degree of incoherence" between the unknown matrix and the basis. Existing work concentrated mostly on the problem of "matrix completion" where one aims to recover a low-rank matrix from randomly selected matrix elements. Our result covers this situation as a special case. The proof consists of a series of relatively elementary steps, which stands in contrast to the highly involved methods previously employed to obtain comparable results. In cases where bounds had been known before, our estimates are slightly tighter. We discuss operator bases which are incoherent to all low-rank matrices simultaneously. For these bases, we show that $O(nr\nu ln n) randomly sampled expansion coefficients suffice to recover any low-rank matrix with high probability. The latter bound is tight up to multiplicative constants. {\textcopyright} 2011 IEEE.},
  archiveprefix = {arXiv},
  arxivid       = {0910.1879},
  doi           = {10.1109/TIT.2011.2104999},
  eprint        = {0910.1879},
  keywords      = {Compressed sensing, Computer Science - Information Theory, Computer Science - Numerical Analysis, Folder - Generic Signal Processing, Mathematics - Numerical Analysis, Quantum Physics, matrix completion, matrix recovery, operator large-deviation bound, quantum-state tomography},
  language      = {en},
  mendeley-tags = {Computer Science - Information Theory,Computer Science - Numerical Analysis,Folder - Generic Signal Processing,Mathematics - Numerical Analysis,Quantum Physics},
  url           = {http://arxiv.org/abs/0910.1879},
}

@InProceedings{Cheng2005,
  author        = {Cheng, Jiqi and Lu, Jian Yu},
  booktitle     = {Proceedings - IEEE Ultrasonics Symposium},
  title         = {{Fourier based imaging method with steered plane waves and limited-diffraction array beams}},
  year          = {2005},
  address       = {Rotterdam, The Netherlands},
  pages         = {1976--1979},
  publisher     = {IEEE},
  volume        = {4},
  abstract      = {A high frame rate (HFR) imaging theory was developed based on limited diffraction beams in 1997 (up to 3750 three-dimensional (3D) volumes/s for a depth of 200 mm in biological soft tissues). In this paper, the theory is extended to include explicitly various transmission schemes such as multiple limited-diffraction array beams and steered plane waves. Computer simulations and in vitro and in vivo experiments were performed to verify the extended theory. Results show that the extended theory provides a continuous compromise between image quality and frame rate which is useful in clinic. {\textcopyright} 2005 IEEE.},
  doi           = {10.1109/ULTSYM.2005.1603263},
  isbn          = {0780393821},
  issn          = {10510117},
  keywords      = {Folder - Classical beamforming, Fourier method, High frame rate imaging, Limited diffraction beams, Ultrasound imaging},
  language      = {en},
  mendeley-tags = {Folder - Classical beamforming},
  url           = {http://ieeexplore.ieee.org/document/1603263/},
}

@article{Nath2020,
abstract = {Recurrent neural networks (RNNs) allow an agent to construct a state-representation from a stream of experience, which is essential in partially observable problems. However, there are two primary issues one must overcome when training an RNN: the sensitivity of the learning algorithm's performance to truncation length and and long training times. There are variety of strategies to improve training in RNNs, the mostly notably Backprop Through Time (BPTT) and by Real-Time Recurrent Learning. These strategies, however, are typically computationally expensive and focus computation on computing gradients back in time. In this work, we reformulate the RNN training objective to explicitly learn state vectors; this breaks the dependence across time and so avoids the need to estimate gradients far back in time. We show that for a fixed buffer of data, our algorithm-called Fixed Point Propagation (FPP)-is sound: it converges to a stationary point of the new objective. We investigate the empirical performance of our online FPP algorithm, particularly in terms of computation compared to truncated BPTT with varying truncation levels.},
author = {Nath, Somjit and Liu, Vincent and Chan, Alan and Li, Xin and White, Adam and White, Martha},
language = {en},
pages = {21},
title = {{Training Recurrent Neural Networks Online By Learning Explicit State Variables}},
year = {2020}
}

@inproceedings{Rizzuti2019,
abstract = {We propose a `learned' iterative solver for the Helmholtz equation, by combining traditional Krylov-based solvers with machine learning. The method is, in principle, able to circumvent the shortcomings of classical iterative solvers, and has clear advantages over purely data-driven approaches. We demonstrate the effectiveness of this approach under a 1.5-D assumption, when adequate a priori information about the velocity distribution is known.},
address = {London, UK},
author = {Rizzuti, G. and Siahkoohi, A. and Herrmann, F. J.},
booktitle = {81st EAGE Conference and Exhibition 2019},
doi = {10.3997/2214-4609.201901542},
isbn = {9789462822894},
language = {en},
month = {jun},
title = {{Learned iterative solvers for the Helmholtz equation}},
url = {http://www.earthdoc.org/publication/publicationdetails/?publication=97298},
year = {2019}
}

@Article{Deng2009,
  author        = {Deng, Hai and Himed, Braham},
  journal       = {IEEE Transactions on Antennas and Propagation},
  title         = {{A virtual antenna beamforming (VAB) approach for radar systems by using orthogonal coding waveforms}},
  year          = {2009},
  issn          = {0018926X},
  number        = {2},
  pages         = {425--435},
  volume        = {57},
  abstract      = {An innovative approach is introduced to form virtual transmitting and receiving radar antenna beams simultaneously by transmitting orthogonal coding waveforms from the antenna elements and digitally processing of their echoes at the receiver. Multiple virtual transmitting-receiving beams can be formed simultaneously by employing an equal number of beamforming filters without increasing transmitting power or antenna gain or resolution loss. The virtually formed antenna beams can provide equivalent antenna gains and spatial resolutions as the conventional phased arrays of the same size. Because the actual antenna radiation pattern can be made almost isotropic, the new system has low probability of intercept (LPI) property. With both transmitting and receiving beams virtually implemented through digital filtering, costly radiation phase shift used in phased arrays is not needed for beam scanning in the proposed system. {\textcopyright} 2009 IEEE.},
  doi           = {10.1109/TAP.2008.2011387},
  keywords      = {Active antenna array, Digital beamforming, Folder - Beamforming special, Orthogonal waveforms, Phased arrays, Virtual antenna beams},
  mendeley-tags = {Active antenna array,Digital beamforming,Folder - Beamforming special,Orthogonal waveforms,Phased arrays,Virtual antenna beams},
}

@InProceedings{Thomas1991,
  author        = {Thomas, N. and Leeman, S.},
  booktitle     = {Proceedings - IEEE Ultrasonics Symposium},
  title         = {{Mean frequency via zero crossings}},
  year          = {1991},
  number        = {3},
  pages         = {1297--1300},
  volume        = {2},
  abstract      = {It is shown that the mean frequency of a Doppler shifted signal can be estimated, in principle, in the time domain, using the zero crossings of the signal. This is of note as zero crossing detectors have been criticised for their inaccuracy in measuring the mean frequency. By using the complex analytic signal, it is demonstrated that, the use of zero crossing methods to determine mean frequency are much more accurate than is generally appreciated, provided that envelope information is incorporated into the algorithm. It is shown that interference effects cause large spike-like excursions in the instantaneous frequency of received RF echoes and hence will also affect their zero crossing rate. This applies also to the demodulated Doppler shifted signals and thus the estimated mean frequency. However it is shown that the relation between the envelope and instantaneous frequency of such data segments allows the algorithm to minimise the size of the effect.},
  doi           = {10.1109/ULTSYM.1991.234055},
  issn          = {10510117},
  keywords      = {Doppler shifted signal, algorithm, biomedical ultrasonics, complex analytic signal, data segments, envelope information, instantaneous frequency, interference effects, medical ultrasound, received RF echoes, signal mean frequency, spike-like excursions, time domain estimation, zero crossings},
  mendeley-tags = {Doppler shifted signal,algorithm,biomedical ultrasonics,complex analytic signal,data segments,envelope information,instantaneous frequency,interference effects,medical ultrasound,received RF echoes,signal mean frequency,spike-like excursions,time domain estimation,zero crossings},
  url           = {Thomas1991.pdf},
}

@Misc{Hu2019,
  author        = {Hu, Yuanming and Anderson, Luke and Li, Tzu Mao and Sun, Qi and Carr, Nathan and Ragan-Kelley, Jonathan and Durand, Fr{\'{e}}do},
  month         = {oct},
  title         = {{DiffTaichi: Differentiable programming for physical simulation}},
  year          = {2019},
  abstract      = {We present DiffTaichi, a new differentiable programming language tailored for building high-performance differentiable physical simulators. Based on an imperative programming language, DiffTaichi generates gradients of simulation steps using source code transformations that preserve arithmetic intensity and parallelism. A light-weight tape is used to record the whole simulation program structure and replay the gradient kernels in a reversed order, for end-to-end backpropagation. We demonstrate the performance and productivity of our language in gradient-based learning and optimization tasks on 10 different physical simulators. For example, a differentiable elastic object simulator written in our language is 4.2× shorter than the hand-engineered CUDA version yet runs as fast, and is 188× faster than the TensorFlow implementation. Using our differentiable programs, neural network controllers are typically optimized within only tens of iterations.},
  archiveprefix = {arXiv},
  arxivid       = {1910.00935},
  booktitle     = {arXiv},
  eprint        = {1910.00935},
  issn          = {23318422},
  keywords      = {Computer Science - Graphics, Computer Science - Machine Learning, Physics - Computational Physics, Statistics - Machine Learning},
  language      = {en},
  mendeley-tags = {Computer Science - Graphics,Computer Science - Machine Learning,Physics - Computational Physics,Statistics - Machine Learning},
  shorttitle    = {DiffTaichi},
  url           = {http://arxiv.org/abs/1910.00935},
}

@Article{TremblayDarveau2017,
  author        = {Tremblay-Darveau, Charles and Bar-Zion, Avinoam and Williams, Ross and Sheeran, Paul S. and Milot, Laurent and Loupas, Thanasis and Adam, Dan and Bruce, Matthew and Burns, Peter N.},
  journal       = {IEEE Transactions on Medical Imaging},
  title         = {{Improved contrast-enhanced power doppler using a coherence-based estimator}},
  year          = {2017},
  issn          = {1558254X},
  number        = {9},
  pages         = {1901--1911},
  volume        = {36},
  abstract      = {While plane-wave imaging can improve the performance of power Doppler by enabling much longer ensembles than systems using focused beams, the long-ensemble averaging of the zero-lag autocorrelation R(0) estimates does not directly decrease the mean noise level, but only decreases its variance. Spatial variation of the noise due to the time-gain compensation and the received beamforming aperture ultimately limits sensitivity. In this paper, we demonstrate that the performance of power Doppler imaging can be improved by leveraging the higher lags of the autocorrelation [e.g., R(1), R(2),...] instead of the signal power (R(0)). As noise is completely uncorrelated from pulse-to-pulse while the flow signal remains correlated significantly longer, weak signals just above the noise floor can be made visible through the reduction of the noise floor. Finally, as coherence decreases proportionally with respect to velocity, we demonstrate how signal coherence can be targeted to separate flows of different velocities. For instance, we show how long-time-range coherence of microbubble contrast-enhanced flow specifically isolates slow capillary perfusion (as opposed to conduit flow).},
  doi           = {10.1109/TMI.2017.2699672},
  keywords      = {Folder - Correlation approaches, Plane-wave ultrasound, blood perfusion imaging, microbubbles, signal coherence, speckle interferometry},
  mendeley-tags = {Folder - Correlation approaches,Plane-wave ultrasound,blood perfusion imaging,microbubbles,signal coherence,speckle interferometry},
  pmid          = {28463190},
}

@Article{Stoica2008,
  author        = {Stoica, Petre and Li, Jian and Tan, Xing},
  journal       = {IEEE Transactions on Signal Processing},
  title         = {{On spatial power spectrum and signal estimation using the Pisarenko framework}},
  year          = {2008},
  issn          = {1053587X},
  number        = {10 II},
  pages         = {5109--5119},
  volume        = {56},
  abstract      = {This paper makes use of the Pisarenko framework, originally devised for temporal power spectrum estimation, to introduce a method for spatial power estimation that outperforms the beamforming method (except in extreme cases with serious calibration errors) as well as the Capon method (except in idealized situations with plentiful data and no miscalibration). An important feature of the proposed method is that it is user parameter-free, unlike most previous proposals with a similar character. Throughout the paper we emphasize a covariance matrix fitting approach to spatial power estimation, which provides clear intuitive explanations of the typical performance of the methods in the class under discussion. In a somewhat separated analysis, of interest for signal estimation applications, we derive the beamformer that passes a signal of interest in an undistorted manner, has minimum white-noise gain, and whose output power equals a given value (that should be larger than the Capon beamformer output power, which is known to have the smallest possible value). The given power value, referred to above, can be either obtained with a spatial power estimation method or perhaps provided directly by the user. {\textcopyright} 2008 IEEE.},
  doi           = {10.1109/TSP.2008.928935},
  keywords      = {Folder - Adaptive beamforming, Midway and beamformer design, Modified diagonon loading, Pisarenko framework, Spatial power spectrum estimation},
  mendeley-tags = {Folder - Adaptive beamforming},
}

@Article{Weinan2018a,
  author     = {Weinan, E. and Yu, Bing},
  journal    = {Communications in Mathematics and Statistics},
  title      = {{The Deep Ritz Method: A Deep Learning-Based Numerical Algorithm for Solving Variational Problems}},
  year       = {2018},
  issn       = {2194671X},
  month      = {mar},
  number     = {1},
  pages      = {1--12},
  volume     = {6},
  abstract   = {We propose a deep learning-based method, the Deep Ritz Method, for numerically solving variational problems, particularly the ones that arise from partial differential equations. The Deep Ritz Method is naturally nonlinear, naturally adaptive and has the potential to work in rather high dimensions. The framework is quite simple and fits well with the stochastic gradient descent method used in deep learning. We illustrate the method on several problems including some eigenvalue problems.},
  doi        = {10.1007/s40304-018-0127-z},
  keywords   = {Deep Ritz Method, Eigenvalue problems, PDE, Variational problems},
  language   = {en},
  shorttitle = {The Deep Ritz Method},
  url        = {http://link.springer.com/10.1007/s40304-018-0127-z},
}

@InProceedings{Lu2014,
  author    = {Lu, Jian Yu},
  booktitle = {IEEE International Ultrasonics Symposium, IUS},
  title     = {{Recursive fourier-based high-frame rate imaging}},
  year      = {2014},
  address   = {Chicago, IL, USA},
  month     = {sep},
  pages     = {121--124},
  publisher = {IEEE},
  abstract  = {The high-frame-rate (HFR) imaging method developed in 1997 used broad beams such as steered plane waves or limited-diffraction beams to illuminate an object, and then received echo signals are used to reconstruct images with Fourier transform. This method can be used in fast ultrasound cardiac imaging, flow velocity vector imaging, elasticity imaging, strain and strain rate imaging, and functional imaging. However, when multiple transmissions are used to reconstruct a frame of image to increase image field of view and improve image quality, image frame rate is reduced. To achieve the highest image frame rate limited only by the ultrasound round-trip time while multiple transmissions are used to reconstruct each frame of image, a recursive method is used. In this method, images reconstructed from each transmission are weighted with a constant that is between 0 and 1, and then added to the most recently reconstructed image. Experiments were performed with a tissue-mimicking phantom to demonstrate the efficacy of the method. Results show that high-quality images can be reconstructed at the highest image frame rate that is usually achievable only when one transmission is used to reconstruct a frame of image.},
  doi       = {10.1109/ULTSYM.2014.0031},
  isbn      = {9781479970490},
  issn      = {19485727},
  keywords  = {Recursive imaging, fast Fourier transform, high-frame-rate imaging, limited-diffraction beams, plane wave and diverging wave},
  language  = {en},
  url       = {http://ieeexplore.ieee.org/document/6932339/},
}

@InProceedings{Jin2016,
  author        = {Jin, Kyong Hwan and Han, Yo Seob and Ye, Jong Chul},
  booktitle     = {Proceedings - International Symposium on Biomedical Imaging},
  title         = {{Compressive dynamic aperture B-mode ultrasound imaging using annihilating filter-based low-rank interpolation}},
  year          = {2016},
  month         = {apr},
  pages         = {1009--1012},
  volume        = {2016-June},
  abstract      = {To reduce data rate for power-limited portable ultrasound imaging systems, various compressed sensing approaches have been investigated. However, most of the existing approaches require either hardware changes or computationally expensive forward modeling of wave propagation. To overcome these limitations, here we propose a novel low rank interpolation method that exploits the annihilation property of ultrasound measurements. Specifically, based on the observation that the pre-beamformed signals from a ultrasound probe have significant redundancy in spatial domain, only random subset of scan line measurements are obtained and the missing data are interpolated using a recently proposed annihilating filter-based low-rank Hankel matrix approach (ALOHA). Moreover, we exploit temporal correlation between the measurements from consecutive frames by augmenting Hankel matrix side by side for a low rank matrix completion. Reconstruction results confirmed that the proposed method can effectively reduce the data rate for ultrasound acquisition without sacrificing the image quality.},
  doi           = {10.1109/ISBI.2016.7493436},
  isbn          = {9781479923502},
  issn          = {19458452},
  keywords      = {Compressed sensing, Correlation, Image reconstruction, Imaging, Probes, Ultrasonic imaging, Ultrasonic variables measurement, Ultrasound, annihilating filter, compressed sensing, structured matrix completion},
  mendeley-tags = {Compressed sensing,Correlation,Image reconstruction,Imaging,Probes,Ultrasonic imaging,Ultrasonic variables measurement,Ultrasound,annihilating filter,compressed sensing,structured matrix completion},
}

@article{Wells1999,
abstract = {Ultrasonic imaging is a mature medical technology. It accounts for one in four imaging studies and this proportion is increasing. Wave propagation, beam formation, the Doppler effect and the properties of tissues that affect imaging are discussed. The transducer materials and construction of the probes used in imaging are described, as well as the methods of measuring the ultrasonic field. The history of ultrasonic imaging is briefly reviewed. The pulse-echo technique is used for real-time grey-scale imaging and the factors that limit the spatial and temporal resolutions are considered. The construction and performance of transducer arrays are discussed, together with the associated beam steering and signal processing systems. Speckle and scattering by blood are introduced, particularly in the context of the observation of blood flow by means of the Doppler effect and by time-domain signal processing. Colour flow imaging, and the colour coding schemes used for velocity and power imaging, are explained. The acquisition and display of three-dimensional images are discussed, with particular reference to speed and segmentation. Specialized imaging methods, including endoluminal scanning, synthetic aperture imaging, computed tomography, elasticity imaging, microscanning, contrast agents, and tissue harmonic imaging, are reviewed. There is a discussion of issues relating to safety. Conclusions are drawn and future prospects are considered. {\textcopyright} 1999 IOP Publishing Ltd.},
author = {Wells, P. N.T.},
doi = {10.1088/0034-4885/62/5/201},
issn = {00344885},
journal = {Reports on Progress in Physics},
keywords = {Folder - General US},
mendeley-tags = {Folder - General US},
number = {5},
pages = {671--722},
title = {{Ultrasonic imaging of the human body}},
url = {http://stacks.iop.org/0034-4885/62/i=5/a=201?key=crossref.5491ff1d7ef665f8c859e1c1d18b3e11},
volume = {62},
year = {1999}
}

@Article{Bottou1991,
  author   = {Bottou, L},
  journal  = {Proceedings of Neuro-Nımes},
  title    = {{Stochastic Gradient Learning in Neural Networks}},
  year     = {1991},
  number   = {8},
  pages    = {12},
  volume   = {91},
  abstract = {... Proper learning rates ensure that this algorithm converges to\na local minimum of the cost ... are updated after the presentation\nof each example, according to the gradient of the ... A convergence\ntheorem for the stochastic back- propagation algorithm for one hidden\nlayered networks ...},
  keywords = {Convergence Topic: Theory, Learning, Loss function, Stochastic gradient},
}

@Article{Quintana2005,
  author        = {Quintana, Miguel and Gustafsson, Thomas and Sundblad, Patrick and Langanger, Jenny},
  journal       = {European Journal of Echocardiography},
  title         = {{The effects of heart rate on myocardial velocity and atrio-ventricular displacement during exercise with and without beta-blockade: A tissue Doppler echocardiographic study}},
  year          = {2005},
  issn          = {15252167},
  number        = {2},
  pages         = {127--133},
  volume        = {6},
  abstract      = {Background: Colour tissue Doppler echocardiography (TDE) allows an objective assessment of regional myocardial function. Peak systolic velocity (PSV) and A-V plane displacement (AVPD) obtained from colour TDE correlate well with changes in cardiac wall motion and can discriminate ischemic areas during stress echocardiography. During exercise, the relationship between PSV and AVPD depends on several factors besides ischemia and should be considered when performing exercise stress echocardiography. Aims: To investigate the relation between PSV, AVPD and heart rate (HR) during semi-upright exercise with and without beta-blockade. Subjects and methods Twelve healthy men underwent semi-upright exercise stress echocardiography with and without beta-blockade on two separate occasions. Standard echocardiographic projections were used for the stress echocardiography. Grey-scale echocardiographic pictures containing colour TDE information were obtained at rest and during a two-stage exercise test, and the images were analyzed off-line. The PSV and AVPD were measured at four points at the base of the left ventricle at the septum and lateral, inferior and anterior walls. Results: PSV, A VPD and HR gradually increased during exercise. The increases in PSV and AVPD were linearly correlated with the increase in HR. The increases in PSV were significantly lower during exercise with beta-blockade than without beta-blockade (P < 0.05). This was not observed in AVPD, as increments were not affected by beta-blockade. Conclusion: These data showing a relationship between HR and PSV, and a significantly lower PSV with beta-blockade at a given HR, suggest that PSV is influenced by HR and myocardial contractility, both of which are augmented by physical exercise-induced sympathetic stimulation. {\textcopyright} 2004 The European Society of Cardiology. Published by Elsevier Ltd. All rights reserved.},
  doi           = {10.1016/j.euje.2004.07.008},
  keywords      = {*Echocardiography, Adrenergic beta-Antagonists/*pharmacology, Adult, Atrial Function, Beta-blockade, Color/methods, Doppler, Echocardiography, Electrocardiography, Exercise, Exercise Test, Exercise/*physiology, Heart Rate/*physiology, Humans, Left ventricular function, Left/physiology, Male, Metoprolol/pharmacology, Myocardial Contraction/*physiology, Myocardial Ischemia/*ultrasonography, Stress, Tissue Doppler echocardiography, Ventricular Function},
  mendeley-tags = {*Echocardiography,Adrenergic beta-Antagonists/*pharmacology,Adult,Atrial Function,Color/methods,Doppler,Echocardiography,Electrocardiography,Exercise Test,Exercise/*physiology,Heart Rate/*physiology,Humans,Left/physiology,Male,Metoprolol/pharmacology,Myocardial Contraction/*physiology,Myocardial Ischemia/*ultrasonography,Stress,Ventricular Function},
  pmid          = {15760689},
  url           = {http://www.ncbi.nlm.nih.gov/pubmed/15760689},
}

@article{Judson2014,
abstract = {Abstract Algebra: Theory and Applications is an open-source textbook that is designed to teach the principles and theory of abstract algebra to college juniors and seniors in a rigorous manner. Its strengths include a wide range of exercises, both computational and theoretical, plus many non-trivial applications. The first half of the book presents group theory, through the Sylow theorems, with enough material for a semester-long course. The second-half is suitable for a second semester and presents rings, integral domains, Boolean algebras, vector spaces, and fields, concluding with Galois Theory.},
author = {Judson, Thomas W.},
isbn = {0989897540},
language = {en},
pages = {406},
title = {{Abstract Algebra Theory and Applications}},
url = {https://books.google.com/books?id=mebAoQEACAAJ&pgis=1},
year = {2014}
}

@article{Ustuner2011,
abstract = {Adaptive grating lobe suppression is provided. Received ultrasound data is measured, compared or otherwise processed to determine the presence of grating lobe energy. A further process is then altered as a function of the level of grating lobe energy. In one embodiment, the adaptive grating lobe suppression is implemented in the receive beamformer. Data representing a virtual element is formed as a normalized sum of data from adjacent sparse elements. The data from the adjacent elements is correlated to determine the presence of grating lobe energy as a function of the amount of shift associated with the peak correlation. A phase shift is applied to the data representing the virtual element where sufficient grating lobe energy is determined. In another embodiment, an amount of grating lobe energy is measured by comparing data from prior to a filter with filtered data. The filter is selected to isolate main lobe energy from grating lobe energy. A gain is modulated as a function of any detected grating lobe energy or filtered or unfiltered data is selected for further processing.},
author = {Ustuner, Kutay F. and Gee, Albert},
doi = {10.1121/1.3625682},
issn = {00014966},
journal = {The Journal of the Acoustical Society of America},
keywords = {Folder - Side and grating lobes reduction},
mendeley-tags = {Folder - Side and grating lobes reduction},
number = {2},
pages = {1088},
title = {{Adaptive Grating Lobe Suppression in Ultrasound Imaging}},
volume = {130},
year = {2011}
}

@Article{Myronenko2010,
  author   = {Myronenko, Andriy and Song, Xubo},
  journal  = {IEEE Transactions on Medical Imaging},
  title    = {{Intensity-based image registration by minimizing residual complexity}},
  year     = {2010},
  issn     = {02780062},
  month    = {nov},
  number   = {11},
  pages    = {1882--1891},
  volume   = {29},
  abstract = {Accurate definition of the similarity measure is a key component in image registration. Most commonly used intensity-based similarity measures rely on the assumptions of independence and stationarity of the intensities from pixel to pixel. Such measures cannot capture the complex interactions among the pixel intensities, and often result in less satisfactory registration performances, especially in the presence of spatially-varying intensity distortions. We propose a novel similarity measure that accounts for intensity nonstationarities and complex spatially-varying intensity distortions in mono-modal settings. We derive the similarity measure by analytically solving for the intensity correction field and its adaptive regularization. The final measure can be interpreted as one that favors a registration with minimum compression complexity of the residual image between the two registered images. One of the key advantages of the new similarity measure is its simplicity in terms of both computational complexity and implementation. This measure produces accurate registration results on both artificial and real-world problems that we have tested, and outperforms other state-of-the-art similarity measures in these cases. {\textcopyright} 2006 IEEE.},
  doi      = {10.1109/TMI.2010.2053043},
  keywords = {Bias field, image registration, nonstationary intensity distortion, residual complexity, sparseness},
  language = {en},
  pmid     = {20562036},
  url      = {http://ieeexplore.ieee.org/document/5487419/},
}

@article{Marmottant2005,
abstract = {We present a model applicable to ultrasound contrast agent bubbles that takes into account the physical properties of a lipid monolayer coating on a gas microbubble. Three parameters describe the properties of the shell: a buckling radius, the compressibility of the shell, and a break-up shell tension. The model presents an original non-linear behavior at large amplitude oscillations, termed compression-only, induced by the buckling of the lipid monolayer. This prediction is validated by experimental recordings with the high-speed camera Brandaris 128, operated at several millions of frames per second. The effect of aging, or the resultant of repeated acoustic pressure pulses on bubbles, is predicted by the model. It corrects a flaw in the shell elasticity term previously used in the dynamical equation for coated bubbles. The break-up is modeled by a critical shell tension above which gas is directly exposed to water.},
author = {Marmottant, Philippe and van der Meer, Sander and Emmer, Marcia and Versluis, Michel and de Jong, Nico and Hilgenfeldt, Sascha and Lohse, Detlef},
doi = {10.1121/1.2109427},
issn = {0001-4966},
journal = {The Journal of the Acoustical Society of America},
number = {6},
pages = {3499--3505},
title = {{A model for large amplitude oscillations of coated bubbles accounting for buckling and rupture}},
volume = {118},
year = {2005}
}

@article{LeCun2006,
abstract = {Energy-Based Models (EBMs) capture dependencies between variables by associating a scalar energy to each configuration of the variables. Inference consists in clamping the value of observed variables and finding configurations of the remaining variables that minimize the energy. Learning consists in finding an energy function in which observed configurations of the variables are given lower energies than unobserved ones. The EBM approach provides a common theoretical framework for many learning models, including traditional discriminative and generative approaches, as well as graph-transformer networks, conditional random fields, maximum margin Markov networks, and several manifold learning methods. Probabilistic models must be properly normalized, which sometimes requires evaluating intractable integrals over the space of all possible variable configurations. Since EBMs have no requirement for proper normalization, this problem is naturally circumvented. EBMs can be viewed as a form of non-probabilistic factor graphs, and they provide considerably more flexibility in the design of architectures and training criteria than probabilistic approaches.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {LeCun, Yann and Chopra, Sumit and Hadsell, Raia and Ranzato, Marc'Aurelio and Huang, Fu Jie},
doi = {10.1198/tech.2008.s913},
eprint = {arXiv:1011.1669v3},
isbn = {9780262026178},
issn = {<null>},
journal = {Predicting Structured Data},
language = {en},
pages = {191--246},
pmid = {25246403},
title = {{A Tutorial on Energy-Based Learning}},
year = {2006}
}

@Misc{Sappl2019,
  author        = {Sappl, Johannes and Seiler, Laurent and Harders, Matthias and Rauch, Wolfgang},
  month         = {jun},
  title         = {{Deep learning of preconditioners for conjugate gradient solvers in urban water related problems}},
  year          = {2019},
  abstract      = {Solving systems of linear equations is a problem occuring frequently in water engineering applications. Usually the size of the problem is too large to be solved via direct factorization. One can resort to iterative approaches, in particular the conjugate gradients method if the matrix is symmetric positive definite. Preconditioners further enhance the rate of convergence but hitherto only handcrafted ones requiring expert knowledge have been used. We propose an innovative approach employing Machine Learning, in particular a Convolutional Neural Network, to unassistedly design preconditioning matrices specifically for the problem at hand. Based on an in-depth case study in fluid simulation we are able to show that our learned preconditioner is able to improve the convergence rate even beyond well established methods like incomplete Cholesky factorization or Algebraic MultiGrid.},
  archiveprefix = {arXiv},
  arxivid       = {1906.06925},
  booktitle     = {arXiv},
  eprint        = {1906.06925},
  issn          = {23318422},
  keywords      = {Computer Science - Machine Learning, Mathematics - Numerical Analysis, Statistics - Machine Learning},
  language      = {en},
  mendeley-tags = {Computer Science - Machine Learning,Mathematics - Numerical Analysis,Statistics - Machine Learning},
  url           = {http://arxiv.org/abs/1906.06925},
}

@Article{Dahl2008,
  author        = {Dahl, Jeremy J. and Feehan, Thomas J.},
  journal       = {Ultrasonic Imaging},
  title         = {{Direction of arrival filters for improved aberration estimation}},
  year          = {2008},
  issn          = {01617346},
  number        = {1},
  pages         = {1--20},
  volume        = {30},
  abstract      = {Successful adaptive imaging requires accurate measurements of the aberration profile across the array surface. Two-dimensional spatial filters are used to obtain more accurate estimates of aberrating layers by suppressing wavefronts emanating from off-axis scatterers. Application of these filters to the rf signals of the individual elements rejects wavefronts arriving from angles other than the look direction of the array and results in an increase in element-to-element correlation. Spatial filtering reduced the amount of error in the measured aberration profiles and adaptive spatial filtering further improved the estimates. The improvements in aberration estimation obtained with these methods are verified using simulations and experiments in tissue-mimicking phantoms. The technique is applied to signals obtained from in vivo human thyroid. Copyright 2008 by Dynamedia, Inc. All rights of reproduction in any form reserved.},
  doi           = {10.1177/016173460803000103},
  keywords      = {Beamforming, Direction of arrival estimation, Folder - Beamforming special, Phase aberration correction, Ultrasound, beamforming, direction of arrival estimation, phase aberration correction, ultrasound},
  mendeley-tags = {Folder - Beamforming special,beamforming,direction of arrival estimation,phase aberration correction,ultrasound},
  pmid          = {18564593},
}

@article{Bercoff2004,
abstract = {Supersonic shear imaging (SSI) is a new ultrasound-based technique for real-time visualization of soft tissue viscoelastic properties. Using ultrasonic focused beams, it is possible to remotely generate mechanical vibration sources radiating low-frequency, shear waves inside tissues. Relying on this concept, SSI proposes to create such a source and make it move at a supersonic speed. In analogy with the "sonic boom" created by a supersonic aircraft, the resulting shear waves will interfere constructively along a Mach cone, creating two intense plane shear waves. These waves propagate through the medium and are progressively distorted by tissue heterogeneities. An ultrafast scanner prototype is able to both generate this supersonic source and image (5000 frames/s) the propagation of the resulting shear waves. Using inversion algorithms, the shear elasticity of medium can be mapped quantitatively from this propagation movie. The SSI enables tissue elasticity mapping in less than 20 ms, even in strongly viscous medium like breast. Modalities such as shear compounding are implementable by tilting shear waves in different directions and improving the elasticity estimation. Results validating SSI in heterogeneous phantoms are presented. The first in vivo investigations made on healthy volunteers emphasize the potential clinical applicability of SSI for breast cancer detection.},
author = {Bercoff, J{\'{e}}r{\'{e}}my and Tanter, Micka{\"{e}}l and Fink, Mathias},
doi = {10.1109/TUFFC.2004.1295425},
issn = {08853010},
journal = {IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
number = {4},
pages = {396--409},
pmid = {15139541},
title = {{Supersonic shear imaging: A new technique for soft tissue elasticity mapping}},
volume = {51},
year = {2004}
}

@Misc{DeHoop2019,
  author        = {{De Hoop}, Maarten V. and Lassas, Matti and Wong, Christopher A.},
  month         = {jan},
  title         = {{Deep learning architectures for nonlinear operator functions and nonlinear inverse problems}},
  year          = {2019},
  abstract      = {We develop a theoretical analysis for special neural network architectures, termed operator recurrent neural networks, for approximating highly nonlinear functions whose inputs are linear operators. Such functions commonly arise in solution algorithms for inverse problems for the wave equation. Traditional neural networks treat input data as vectors, and thus they do not effectively capture the multiplicative structure associated with the linear operators that correspond to the measurement data in such inverse problems. We therefore introduce a new parametric family that resembles a standard neural network architecture, but where the input data acts multiplicatively on vectors. Moti- vated by compact operators appearing in boundary control and the analysis of inverse boundary value problems for the wave equation, we promote structure and sparsity in selected weight matrices in the network. After describing this architecture, we study its representation properties as well as its approximation properties. We furthermore show that an explicit regularization can be intro- duced that can be derived from the mathematical analysis of the mentioned inverse problems, and which leads to some guarantees on the generalization properties. We observe that the sparsity of the weight matrices improves the generalization estimates. Lastly, we discuss how operator recurrent networks can be viewed as a deep learning analogue to deterministic algorithms such as boundary control for reconstructing the unknown wavespeed in the acoustic wave equation from boundary measurements. MSC Codes 68T05, 35R30, 62M45},
  archiveprefix = {arXiv},
  arxivid       = {1912.11090},
  booktitle     = {arXiv},
  eprint        = {1912.11090},
  issn          = {23318422},
  keywords      = {68T05- 35R30- 62M45, Computer Science - Machine Learning, Inverse problems, Mathematics - Optimization and Control, Neural networks, Sparse matrixes, Wave equation},
  language      = {en},
  mendeley-tags = {68T05- 35R30- 62M45,Computer Science - Machine Learning,Mathematics - Optimization and Control},
  url           = {http://arxiv.org/abs/1912.11090},
}

@Article{Engelbrecht2013,
  author        = {Engelbrecht, J{\"{u}}ri},
  journal       = {Estonian Journal of Engineering},
  title         = {{Lainev{\~{o}}rrandid mehaanikas}},
  year          = {2013},
  issn          = {17366038},
  number        = {4},
  pages         = {273--282},
  volume        = {19},
  abstract      = {The classical wave equation is a cornerstone in mathematical physics and mechanics. Its modifications are widely used in order to describe wave phenomena. In mechanics deformation waves are related to impact problems, acoustic waves are used in Nondestructive Evaluation, seismic waves may cause a lot of damage, etc. In this paper it is shown how the classical wave equation can be modified in order to model better the physics of processes. The examples cover microstructured and inhomogeneous materials together with linear and nonlinear models. Beside usual two-wave models, the evolution equations are described which govern the distortion of a single wave.},
  doi           = {10.3176/eng.2013.4.02},
  keywords      = {Evolution equation, Modified wave equation, Wave equation, evolution equation, modified wave equation, wave equation},
  mendeley-tags = {evolution equation,modified wave equation,wave equation},
  url           = {http://www.kirj.ee/?id=23355&tpl=1061&c_tpl=1064},
}

@misc{Hasegawa2012,
abstract = {Echocardiography has become an indispensable modality for diagnosis of the heart. It enables observation of the shape of the heart and estimation of global heart function based on B-mode and M-mode imaging. Methods for echocardiographic estimation of myocardial strain and strain rate have also been developed to evaluate regional heart function. Furthermore, it has been recently shown that echocardiographic measurements of transmural transition of myocardial contraction/ relaxation and propagation of vibration caused by closure of the heart valve would be useful for evaluation of myocardial function and viscoelasticity. However, such measurements require a frame rate (typically >200 Hz) much higher than that achieved by conventional ultrasonic diagnostic equipment. We have recently realized a high frame rate of about 300 Hz with a full field of view of 90 using diverging transmit beams and parallel receive beamforming. Although high-frame-rate imaging was made possible by this method, the side lobe level was slightly larger than that of the conventional method. To reduce the side lobe level, phase coherence imaging has recently been developed. Using this method, the spatial resolution is improved and the side lobe level is also reduced. However, speckle-like echoes, for example, echoes from the inside of the heart wall, are also suppressed. In the present study, a method for reducing the side lobe level while preserving speckle-like echoes was developed. The side lobe level was evaluated using a wire phantom. The side lobe level of the high-frame-rate imaging using unfocused diverging beams was improved by 13.3 dB by the proposed method. In in vivo measurements, a B-mode image of the heart of a 23-year-old healthy male could be obtained while preserving the speckle pattern in the heart wall at a frame rate of 316 Hz with a full field of view of 90°. {\textcopyright} 2012 IEEE.},
author = {Hasegawa, Hideyuki and Kanai, Hiroshi},
booktitle = {IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
doi = {10.1109/TUFFC.2012.2490},
issn = {08853010},
keywords = {Folder - Side and grating lobes reduction},
mendeley-tags = {Folder - Side and grating lobes reduction},
number = {11},
pages = {2569--2575},
pmid = {23192821},
title = {{High-frame-rate echocardiography with reduced sidelobe level}},
volume = {59},
year = {2012}
}

@InProceedings{Song2019,
  author        = {Song, Yang and Ermon, Stefano},
  booktitle     = {Advances in Neural Information Processing Systems},
  title         = {{Generative modeling by estimating gradients of the data distribution}},
  year          = {2019},
  month         = {oct},
  volume        = {32},
  abstract      = {We introduce a new generative model where samples are produced via Langevin dynamics using gradients of the data distribution estimated with score matching. Because gradients can be ill-defined and hard to estimate when the data resides on low-dimensional manifolds, we perturb the data with different levels of Gaussian noise, and jointly estimate the corresponding scores, i.e., the vector fields of gradients of the perturbed data distribution for all noise levels. For sampling, we propose an annealed Langevin dynamics where we use gradients corresponding to gradually decreasing noise levels as the sampling process gets closer to the data manifold. Our framework allows flexible model architectures, requires no sampling during training or the use of adversarial methods, and provides a learning objective that can be used for principled model comparisons. Our models produce samples comparable to GANs on MNIST, CelebA and CIFAR-10 datasets, achieving a new state-of-the-art inception score of 8.87 on CIFAR-10. Additionally, we demonstrate that our models learn effective representations via image inpainting experiments.},
  issn          = {10495258},
  keywords      = {Computer Science - Machine Learning, Statistics - Machine Learning},
  language      = {en},
  mendeley-tags = {Computer Science - Machine Learning,Statistics - Machine Learning},
  url           = {http://arxiv.org/abs/1907.05600},
}

@article{Welch1967,
abstract = {The use of the fast Fourier transform in power spectrum analysis is described. Principal advantages of this method are a reduction in the number of computations and in required core storage, and convenient application in nonstationarity tests. The method involves sectioning the record and averaging modified periodograms of the sections. {\textcopyright} 1967, IEEE. All rights reserved.},
author = {Welch, Peter D.},
doi = {10.1109/TAU.1967.1161901},
issn = {00189278},
journal = {IEEE Transactions on Audio and Electroacoustics},
number = {2},
pages = {70--73},
title = {{The Use of Fast Fourier Transform for the Estimation of Power Spectra: A Method Based on Time Averaging Over Short, Modified Periodograms}},
volume = {15},
year = {1967}
}

@Misc{Wang2019,
  author        = {Wang, Zhengwei and She, Qi and Ward, Tom{\'{a}}s E.},
  month         = {feb},
  title         = {{Generative adversarial networks: A survey and taxonomy}},
  year          = {2019},
  abstract      = {Generative adversarial networks (GANs) have been extensively studied in the past few years. Arguably the revolutionary techniques are in the area of computer vision such as plausible image generation, image to image translation, facial attribute manipulation and similar domains. Despite the significant success achieved in the computer vision field, applying GANs to real-world problems still poses significant challenges, three of which we focus on here: (1) High quality image generation; (2) Diverse image generation; and (3) Stable training. Through an in-depth review of GAN-related research in the literature, we provide an account of the architecture-variants and loss-variants, which have been proposed to handle these three challenges from two perspectives. We propose loss-variants and architecture-variants for classifying the most popular GANs, and discuss the potential improvements with focusing on these two aspects. While several reviews for GANs have been presented to date, none have focused on the review of GAN-variants based on their handling the challenges mentioned above. In this paper, we review and critically discuss 7 architecture-variant GANs and 9 loss-variant GANs for remedying those three challenges. The objective of this review is to provide an insight on the footprint that current GANs research focuses on the performance improvement. Code related to GAN-variants studied in this work is summarized on https:// github.com/ sheqi/GAN Review.},
  booktitle     = {arXiv},
  issn          = {23318422},
  keywords      = {Architecture-variants, Computer Science - Computer Vision and Pattern Rec, Computer Science - Machine Learning, Computer vision, Generative adversarial networks, Loss-variants, Stable training},
  language      = {en},
  mendeley-tags = {Computer Science - Computer Vision and Pattern Rec,Computer Science - Machine Learning},
  shorttitle    = {Generative Adversarial Networks in Computer Vision},
  url           = {http://arxiv.org/abs/1906.01529},
}

@Article{Diamantis2019,
  author        = {Diamantis, Konstantinos and Anderson, Tom and Butler, Mairead B. and Villagomez-Hoyos, Carlos A. and Jensen, Jorgen Arendt and Sboros, Vassilis},
  journal       = {IEEE Transactions on Medical Imaging},
  title         = {{Resolving ultrasound contrast microbubbles using minimum variance beamforming}},
  year          = {2019},
  issn          = {1558254X},
  number        = {1},
  pages         = {194--204},
  volume        = {38},
  abstract      = {Minimum Variance (MV) beamforming is known to improve the lateral resolution of ultrasound images and enhance the separation of isolated point scatterers. This paper aims to evaluate the adaptive beamformer's performance with flowing microbubbles (MBs) which are relevant to super-resolution ultrasound imaging. Simulations using point scatterer data from single emissions were complemented by an experimental investigation performed using a capillary tube phantom and the Synthetic Aperture Real-time Ultrasound System (SARUS). The MV performance was assessed by the minimum distance that allows the display of two scatterers positioned side-by-side, the lateral Full-Width-at-Half-Maximum (FWHM), and the Peak-Sidelobe-Level (PSL). In the tube, scatterer responses separated by down to 196$\mu$m (or 1.05$\lambda$) were distinguished by the MV method, while the standard Delay-And-Sum (DAS) beamformers were unable to achieve such separation. Up to ninefold FWHM decrease was also measured in favor of the MV beamformer for individual echoes from MBs. The lateral distance between two scatterers impacted on their FWHM value, and additional differences in the scatterers' axial or out-of-plane position also impacted on their size and appearance. The simulation and experimental results were in agreement in terms of lateral resolution. The point scatterer study showed that the proposed MV imaging scheme provided clear resolution benefits compared to DAS. Current super-resolution methods mainly depend on DAS beamformers. Instead, the use of the MV method may provide a larger number of detected, and potentially better localized, MB scatterers.},
  doi           = {10.1109/TMI.2018.2859262},
  keywords      = {Closely-spaced scatterers, Folder - Adaptive beamforming, Folder - Correlation approaches, Minimum Variance beamforming, lateral resolution, microbubbles, super-resolution ultrasound},
  language      = {en},
  mendeley-tags = {Folder - Adaptive beamforming,Folder - Correlation approaches},
  pmid          = {30059295},
  url           = {https://ieeexplore.ieee.org/document/8421245/},
}

@article{Partridge2000,
abstract = {Principal component analysis (PCA) is a technique used to reduce the dimensionality of data. In particular, it may be used to reduce the noise component of a signal. However, traditional PCA techniques may themselves be sensitive to noise. Some robust techniques have been developed, but these tend not to work so well in high dimensional spaces. This paper discusses the robustness properties of a recent PCA algorithm, SPCA1. It shows theoretically and experimentally that this algorithm is less sensitive to the presence of outliers.},
author = {Partridge, Matthew and Jabri, Marwan},
doi = {10.1201/b20190-2},
journal = {Neural Networks for Signal Processing - Proceedings of the IEEE Workshop},
keywords = {Folder - Generic Signal Processing},
language = {en},
mendeley-tags = {Folder - Generic Signal Processing},
pages = {289--298},
title = {{Robust principal component analysis}},
volume = {1},
year = {2000}
}

@Article{Toulemonde2018a,
  author     = {Toulemonde, Matthieu and Li, Yuanwei and Lin, Shengtao and Cordonnier, Fabien and Butler, Mairead and Duncan, W. Colin and Eckersley, Robert J. and Sboros, Vassilis and Tang, Meng Xing},
  journal    = {IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
  title      = {{High-frame-rate contrast echocardiography using diverging waves: Initial in vitro and In vivo evaluation}},
  year       = {2018},
  issn       = {15258955},
  month      = {dec},
  number     = {12},
  pages      = {2212--2221},
  volume     = {65},
  abstract   = {Contrast echocardiography (CE) ultrasound with microbubble contrast agents has significantly advanced our capability for assessment of cardiac function, including myocardium perfusion quantification. However, in standard CE techniques obtained with line by line scanning, the frame rate and image quality are limited. Recent research has shown significant frame-rate improvement in noncontrast cardiac imaging. In this work, we present and initially evaluate, both in vitro and in vivo, a high-frame-rate (HFR) CE imaging system using diverging waves and pulse inversion sequence. An imaging frame rate of 5500 frames/s before and 250 frames/s after compounding is achieved. A destruction-replenishment sequence has also been developed. The developed HFR CE is compared with standard CE in vitro on a phantom and then in vivo on a sheep heart. The image signal-to-noise ratio and contrast between the myocardium and the chamber are evaluated. The results show up to 13.4-dB improvement in contrast for HFR CE over standard CE when compared at the same display frame rate even when the average spatial acoustic pressure in HFR CE is 36% lower than the standard CE. It is also found that when coherent compounding is used, the HFR CE image intensity can be significantly modulated by the flow motion in the chamber.},
  doi        = {10.1109/TUFFC.2018.2856756},
  keywords   = {Contrast-enhanced ultrasound (CEUS) imaging, High-frame-rate echocardiography, In vivo, Myocardium perfusion, Ultrafast diverging beams},
  language   = {en},
  pmid       = {30028698},
  shorttitle = {High-Frame-Rate Contrast Echocardiography Using Di},
  url        = {https://ieeexplore.ieee.org/document/8412216/},
}

@Misc{Moskovitz2019,
  author        = {Moskovitz, Ted and Wang, Rui and Lan, Janice and Kapoor, Sanyam and Miconi, Thomas and Yosinski, Jason and Rawal, Aditya},
  month         = {oct},
  title         = {{First-order preconditioning via hypergradient descent}},
  year          = {2019},
  abstract      = {Standard gradient descent methods are susceptible to a range of issues that can impede training, such as high correlations and different scaling in parameter space. These difficulties can be addressed by second-order approaches that apply a preconditioning matrix to the gradient to improve convergence. Unfortunately, such algorithms typically struggle to scale to high-dimensional problems, in part because the calculation of specific preconditioners such as the inverse Hessian or Fisher information matrix is highly expensive. We introduce first-order preconditioning (FOP), a fast, scalable approach that generalizes previous work on hypergradient descent (Almeida et al., 1998; Maclaurin et al., 2015; Baydin et al., 2017) to learn a preconditioning matrix that only makes use of first-order information. Experiments show that FOP is able to improve the performance of standard deep learning optimizers on several visual classification tasks with minimal computational overhead. We also investigate the properties of the learned preconditioning matrices and perform a preliminary theoretical analysis of the algorithm.},
  archiveprefix = {arXiv},
  arxivid       = {1910.08461},
  booktitle     = {arXiv},
  eprint        = {1910.08461},
  issn          = {23318422},
  keywords      = {Computer Science - Machine Learning, Statistics - Machine Learning},
  language      = {en},
  mendeley-tags = {Computer Science - Machine Learning,Statistics - Machine Learning},
  url           = {http://arxiv.org/abs/1910.08461},
}

@Article{Provost2014,
  author        = {Provost, Jean and Papadacci, Clement and Arango, Juan Esteban and Imbault, Marion and Fink, Mathias and Gennisson, Jean Luc and Tanter, Mickael and Pernot, Mathieu},
  journal       = {Physics in Medicine and Biology},
  title         = {{3D ultrafast ultrasound imaging in vivo}},
  year          = {2014},
  issn          = {13616560},
  number        = {19},
  pages         = {L1--L13},
  volume        = {59},
  abstract      = {Very high frame rate ultrasound imaging has recently allowed for the extension of the applications of echography to new fields of study such as the functional imaging of the brain, cardiac electrophysiology, and the quantitative imaging of the intrinsic mechanical properties of tumors, to name a few, non-invasively and in real time. In this study, we present the first implementation of Ultrafast Ultrasound Imaging in 3D based on the use of either diverging or plane waves emanating from a sparse virtual array located behind the probe. It achieves high contrast and resolution while maintaining imaging rates of thousands of volumes per second. A customized portable ultrasound system was developed to sample 1024 independent channels and to drive a 32 x 32 matrix-array probe. Its ability to track in 3D transient phenomena occurring in the millisecond range within a single ultrafast acquisition was demonstrated for 3D Shear-Wave Imaging, 3D Ultrafast Doppler Imaging, and, finally, 3D Ultrafast combined Tissue and Flow Doppler Imaging. The propagation of shear waves was tracked in a phantom and used to characterize its stiffness. 3D Ultrafast Doppler was used to obtain 3D maps of Pulsed Doppler, Color Doppler, and Power Doppler quantities in a single acquisition and revealed, at thousands of volumes per second, the complex 3D flow patterns occurring in the ventricles of the human heart during an entire cardiac cycle, as well as the 3D in vivo interaction of blood flow and wall motion during the pulse wave in the carotid at the bifurcation. This study demonstrates the potential of 3D Ultrafast Ultrasound Imaging for the 3D mapping of stiffness, tissue motion, and flow in humans in vivo and promises new clinical applications of ultrasound with reduced intra - and inter-observer variability.},
  doi           = {10.1088/0031-9155/59/19/L1},
  keywords      = {3D ultrasound imaging, Folder - HFR US, blood flow, cardiac imaging, tissue Doppler, ultrafast imaging, ultrasound imaging, volumetric imaging},
  mendeley-tags = {Folder - HFR US},
  pmid          = {25207828},
}

@inproceedings{Holm2009,
abstract = {Medical ultrasound imaging has unique requirements regarding spatial and amplitude resolution, near-field focusing, wide bandwidth, and real-time operation. Only recently has Capon beamforming been adapted to this. We give examples of images of point targets, cysts, and regions dominated by speckle and discuss how subaperture smoothing, diagonal loading and range/time averaging must be balanced for best performance. {\textcopyright}2009 IEEE.},
author = {Holm, Sverre and Synnev{\aa}g, Johan Fredrik and Austeng, Andreas},
booktitle = {2009 IEEE 13th Digital Signal Processing Workshop and 5th IEEE Signal Processing Education Workshop, DSP/SPE 2009, Proceedings},
doi = {10.1109/DSP.2009.4785896},
isbn = {9781424436774},
keywords = {Folder - Adaptive beamforming},
mendeley-tags = {Folder - Adaptive beamforming},
pages = {60--65},
publisher = {IEEE},
title = {{Capon beamforming for active ultrasound imaging systems}},
year = {2009}
}

@Misc{Sun2017,
  author        = {Sun, Xu and Ren, Xuancheng and Ma, Shuming and Wang, Houfeng},
  month         = {jun},
  title         = {{meProp: Sparsified back propagation for accelerated deep learning with reduced overfitting}},
  year          = {2017},
  abstract      = {We propose a simple yet effective technique for neural network learning. The forward propagation is computed as usual. In back propagation, only a small subset of the full gradient is computed to update the model parameters. The gradient vectors are sparsified in such a way that only the top-k elements (in terms of magnitude) are kept. As a result, only k rows or columns (depending on the layout) of the weight matrix are modified, leading to a linear reduction (k divided by the vector dimension) in the computational cost. Surprisingly, experimental results demonstrate that we can update only 1-4% of the weights at each back propagation pass. This does not result in a larger number of training iterations. More interestingly, the accuracy of the resulting models is actually improved rather than degraded, and a detailed analysis is given.},
  booktitle     = {arXiv},
  issn          = {23318422},
  keywords      = {Computer Science - Artificial Intelligence, Computer Science - Computation and Language, Computer Science - Computer Vision and Pattern Rec, Computer Science - Machine Learning},
  language      = {en},
  mendeley-tags = {Computer Science - Artificial Intelligence,Computer Science - Computation and Language,Computer Science - Computer Vision and Pattern Rec,Computer Science - Machine Learning},
  shorttitle    = {meProp},
  url           = {http://arxiv.org/abs/1706.06197},
}

@Misc{Elson2011,
  author        = {Elson, Daniel S. and Li, Rui and Dunsby, Christopher and Eckersley, Robert and Tang, Meng Xing},
  title         = {{Ultrasound-mediated optical tomography: A review of current methods}},
  year          = {2011},
  abstract      = {Ultrasound-mediated optical tomography (UOT) is a hybrid technique that is able to combine the high penetration depth and high spatial resolution of ultrasound imaging to overcome the limits imposed by optical scattering for deep tissue optical sensing and imaging. It has been proposed as a method to detect blood concentrations, oxygenation and metabolism at depth in tissue for the detection of vascularized tumours or the presence of absorbing or scattering contrast agents. In this paper, the basic principles of the method are outlined and methods for simulating the UOT signal are described. The main detection methods are then summarized with a discussion of the advantages and disadvantages of each. The recent focus on increasing the weak UOT signal through the use of the acoustic radiation force is explained, together with a summary of our results showing sensitivity to the mechanical shear stiffness and optical absorption properties of tissue-mimicking phantoms. {\textcopyright} 2011 The Royal Society.},
  booktitle     = {Interface Focus},
  doi           = {10.1098/rsfs.2011.0021},
  issn          = {20428901},
  keywords      = {Acoustic radiation force, Acousto-optics, Ultrasound-mediated optical tomography, acoustic radiation force, acousto-optics, ultrasound-mediated optical tomography},
  mendeley-tags = {acoustic radiation force,acousto-optics,ultrasound-mediated optical tomography},
  number        = {4},
  pages         = {632--648},
  url           = {http://rsfs.royalsocietypublishing.org/cgi/doi/10.1098/rsfs.2011.0021},
  volume        = {1},
}

@Misc{Seeger2004,
  author        = {Seeger, Matthias},
  title         = {{Gaussian processes for machine learning.}},
  year          = {2004},
  abstract      = {Gaussian processes (GPs) are natural generalisations of multivariate Gaussian random variables to infinite (countably or continuous) index sets. GPs have been applied in a large number of fields to a diverse range of ends, and very many deep theoretical analyses of various properties are available. This paper gives an introduction to Gaussian processes on a fairly elementary level with special emphasis on characteristics relevant in machine learning. It draws explicit connections to branches such as spline smoothing models and support vector machines in which similar ideas have been investigated. Gaussian process models are routinely used to solve hard machine learning problems. They are attractive because of their flexible non-parametric nature and computational simplicity. Treated within a Bayesian framework, very powerful statistical methods can be implemented which offer valid estimates of uncertainties in our predictions and generic model selection procedures cast as nonlinear optimization problems. Their main drawback of heavy computational scaling has recently been alleviated by the introduction of generic sparse approximations.13,78,31 The mathematical literature on GPs is large and often uses deep concepts which are not required to fully understand most machine learning applications. In this tutorial paper, we aim to present characteristics of GPs relevant to machine learning and to show up precise connections to other "kernel machines" popular in the community. Our focus is on a simple presentation, but references to more detailed sources are provided.},
  address       = {Cambridge, Mass},
  booktitle     = {International journal of neural systems},
  doi           = {10.1142/S0129065704001899},
  isbn          = {978-0-262-18253-9},
  issn          = {01290657},
  keywords      = {Data processing, Gaussian processes, Machine learning, Mathematical models},
  language      = {en},
  mendeley-tags = {Data processing,Gaussian processes,Machine learning,Mathematical models},
  number        = {2},
  pages         = {69--106},
  pmid          = {15112367},
  publisher     = {MIT Press},
  series        = {Adaptive computation and machine learning},
  volume        = {14},
}

@article{Stanford2015,
abstract = {A common problem faced by internet companies is that of recommending new products to users in personalized settings (e.g. Amazon's product recommender system, and Netflix movie recom-mendations). This can be formulated as a learning problem in which we are given the ratings that users have given certain items and are tasked with predicting their ratings for the rest of the items. Formally, if there are n users and m items, we are given an n × m matrix R in which the (u, i) th entry is r ui – the rating for item i by user u. Matrix R has many missing entries indicating unobserved ratings, and our task is to estimate these unobserved ratings.},
author = {Stanford},
journal = {Stanford lecture},
pages = {1--4},
title = {{4.2 Matrix Factorization: Objective and ALS Algorithm on a Single Machine}},
volume = {323},
year = {2015}
}

@article{Stanziola2016,
author = {Stanziola, A. and Tang, Meng-xing},
journal = {The 21 st European Symposium on Ultrasound Contrast Imaging},
number = {January},
title = {{Temporal and spatial processing of high frame-rate contrast enhanced ultrasound data}},
year = {2016}
}

@incollection{Peng2011,
author = {Peng, Hu},
booktitle = {Fourier Transforms - Approach to Scientific Principles},
doi = {10.5772/16022},
keywords = {Folder - Beamforming special},
language = {en},
mendeley-tags = {Folder - Beamforming special},
pages = {22},
title = {{High Frame Rate Ultrasonic Imaging through Fourier Transform using an Arbitrary Known Transmission Field}},
year = {2011}
}

@Article{Strupl2003,
  author        = {{\v{S}}trupl, Miroslav and Sovka, Pavel},
  journal       = {Radioengineering},
  title         = {{Analysis and simulation of frost's beamformer}},
  year          = {2003},
  issn          = {12102512},
  number        = {2},
  pages         = {1--9},
  volume        = {12},
  abstract      = {Sensor arrays are often used for a signal separation from noises using the information about the direction of arrival. The aim of this paper is to analyze Frost's beamformer with respect to the speech preprocessing for the hearing impaired people. The frequency response of the system including the background noise attenuation are derived as functions of the direction of arrival. The derivation supposes a uniform linear array of sensors and plane waves. It is shown that the number of possible configurations can be decreased by using some symmetries. The impact of the used algorithm constraint on the frequency response and subsequently on the directional noise suppression is derived analytically.},
  keywords      = {Adaptive arrays, Folder - Adaptive beamforming, Frost's beamformer, Noise reduction, Speech enhancement},
  mendeley-tags = {Folder - Adaptive beamforming},
}

@InProceedings{Cohen2015,
  author        = {Cohen, Regev and Sde-Chen, Yael and Chernyakova, Tanya and Fraschini, Christophe and Bercoff, Jeremy and Eldar, Yonina C.},
  booktitle     = {2015 IEEE International Ultrasonics Symposium, IUS 2015},
  title         = {{Fourier domain beamforming for coherent plane-wave compounding}},
  year          = {2015},
  pages         = {1--4},
  abstract      = {Ultrafast imaging based on coherent plane-wave compounding is one of the most important recent developments in medical ultrasound. It significantly improves image quality and allows for much faster image acquisition. This method, however, incurs severe computational loads that create a major bottleneck in its implementation using existing commercial systems. To overcome this limitation we translate the beamforming, which is the basic processing step, to the frequency domain. As a result the computations can be carried out much more efficiently and using less data samples. To this end, we extend the frequency domain beamforming (FDBF) framework developed recently for the focused imaging mode to plane-wave imaging. We show that the core of FDBF, the relationship between the beam and the detected signals in the frequency domain, holds and can be implemented efficiently by introducing an appropriate approximation. We also show that dynamic aperture and apodization, crucial for image quality improvement, can be applied directly in frequency as a part of FDBF. The translation of beamforming into the frequency domain allows for data rate reduction by eliminating oversampling, required by digital implementation of beamforming in time. As a result the signals are sampled and processed at their effective Nyquist rate, leading to a 4-fold reduction in the number of samples.},
  doi           = {10.1109/ULTSYM.2015.0127},
  isbn          = {9781479981823},
  keywords      = {Array processing, Folder - Classical beamforming, beamforming, planewave, ultrafast imaging, ultrasound},
  mendeley-tags = {Folder - Classical beamforming},
  url           = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=7329373},
}

@article{,
abstract = {Ultrasound localization microscopy offers new radiation-free diagnostic tools for vascular imaging deep within the tissue. Sequential localization of echoes returned from inert microbubbles with low-concentration within the bloodstream reveal the vasculature with capillary resolution. Despite its high spatial resolution, low microbubble concentrations dictate the acquisition of tens of thousands of images, over the course of several seconds to tens of seconds, to produce a single super-resolved image. Such long acquisition times and stringent constraints on microbubble concentration are undesirable in many clinical scenarios. To address these restrictions, sparsitybased approaches have recently been developed. These methods reduce the total acquisition time dramatically, while maintaining good spatial resolution in settings with considerable microbubble overlap. Here, we further improve sparsity-based superresolution ultrasound imaging by exploiting the inherent ﬂow of microbubbles and utilize their motion kinematics. While doing so, we also provide quantitative measurements of microbubble velocities. Our method relies on simultaneous tracking and superlocalization of individual microbubbles in a frame-by-frame manner, and as such, may be suitable for real-time implementation. We demonstrate the effectiveness of the proposed approach on both simulations and in-vivo contrast enhanced human prostate scans, acquired with a clinically approved scanner.},
keywords = {Folder - Compressed Sensing},
language = {en},
mendeley-tags = {Folder - Compressed Sensing},
pages = {11},
title = {{Exploiting ﬂow dynamics for super-resolution in contrast-enhanced ultrasound}}
}

@Article{Alger2019,
  author        = {Alger, Nick and Rao, Vishwas and Myers, Aaron and Bui-Thanh, Tan and Ghattas, Omar},
  journal       = {SIAM Journal on Scientific Computing},
  title         = {{Scalable matrix-free adaptive product-convolution approximation for locally translation-invariant operators∗}},
  year          = {2019},
  issn          = {10957197},
  month         = {jan},
  number        = {4},
  pages         = {A2296--A2328},
  volume        = {41},
  abstract      = {We present an adaptive grid matrix-free operator approximation scheme based on a “product-convolution” interpolation of convolution operators. This scheme is appropriate for operators that are locally translation-invariant, even if these operators are high rank or full rank. Such operators arise in Schur complement methods for solving partial differential equations (PDEs), as Hessians in PDE-constrained optimization and inverse problems, as integral operators, as covariance operators, and as Dirichlet-to-Neumann maps. Constructing the approximation requires computing the impulse responses of the operator to point sources centered on nodes in an adaptively refined grid of sample points. A randomized a posteriori error estimator drives the adaptivity. Once constructed, the approximation can be efficiently applied to vectors using the fast Fourier transform. The approximation can be efficiently converted to hierarchical matrix (H-matrix) format, then inverted or factorized using scalable H-matrix arithmetic. The quality of the approximation degrades gracefully as fewer sample points are used, allowing cheap lower quality approximations to be used as preconditioners. This yields an automated method to construct preconditioners for locally translation-invariant Schur complements. We directly address issues related to boundaries and prove that our scheme eliminates boundary artifacts. We test the scheme on a spatially varying blurring kernel, on the nonlocal component of an interface Schur complement for the Poisson operator, and on the data misfit Hessian for an advection dominated advection-diffusion inverse problem. Numerical results show that the scheme outperforms existing methods.},
  archiveprefix = {arXiv},
  arxivid       = {1805.06018},
  doi           = {10.1137/18M1189324},
  eprint        = {1805.06018},
  keywords      = {Convolution, Data scalability, Hierarchical matrix, Matrix-free, Operator approximation, PDE constrained inverse problems},
  language      = {en},
  url           = {https://epubs.siam.org/doi/10.1137/18M1189324},
}

@Article{Goldstein2009,
  author   = {Goldstein, Tom and Osher, Stanley},
  journal  = {SIAM Journal on Imaging Sciences},
  title    = {{The split Bregman method for L1-regularized problems}},
  year     = {2009},
  issn     = {19364954},
  month    = {jan},
  number   = {2},
  pages    = {323--343},
  volume   = {2},
  abstract = {The class of L1-regularized optimization problems has received much attention recently because of the introduction of “compressed sensing,” which allows images and signals to be reconstructed from small amounts of data. Despite this recent attention, many L1-regularized problems still remain difficult to solve, or require techniques that are very problem-specific. In this paper, we show that Bregman iteration can be used to solve a wide variety of constrained optimization problems. Using this technique, we propose a “split Bregman” method, which can solve a very broad class of L1- regularized problems. We apply this technique to the Rudin-Osher-Fatemi functional for image denoising and to a compressed sensing problem that arises in magnetic resonance imaging.},
  doi      = {10.1137/080725891},
  keywords = {Compressed sensing, Constrained optimization, L1-regularization, Total variation denoising},
  language = {en},
  url      = {http://epubs.siam.org/doi/10.1137/080725891},
}

@Article{Warner2013,
  author   = {Warner, Michael and Ratcliffe, Andrew and Nangoo, Tenice and Morgan, Joanna and Umpleby, Adrian and Shah, Nikhil and Vinje, Vetle and {\v{S}}tekl, Ivan and Guasch, Llu{\'{i}}s and Win, Caroline and Conroy, Graham and Bertrand, Alexandre},
  journal  = {Geophysics},
  title    = {{Anisotropic 3D full-waveform inversion}},
  year     = {2013},
  issn     = {00168033},
  month    = {mar},
  number   = {2},
  pages    = {R59--R80},
  volume   = {78},
  abstract = {We have developed and implemented a robust and practical scheme for anisotropic 3D acoustic full-waveform inversion (FWI). We demonstrate this scheme on a field data set, applying it to a 4C ocean-bottom survey over the Tommeliten Alpha field in the North Sea. This shallow-water data set provides good azimuthal coverage to offsets of 7 km, with reduced coverage to a maximum offset of about 11 km. The reservoir lies at the crest of a high-velocity antiformal chalk section, overlain by about 3000 m of clastics within which a low-velocity gas cloud produces a seismic obscured area.We inverted only the hydrophone data, and we retained free-surface multiples and ghosts within the field data. We invert in six narrow frequency bands, in the range 3 to 6.5 Hz. At each iteration, we selected only a subset of sources, using a different subset at each iteration; this strategy is more efficient than inverting all the data every iteration. Our starting velocity model was obtained using standard PSDM model building including anisotropic reflection tomography, and contained epsilon values as high as 20%. The final FWI velocity model shows a network of shallow high-velocity channels that match similar features in the reflection data. Deeper in the section, the FWI velocity model reveals a sharper and moreintense low-velocity region associated with the gas cloud in which low-velocity fingers match the location of gas-filled faults visible in the reflection data. The resulting velocity model provides a better match to well logs, and better flattens common- image gathers, than does the starting model. Reverse-time migration, using the FWI velocity model, provides significant uplift to the migrated image, simplifying the planform of the reservoir section at depth. The workflows, inversion strategy, and algorithms that we have used have broad application to invert a wide-range of analogous data sets. {\textcopyright} 2013 Society of Exploration Geophysicists.},
  doi      = {10.1190/GEO2012-0338.1},
  groups   = {Ultrasound and wave imaging},
  language = {en},
  url      = {http://library.seg.org/doi/10.1190/geo2012-0338.1},
}

@inproceedings{Birchfield2002,
abstract = {We derive a probabilistic formulation, based upon Bayes' rule, for the acoustic localization problem. The resulting formula is shown to be closely related to the energy of a conventionally beamformed signal. We then present a close approximation to both which is much faster to compute - by two orders of magnitude with our experimental setup. The fast algorithm is essentially a generalization of approaches based upon time delay estimates (TDE's), by applying the principle of least commitment. Experiments on real signals demonstrate accurate localization in noisy, reverberant environments (less than 3 dB SNR) several times faster than real time.},
author = {Birchfield, Stanley T. and Gillmor, Daniel Kahn},
booktitle = {ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
doi = {10.1109/icassp.2002.5744971},
issn = {15206149},
keywords = {Folder - BSS and acoustic source localization},
mendeley-tags = {Folder - BSS and acoustic source localization},
number = {May},
title = {{Fast Bayesian acoustic localization}},
volume = {2},
year = {2002}
}

@Misc{Raissi2017,
  author        = {Raissi, Maziar and Perdikaris, Paris and Karniadakis, George Em},
  month         = {mar},
  title         = {{Numerical Gaussian Processes for Time-dependent and Non-linear Partial Differential Equations}},
  year          = {2017},
  abstract      = {We introduce the concept of numerical Gaussian processes, which we define as Gaussian processes with covariance functions resulting from temporal discretization of time-dependent partial differential equations. Numerical Gaussian processes, by construction, are designed to deal with cases where: (1) all we observe are noisy data on black-box initial conditions, and (2) we are interested in quantifying the uncertainty associated with such noisy data in our solutions to time-dependent partial differential equations. Our method circumvents the need for spatial discretization of the differential operators by proper placement of Gaussian process priors. This is an attempt to construct structured and data-efficient learning machines, which are explicitly informed by the underlying physics that possibly generated the observed data. The effectiveness of the proposed approach is demonstrated through several benchmark problems involving linear and nonlinear time-dependent operators. In all examples, we are able to recover accurate approximations of the latent solutions, and consistently propagate uncertainty, even in cases involving very long time integration. MSC Codes 65C20, 68T05, 65M75},
  booktitle     = {arXiv},
  issn          = {23318422},
  keywords      = {65C20- 68T05- 65M75, Bayesian modeling, Linear multi-step methods, Mathematics - Analysis of PDEs, Mathematics - Dynamical Systems, Mathematics - Numerical Analysis, Probabilistic machine learning, Runge-Kutta methods, Statistics - Machine Learning, Uncertainty quantification},
  language      = {en},
  mendeley-tags = {65C20- 68T05- 65M75,Mathematics - Analysis of PDEs,Mathematics - Dynamical Systems,Mathematics - Numerical Analysis,Statistics - Machine Learning},
  url           = {http://arxiv.org/abs/1703.10230},
}

@article{Hasegawa2014,
abstract = {High-frame-rate echocardiography using unfocused transmit beams and parallel receive beamforming is a promising method for evaluation of cardiac function, such as imaging of rapid propagation of vibration of the heart wall resulting from electrical stimulation of the myocardium. In this technique, high temporal resolution is realized at the expense of spatial resolution and contrast. The phase coherence factor has been developed to improve spatial resolution and contrast in ultrasonography. It evaluates the variance in phases of echo signals received by individual transducer elements after delay compensation, as in the conventional delay-andsum beamforming process. However, the phase coherence factor suppresses speckle echoes because phases of speckle echoes fluctuate as a result of interference of echoes. In the present study, the receiving aperture was divided into several subapertures, and conventional delay-and-sum beamforming was performed with respect to each subaperture to suppress echoes from scatterers except for that at a focal point. After subaperture beamforming, the phase coherence factor was obtained from beamformed RF signals from respective subapertures. By means of this procedure, undesirable echoes, which can interfere with the echo from a focal point, can be suppressed by subaperture beamforming, and the suppression of the phase coherence factor resulting from phase fluctuation caused by such interference can be avoided. In the present study, the effect of subaperture beamforming in high-frame-rate echocardiography with the phase coherence factor was evaluated using a phantom. By applying subaperture beamforming, the average intensity of speckle echoes from a diffuse scattering medium was significantly higher (-39.9 dB) than that obtained without subaperture beamforming (-48.7 dB). As for spatial resolution, the width at half-maximum of the lateral echo amplitude profile obtained without the phase coherence factor was 1.06 mm. By using the phase coherence factor, spatial resolution was improved significantly, and subaperture beamforming achieved a better spatial resolution of 0.75 mm than that of 0.78 mm obtained without subaperture beamforming.},
author = {Hasegawa, Hideyuki and Kanai, Hiroshi},
doi = {10.1109/TUFFC.2014.006365},
issn = {08853010},
journal = {IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
keywords = {Folder - Correlation approaches},
mendeley-tags = {Folder - Correlation approaches},
number = {11},
pages = {1779--1790},
pmid = {25389157},
title = {{Effect of subaperture beamforming on phase coherence imaging}},
volume = {61},
year = {2014}
}

@InProceedings{Wu2013,
  author        = {Wu, Kaizhi and Zhang, Xuming and Chen, Guangxie and Weng, Fei and Ding, Mingyue},
  booktitle     = {MIPPR 2013: Parallel Processing of Images and Optimization and Medical Imaging Processing},
  title         = {{Respiratory motion compensation algorithm of ultrasound hepatic perfusion data acquired in free-breathing}},
  year          = {2013},
  pages         = {89200I},
  volume        = {8920},
  abstract      = {Images acquired in free breathing using contrast enhanced ultrasound exhibit a periodic motion that needs to be compensated for if a further accurate quantification of the hepatic perfusion analysis is to be executed. In this work, we present an algorithm to compensate the respiratory motion by effectively combining the PCA (Principal Component Analysis) method and block matching method. The respiratory kinetics of the ultrasound hepatic perfusion image sequences was firstly extracted using the PCA method. Then, the optimal phase of the obtained respiratory kinetics was detected after normalizing the motion amplitude and determining the image subsequences of the original image sequences. The image subsequences were registered by the block matching method using cross-correlation as the similarity. Finally, the motion-compensated contrast images can be acquired by using the position mapping and the algorithm was evaluated by comparing the TICs extracted from the original image sequences and compensated image subsequences. Quantitative comparisons demonstrated that the average fitting error estimated of ROIs (region of interest) was reduced from 10.9278 ? 6.2756 to 5.1644 ? 3.3431 after compensating. ? 2013 SPIE.},
  doi           = {10.1117/12.2032179},
  groups        = {Motion},
  isbn          = {9780819498052},
  issn          = {0277786X},
  keywords      = {block matching, contrast-enhanced ultrasound, free-breathing, of ultrasound hepatic, perfusion data acquired in, respiratory motion compensation, respiratory motion compensation algorithm, time intensity curve},
  mendeley-tags = {block matching,contrast-enhanced ultrasound,free-breathing,of ultrasound hepatic,perfusion data acquired in,respiratory motion compensation,respiratory motion compensation algorithm,time intensity curve},
  url           = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?doi=10.1117/12.2032179},
}

@article{,
number = {2},
title = {{Compressed sensing in medical ultrasound.PDF}}
}

@inproceedings{Lediju2010,
abstract = {Conventional ultrasound images are formed by delay-and-sum beamforming ofthe backscattered echoes received by the transducer aperture. Although thedelay-and-sum beamformer is well suited for ultrasound image formation, it ischallenged under non-ideal circumstances, such as the presence of acousticclutter and phase aberration. We propose an alternative method of imagingutilizing the short-lag spatial coherence of the backscattered echoes. Comparedto matched B-mode images, short-lag spatial coherence (SLSC) images demonstratesuperior SNR and CNR in simulated speckle-generating phantom targets. Similarresults are achieved in matched experimental B-mode and SLSC images of aspeckle-generating phantom target, a human thyroid, and a sheep heart. {\textcopyright}2010 IEEE.},
author = {Lediju, Muyinatu A. and Trahey, Gregg E. and Jakovlijevic, Marko and Byram, Brett C. and Dahl, Jeremy J.},
booktitle = {Proceedings - IEEE Ultrasonics Symposium},
doi = {10.1109/ULTSYM.2010.5935711},
isbn = {9781457703829},
issn = {10510117},
keywords = {Folder - Correlation approaches},
mendeley-tags = {Folder - Correlation approaches},
pages = {987--990},
title = {{Short-lag spatial coherence imaging}},
year = {2010}
}

@Article{Malioutov2005,
  author        = {Malioutov, Dmitry and {\c{C}}etin, M{\"{u}}jdat and Willsky, Alan S.},
  journal       = {IEEE Transactions on Signal Processing},
  title         = {{A sparse signal reconstruction perspective for source localization with sensor arrays}},
  year          = {2005},
  issn          = {1053587X},
  number        = {8},
  pages         = {3010--3022},
  volume        = {53},
  abstract      = {We present a source localization method based on a sparse representation of sensor measurements with an overcomplete basis composed of samples from the array manifold. We enforce sparsity by imposing penalties based on the ℓ1-norm. A number of recent theoretical results on sparsifying properties of ℓ1 penalties justify this choice. Explicitly enforcing the sparsity of the representation is motivated by a desire to obtain a sharp estimate of the spatial spectrum that exhibits super-resolution. We propose to use the singular value decomposition (SVD) of the data matrix to summarize multiple time or frequency samples. Our formulation leads to an optimization problem, which we solve efficiently in a second-order cone (SOC) programming framework by an interior point implementation. We propose a grid refinement method to mitigate the effects of limiting estimates to a grid of spatial locations and introduce an automatic selection criterion for the regularization parameter involved in our approach. We demonstrate the effectiveness of the method on simulated data by plots of spatial spectra and by comparing the estimator variance to the Cram{\'{e}}r-Rao bound (CRB). We observe that our approach has a number of advantages over other source localization techniques, including increased resolution, improved robustness to noise, limitations in data quantity, and correlation of the sources, as well as not requiring an accurate initialization. {\textcopyright} 2005 IEEE.},
  doi           = {10.1109/TSP.2005.850882},
  keywords      = {Acoustic sensors, Array signal processing, Direction-of-arrival estimation, Folder - BSS and acoustic source localization, Maximum likelihood estimation, Multiple signal classification, Overcomplete representation, Sensor array processing, Sensor arrays, Signal reconstruction, Signal representations, Signal resolution, Singular value decomposition, Source localization, Sparse representation, Spatial resolution, Superresolution, array signal processing, automatic selection criterion, data matrix, direction-of-arrival estimation, grid refinement method, optimization, overcomplete representation, regularization parameter, second-order cone programming framework, sensor array processing, signal reconstruction, signal representation, signal resolution, signal sampling, signal superresolution, singular value decomposition, source localization, source localization method, sparse representation, sparse signal reconstruction perspective, sparse signal representation, spatial spectrum estimation, superresolution, time-frequency analysis},
  mendeley-tags = {Acoustic sensors,Array signal processing,Direction-of-arrival estimation,Folder - BSS and acoustic source localization,Maximum likelihood estimation,Multiple signal classification,Sensor arrays,Signal reconstruction,Signal representations,Signal resolution,Singular value decomposition,Spatial resolution,array signal processing,automatic selection criterion,data matrix,direction-of-arrival estimation,grid refinement method,optimization,overcomplete representation,regularization parameter,second-order cone programming framework,sensor array processing,signal reconstruction,signal representation,signal resolution,signal sampling,signal superresolution,singular value decomposition,source localization,source localization method,sparse representation,sparse signal reconstruction perspective,sparse signal representation,spatial spectrum estimation,superresolution,time-frequency analysis},
  url           = {http://ieeexplore.ieee.org/xpl/login.jsp?tp=&arnumber=1468495&url=http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1468495%5Cnhttp://ieeexplore.ieee.org/articleDetails.jsp?arnumber=1468495},
}

@InProceedings{Shajkofci2018,
  author        = {Shajkofci, Adrian and Liebling, Michael},
  booktitle     = {Proceedings - International Conference on Image Processing, ICIP},
  title         = {{Semi-blind spatially-variant deconvolution in optical microscopy with local point spread function estimation by use of convolutional neural networks}},
  year          = {2018},
  month         = {oct},
  pages         = {3818--3822},
  abstract      = {We present a semi-blind, spatially-variant deconvolution technique aimed at optical microscopy that combines a local estimation step of the point spread function (PSF) and deconvolution using a spatially variant, regularized Richardson-Lucy algorithm [1]. To find the local PSF map in a computationally tractable way, we train a convolutional neural network to perform regression of an optical parametric model on synthetically blurred image patches. We deconvolved both synthetic and experimentally-acquired data, and achieved an improvement of image SNR of 1.00 dB on average, compared to other deconvolution algorithms.},
  archiveprefix = {arXiv},
  arxivid       = {1803.07452},
  doi           = {10.1109/ICIP.2018.8451736},
  eprint        = {1803.07452},
  isbn          = {9781479970612},
  issn          = {15224880},
  keywords      = {Blind deconvolution, Computer Science - Computer Vision and Pattern Rec, Computer Science - Machine Learning, Convolutional neural networks, Microscopy, Point spread function},
  mendeley-tags = {Computer Science - Computer Vision and Pattern Rec,Computer Science - Machine Learning},
  url           = {http://arxiv.org/abs/1803.07452},
}

@article{Varray2011,
abstract = {The simulation of nonlinear propagation of ultrasound waves is typically based on the Kuznetsov-Zabolotskaya- Khokhlov equation. A set of simulators has been proposed in the literature but none of them takes into account a possible spatial 3-D variation of the nonlinear parameter in the investigated medium. This paper proposes a generalization of the angular spectrum method (GASM) including the spatial variation of the nonlinear parameter. The proposed method computes the evolution of the fundamental and second-harmonic waves in four dimensions (spatial 3-D and time). For validation purposes, the one-way fields produced by the GASM are first compared with those produced by established reference simulators and with experimental one-way fields in media with a homogeneous nonlinear parameter. The same simulations are repeated for media having an axial variation of the nonlinear parameter. The mean errors estimated in the focal region are less than 4.0% for the fundamental and 5.4% for the second harmonic in all cases. Finally, the fundamental and second-harmonic fields simulated for media having nonlinear parameter variations in the axial, lateral, and elevation directions, which cannot be simulated with other currently available methods, are presented. The new approach is also shown to yield a reduction in computation time by a factor of 13 with respect to the standard nonlinear simulator. {\textcopyright} 2011 IEEE.},
author = {Varray, Fran{\c{c}}ois and Ramalli, Alessandro and Cachard, Christian and Tortoli, Piero and Basset, Olivier},
doi = {10.1109/TUFFC.2011.1956},
issn = {08853010},
journal = {IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
number = {7},
pages = {1366--1376},
pmid = {21768021},
title = {{Fundamental and second-harmonic ultrasound field computation of inhomogeneous nonlinear medium with a generalized angular spectrum method}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5953992%5Cnfile:///Users/ket/Documents/Library.papers3/Articles/2011/Varray/IEEE_Trans_Ultrason_Ferroelectr_Freq_Control_2011_Varray.pdf%5Cnpapers3://publication/doi/10.1109/TUFFC.2011.1956},
volume = {58},
year = {2011}
}

@Article{Bouhlel2014,
  author        = {Bouhlel, Nizar and Coron, Alain and Barrois, Guillaume and Lucidarme, Olivier and Bridal, S. Lori},
  journal       = {Ultrasonics},
  title         = {{Dual-mode registration of dynamic contrast-enhanced ultrasound combining tissue and contrast sequences}},
  year          = {2014},
  issn          = {0041624X},
  number        = {5},
  pages         = {1289--1299},
  volume        = {54},
  abstract      = {This study proposes a new method for automatic, iterative image registration in the context of dynamic contrast-enhanced ultrasound (DCE-US) imaging. By constructing a cost function of image registration using a combination of the tissue and contrast-microbubble responses, this new method, referred to as dual-mode registration, performs alignment based on both tissue and vascular structures. Data from five focal liver lesions (FLLs) were used for the evaluation. Automatic registration based on the dual-mode registration technique and tissue-mode registration obtained using the linear response image sequence alone were compared to manual alignment of the sequence by an expert. Comparison of the maximum distance between the transformations applied by the automatic registration techniques and those from expert manual registration reference showed that the dual-mode registration provided better precision than the tissue-mode registration for all cases. The reduction of maximum distance ranged from 0.25 to 9.3 mm. Dual-mode registration is also significantly better than tissue-mode registration for the five sequences with p-values lower than 0.03. The improved sequence alignment is also demonstrated visually by comparison of images from the sequences and the video playbacks of the motion-corrected sequences. This new registration technique better maintains a selected region of interest (ROI) within a fixed position of the image plane throughout the DCE-US sequence. This should reduce motion-related variability of the echo-power estimations and, thus, contribute to more robust perfusion quantification with DCE-US. {\textcopyright} 2014 Elsevier B.V. All rights reserved.},
  doi           = {10.1016/j.ultras.2014.01.005},
  keywords      = {Contrast image, Dynamic contrast-enhanced ultrasound, Maximum distance, Motion compensation, Registration},
  mendeley-tags = {Contrast image,Dynamic contrast-enhanced ultrasound,Maximum distance,Motion compensation,Registration},
  pmid          = {24529339},
  url           = {http://dx.doi.org/10.1016/j.ultras.2014.01.005},
}

@InProceedings{Toulemonde2017,
  author    = {Toulemonde, Matthieu and Duncan, William C. and Stanziola, Antonio and Sboros, Vassilis and Li, Yuanwei and Eckersley, Robert J. and Lin, Shengtao and Tang, Meng Xing and Butler, Mairead},
  booktitle = {IEEE International Ultrasonics Symposium, IUS},
  title     = {{Effects of motion on high frame rate contrast enhanced echocardiography and its correction}},
  year      = {2017},
  pages     = {31--34},
  abstract  = {Contrast echocardiography (CE) ultrasound with microbubble contrast agents have significantly advanced our capability in assessing cardiac function, including myocardium perfusion imaging and quantification. However in conventional CE techniques with line by line scanning, the frame rate is limited to tens of frames per second and image quality is low. Recent research works in high frame-rate (HFR) ultrasound have shown significant improvement of the frame rate in non-contrast cardiac imaging. But with a higher frame rate, the coherent compounding of HFR CE images shows some artifacts due to the motion of the microbubbles. In this work we demonstrate the impact of this motion on compounded HFR CE in simulation and then apply a motion correction algorithm on in-vivo data acquired from the left ventricle (LV) chamber of a sheep. It shows that even if with the fast flow found inside the LV, the contrast is improved at least 100%.},
  doi       = {10.1109/ULTSYM.2017.8092362},
  isbn      = {9781538633830},
  issn      = {19485727},
  keywords  = {Coherent compounding, Contrast enhanced ultrasound, In-vivo High frame rate / ultrafast contrast echoc, Motion effects and correction, Pulse Inversion},
}

@InProceedings{Carvalho2014,
  author        = {Carvalho, Diego D. B. and Akkus, Zeynettin and Bosch, Johan G. and van den Oord, Stijn C. H. and Niessen, Wiro J. and Klein, Stefan},
  booktitle     = {Medical Imaging 2014: Image Processing},
  title         = {{Nonrigid motion compensation in B-mode and contrast enhanced ultrasound image sequences of the carotid artery}},
  year          = {2014},
  pages         = {90340N},
  volume        = {9034},
  abstract      = {In this work, we investigate nonrigid motion compensation in simultaneously acquired (side-by-side) B-mode ultrasound (BMUS) and contrast enhanced ultrasound (CEUS) image sequences of the carotid artery. These images are acquired to study the presence of intraplaque neovascularization (IPN), which is a marker of plaque vulnerability. IPN quantification is visualized by performing the maximum intensity projection (MIP) on the CEUS image sequence over time. As carotid images contain considerable motion, accurate global nonrigid motion compensation (GNMC) is required prior to the MIP. Moreover, we demonstrate that an improved lumen and plaque differentiation can be obtained by averaging the motion compensated BMUS images over time. We propose to use a previously published 2D+t nonrigid registration method, which is based on minimization of pixel intensity variance over time, using a spatially and temporally smooth B-spline deformation model. The validation compares displacements of plaque points with manual trackings by 3 experts in 11 carotids. The average (± standard deviation) root mean square error (RMSE) was 99±74$\mu$m for longitudinal and 47±18$\mu$m for radial displacements. These results were comparable with the interobserver variability, and with results of a local rigid registration technique based on speckle tracking, which estimates motion in a single point, whereas our approach applies motion compensation to the entire image. In conclusion, we evaluated that the GNMC technique produces reliable results. Since this technique tracks global deformations, it can aid in the quantification of IPN and the delineation of lumen and plaque contours. {\textcopyright} 2014 SPIE.},
  doi           = {10.1117/12.2043549},
  isbn          = {9780819498274},
  issn          = {1605-7422},
  keywords      = {atherosclerosis, b-mode, carotid artery, contrast, motion compensation, registration, ultrasound},
  mendeley-tags = {atherosclerosis,b-mode,carotid artery,contrast,motion compensation,registration,ultrasound},
  url           = {http://proceedings.spiedigitallibrary.org/proceeding.aspx?doi=10.1117/12.2043549},
}

@article{Wang2007,
abstract = {Based on the high frame rate (HFR) imaging method developed in our lab, an extended high frame rate imaging method with various transmission schemes was developed recently. In this method, multiple, limiteddiffraction array beams or steered plane wave transmissions are used to increase image resolution and field of view as well as to reduce sidelobes. Furthermore, the multiple, limited-diffraction array beam transmissions can be approximated with square-wave aperture weightings, allowing one or two transmitters to be used with a multielement array transducer to simplify imaging systems. By varying the number of transmissions, the extended HFR imaging method allows a continuous trade-off between image quality and frame rate. Because multiple transmissions are needed to obtain one frame of image for the method, motion could cause phase misalignment and thus produce artifacts, reducing image contrast and resolution and leading to an inaccurate clinical interpretation of images. Therefore, it is important to study how motion affects the method and provide a useful guidance of using the method properly in various applications. In this paper, computer simulations, in vitro and in vivo experiments were performed to study the effects of motion on the method in different conditions. Results show that a number of factors may affect the motion effects. However, it was found that the extended HFR imaging method is not sensitive to the motions commonly encountered in the clinical applications, as is demonstrated by an in vivo heart experiment, unless the number of transmissions is large and objects are moving at a high velocity near the surface of a transducer. {\textcopyright} 2007 IEEE.},
author = {Wang, Jing and Lu, Jian Yu},
doi = {10.1109/TUFFC.2007.391},
issn = {08853010},
journal = {IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
language = {en},
month = {jul},
number = {7},
pages = {1303--1315},
pmid = {17718320},
title = {{Motion artifacts of extended high frame rate imaging}},
url = {http://ieeexplore.ieee.org/document/4277147/},
volume = {54},
year = {2007}
}

@Article{Kim2002,
  author   = {Kim, K. S. and Hwang, J. S. and Jeong, J. S. and Song, T. K.},
  journal  = {Ultrasonic Imaging},
  title    = {{An efficient motion estimation and compensation method for ultrasound synthetic aperture imaging}},
  year     = {2002},
  issn     = {01617346},
  month    = {apr},
  number   = {2},
  pages    = {81--99},
  volume   = {24},
  abstract = {This paper describes a method for overcoming motion artifacts in synthetic aperture imaging. The method is based on a computer simulation study on the influence of target motion on synthetic aperture techniques. A region-based motion compensation approach is used in which only the axial motion is estimated and compensated for a given region of interest under the assumption that the whole ROI moves uniformly. The estimated axial motion is calculated with a crosscorrelation method at the point where the focused signal has the maximum energy within the ROI. We also present a method for estimating axial motion using the autocorrelation method that is widely used to estimate average Doppler frequency. Both computer simulations and in vivo experiments show that the proposed crosscorrelation-based method can greatly improve the spatial resolution and SNR of ultrasound imaging by implementing SA techniques for two-way dynamic focusing without motion artifacts. In addition, the autocorrelation-based motion compensation method provides almost the same results as the crosscorrelation-based method, but with a dramatically reduced computational complexity.},
  doi      = {10.1177/016173460202400202},
  keywords = {Medical ultrasound imaging, Motion compensation, Motion estimation, Phase distortion, Spatial resolution, Synthetic aperture},
  language = {en},
  pmid     = {12199420},
  url      = {http://journals.sagepub.com/doi/10.1177/016173460202400202},
}

@article{Shen2002,
abstract = {Motion artifacts of the pulse inversion technique were studied for finite amplitude distortion-based harmonic imaging. Motion in both the axial and the lateral directions was considered. Two performance issues were investigated. One is the harmonic signal intensity relative to the fundamental intensity and the other is the potential image quality degradation resulting from spectral leakage. A one-dimensional (1-D) correlation-based correction scheme also was used to compensate for motion artifacts. Results indicated that the tissue harmonic signal is significantly affected by tissue motion. For axial motion, the tissue harmonic intensity decreases much more rapidly than with lateral motion. The fundamental signal increases for both axial and lateral motion. Thus, filtering is still required to remove the fundamental signal, even if the pulse inversion technique is applied. The motion also potentially decreases contrast resolution because of the uncancelled spectral leakage. Also, it was indicated that 1-D motion correction is not adequate if nonaxial motion is present.},
author = {Shen, Che Chou and Li, Pai Chi},
doi = {10.1109/TUFFC.2002.1041536},
issn = {08853010},
journal = {IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
number = {9},
pages = {1203--1211},
pmid = {12243571},
title = {{Motion artifacts of pulse inversion-based tissue harmonic imaging}},
volume = {49},
year = {2002}
}

@Article{Poree2016,
  author   = {Poree, Jonathan and Posada, Daniel and Hodzic, Amir and Tournoux, Francois and Cloutier, Guy and Garcia, Damien},
  journal  = {IEEE Transactions on Medical Imaging},
  title    = {{High-Frame-Rate Echocardiography Using Coherent Compounding with Doppler-Based Motion-Compensation}},
  year     = {2016},
  issn     = {1558254X},
  number   = {7},
  pages    = {1647--1657},
  volume   = {35},
  abstract = {High-frame-rate ultrasonography based on coherent compounding of unfocused beams can potentially transform the assessment of cardiac function. As it requires successive waves to be combined coherently, this approach is sensitive to high-velocity tissue motion. We investigated coherent compounding of tilted diverging waves, emitted from a 2.5 MHz clinical phased array transducer. To cope with high myocardial velocities, a triangle transmit sequence of diverging waves is proposed, combined with tissue Doppler imaging to perform motion compensation (MoCo). The compound sequence with integrated MoCo was adjusted from simulations and was tested in vitro and in vivo. Realistic myocardial velocities were analyzed in an in vitro spinning disk with anechoic cysts. While a 8 dB decrease (no motion versus high motion) was observed without MoCo, the contrast-to-noise ratio of the cysts was preserved with the MoCo approach. With this method, we could provide high-quality in vivo B-mode cardiac images with tissue Doppler at 250 frames per second. Although the septum and the anterior mitral leaflet were poorly apparent without MoCo, they became well perceptible and well contrasted with MoCo. The septal and lateral mitral annulus velocities determined by tissue Doppler were concordant with those measured by pulsed-wave Doppler with a clinical scanner (r2=0.7,y=0.9 x+0.5,N=60). To conclude, high-contrast echo cardiographic B-mode and tissue Doppler images can be obtained with diverging beams when motion compensation is integrated in the coherent compounding process.},
  doi      = {10.1109/TMI.2016.2523346},
  keywords = {Diverging beams, high-frame-rate echocardiography, motion compensation, ultrafast ultrasound imaging},
  pmid     = {26863650},
}

@Article{Harput2018,
  author   = {Harput, Sevan and Christensen-Jeffries, Kirsten and Brown, Jemma and Li, Yuanwei and Williams, Katherine J. and Davies, Alun H. and Eckersley, Robert J. and Dunsby, Christopher and Tang, Meng Xing},
  journal  = {IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
  title    = {{Two-Stage Motion Correction for Super-Resolution Ultrasound Imaging in Human Lower Limb}},
  year     = {2018},
  issn     = {08853010},
  month    = {may},
  number   = {5},
  pages    = {803--814},
  volume   = {65},
  abstract = {The structure of microvasculature cannot be resolved using conventional ultrasound (US) imaging due to the fundamental diffraction limit at clinical US frequencies. It is possible to overcome this resolution limitation by localizing individual microbubbles through multiple frames and forming a superresolved image, which usually requires seconds to minutes of acquisition. Over this time interval, motion is inevitable and tissue movement is typically a combination of large- and small-scale tissue translation and deformation. Therefore, super-resolution (SR) imaging is prone to motion artifacts as other imaging modalities based on multiple acquisitions are. This paper investigates the feasibility of a two-stage motion estimation method, which is a combination of affine and nonrigid estimation, for SR US imaging. First, the motion correction accuracy of the proposed method is evaluated using simulations with increasing complexity of motion. A mean absolute error of 12.2 \mu \text{m} was achieved in simulations for the worst-case scenario. The motion correction algorithm was then applied to a clinical data set to demonstrate its potential to enable in vivo SR US imaging in the presence of patient motion. The size of the identified microvessels from the clinical SR images was measured to assess the feasibility of the two-stage motion correction method, which reduced the width of the motion-blurred microvessels to approximately 1.5-fold.},
  doi      = {10.1109/TUFFC.2018.2824846},
  keywords = {Motion correction, motion estimation, non-rigid motion, super-localization, super-resolution imaging},
  language = {en},
  pmid     = {29733283},
  url      = {https://ieeexplore.ieee.org/document/8334280/},
}

@article{Hein1993,
abstract = {The Doppler technique has traditionally been the method used to extract motion information from ultrasonic echoes reflected by moving tissues. The Doppler technique has been around for a long time, and has been extensively reviewed and analyzed in the literature. Recently, time-domain methodologies for estimating tissue motion have gained in popularity. Time-domain methods have advantages over Doppler methods in many applications, and as of yet have not been comprehensively reviewed. The purpose of the paper is to present an overview of time-domain techniques that have appeared in the literature over the past few years; to look at their potential advantages compared to Doppler, and to compare and contrast the individual techniques. {\textcopyright} 1993 IEEE},
author = {Hein, I. A. and {O Brien}, William D.},
doi = {10.1109/58.212556},
issn = {08853010},
journal = {IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
number = {2},
pages = {84--102},
title = {{Current Time-Domain Methods for Assessing Tissue Motion by Analysis from Reflected Ultrasound Echoes—A Review}},
volume = {40},
year = {1993}
}

@Article{TremblayDarveau2016,
  author        = {Tremblay-Darveau, Charles and Williams, Ross and Milot, Laurent and Bruce, Matthew and Burns, Peter N.},
  journal       = {IEEE Transactions on Medical Imaging},
  title         = {{Visualizing the Tumor Microvasculature with a Nonlinear Plane-Wave Doppler Imaging Scheme Based on Amplitude Modulation}},
  year          = {2016},
  issn          = {1558254X},
  number        = {2},
  pages         = {699--709},
  volume        = {35},
  abstract      = {Imaging with ultrasonic plane waves enables the combination of Doppler and microbubble contrast-enhanced imaging without compromising the Doppler ensemble length, as is the case for conventional line-by-line imaging, thus maintaining flow sensitivity. This permits the separation of conduit flow in large vessels from the perfusion background and the presentation of velocity estimates in real-time. However, the ability to differentiate perfusion from the tissue signal is limited by the contrast-to-tissue (CTR) ratio achieved with the contrast-enhanced pulsing sequence, independently of the acquisition length. One way to improve the CTR is to use a Doppler sequence based on amplitude modulation instead of one based on pulse inversion. In this work, we discuss how amplitude modulation can be adapted to Doppler processing. We show that amplitude modulation Doppler, like pulse inversion Doppler, can separate the signal of moving tissue from that of moving microbubbles, while achieving a better contrast-to-tissue ratio than pulse inversion Doppler, both in vitro and in vivo. Both amplitude modulation Doppler and pulse inversion Doppler yield similar velocity estimates when the bandwidth of the RF echo is properly compensated. Finally, we demonstrate how amplitude modulation Doppler can be used to reveal both the conduit flow and the capillary perfusion at high frame rates in an in vivo tumor.},
  doi           = {10.1109/TMI.2015.2491302},
  keywords      = {Amplitude modulation nonlinear doppler, Blood perfusion imaging, Folder - Contrast agents doppler, Microbubbles, Plane-wave ultrasound},
  mendeley-tags = {Amplitude modulation nonlinear doppler,Blood perfusion imaging,Folder - Contrast agents doppler,Microbubbles,Plane-wave ultrasound},
  pmid          = {26485609},
}

@article{Kasai1985,
abstract = {A new blood flow imaging system is described that com-bines a conventional pulsed Doppler device and a newly developed autocorrelator. In the system blood flow within a given cross section of a live organ is displayed in real time. The direction of blood flow and its variance are expressed by means of a difference in color and its hue, respectively. Experiments were conducted with a mechanical and an electrical scanner using phantoms, and good agreement with the theory was obtained. Studies on clinical significance have also been carried out for normal and diseased hearts, and successful results have been found. Copyright {\textcopyright} 1985 by The Institute of Electrical and Electronics Engineers, Inc.},
author = {Kasai, Chihiro and Namekawa, Koroku and Koyano, Akira and Omoto, Ryozo},
doi = {10.1109/T-SU.1985.31615},
issn = {00189537},
journal = {IEEE Transactions on Sonics and Ultrasonics},
keywords = {Folder - 1D Doppler},
mendeley-tags = {Folder - 1D Doppler},
number = {3},
pages = {458--464},
title = {{Real-Time Two-Dimensional Blood Flow Imaging Using an Autocorrelation Technique}},
volume = {32},
year = {1985}
}

@Article{Kim2018,
  author   = {Kim, Minwoo and Zhu, Yang and Hedhli, Jamila and Dobrucki, Lawrence W. and Insana, Michael F.},
  journal  = {IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
  title    = {{Multidimensional Clutter Filter Optimization for Ultrasonic Perfusion Imaging}},
  year     = {2018},
  issn     = {15258955},
  number   = {11},
  pages    = {2020--2029},
  volume   = {65},
  abstract = {Combinations of novel pulse-echo acquisitions and clutter filtering techniques can improve the sensitivity and the specificity of power Doppler (PD) images, thus reducing the need for exogenous contrast enhancement. We acquire echoes following bursts of Doppler pulse transmissions sparsely applied in regular patterns over long durations. The goal is to increase the sensitivity of the acquisition to slow disorganized patterns of motion from the peripheral blood perfusion. To counter a concomitant increase in clutter signal power, we arrange the temporal echo acquisitions into two data-array axes, combine them with a spatial axis for the tissue region of interest, and apply 3-D singular-value decomposition (SVD) clutter filtering. Successful separation of blood echoes from other echo signal sources requires that we partition the 3-D SVD core tensor. Unfortunately, the clutter and blood subspaces do not completely uncouple in all situations, so we developed a statistical classifier that identifies the core tensor subspace dominated by tissue clutter power. This paper describes an approach to subspace partitioning as required for optimizing PD imaging of peripheral perfusion. The technique is validated using echo simulation, flow-phantom data, and in vivo data from a murine melanoma model. We find that for narrow eigen-bandwidth clutter signals, we can routinely map phantom flows and tumor perfusion signals at speeds less than 3 mL/min. The proposed method is well suited to peripheral perfusion imaging applications.},
  doi      = {10.1109/TUFFC.2018.2868441},
  keywords = {Higher order singular-value decomposition (HOSVD), peripheral perfusion imaging, source separation, subspace partitioning},
  language = {en},
  pmid     = {30183625},
  url      = {https://ieeexplore.ieee.org/document/8453905/},
}

@Article{Leow2018,
  author        = {Leow, Chee Hau and Tang, Meng Xing},
  journal       = {Ultrasound in Medicine and Biology},
  title         = {{Spatio-Temporal Flow and Wall Shear Stress Mapping Based on Incoherent Ensemble-Correlation of Ultrafast Contrast Enhanced Ultrasound Images}},
  year          = {2018},
  issn          = {1879291X},
  month         = {jan},
  number        = {1},
  pages         = {134--152},
  volume        = {44},
  abstract      = {In this study, a technique for high-frame-rate ultrasound imaging velocimetry (UIV) is extended first to provide more robust quantitative flow velocity mapping using ensemble correlation of images without coherent compounding, and second to generate spatio-temporal wall shear stress (WSS) distribution. A simulation model, which couples the ultrasound simulator with analytical flow solution, was implemented to evaluate its accuracy. It is shown that the proposed approach can reduce errors in velocity estimation by up to 10-fold in comparison with the coherent correlation approach. Mean errors (ME) of 3.2% and 8.6% were estimated under a steady flow condition, while 3.0% and 10.6% were found under a pulsatile condition for the velocity and wall shear rate (WSR) measurement, respectively. Appropriate filter parameters were selected to constrain the velocity profiles before WSR estimations and the effects of incorrect wall tracking were quantified under a controlled environment. Although accurate wall tracking is found to be critical in WSR measurement (as a 200 µm deviation from the wall may yield up to a 60% error), this can be mitigated by HFR imaging (of up to 10 kHz) with contrast agents, which allow for improved differentiation of the wall-fluid boundaries. In vitro investigations on two carotid bifurcation phantoms, normal and diseased, were conducted, and their relative differences in terms of the flow patterns and WSR distribution were demonstrated. It is shown that high-frame-rate UIV technique can be a non-invasive tool to measure quantitatively the spatio-temporal velocity and WSS distribution.},
  doi           = {10.1016/j.ultrasmedbio.2017.08.930},
  keywords      = {Contrast enhanced ultrasound, Flow measurement, Folder - advanced doppler, Image tracking, Microbubble contrast agents, Motion effect, Ultrafast ultrasound imaging, Wall shear rate},
  language      = {en},
  mendeley-tags = {Folder - advanced doppler},
  pmid          = {29037843},
  url           = {https://linkinghub.elsevier.com/retrieve/pii/S0301562917312917},
}

@Article{Correia2016,
  author        = {Correia, Mafalda and Provost, Jean and Chatelin, Simon and Villemain, Olivier and Tanter, Mickael and Pernot, Mathieu},
  journal       = {IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
  title         = {{Ultrafast Harmonic Coherent Compound (UHCC) Imaging for High Frame Rate Echocardiography and Shear-Wave Elastography}},
  year          = {2016},
  issn          = {08853010},
  number        = {3},
  pages         = {420--431},
  volume        = {63},
  abstract      = {Transthoracic shear-wave elastography (SWE) of the myocardium remains very challenging due to the poor quality of transthoracic ultrafast imaging and the presence of clutter noise, jitter, phase aberration, and ultrasound reverberation. Several approaches, such as diverging-wave coherent compounding or focused harmonic imaging, have been proposed to improve the imaging quality. In this study, we introduce ultrafast harmonic coherent compounding (UHCC), in which pulse-inverted diverging waves are emitted and coherently compounded, and show that such an approach can be used to enhance both SWE and high frame rate (FR) B-mode Imaging. UHCC SWE was first tested in phantoms containing an aberrating layer and was compared against pulse-inversion harmonic imaging and against ultrafast coherent compounding (UCC) imaging at the fundamental frequency. In vivo feasibility of the technique was then evaluated in six healthy volunteers by measuring myocardial stiffness during diastole in transthoracic imaging. We also demonstrated that improvements in imaging quality could be achieved using UHCC B-mode imaging in healthy volunteers. The quality of transthoracic images of the heart was found to be improved with the number of pulse-inverted diverging waves with a reduction of the imaging mean clutter level up to 13.8 dB when compared against UCC at the fundamental frequency. These results demonstrated that UHCC B-mode imaging is promising for imaging deep tissues exposed to aberration sources with a high FR.},
  doi           = {10.1109/TUFFC.2016.2530408},
  keywords      = {Cardiac stiffness, Folder - Cardiac, coherent compounding, pulse-inversion (PI) harmonic imaging, shear-wave elastography (SWE), ultrafast imaging},
  mendeley-tags = {Cardiac stiffness,Folder - Cardiac,coherent compounding,pulse-inversion (PI) harmonic imaging,shear-wave elastography (SWE),ultrafast imaging},
  pmid          = {26890730},
}

@article{Stanziola2016a,
abstract = {Medical ultrasound (US) imaging, also known as echography, is one of the most frequently used frontline clinical imaging modalities and is characterized by its safety, affordability, accessibility, and real-time image display. Sound pulses, typically in the megahertz range, are sent into the body and the backscattered echoes are used to create a tomographic image. The contrast of an US image arises from local variations in the physical properties of the tissues, primarily density and elasticity, revealing tissue structures at depth.},
author = {Stanziola, Antonio and Toulemonde, Matthieu and Yildiz, Yesna O. and Eckersley, Robert J. and Tang, Meng Xing},
doi = {10.1109/MSP.2015.2496914},
issn = {10535888},
journal = {IEEE Signal Processing Magazine},
keywords = {Folder - Contrast agents detection},
mendeley-tags = {Folder - Contrast agents detection},
number = {2},
pages = {111--117},
title = {{Ultrasound imaging with microbubbles}},
volume = {33},
year = {2016}
}

@Article{Bercoff2011,
  author        = {Bercoff, Jeremy and Montaldo, Gabriel and Loupas, Thanasis and Savery, David and M{\'{e}}zi{\`{e}}re, Fabien and Fink, Mathias and Tanter, Mickael},
  journal       = {IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
  title         = {{Ultrafast compound doppler imaging: Providing full blood flow characterization}},
  year          = {2011},
  issn          = {08853010},
  number        = {1},
  pages         = {134--147},
  volume        = {58},
  abstract      = {Doppler-based flow analysis methods require acquisition of ultrasound data at high spatio-temporal sampling rates. These rates represent a major technical challenge for ultrasound systems because a compromise between spatial and temporal resolution must be made in conventional approaches. Consequently, ultrasound scanners can either provide full quantitative Doppler information on a limited sample volume (spectral Doppler), or averaged Doppler velocity and/or power estimation on a large region of interest (Doppler flow imaging). In this work, we investigate a different strategy for acquiring Doppler information that can overcome the limitations of the existing Doppler modes by significantly reducing the required acquisition time. This technique is called ultrafast compound Doppler imaging and is based on the following concept: instead of successively insonifying the medium with focused beams, several tilted plane waves are sent into the medium and the backscattered signals are coherently summed to produce highresolution ultrasound images. We demonstrate that this strategy allows reduction of the acquisition time by a factor of up to of 16 while keeping the same Doppler performance. Depending on the application, different directions to increase performance of Doppler analysis are proposed and the improvement is quantified: the ultrafast compound Doppler method allows faster acquisition frame rates for high-velocity flow imaging, or very high sensitivity for low-flow applications. Full quantitative Doppler flow analysis can be performed on a large region of interest, leading to much more information and improved functionality for the physician. By leveraging the recent emergence of ultrafast parallel beamforming systems, this paper demonstrates that breakthrough performances in flow analysis can be reached using this concept of ultrafast compound Doppler. {\textcopyright} 2011 IEEE.},
  doi           = {10.1109/TUFFC.2011.1780},
  keywords      = {Algorithms, Computer-Assisted, Computer-Assisted: methods, Doppler, Doppler: methods, Folder - advanced doppler, Humans, Image Processing, Imaging, Phantoms, Signal Processing, Time Factors, Ultrasonography},
  mendeley-tags = {Algorithms,Computer-Assisted,Computer-Assisted: methods,Doppler,Doppler: methods,Folder - advanced doppler,Humans,Image Processing,Imaging,Phantoms,Signal Processing,Time Factors,Ultrasonography},
  pmid          = {21244981},
  url           = {http://www.ncbi.nlm.nih.gov/pubmed/21244981},
}

@Article{Viti2016,
  author        = {Viti, Jacopo and Vos, Hendrik J. and Jong, Nico De and Guidi, Francesco and Tortoli, Piero},
  journal       = {IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
  title         = {{Detection of Contrast Agents: Plane Wave Versus Focused Transmission}},
  year          = {2016},
  issn          = {08853010},
  month         = {feb},
  number        = {2},
  pages         = {203--211},
  volume        = {63},
  abstract      = {Ultrasound contrast agent (UCA) imaging provides a cost-effective diagnostic tool to assess tissue perfusion and vascular pathologies. However, excessive transmission (TX) levels may negatively impact both uniform diffusion and survival rates of contrast agents, limiting their density and thus their echogenicity. Contrast detection methods with both high sensitivity and low-contrast destruction rate are thus essential to maintain diagnostic capabilities. Plane-wave TX with a high number of compounding angles has been suggested to produce good quality images at pressure levels that do not destroy UCA. In this paper, we performed a quantitative evaluation of detection efficacy of flowing UCA with either traditional focused scanning or ultrafast plane-wave imaging. Amplitude modulation (AM) at nondestructive pressure levels was implemented in the ULA-OP ultrasound research platform. The influence of the number of compounding angles, peak-negative pressure, and flow speed on the final image quality was investigated. Results show that the images obtained by compounding multiple angled plane waves offer a greater contrast (up to a 12-dB increase) with respect to focused AM. This increase is attributed mainly to noise reduction caused by the coherent summation in the compounding step. Additionally, we show that highly sensitive detection is already achieved with a limited compounding number (N < 16), thus suggesting the feasibility of continuous contrast monitoring at a high frame rate. This capability is essential to properly detect contrast agents flowing at high speed, as an excessive angle compounding is shown to be destructive for the contrast signal, as the UCA motion quickly causes loss of correlation between consecutive echoes.},
  doi           = {10.1109/TUFFC.2015.2504546},
  keywords      = {Compounding, Contrast to tissue ratio, Folder - Contrast agents detection, High frame rate imaging, Plane wave imaging, Ultrasound contrast agents},
  language      = {en},
  mendeley-tags = {Folder - Contrast agents detection},
  pmid          = {26642451},
  shorttitle    = {Detection of Contrast Agents},
  url           = {http://ieeexplore.ieee.org/document/7342972/},
}

@Article{Lin2015,
  author        = {Lin, Fanglue and Cachard, Christian and Varray, Fran{\c{c}}ois and Basset, Olivier},
  journal       = {Ultrasonic Imaging},
  title         = {{Generalization of multipulse transmission techniques for ultrasound imaging}},
  year          = {2015},
  issn          = {01617346},
  month         = {oct},
  number        = {4},
  pages         = {294--311},
  volume        = {37},
  abstract      = {To increase the contrast-to-tissue ratio (CTR) in contrast imaging or the signal-to-noise ratio (SNR) in tissue harmonic imaging, many multipulse transmission techniques have been suggested. This article first recalls the various imaging techniques proposed in the literature and then presents a mathematical background to synthesize and generalize most of the multipulse ultrasound imaging techniques. The formulation presented can be used to predict the relative amplitude of the nonlinear components in each frequency band and to design new transmission sequences to either increase or decrease specified nonlinear components in each harmonic band. Simulation results on several multipulse techniques agree with the results from previous studies.},
  doi           = {10.1177/0161734614566696},
  keywords      = {Folder - Contrast agents detection, harmonic imaging, multipulse transmission, nonlinear imaging, ultrasound contrast agents, ultrasound imaging},
  language      = {en},
  mendeley-tags = {Folder - Contrast agents detection},
  pmid          = {25628094},
  url           = {http://journals.sagepub.com/doi/10.1177/0161734614566696},
}

@Misc{VanRooij2015,
  author        = {{Van Rooij}, Tom and Daeichin, Verya and Skachkov, Ilya and {De Jong}, Nico and Kooiman, Klazina},
  title         = {{Targeted ultrasound contrast agents for ultrasound molecular imaging and therapy}},
  year          = {2015},
  abstract      = {Ultrasound contrast agents (UCAs) are used routinely in the clinic to enhance contrast in ultrasonography. More recently, UCAs have been functionalised by conjugating ligands to their surface to target specific biomarkers of a disease or a disease process. These targeted UCAs (tUCAs) are used for a wide range of pre-clinical applications including diagnosis, monitoring of drug treatment, and therapy. In this review, recent achievements with tUCAs in the field of molecular imaging, evaluation of therapy, drug delivery, and therapeutic applications are discussed. We present the different coating materials and aspects that have to be considered when manufacturing tUCAs. Next to tUCA design and the choice of ligands for specific biomarkers, additional techniques are discussed that are applied to improve binding of the tUCAs to their target and to quantify the strength of this bond. As imaging techniques rely on the specific behaviour of tUCAs in an ultrasound field, it is crucial to understand the characteristics of both free and adhered tUCAs. To image and quantify the adhered tUCAs, the state-of-the-art techniques used for ultrasound molecular imaging and quantification are presented. This review concludes with the potential of tUCAs for drug delivery and therapeutic applications.},
  booktitle     = {International Journal of Hyperthermia},
  doi           = {10.3109/02656736.2014.997809},
  issn          = {14645157},
  keywords      = {Drug delivery, Folder - Contrast agents applications, Microbubble, Molecular imaging, Targeted ultrasound contrast agents, Therapy},
  mendeley-tags = {Folder - Contrast agents applications},
  number        = {2},
  pages         = {90--106},
  pmid          = {25707815},
  volume        = {31},
}

@Article{Errico2016,
  author        = {Errico, Claudia and Osmanski, Bruno F{\'{e}}lix and Pezet, Sophie and Couture, Olivier and Lenkei, Zsolt and Tanter, Mickael},
  journal       = {NeuroImage},
  title         = {{Transcranial functional ultrasound imaging of the brain using microbubble-enhanced ultrasensitive Doppler}},
  year          = {2016},
  issn          = {10959572},
  pages         = {752--761},
  volume        = {124},
  abstract      = {Functional ultrasound (fUS) is a novel neuroimaging technique, based on high-sensitivity ultrafast Doppler imaging of cerebral blood volume, capable of measuring brain activation and connectivity in rodents with high spatiotemporal resolution (100 $\mu$m, 1 ms). However, the skull attenuates acoustic waves, so fUS in rats currently requires craniotomy or a thinned-skull window. Here we propose a non-invasive approach by enhancing the fUS signal with a contrast agent, inert gas microbubbles. Plane-wave illumination of the brain at high frame rate (500 Hz compounded sequence with three tilted plane waves, PRF = 1500Hz with a 128 element 15 MHz linear transducer), yields highly-resolved neurovascular maps. We compared fUS imaging performance through the intact skull bone (transcranial fUS) versus a thinned-skull window in the same animal. First, we show that the vascular network of the adult rat brain can be imaged transcranially only after a bolus intravenous injection of microbubbles, which leads to a 9 dB gain in the contrast-to-tissue ratio. Next, we demonstrate that functional increase in the blood volume of the primary sensory cortex after targeted electrical-evoked stimulations of the sciatic nerve is observable transcranially in presence of contrast agents, with high reproducibility (Pearson's coefficient $\rho$ = 0.7 ± 0.1, p = 0.85). Our work demonstrates that the combination of ultrafast Doppler imaging and injection of contrast agent allows non-invasive functional brain imaging through the intact skull bone in rats. These results should ease non-invasive longitudinal studies in rodents and open a promising perspective for the adoption of highly resolved fUS approaches for the adult human brain.},
  doi           = {10.1016/j.neuroimage.2015.09.037},
  keywords      = {Blood volume, Folder - Contrast agents detection, Functional ultrasound imaging, Microbubbles, Primary sensory cortex, Somatosensory activation, Transcranial},
  mendeley-tags = {Blood volume,Folder - Contrast agents detection,Functional ultrasound imaging,Microbubbles,Primary sensory cortex,Somatosensory activation,Transcranial},
  pmid          = {26416649},
  url           = {http://dx.doi.org/10.1016/j.neuroimage.2015.09.037},
}

@InProceedings{Bassi2012,
  author        = {Bassi, L. and Ricci, S. and Tortoli, P.},
  booktitle     = {IEEE International Ultrasonics Symposium, IUS},
  title         = {{Real-time vector velocity profile measurement based on plane wave transmission}},
  year          = {2012},
  pages         = {338--341},
  abstract      = {Standard Doppler ultrasound investigations are limited to detect the axial blood velocity component, as they cannot directly estimate the flow direction. A typical approach for obtaining a 2D velocity vector consists in combining the echoes received from two PW lines investigating the region of interest from different angles. The estimate is usually limited to the sample volume (SV) where the focused lines intersect. To get a complete picture of flow distribution, at least the entire velocity profile across a vessel must be reconstructed. In this work, we propose exploiting the plane waves originated from two different sub-arrays of a linear probe, to estimate the vector velocities in 512 SVs aligned to cover the diameter of large vessels. The method was tested on a laminar flow in a 8 mm diameter pipe. The probe was placed longitudinally over the pipe and the angle, a, between the probe surface and the pipe axis, was changed in the range 0°∼20°. In particular, at $\alpha$ = 12°, the flow was perpendicular to one of the plane waves. The direction measurements featured a gain accuracy of 0.89 and a standard deviation (SD) < 1.8°, while the velocity magnitude featured an average 2.8% overestimation with a coefficient of variation less than 1%. {\textcopyright} 2012 IEEE.},
  doi           = {10.1109/ULTSYM.2012.0083},
  isbn          = {9781467345613},
  issn          = {19485719},
  keywords      = {Blood velocity measurement, Doppler angle ambiguity, Doppler effect, Doppler measurement, Fluid flow measurement, Folder - Vector doppler, Plane Waves, Probes, Standards, Ultrasonic imaging, Vector Multigate Doppler, Vectors, Velocity measurement, biomedical ultrasonics, blood velocity component, blood vessel, blood vessels, direction measurement, flow distribution, laminar flow, pipe, plane wave transmission, real-time systems, real-time vector velocity profile measurement, size 8 mm, standard Doppler ultrasound, standard deviation},
  mendeley-tags = {Blood velocity measurement,Doppler angle ambiguity,Doppler effect,Doppler measurement,Fluid flow measurement,Folder - Vector doppler,Plane Waves,Probes,Standards,Ultrasonic imaging,Vector Multigate Doppler,Vectors,Velocity measurement,biomedical ultrasonics,blood velocity component,blood vessel,blood vessels,direction measurement,flow distribution,laminar flow,pipe,plane wave transmission,real-time systems,real-time vector velocity profile measurement,size 8 mm,standard Doppler ultrasound,standard deviation},
  url           = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6562392},
}

@Article{Leow2015a,
  author        = {Leow, Chee Hau and Iori, Francesco and Corbett, Richard and Duncan, Neill and Caro, Colin and Vincent, Peter and Tang, Meng Xing},
  journal       = {Ultrasound in Medicine and Biology},
  title         = {{Microbubble void imaging: A non-invasive technique for flow visualisation and quantification of mixing in large vessels using plane wave ultrasound and controlled microbubble contrast agent destruction}},
  year          = {2015},
  issn          = {1879291X},
  number        = {11},
  pages         = {2926--2937},
  volume        = {41},
  abstract      = {There is increasing recognition of the influence of the flow field on the physiology of blood vessels and their development of pathology. Preliminary work is reported on a novel non-invasive technique, microbubble void imaging, which is based on ultrasound and controlled destruction of microbubble contrast agents, permitting flow visualisation and quantification of flow-induced mixing in large vessels. The generation of microbubble voids can be controlled both spatially and temporally using ultrasound parameters within the safety limits. Three different model vessel geometries-straight, planar-curved and helical-with known effects on the flow field and mixing were chosen to evaluate the technique. A high-frame-rate ultrasound system with plane wave transmission was used to acquire the contrast-enhanced ultrasound images, and an entropy measure was calculated to quantify mixing. The experimental results were cross-compared between the different geometries and with computational fluid dynamics. The results indicated that the technique is able to quantify the degree of mixing within the different configurations, with a helical geometry generating the greatest mixing, and a straight geometry, the lowest. There is a high level of concordance between the computational fluid dynamics and experimental results. The technique could also serve as a flow visualisation tool.},
  doi           = {10.1016/j.ultrasmedbio.2015.06.023},
  keywords      = {Contrast-enhanced ultrasound, Flow indicator, Folder - Contrast agents detection, High-frame-rate plane wave imaging, Microbubble contrast agents, Microbubble void imaging, Mixing},
  mendeley-tags = {Contrast-enhanced ultrasound,Flow indicator,Folder - Contrast agents detection,High-frame-rate plane wave imaging,Microbubble contrast agents,Microbubble void imaging,Mixing},
  pmid          = {26297515},
}

@article{Tang2006,
abstract = {Microbubble contrast agents produce nonlinear echoes under ultrasound insonation, and current imaging techniques detect these nonlinear echoes to generate contrast agent images accordingly. For these techniques, there is a potential problem in that bubbles along the ultrasound transmission path between transducer and target can alter the ultrasound transmission nonlinearly and contribute to the nonlinear echoes. This can lead to imaging artefacts, especially in regions at depth. In this paper we provide insight, through both simulation and experimental measurement, into the nonlinear propagation caused by microbubbles and the implications for current imaging techniques. A series of investigations at frequencies below, at, and above the resonance frequency of microbubbles were performed. Three specific effects on the pulse propagation (i.e., amplitude attenuation, phase changes, and harmonic generation) were studied. It was found that all these effects are dependent on the initial pulse amplitude, and their dependence on the initial phase of the pulse is shown to be insignificant. Two types of imaging errors are shown to result from this nonlinear propagation: first, that tissue can be misclassified as microbubbles; second, the concentration of microbubbles in the image can be misrepresented. It is found that these imaging errors are significant for all three pulse frequencies when the pulses transmit through a microbubble suspension of 6 cm in path length. It also is found that the first type of error is larger at the bubble resonance frequency. {\textcopyright} 2006 IEEE.},
author = {Tang, Meng Xing and Eckersley, Robert J.},
doi = {10.1109/TUFFC.2006.189},
issn = {08853010},
journal = {IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
keywords = {Folder - Contrast agents detection},
mendeley-tags = {Folder - Contrast agents detection},
number = {12},
pages = {2406--2415},
pmid = {17186923},
title = {{Nonlinear propagation of ultrasound through microbubble contrast agents and implications for imaging}},
volume = {53},
year = {2006}
}

@article{Analysis,
archivePrefix = {arXiv},
arxivId = {arXiv:1611.06391v2},
author = {Analysis, Homology and Han, Yo Seob and Yoo, Jaejun and Ye, Jong Chul},
eprint = {arXiv:1611.06391v2},
file = {:home/antonio/Documents/bibliography/files/Analysis et al. - Unknown - Deep Residual Learning for Compressed Sensing CT Reconstruction.pdf:pdf},
title = {{Deep Residual Learning for Compressed Sensing CT Reconstruction}}
}

@Article{Wei1998,
  author        = {Wei, Kevin and Jayaweera, Ananda R. and Firoozan, Soroosh and Linka, Andre and Skyba, Danny M. and Kaul, Sanjiv},
  journal       = {Circulation},
  title         = {{Quantification of myocardial blood flow with ultrasound-induced destruction of microbubbles administered as a constant venous infusion}},
  year          = {1998},
  issn          = {00097322},
  number        = {5},
  pages         = {473--483},
  volume        = {97},
  abstract      = {Background-Ultrasound can cause microbubble destruction. If microbubbles are administered as a continuous infusion, then their destruction within the myocardium and measurement of their myocardial reappearance rate at steady state will provide a measure of mean myocardial microbubble velocity. Conversely, measurement of their myocardial concentration at steady state will provide an assessment of microvascular cross-sectional area. Myocardial blood flow (MBF) can then be calculated from the product of the two. Methods and Results-Ex vivo and in vitro experiments were performed in which either flow was held constant and pulsing interval (interval between microbubble destruction and replenishment) was altered, or vice versa. In vivo experiments were performed in 21 dogs. In group 1 dogs (n=7), MBF was mechanically altered in a model in which coronary blood volume was constant. In group 2 dogs (n=5), MBF was altered by direct coronary infusions of vasodilators. In group 3 dogs (n=9), non-flow-limiting coronary stenoses were created, and MBF was measured before and after the venous administration of a coronary vasodilator. In all experiments, microbubbles were delivered as a constant infusion, and myocardial contrast echocardiography was performed using different pulsing intervals. The myocardial video intensity versus pulsing interval plots were fitted to an exponential function: y=A(1-e(- $\beta$t)), where A is the plateau video intensity reflecting the microvascular cross-sectional area, and $\beta$ reflects the rate of rise of video intensity and, hence, microbubble velocity. Excellent correlations were found between flow and $\beta$, as well as flow and the product of A and $\beta$. Conclusions-MBF can be quantified with myocardial contrast echocardiography during a venous infusion of microbubbles. This novel approach has potential for measuring tissue perfusion in any organ accessible to ultrasound.},
  doi           = {10.1161/01.CIR.97.5.473},
  keywords      = {Blood flow, Contrast media, Echocardiography, Folder - Cardiac, Microcirculation, echocardiography ⅲ contrast media, microcirculation, ⅲ blood flow ⅲ},
  mendeley-tags = {Folder - Cardiac,echocardiography ⅲ contrast media,microcirculation,ⅲ blood flow ⅲ},
  pmid          = {9490243},
}

@InProceedings{Couture2008,
  author        = {Couture, Olivier and Aubry, Jean Fran{\c{c}}ois and Montaldo, Gabriel and Tanter, Mickael and Fink, Mathias},
  booktitle     = {Proceedings - IEEE Ultrasonics Symposium},
  title         = {{Tissue harmonics cancellation using time-reversal}},
  year          = {2008},
  address       = {Beijing, China},
  month         = {nov},
  pages         = {1104--1107},
  publisher     = {IEEE},
  abstract      = {Pulse-inversion sequences are sensitive to the nonlinear echoes from microbubbles allowing an improvement in the bloodto- tissue contrast. However, at larger mechanical indexes, this contrast is reduced by harmonics produced during nonlinear propagation. A method for tissue harmonics cancellation exploiting time-reversal is experimentally implemented using a 128-channel 12-bit emitter-receiver. The probe calibration is performed by acquiring the nonlinear echo of a wire in water. These distorted pulses are time-reversed, optimized and used for the pulse-inversion imaging of a tissue phantom. Compared to normal (straight) pulses, the time-reversed distorted pulses reduced the tissue signal in pulse-inversion by 11 dB. The second harmonics signal from microbubbles flowing in a wall-less vessel was unaffected by the correction. This technique can thus increase the blood-to-tissue contrast ratio while keeping the pressure and the number of pulses constant. {\textcopyright}2008 IEEE.},
  doi           = {10.1109/ULTSYM.2008.0266},
  isbn          = {978-1-4244-2428-3},
  issn          = {10510117},
  keywords      = {Cancellation, Folder - Contrast agents detection, Nonlinear propagation, Pulseinversion, Tissue harmonics},
  language      = {en},
  mendeley-tags = {Folder - Contrast agents detection},
  url           = {http://ieeexplore.ieee.org/document/4803417/},
}

@InProceedings{Osmanski2012,
  author        = {Osmanski, Bruno Felix and Montaldo, Gabriel and Bercoff, Jeremy and Loupas, Thanasis and Fink, Mathias and Tanter, Mickael},
  booktitle     = {IEEE International Ultrasonics Symposium, IUS},
  title         = {{Ultrafast plane wave imaging: Doppler frequency distribution}},
  year          = {2012},
  pages         = {1580--1583},
  abstract      = {Ultrafast plane wave imaging enables the acquisition of thousands of temporal samples per second over a large field of view compared to the scarce 100 frames per second of a conventional focused mode. However, a main problem remains: How to compute with this huge amount of data relevant information for diagnosis? In this article, we present a statistical technique that analyses the spatio-temporal distribution of the Doppler frequency. This statistical technique gives a two dimensional output frequency versus time as the standard pulse wave Doppler commonly used by sonographers but reduces dramatically the presence of geometric broadening on Doppler spectrums. Thereby, this technique becomes highly sensitive to the type of the flow profile and turbulences which could help to diagnosis vascular diseases as plaques in the carotid artery. By summarizing all the main information contained in the ultrafast acquisition it permits a direct visualization of the flow speed and its gradient. We compare this statistical technique and a standard pulse wave Doppler in vivo on the carotid artery. {\textcopyright} 2012 IEEE.},
  doi           = {10.1109/ULTSYM.2012.0395},
  isbn          = {9781467345613},
  issn          = {19485719},
  keywords      = {- ultrafast imaging, Folder - 1D Doppler, Ultrafast Doppler, Ultrafast imaging, a 2d output in, a frequency-time space, acquisition data to give, in a similar manner, one solution could be, screening, than the standard pulse, to post process the, ultrafast, ultrafast doppler, wave doppler},
  mendeley-tags = {- ultrafast imaging,Folder - 1D Doppler,a 2d output in,a frequency-time space,acquisition data to give,in a similar manner,one solution could be,screening,than the standard pulse,to post process the,ultrafast,ultrafast doppler,wave doppler},
  url           = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6562183},
}

@article{Gessner2013,
abstract = {The purpose of this paper is to provide the biomedical imaging community with details of a new high resolution contrast imaging approach referred to as "acoustic angiography." Through the use of dual-frequency ultrasound transducer technology, images acquired with this approach possess both high resolution and a high contrast-to-tissue ratio, which enables the visualization of microvascular architecture without significant contribution from background tissues. Additionally, volumetric vessel-tissue integration can be visualized by using b-mode overlays acquired with the same probe. We present a brief technical overview of how the images are acquired, followed by several examples of images of both healthy and diseased tissue volumes. 3D images from alternate modalities often used in preclinical imaging, contrast-enhanced micro-CT and photoacoustics, are also included to provide a perspective on how acoustic angiography has qualitatively similar capabilities to these other techniques. These preliminary images provide visually compelling evidence to suggest that acoustic angiography may serve as a powerful new tool in preclinical and future clinical imaging. {\textcopyright} 2013 Ryan C. Gessner et al.},
author = {Gessner, Ryan C. and Frederick, C. Brandon and Foster, F. Stuart and Dayton, Paul A.},
doi = {10.1155/2013/936593},
issn = {16874188},
journal = {International Journal of Biomedical Imaging},
title = {{Acoustic angiography: A new imaging modality for assessing microvasculature architecture}},
volume = {2013},
year = {2013}
}

@Misc{Correas2006,
  author        = {Correas, Jean Michel and Claudon, Michel and Tranquart, Fran{\c{c}}ois and H{\'{e}}l{\'{e}}non, Olivier},
  title         = {{The kidney: Imaging with microbubble contrast agents}},
  year          = {2006},
  abstract      = {Conventional ultrasonography of the kidney is faced by limitations due to the poor contrast of B-mode imaging for parenchymal disease and limited sensitivity of color Doppler for the detection of intracortical capillaries and deep pedicular vessels. Ultrasound contrast agents (USCAs) overcome these limitations, allowing the development of new applications for renal blood flow imaging and quantification. These improvements result from the increased acoustic response obtained from the microbubbles, as well as from the development of pulse sequences for bubble-specific imaging. In radiology, the liver has been considered as the primary target for contrast because USCAs allow both detection and characterization of focal lesions. The kidney has been less studied because USCA kinetics do not provide the same obvious potential for tumor characterization, and most clinical trials for contrast-enhanced renal imaging were conducted using color Doppler. Despite this, the kidney offers promising applications as USCAs improve the detection of abnormal microvascular and macrovascular disorders. Contrast-enhanced US may become the modality of choice for diagnosis of renal artery stenosis and detection of a perfusion deficit, as well as for characterization of indeterminate renal lesions, atypical cystic lesions, and the identification of acute pyelonephritis. {\textcopyright} 2006 Lippincott Williams & Wilkins, Inc.},
  booktitle     = {Ultrasound Quarterly},
  issn          = {08948771},
  keywords      = {Folder - Contrast agents applications, Kidney infection, Kidney nephritis, Kidney transplantation, Kidney ultrasound, Ultrasound contrast media},
  mendeley-tags = {Folder - Contrast agents applications},
  number        = {1},
  pages         = {53--66},
  pmid          = {16641794},
  volume        = {22},
}

@Article{Goldberg1994,
  author        = {Goldberg, Barry B. and Liu, Ji Bin and Forsberg, Flemming},
  journal       = {Ultrasound in Medicine and Biology},
  title         = {{Ultrasound contrast agents: A review}},
  year          = {1994},
  issn          = {03015629},
  number        = {4},
  pages         = {319--333},
  volume        = {20},
  abstract      = {During the past 25 years, many attempts have been made to establish effective ultrasound contrast agents for both cardiac and noncardiac applications. The ideal ultrasound contrast agent would be: (a) nontoxic; (b) injectable intravenously; (c) capable of passing through the pulmonary, cardiac and capillary circulations; and (d) stable for recirculation. A variety of potential ultrasound contrast agents have been or are now under development. Present and future ultrasound contrast agents should provide for increased diagnostic capabilities in a variety of normal and abnormal vessels and organs throughout the body. These agents will enhance tumor vascularity, delineate areas of ischemia, as well as improve visualization of vascular stenosis. Future developments with modification of ultrasound equipment should increase the capabilities of these agents to improve imaging as well as Doppler sensitivity. {\textcopyright} 1994.},
  doi           = {10.1016/0301-5629(94)90001-9},
  keywords      = {Contrast agents, Doppler, Folder - Contrast agents detection, Tumors, Ultrasound, Vascularity},
  mendeley-tags = {Folder - Contrast agents detection},
  pmid          = {8085289},
}

@article{Errico2015,
abstract = {Non-invasive imaging deep into organs at microscopic scales remains an open quest in biomedical imaging. Although optical microscopy is still limited to surface imaging owing to optical wave diffusion and fast decorrelation in tissue, revolutionary approaches such as fluorescence photo-activated localization microscopy led to a striking increase in resolution by more than an order of magnitude in the last decade. In contrast with optics, ultrasonic waves propagate deep into organs without losing their coherence and are much less affected by in vivo decorrelation processes. However, their resolution is impeded by the fundamental limits of diffraction, which impose a long-standing trade-off between resolution and penetration. This limits clinical and preclinical ultrasound imaging to a sub-millimetre scale. Here we demonstrate in vivo that ultrasound imaging at ultrafast frame rates (more than 500 frames per second) provides an analogue to optical localization microscopy by capturing the transient signal decorrelation of contrast agents - inert gas microbubbles. Ultrafast ultrasound localization microscopy allowed both non-invasive sub-wavelength structural imaging and haemodynamic quantification of rodent cerebral microvessels (less than ten micrometres in diameter) more than ten millimetres below the tissue surface, leading to transcranial whole-brain imaging within short acquisition times (tens of seconds). After intravenous injection, single echoes from individual microbubbles were detected through ultrafast imaging. Their localization, not limited by diffraction, was accumulated over 75,000 images, yielding 1,000,000 events per coronal plane and statistically independent pixels of ten micrometres in size. Precise temporal tracking of microbubble positions allowed us to extract accurately in-plane velocities of the blood flow with a large dynamic range (from one millimetre per second to several centimetres per second). These results pave the way for deep non-invasive microscopy in animals and humans using ultrasound. We anticipate that ultrafast ultrasound localization microscopy may become an invaluable tool for the fundamental understanding and diagnostics of various disease processes that modify the microvascular blood flow, such as cancer, stroke and arteriosclerosis.},
author = {Errico, Claudia and Pierre, Juliette and Pezet, Sophie and Desailly, Yann and Lenkei, Zsolt and Couture, Olivier and Tanter, Mickael},
doi = {10.1038/nature16066},
issn = {14764687},
journal = {Nature},
keywords = {Folder - Contrast agents detection},
mendeley-tags = {Folder - Contrast agents detection},
number = {7579},
pages = {499--502},
pmid = {26607546},
title = {{Ultrafast ultrasound localization microscopy for deep super-resolution vascular imaging}},
url = {http://www.nature.com/doifinder/10.1038/nature16066%5Cnhttp://www.ncbi.nlm.nih.gov/pubmed/26607546},
volume = {527},
year = {2015}
}

@Article{Yiu2014,
  author        = {Yiu, Billy Y.S. and Lai, Simon S.M. and Yu, Alfred C.H.},
  journal       = {Ultrasound in Medicine and Biology},
  title         = {{Vector Projectile Imaging: Time-Resolved Dynamic Visualization of Complex Flow Patterns}},
  year          = {2014},
  issn          = {1879291X},
  number        = {9},
  pages         = {2295--2309},
  volume        = {40},
  abstract      = {Achieving non-invasive, accurate and time-resolved imaging of vascular flow with spatiotemporal fluctuations is well acknowledged to be an ongoing challenge. In this article, we present a new ultrasound-based framework called vector projectile imaging (VPI) that can dynamically render complex flow patterns over an imaging view at millisecond time resolution. VPI is founded on three principles: (i) high-frame-rate broad-view data acquisition (based on steered plane wave firings); (ii) flow vector estimation derived from multi-angle Doppler analysis (coupled with data regularization and least-squares fitting); (iii) dynamic visualization of color-encoded vector projectiles (with flow speckles displayed as adjunct). Calibration results indicated that by using three transmit angles and three receive angles (-10°, 0°, +10° for both), VPI can consistently compute flow vectors in a multi-vessel phantom with three tubes positioned at different depths (1.5, 4, 6 cm), oriented at different angles (-10°, 0°, +10°) and of different sizes (dilated diameter: 2.2, 4.4 and 6.3 mm; steady flow rate: 2.5 mL/s). The practical merit of VPI was further illustrated through an anthropomorphic flow phantom investigation that considered both healthy and stenosed carotid bifurcation geometries. For the healthy bifurcation with 1.2-Hz carotid flow pulses, VPI was able to render multi-directional and spatiotemporally varying flow patterns (using a nominal frame rate of 416 fps or 2.4-ms time resolution). In the case of stenosed bifurcations (50% eccentric narrowing), VPI enabled dynamic visualization of flow jet and recirculation zones. These findings suggest that VPI holds promise as a new tool for complex flow analysis. {\textcopyright} 2014 World Federation for Ultrasound in Medicine & Biology.},
  doi           = {10.1016/j.ultrasmedbio.2014.03.014},
  keywords      = {Complex flow analysis, Dynamic visualization, Folder - Vector doppler, Ultrasound flow imaging, Vector estimation, Vector projectile},
  mendeley-tags = {Complex flow analysis,Dynamic visualization,Folder - Vector doppler,Ultrasound flow imaging,Vector estimation,Vector projectile},
  pmid          = {24972498},
}

@article{Bohs1998,
abstract = {We describe a new method, called Ensemble Tracking, for estimating two-dimensional velocities with ultrasound. Compared to previous speckle tracking techniques, Ensemble Tracking measures motion over smaller times and distances, increasing maximum velocities and reducing errors due to echo decorrelation. Ensemble Tracking uses parallel receive processing, 2D pattern matching, and interpolation of the resulting tracking grid to estimate subpixel speckle translations between successive ultrasonic acquisitions. In this study, small translations of a tissue mimicking phantom were quantified at transducer angles of 0°, 45°. and 90°. Measurements over three parallel beam spacings and all transducer angles liad mean errors from -4% to +11%, when parallel beam amplitudes were normalized. Such amplitude normalization substantially improved results at 45° and 90°. The amplitude, spacing, and correlation between the parallel beams were quantified, and their effects on the accuracy and precision of estimates are discussed. Finally, initial clinical results demonstrate the ability to track and display blood flow in the carotid artery. {\textcopyright} 1998 IEEE.},
author = {Bohs, Laurence N. and Geiman, Beth J. and Anderson, Martin E. and Breit, Sean M. and Trahey, Gregg E.},
doi = {10.1109/58.710557},
issn = {08853010},
journal = {IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
keywords = {Folder - Vector doppler},
mendeley-tags = {Folder - Vector doppler},
number = {4},
pages = {912--924},
title = {{Ensemble tracking for 2D vector velocity measurement: experimental and initial clinical results}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18244246},
volume = {45},
year = {1998}
}

@Article{Armstrong2008,
  author        = {Armstrong, William F. and Ryan, Thomas},
  journal       = {Journal of the American Society of Echocardiography},
  title         = {{Stress Echocardiography from 1979 to Present}},
  year          = {2008},
  issn          = {08947317},
  month         = {jan},
  number        = {1},
  pages         = {22--28},
  volume        = {21},
  abstract      = {Stress echocardiography was initially developed in 1979 and has seen substantial success in the evaluation of patients with known or suspected coronary artery disease. It has proven applicable to clinical questions of diagnosis, prognosis and follow-up. It has been heavily dependent on technologic advancements, initially digital capturing for side-by-side visualization and, more recently, developments in detailed methods of evaluating myocardial mechanics and contrast echocardiography for perfusion. {\textcopyright} 2008 American Society of Echocardiography.},
  doi           = {10.1016/j.echo.2007.11.005},
  keywords      = {Coronary artery disease, Folder - Contrast agents applications, Myocardial ischemia, Prognosis, Stress echocardiography, Viability},
  language      = {en},
  mendeley-tags = {Folder - Contrast agents applications},
  pmid          = {18165125},
  url           = {http://linkinghub.elsevier.com/retrieve/pii/S0894731707008103},
}

@Article{Wang2016,
  author        = {Wang, Diya and Zong, Yujin and Yang, Xuan and Hu, Hong and Wan, Jinjin and Zhang, Lei and Bouakaz, Ayache and Wan, Mingxi},
  journal       = {Ultrasound in Medicine and Biology},
  title         = {{Ultrasound contrast plane wave imaging based on bubble wavelet transform: In vitro and in vivo validations}},
  year          = {2016},
  issn          = {1879291X},
  number        = {7},
  pages         = {1584--1597},
  volume        = {42},
  abstract      = {The aim of the study described here was to develop an ultrasound contrast plane wave imaging (PWI) method based on pulse-inversion bubble wavelet transform imaging (PIWI) to improve the contrast-to-tissue ratio of contrast images. A pair of inverted "bubble wavelets" with plane waves was constructed according to the modified Herring equation. The original echoes were replaced by the maximum wavelet correlation coefficients obtained from bubble wavelet correlation analysis. The echoes were then summed to distinguish microbubbles from tissues. In in vivo experiments on rabbit kidney, PIWI improved the contrast-to-tissue ratio of contrast images up to 4.5 ± 1.5 dB, compared with that obtained in B-mode (p < 0.05), through use of a pair of inverted plane waves. The disruption rate and infusion time of microbubbles in PIWI-based PWI were then quantified using two perfusion parameters, area under the curve and half transmit time estimated from time-intensity curves, respectively. After time-intensity curves were denoised by detrended fluctuation analysis, the average area under the curve and half transit time of PIWI-based PWI were 55.94% (p < 0.05) and 20.51% (p < 0.05) higher than those of conventional focused imaging, respectively. Because of its high contrast-to-tissue ratio and low disruption of microbubbles, PIWI-based PWI has a long infusion time and is therefore beneficial for transient monitoring and perfusion assessment of microbubbles circulating in vessels.},
  doi           = {10.1016/j.ultrasmedbio.2016.02.002},
  keywords      = {Bubble wavelet, Detrended fluctuation analysis, Folder - Contrast agents detection, Plane wave imaging, Ultrasound contrast imaging, bubble wavelet, detrended fluctuation analysis, plane wave imaging, ultrasound contrast imaging},
  mendeley-tags = {Folder - Contrast agents detection,bubble wavelet,detrended fluctuation analysis,plane wave imaging,ultrasound contrast imaging},
  pmid          = {27067280},
}

@Article{Fraser2017,
  author        = {Fraser, Katharine H. and Poelma, Christian and Zhou, Bin and Bazigou, Eleni and Tang, Meng Xing and Weinberg, Peter D.},
  journal       = {Journal of the Royal Society Interface},
  title         = {{Ultrasound imaging velocimetry with interleaved images for improved pulsatile arterial flow measurements: A new correction method, experimental and in vivo validation}},
  year          = {2017},
  issn          = {17425662},
  number        = {127},
  pages         = {20160761},
  volume        = {14},
  abstract      = {Blood velocity measurements are important in physiological science and clinical diagnosis. Doppler ultrasound is the most commonly used method but can only measure one velocity component. Ultrasound imaging velocimetry (UIV) is a promising technique capable of measuring two velocity components; however, there is a limit on the maximum velocity that can be measured with conventional hardware which results from the way images are acquired by sweeping the ultrasound beam across the field of view. Interleaved UIV is an extension of UIV in which two image frames are acquired concurrently, allowing the effective interframe separation time to be reduced and therefore increasing the maximum velocity that can be measured. The sweeping of the ultrasound beam across the image results in a systematic error which must be corrected: in this work, we derived and implemented a new velocity correction method which accounts for acceleration of the scatterers. We then, for the first time, assessed the performance of interleaved UIV for measuring pulsatile arterial velocities by measuring flows in phantoms and in vivo and comparing the results with spectral Doppler ultrasound and transit-time flow probe data. The velocity and flow rate in the phantom agreed within 5-10% of peak velocity, and 2-9% of peak flow, respectively, and in vivo the velocity difference was 9% of peak velocity. The maximum velocity measured was 1.8 m s21, the highest velocity reported with UIV. This will allow flows in diseased arteries to be investigated and so has the potential to increase diagnostic accuracy and enable new vascular research.},
  doi           = {10.1098/rsif.2016.0761},
  keywords      = {Atherosclerosis, Blood flow, Echo-PIV, Folder - Vector doppler, Haemodynamics, Particle image velocimetry, Ultrasound, bioengineering, biomedical engineering},
  mendeley-tags = {Folder - Vector doppler,bioengineering,biomedical engineering},
  pmid          = {28148767},
  url           = {http://rsif.royalsocietypublishing.org/lookup/doi/10.1098/rsif.2016.0761},
}

@Article{Frinking2000,
  author        = {Frinking, Peter J.A. and Bouakaz, Ayache and Kirkhorn, Johan and {Ten Cate}, Folkert J. and {De Jong}, Nico},
  journal       = {Ultrasound in Medicine and Biology},
  title         = {{Ultrasound contrast imaging: Current and new potential methods}},
  year          = {2000},
  issn          = {03015629},
  number        = {6},
  pages         = {965--975},
  volume        = {26},
  abstract      = {For 10 years, it was thought that ultrasound (US) contrast agents could be sufficiently detected and imaged with the conventional imaging techniques, now referred to as fundamental imaging. However, it turned out that fundamental imaging was not sensitive enough to detect the contrast agents in the presence of tissue. New imaging techniques that are based on specific properties of the contrast agents, such as nonlinear and transient scattering, proved to be more sensitive. US contrast imaging modalities used today are fundamental, second harmonic, harmonic power Doppler, and pulse inversion; new modalities, such as release burst and subharmonic imaging are emerging. Second harmonic imaging is still not optimal for perfusion imaging applications. However, in combination with Doppler techniques such as power Doppler, it is one of the most sensitive techniques currently available. A complete understanding of the US-contrast agent interaction is essential for further improvements of current detection methods, and the development of new imaging techniques. (C) 2000 World Federation for Ultrasound in Medicine and Biology.},
  doi           = {10.1016/S0301-5629(00)00229-5},
  keywords      = {Contrast agents, Folder - Contrast agents detection, Ultrasound imaging},
  mendeley-tags = {Folder - Contrast agents detection},
  pmid          = {10996696},
}

@Article{Torp1995,
  author        = {Torp, Hans and Kristoffersen, Kjell},
  journal       = {Ultrasound in Medicine and Biology},
  title         = {{Velocity matched spectrum analysis: A new method for suppressing velocity ambiguity in pulsed-wave Doppler}},
  year          = {1995},
  issn          = {03015629},
  month         = {jan},
  number        = {7},
  pages         = {937--944},
  volume        = {21},
  abstract      = {A new approach to spectrum analysis, which is capable of suppressing velocity ambiguity in pulsed-wave ultrasonic Doppler, is presented. By simultaneous processing of several data samples from a range in depth, the movement of the scatterers along the ultrasonic beam can be tracked from pulse to pulse for each velocity component in the spectrum. In this way the correlation length of the signal component arising from a specific velocity increases when that velocity matches the expected velocity. The resulting velocity/time spectral display shows a more clearly defined spectral envelope of the maximum velocity than with conventional methods based on the discrete Fourier transform of the Doppler signal. This makes it possible to delineate velocity waveforms with peak velocity up to several times the Nyquist limit. Experimental data from human subclavian and aortic arteries are presented, where the new method is compared to conventional spectrum analysis. {\textcopyright} 1995.},
  doi           = {10.1016/0301-5629(95)00039-T},
  keywords      = {Blood flow, Doppler signal processing, Folder - advanced doppler, Pulsed Doppler ultrasound, Spectrum analysis},
  language      = {en},
  mendeley-tags = {Folder - advanced doppler},
  pmid          = {7491748},
  shorttitle    = {Velocity matched spectrum analysis},
  url           = {http://linkinghub.elsevier.com/retrieve/pii/030156299500039T},
}

@Article{Lin2017a,
  author        = {Lin, Shengtao and Shah, Anant and Hern{\'{a}}ndez-Gil, Javier and Stanziola, Antonio and Harriss, Bethany I. and Matsunaga, Terry O. and Long, Nicholas and Bamber, Jeffrey and Tang, Meng Xing},
  journal       = {Photoacoustics},
  title         = {{Optically and acoustically triggerable sub-micron phase-change contrast agents for enhanced photoacoustic and ultrasound imaging}},
  year          = {2017},
  issn          = {22135979},
  pages         = {26--36},
  volume        = {6},
  abstract      = {We demonstrate a versatile phase-change sub-micron contrast agent providing three modes of contrast enhancement: 1) photoacoustic imaging contrast, 2) ultrasound contrast with optical activation, and 3) ultrasound contrast with acoustic activation. This agent, which we name ‘Cy-droplet', has the following novel features. It comprises a highly volatile perfluorocarbon for easy versatile activation, and a near-infrared optically absorbing dye chosen to absorb light at a wavelength with good tissue penetration. It is manufactured via a ‘microbubble condensation' method. The phase-transition of Cy-droplets can be optically triggered by pulsed-laser illumination, inducing photoacoustic signal and forming stable gas bubbles that are visible with echo-ultrasound in situ. Alternatively, Cy-droplets can be converted to microbubble contrast agents upon acoustic activation with clinical ultrasound. Potentially all modes offer extravascular contrast enhancement because of the sub-micron initial size. Such versatility of acoustic and optical ‘triggerability' can potentially improve multi-modality imaging, molecularly targeted imaging and controlled drug release.},
  doi           = {10.1016/j.pacs.2017.04.001},
  keywords      = {Droplet, Folder - Contrast agents applications, Microbubble, Multispectral optoacoustic tomography (MSOT), Optical/acoustic vaporisation, Phase-change contrast agent, Photoacoustic, Ultrasound},
  mendeley-tags = {Droplet,Folder - Contrast agents applications,Microbubble,Multispectral optoacoustic tomography (MSOT),Optical/acoustic vaporisation,Phase-change contrast agent,Photoacoustic,Ultrasound},
}

@article{Papadacci2014,
abstract = {Noninvasive ultrafast imaging of intrinsic waves such as electromechanical waves or remotely induced shear waves in elastography imaging techniques for human cardiac applications remains challenging. In this paper, we propose ultrafast imaging of the heart with adapted sector size by coherently compounding diverging waves emitted from a standard transthoracic cardiac phased-array probe. As in ultrafast imaging with plane wave coherent compounding, diverging waves can be summed coherently to obtain high-quality images of the entire heart at high frame rate in a full field of view. To image the propagation of shear waves with a large SNR, the field of view can be adapted by changing the angular aperture of the transmitted wave. Backscattered echoes from successive circular wave acquisitions are coherently summed at every location in the image to improve the image quality while maintaining very high frame rates. The transmitted diverging waves, angular apertures, and subaperture sizes were tested in simulation, and ultrafast coherent compounding was implemented in a commercial scanner. The improvement of the imaging quality was quantified in phantoms and in one human heart, in vivo. Imaging shear wave propagation at 2500 frames/s using 5 diverging waves provided a large increase of the SNR of the tissue velocity estimates while maintaining a high frame rate. Finally, ultrafast imaging with 1 to 5 diverging waves was used to image the human heart at a frame rate of 4500 to 900 frames/s over an entire cardiac cycle. Spatial coherent compounding provided a strong improvement of the imaging quality, even with a small number of transmitted diverging waves and a high frame rate, which allows imaging of the propagation of electromechanical and shear waves with good image quality. {\textcopyright} 2014 IEEE.},
author = {Papadacci, Clement and Pernot, Mathieu and Couade, Mathieu and Fink, Mathias and Tanter, Mickael},
doi = {10.1109/TUFFC.2014.6722614},
issn = {08853010},
journal = {IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
keywords = {Folder - Cardiac},
mendeley-tags = {Folder - Cardiac},
number = {2},
pages = {288--301},
pmid = {24474135},
title = {{High-contrast ultrafast imaging of the heart}},
volume = {61},
year = {2014}
}

@Article{Osmanski2012a,
  author        = {Osmanski, Bruno Felix and Pernot, Mathieu and Montaldo, Gabriel and Bel, Alain and Messas, Emmanuel and Tanter, Mickael},
  journal       = {IEEE Transactions on Medical Imaging},
  title         = {{Ultrafast doppler imaging of blood flow dynamics in the myocardium}},
  year          = {2012},
  issn          = {02780062},
  number        = {8},
  pages         = {1661--1668},
  volume        = {31},
  abstract      = {Imaging intramyocardial vascular flows in real-time could strongly help to achieve better diagnostic of cardiovascular diseases. To date, no standard imaging modality allows describing accurately myocardial blood flow dynamics with good spatial and temporal resolution. We recently introduced a novel ultrasonic Doppler imaging technique based on compounded plane waves transmissions at ultrafast frame rate. The high sensitivity of this ultrafast Doppler technique permits to image the intramyocardial blood flow and its dynamics. A dedicated demodulation-filtering process is implemented to compensate for the large tissue velocity of the myocardium during the cardiac cycle. A signed power Doppler processing provides the discrimination between arterial and venous flows. Experiments were performed in vivo in a large animal open chest model (N = 5 sheep) using a conventional ultrasonic probe placed at the surface of the heart. Results show the capability of the technique to image intramyocardial vascular flows in normal physiological conditions with good spatial (200 $\mu$m) and temporal resolution (10 ms). Flow dynamics over the cardiac cycle were investigated and the imaging method demonstrated a phase opposition of flow waveforms between arterial and venous flows. Finally, ultrafast Doppler combined with tissue motion compensation was found able to reveal vascular flow disruption in ischemic regions during occlusion of the main diagonal coronary artery. {\textcopyright} 2012 IEEE.},
  doi           = {10.1109/TMI.2012.2203316},
  keywords      = {Animals, Blood Flow Velocity, Blood Flow Velocity: physiology, Blood flow, Coronary Vessels, Coronary Vessels: physiology, Coronary Vessels: ultrasonography, Doppler, Doppler: methods, Echocardiography, Folder - Cardiac, Heart, Heart: physiology, Myocardial Ischemia, Myocardial Ischemia: physiopathology, Sheep, heart, ultrafast imaging, ultrasound},
  mendeley-tags = {Animals,Blood Flow Velocity,Blood Flow Velocity: physiology,Coronary Vessels,Coronary Vessels: physiology,Coronary Vessels: ultrasonography,Doppler,Doppler: methods,Echocardiography,Folder - Cardiac,Heart,Heart: physiology,Myocardial Ischemia,Myocardial Ischemia: physiopathology,Sheep},
  pmid          = {22717520},
  url           = {http://www.ncbi.nlm.nih.gov/pubmed/22717520},
}

@Article{Eckersley2005,
  author        = {Eckersley, Robert J. and Chin, Chien Ting and Burns, Peter N.},
  journal       = {Ultrasound in Medicine and Biology},
  title         = {{Optimising phase and amplitude modulation schemes for imaging microbubble contrast agents at low acoustic power}},
  year          = {2005},
  issn          = {03015629},
  number        = {2},
  pages         = {213--219},
  volume        = {31},
  abstract      = {A series of in vitro experiments were performed to determine the efficacy of generalised phase- and amplitude-modulated sequences for low-power nonlinear microbubble contrast imaging. The microbubble agent Definity{\textregistered} (Dupont, Boston, MA) was exposed to sequences in which the phase and amplitude were changed from one pulse to the next. Echoes from these pulses were combined to suppress or enhance particular linear or nonlinear components. The results show that established two-pulse pulse-inversion and amplitude-modulation approaches perform similarly, providing 14 ± 1 dB of enhancement, compared with the echoes from the linear scatterer. A two-pulse combined phase and amplitude sequence achieved an additional 4 ± 1 dB of enhancement. This improvement is due to improved preservation of second and third order harmonic signals, while maintaining the suppression of the linear signals. These results were obtained at low power, below the threshold of microbubble destruction, and are applicable to real-time perfusion imaging. {\textcopyright} 2005 World Federation for Ultrasound in Medicine & Biology.},
  doi           = {10.1016/j.ultrasmedbio.2004.10.004},
  keywords      = {Contrast microbubble, Folder - Contrast agents detection, Multipulse imaging, Optimisation, Pulse sequences, Ultrasound contrast agents},
  mendeley-tags = {Contrast microbubble,Folder - Contrast agents detection,Multipulse imaging,Optimisation,Pulse sequences,Ultrasound contrast agents},
  pmid          = {15708461},
}

@Article{Li2015,
  author        = {Li, You Leo and Dahl, Jeremy J.},
  journal       = {IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
  title         = {{Coherent flow power doppler (CFPD): Flow detection using spatial coherence beamforming}},
  year          = {2015},
  issn          = {08853010},
  number        = {6},
  pages         = {1022--1035},
  volume        = {62},
  abstract      = {Power Doppler imaging is a widely used method of flow detection for tissue perfusion monitoring, inflammatory hyperemia detection, deep vein thrombosis diagnosis, and other clinical applications. However, thermal noise and clutter limit its sensitivity and ability to detect slow flow. In addition, large ensembles are required to obtain sufficient sensitivity, which limits frame rate and yields flash artifacts during moderate tissue motion. We propose an alternative method of flow detection using the spatial coherence of backscattered ultrasound echoes. The method enhances slow flow detection and frame rate, while maintaining or improving the signal quality of conventional power Doppler techniques. The feasibility of this method is demonstrated with simulations, flow-phantom experiments, and an in vivo human thyroid study. In comparison with conventional power Doppler imaging, the proposed method can produce Doppler images with 15- to 30-dB SNR improvement. Therefore, the method is able to detect flow with velocities approximately 50% lower than conventional power Doppler, or improve the frame rate by a factor of 3 with comparable image quality. The results show promise for clinical applications of the method.},
  doi           = {10.1109/TUFFC.2014.006793},
  keywords      = {Blood, Doppler effect, Folder - Adaptive Doppler, Phantoms, Signal to noise ratio, Spatial coherence},
  mendeley-tags = {Blood,Doppler effect,Folder - Adaptive Doppler,Phantoms,Signal to noise ratio,Spatial coherence},
  pmid          = {26067037},
  url           = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=4467462&tool=pmcentrez&rendertype=abstract},
}

@Article{Li2018,
  author        = {Li, Yuanwei and Ho, Chin Pang and Toulemonde, Matthieu and Chahal, Navtej and Senior, Roxy and Tang, Meng Xing},
  journal       = {IEEE Transactions on Medical Imaging},
  title         = {{Fully automatic myocardial segmentation of contrast echocardiography sequence using random forests guided by shape model}},
  year          = {2018},
  issn          = {1558254X},
  number        = {5},
  pages         = {1081--1091},
  volume        = {37},
  abstract      = {Myocardial contrast echocardiography (MCE) is an imaging technique that assesses left ventricle function and myocardial perfusion for the detection of coronary artery diseases. Automatic MCE perfusion quantification is challenging and requires accurate segmentation of the myocardium from noisy and time-varying images. Random forests (RF) have been successfully applied to many medical image segmentation tasks. However, the pixel-wise RF classifier ignores contextual relationships between label outputs of individual pixels. RF which only utilizes local appearance features is also susceptible to data suffering from large intensity variations. In this paper, we demonstrate how to overcome the above limitations of classic RF by presenting a fully automatic segmentation pipeline for myocardial segmentation in full-cycle 2-D MCE data. Specifically, a statistical shape model is used to provide shape prior information that guide the RF segmentation in two ways. First, a novel shape model (SM) feature is incorporated into the RF framework to generate a more accurate RF probability map. Second, the shape model is fitted to the RF probability map to refine and constrain the final segmentation to plausible myocardial shapes. We further improve the performance by introducing a bounding box detection algorithm as a preprocessing step in the segmentation pipeline. Our approach on 2-D image is further extended to 2-D+t sequences which ensures temporal consistency in the final sequence segmentations. When evaluated on clinical MCE data sets, our proposed method achieves notable improvement in segmentation accuracy and outperforms other state-of-the-art methods, including the classic RF and its variants, active shape model and image registration.},
  archiveprefix = {arXiv},
  arxivid       = {1806.07497},
  doi           = {10.1109/TMI.2017.2747081},
  eprint        = {1806.07497},
  keywords      = {Echocardiography, Folder - Cardiac, Image segmentation, Myocardium, Radio frequency, Random forest, Shape, Two dimensional displays, contrast echocardiography, convolutional neural network, myocardial segmentation, statistical shape model},
  mendeley-tags = {Echocardiography,Folder - Cardiac,Image segmentation,Myocardium,Radio frequency,Random forest,Shape,Two dimensional displays,contrast echocardiography,convolutional neural network,myocardial segmentation,statistical shape model},
  pmid          = {28961106},
}

@Misc{Kingma2018,
  author        = {Kingma, Diederik P. and Dhariwal, Prafulla},
  month         = {jul},
  title         = {{Glow: Generative flow with invertible 1×1 convolutions}},
  year          = {2018},
  abstract      = {Flow-based generative models (Dinh et al., 2014) are conceptually attractive due to tractability of the exact log-likelihood, tractability of exact latent-variable inference, and parallelizability of both training and synthesis. In this paper we propose Glow, a simple type of generative flow using an invertible 1 × 1 convolution. Using our method we demonstrate a significant improvement in log-likelihood on standard benchmarks. Perhaps most strikingly, we demonstrate that a generative model optimized towards the plain log-likelihood objective is capable of efficient realisticlooking synthesis and manipulation of large images. The code for our model is available at https://github.com/openai/glow.},
  booktitle     = {arXiv},
  issn          = {23318422},
  keywords      = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Folder - 1D Doppler, Statistics - Machine Learning},
  language      = {en},
  mendeley-tags = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Folder - 1D Doppler,Statistics - Machine Learning},
  shorttitle    = {Glow},
  url           = {http://arxiv.org/abs/1807.03039},
}

@misc{Stewart2006,
author = {Stewart, V. R. and Sidhu, Paul S.},
booktitle = {British Journal of Radiology},
doi = {10.1259/bjr/17790547},
issn = {00071285},
keywords = {Folder - Contrast agents applications},
mendeley-tags = {Folder - Contrast agents applications},
number = {939},
pages = {188--194},
pmid = {16498029},
title = {{New directions in ultrasound: Microbubble contrast}},
volume = {79},
year = {2006}
}

@article{Tortoli2000,
abstract = {When contrast agents are injected in a fluid, it is implicitly assumed that they move at the same velocity as the fluid itself. However, a series of in vitro tests performed by using air-filled microbubbles suspended in distilled water, have shown that the Doppler spectrum generated in this case may be notably different from that obtained from non-resonating scatterers. In this paper, we show, through a simple simulation model, that the actual movement of microbubbles may be predicted as the result of the complex balance between two forces: the ultrasound radiation force, which tends to move the particles along the sound beam direction, and the fluid drag force, which tends to move the particles along the fluid stream. The contrast agents turn out to be displaced only during the passage of the ultrasound burst; during the remaining time, they are maintained at the fluid velocity by the drag force. Based on the total particle displacement estimated between consecutive pulses, a series of Doppler spectra corresponding to different intensity levels was computed. This series was shown to be in excellent agreement with the experimental spectra obtained in vitro using Levovist (Schering AG, Berlin, Germany) particles suspended in distilled water flowing at a steady rate.},
author = {Tortoli, Piero and Pratesi, Milco and Michelassi, Vittodo},
doi = {10.1109/58.842061},
issn = {08853010},
journal = {IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
keywords = {Folder - Contrast agents doppler},
language = {en},
mendeley-tags = {Folder - Contrast agents doppler},
month = {may},
number = {3},
pages = {716--726},
title = {{Doppler spectra from contrast agents crossing an ultrasound field}},
url = {http://ieeexplore.ieee.org/document/842061/},
volume = {47},
year = {2000}
}

@Article{Zhao2011,
  author        = {Zhao, Xiaoyan and Zhong, Hui and Wan, Mingxi and Shen, Liang},
  journal       = {Ultrasound in Medicine and Biology},
  title         = {{Ultrasound Contrast Imaging Based on a Novel Algorithm Combined Pulse Inversion with Wavelet Transform}},
  year          = {2011},
  issn          = {03015629},
  number        = {8},
  pages         = {1292--1305},
  volume        = {37},
  abstract      = {In this article, an ultrasound contrast imaging method that combines the pulse-inversion technique with wavelet transform has been proposed to enhance the contrast between bubbles and surrounding tissues. In this technique, wavelet transform is utilized to analyze the correlation between mother wavelet and the received echoes from a pair of inverted transmit pulses, respectively. To obtain a better correlation, a new mother wavelet named " bubble wavelet" is constructed according to the modified Herring equation. Radio-frequency (RF) data were acquired from a modified digital diagnostic ultrasound system that transmits two identical pulses with opposite polarity. The proposed method was validated by simulations. Experiments were performed on an ultrasound flow phantom and results showed that the contrast-to-tissue ratio (CTR) was improved by up to 28 dB depending on types of mother wavelet, scales and depths, compared with that obtained using pulse-inversion-based second-harmonic imaging. Experiments in vivo were also conducted out using kidneys of rabbits and results showed that the signals of surrounding tissues can be well suppressed compared with that of bubbles. The proposed method was compared with the quadratic pulse inversion (QPI) imaging on the same set of experimental data. Further improvements might be achieved with optimized bubble wavelet and imaging algorithm. {\textcopyright} 2011 World Federation for Ultrasound in Medicine & Biology.},
  doi           = {10.1016/j.ultrasmedbio.2011.05.003},
  keywords      = {Bubble wavelet, Folder - Contrast agents detection, Pulse-inversion, Ultrasound contrast agent, Wavelet transform},
  mendeley-tags = {Folder - Contrast agents detection},
  pmid          = {21723450},
}

@Article{Loupas1995,
  author        = {Loupas, Thanasis and Gill, Robert W. and Powers, J. T.},
  journal       = {IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
  title         = {{An Axial Velocity Estimator for Ultrasound Blood Flow Imaging, Based on a Full Evaluation of the Doppler Equation by Means of a Two-Dimensional Autocorrelation Approach}},
  year          = {1995},
  issn          = {08853010},
  number        = {4},
  pages         = {672--688},
  volume        = {42},
  abstract      = {This paper introduces a new velocity estimator, referred to as the 2D autocorrelator, which differs from conventional Doppler techniques in two respects: The derivation of axial velocity values by evaluating the Doppler equation using explicit estimates of both the mean Doppler and the mean RF frequency at each range gate location; and, the 2D nature (depth samples versus pulse transmissions) of processing within the range gate. The estimator's output can be calculated by evaluating the 2D autocorrelation function of the demodulated (baseband) backscattered echoes at two lags. A full derivation and mathematical description of the estimator is presented, based on the framework of the 2D Fourier transform. The same framework is adopted to analyze two other established velocity estimators (the conventional ID autocorrelator and the crosscorrelator) in a unifying manner, and theoretical arguments as well as experimental results are used to highlight the common aspects of all three estimators. In addition, a thorough performance evaluation is carried out by means of extensive simulations, which document the effect of a number of factors (velocity spread, range gate length, ensemble length, noise level, transmitted bandwidth) and provide an insight into the optimum parameters and trade-offs associated with individual algorithms. Overall, the 2D autocorrelator is shown to offer the best performance in the context of the specific simulation conditions considered here. Its superiority over the crosscorrelator is restricted to cases of low signal-to-noise ratios. However, the 2D autocorrelator always outperforms the conventional ID autocorrelator by a significant margin. These comparisons, when linked to the computational requirements of the proposed estimator, suggest that it combines the generally higher performance of 2D broadband time-domain techniques with the relatively modest complexity of ID narrowband phase-domain velocity estimators. {\textcopyright} 1995 IEEE.},
  doi           = {10.1109/58.393110},
  keywords      = {Folder - 1D Doppler, Folder - advanced doppler},
  mendeley-tags = {Folder - 1D Doppler,Folder - advanced doppler},
}

@Article{Bonnefous1986,
  author        = {Bonnefous, O. and Pesqu{\'{e}}, P.},
  journal       = {Ultrasonic Imaging},
  title         = {{Time domain formulation of pulse-doppler ultrasound and blood velocity estimation by cross correlation}},
  year          = {1986},
  issn          = {01617346},
  number        = {2},
  pages         = {73--85},
  volume        = {8},
  abstract      = {The Doppler effect is usually described as a frequency shift of the backscattered signals from moving targets with respect to the frequency transmitted. Recently, real-time blood flow imaging has become possible thanks to the development of a new velocity estimator based on phase-shift measurements of successive echoes. However, this method suffers from the well-known limitations of pulse-Doppler instruments. A new formulation is presented which describes the pulse-Doppler effect on the successive echoes from a cloud of moving targets as a progressive translation in time due to the displacement of the scatterers between two excitations. This approach allows us to generate efficiently computer-simulated data in order to evaluate accurately the various processing techniques. Furthermore, it leads to a novel class of velocity estimators in the time domain which measure the time shifts which are proportional to the local blood velocity. Among them, the cross correlation of the received rf signals turns out to be well suited. A local cross-correlation function is first calculated from a consecutive pair of range-gated echoes and the time shift is then determined by searching for the time position with the maximum correlation. The time-correlation technique is shown to provide accurate velocity profiles with broadband transducers. Moreover, the classical velocity limitation of pulse-Doppler is overcome because there is no ambiguity in measuring a time shift instead of a phase shift. These major advantages should make quantitative flow mapping possible and more reliable. {\textcopyright} 1986, SAGE Publications. All rights reserved.},
  doi           = {10.1177/016173468600800201},
  keywords      = {Aliasing effect, Folder - 1D Doppler, blood velocity estimators, pulse-Doppler modeling, real-time flow mapping},
  mendeley-tags = {Aliasing effect,Folder - 1D Doppler,blood velocity estimators,pulse-Doppler modeling,real-time flow mapping},
  pmid          = {2946098},
}

@InProceedings{Mahue2010,
  author        = {Mahue, Veronique and Mari, Jean Martial and Eckersley, Robert J. and Caro, Colin G. and Tang, Meng Xing},
  booktitle     = {Physics Procedia},
  title         = {{Pulse subtraction doppler}},
  year          = {2010},
  month         = {jan},
  number        = {1},
  pages         = {749--753},
  volume        = {3},
  abstract      = {Recent advances have demonstrated the feasibility of molecular imaging using targeted microbubbles and ultrasound. One technical challenge is to selectively detect attached bubbles from those freely flowing bubbles and surrounding tissue. Pulse Inversion Doppler is an imaging technique enabling the selective detection of both static and moving ultrasound contrast agents: linear scatterers generate a single band Doppler spectrum, while non-linear scatterers generate a double band spectrum, one being uniquely correlated with the presence of contrast agents and non-linear tissue signals. We demonstrate that similar spectrums, and thus the same discrimination, can be obtained through a Doppler implementation of Pulse Subtraction. This is achieved by reconstructing a virtual echo using the echo generated from a short pulse transmission. Moreover by subtracting from this virtual echo the one generated from a longer pulse transmission, it is possible to fully suppress the echo from linear scatterers, while for non-linear scatterers, a signal will remain, allowing classical agent detection. Simulations of a single moving microbubble and a moving linear scatterer subject to these pulses show that when the virtual echo and the long pulse echo are used to perform pulsed Doppler, the power Doppler spectrum allows separation of linear and non-linear moving scattering. Similar results are obtained on experimental data acquired on a flow containing either microbubble contrast agents or linear blood mimicking fluid. This new Doppler method constitutes an alternative to Pulse Inversion Doppler and preliminary results suggest that similar dual band spectrums could be obtained by the combination of any non-linear detection technique with Doppler demodulation.},
  doi           = {10.1016/j.phpro.2010.01.095},
  issn          = {18753892},
  keywords      = {Doppler, Folder - Contrast agents detection, Microbubbles, Pulse inversion, Pulse subtraction, Targeted contrast agents},
  language      = {en},
  mendeley-tags = {Folder - Contrast agents detection},
  url           = {http://linkinghub.elsevier.com/retrieve/pii/S1875389210000969},
}

@article{Udesen2006,
abstract = {Conventional ultrasound scanners can display only the axial component of the blood velocity vector, which is a significant limitation when vessels nearly parallel to the skin surface are scanned. The transverse oscillation (TO) method overcomes this limitation by introducing a TO and an axial oscillation in the pulse echo field. The theory behind the creation of the double oscillation pulse echo field is explained as well as the theory behind the estimation of the vector velocity. A parameter study of the method is performed, using the ultrasound simulation program Field II. A virtual linear-array transducer with center frequency 7 MHz and 128 active elements is created, and a virtual blood vessel of radius 6.4 mm is simulated. The performance of the TO method is found around an initial point in the parameter space. The parameters varied are: flow angle, transmit focus depth, receive apodization, pulse length, transverse wave length, number of emissions, signal-to-noise ratio (SNR), and type of echo-canceling filter used. Using an experimental scanner, the performance of the TO method is evaluated. An experimental flowrig is used to create laminar parabolic flow in a blood mimicking fluid, and the fluid is scanned under different flow-to-beam angles. The relative standard deviation on the transverse velocity estimate is found to be less than 10% for all angles between 50° and 90°. Furthermore, the TO method is evaluated in the flowrig using pulsatile flow, which resembles the flow in the femoral artery. The estimated volume flow as a function of time is compared to the volume flow derived from a conventional axial method at a flow-to-beam angle of 60°. It is found that the method is highly sensitive to the angle between the flow and the beam direction. Also, the choice of echo canceling filter affects the performance significantly. {\textcopyright} 2006 IEEE.},
author = {Udesen, Jesper and Jensen, J{\o}rgen Arendt},
doi = {10.1109/TUFFC.2006.1632686},
issn = {08853010},
journal = {IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
keywords = {Folder - advanced doppler},
mendeley-tags = {Folder - advanced doppler},
number = {5},
pages = {959--971},
pmid = {16764450},
title = {{Investigation of transverse oscillation method}},
volume = {53},
year = {2006}
}

@InProceedings{TremblayDarveau2012,
  author        = {Tremblay-Darveau, Charles and Williams, Ross and Milot, Laurent and Bruce, Matthew and Burns, Peter N.},
  booktitle     = {IEEE International Ultrasonics Symposium, IUS},
  title         = {{Ultrafast Doppler imaging of micro-bubbles}},
  year          = {2012},
  month         = {oct},
  pages         = {1315--1318},
  abstract      = {Plane-wave synthetic ultrasound considerably increases the imaging frame rate, which in turn can be used to improve the SNR or the frequency resolution of Doppler estimators. Ultrafast imaging also allows the implementation of bubble selective multi-pulse imaging sequences, such as pulse inversion, at frame rates sufficient for Doppler processing. It will be demonstrated in an in-vivo rabbit kidney that non-linear contrast enhanced Doppler permits the real-time segmentation of fast flow (arteries and veins), from the slow moving flow in capillaries, using a Doppler frequency filters analogous to conventional wall-filters. {\textcopyright} 2012 IEEE.},
  doi           = {10.1109/ULTSYM.2012.0328},
  isbn          = {9781467345613},
  issn          = {19485719},
  keywords      = {Acoustics, Bandwidth, Clutter, Doppler broadening, Doppler effect, Doppler estimators, Doppler frequency filters, Doppler processing, Folder - Contrast agents detection, Imaging, Kidney, SNR, Ultrasonic imaging, acoustic filters, arteries, biomedical ultrasonics, blood vessels, bubble selective multipulse imaging sequences, bubbles, capillaries, capillarity, fast moving flow, frequency resolution, haemodynamics, image enhancement, image segmentation, image sequences, imaging frame rate, in-vivo rabbit kidney, kidney, medical image processing, microbubbles, nonlinear contrast enhanced Doppler, plane-wave synthetic ultrasound, pulse inversion, real-time segmentation, slow moving flow, ultrafast Doppler imaging, veins},
  mendeley-tags = {Acoustics,Bandwidth,Clutter,Doppler broadening,Doppler effect,Doppler estimators,Doppler frequency filters,Doppler processing,Folder - Contrast agents detection,Imaging,Kidney,SNR,Ultrasonic imaging,acoustic filters,arteries,biomedical ultrasonics,blood vessels,bubble selective multipulse imaging sequences,bubbles,capillaries,capillarity,fast moving flow,frequency resolution,haemodynamics,image enhancement,image segmentation,image sequences,imaging frame rate,in-vivo rabbit kidney,kidney,medical image processing,microbubbles,nonlinear contrast enhanced Doppler,plane-wave synthetic ultrasound,pulse inversion,real-time segmentation,slow moving flow,ultrafast Doppler imaging,veins},
}

@misc{Nehme2018,
abstract = {We present an ultra-fast, precise, parameter-free method, which we term Deep-STORM, for obtaining super-resolution images from stochastically-blinking emitters, such as fluorescent molecules used for localization microscopy. Deep-STORM uses a deep convolutional neural network that can be trained on simulated data or experimental measurements, both of which are demonstrated. The method achieves state-of-the-art resolution under challenging signal-to-noise conditions and high emitter densities, and is significantly faster than existing approaches. Additionally, no prior information on the shape of the underlying structure is required, making the method applicable to any blinking data-set. We validate our approach by super-resolution image reconstruction of simulated and experimentally obtained data.},
archivePrefix = {arXiv},
arxivId = {1801.09631},
author = {Nehme, Elias and Weiss, Lucien E. and Michaeli, Tomer and Shechtman, Yoav},
booktitle = {arXiv},
doi = {10.1364/optica.5.000458},
eprint = {1801.09631},
issn = {23318422},
keywords = {Folder - Super Resolution},
language = {en},
mendeley-tags = {Folder - Super Resolution},
month = {apr},
number = {4},
pages = {458},
shorttitle = {Deep-STORM},
title = {{Deep-STORM: Super-resolution single-molecule microscopy by deep learning}},
url = {https://www.osapublishing.org/abstract.cfm?URI=optica-5-4-458},
volume = {5},
year = {2018}
}

@Misc{Tang2011,
  author        = {Tang, M. X. and Mulvana, H. and Gauthier, T. and Lim, A. K.P. and Cosgrove, D. O. and Eckersley, R. J. and Stride, E.},
  month         = {aug},
  title         = {{Quantitative contrast-enhanced ultrasound imaging: A review of sources of variability}},
  year          = {2011},
  abstract      = {Ultrasound provides a valuable tool for medical diagnosis offering real-time imaging with excellent spatial resolution and low cost. The advent of microbubble contrast agents has provided the additional ability to obtain essential quantitative information relating to tissue vascularity, tissue perfusion and even endothelial wall function. This technique has shown great promise for diagnosis and monitoring in a wide range of clinical conditions such as cardiovascular diseases and cancer, with considerable potential benefits in terms of patient care. A key challenge of this technique, however, is the existence of significant variations in the imaging results, and the lack of understanding regarding their origin. The aim of this paper is to review the potential sources of variability in the quantification of tissue perfusion based on microbubble contrast-enhanced ultrasound images. These are divided into the following three categories: (i) factors relating to the scanner setting, which include transmission power, transmission focal depth, dynamic range, signal gain and transmission frequency, (ii) factors relating to the patient, which include body physical differences, physiological interaction of body with bubbles, propagation and attenuation through tissue, and tissue motion, and (iii) factors relating to the microbubbles, which include the type of bubbles and their stability, preparation and injection and dosage. It has been shown that the factors in all the three categories can significantly affect the imaging results and contribute to the variations observed. How these factors influence quantitative imaging is explained and possible methods for reducing such variations are discussed. {\textcopyright} 2011 The Royal Society.},
  booktitle     = {Interface Focus},
  doi           = {10.1098/rsfs.2011.0026},
  issn          = {20428901},
  keywords      = {Folder - Contrast agents detection, Medical ultrasound, Microbubble contrast agent, Perfusion quantification, Quantitative imaging, Variation},
  language      = {en},
  mendeley-tags = {Folder - Contrast agents detection},
  number        = {4},
  pages         = {520--539},
  shorttitle    = {Quantitative contrast-enhanced ultrasound imaging},
  url           = {http://rsfs.royalsocietypublishing.org/cgi/doi/10.1098/rsfs.2011.0026},
  volume        = {1},
}

@InProceedings{Chen2012,
  author        = {Chen, Hong and Lu, Jian Yu},
  booktitle     = {IEEE International Ultrasonics Symposium, IUS},
  title         = {{A fast method for speckle tracking}},
  year          = {2012},
  pages         = {2579--2582},
  abstract      = {Speckle tracking method has been studied for velocity vector imaging in medical ultrasound for many years. However, the method is slow as compared to the conventional color Doppler imaging due to a larger amount of computation is needed. In this study, a method is developed to reduce the amount of computation. Instead of using an entire rectangular block in a 2D kernel (full kernel) to calculate the sum of absolute difference between image frames, only data in two diagonal lines, two bisectors, or a combination of the diagonal and bisector lines (see Fig. 1(b), (c), and (d)), are used. Both simulation and experiment were conducted to verify the proposed method. 11 frames of images are reconstructed with the delay-and-sum (D&S) and the high-frame-rate (HFR) imaging methods of a single plane wave transmission. In the simulation, two point scatterers, located at depths of 10 and 70 mm with velocities of 0.5 and 1.0 m/s respectively, are placed in the imaging area. Ten velocities are estimated by speckle tracking using both the full kernel and the crosses. The average errors of velocities measured are 7.3% for D&S and 5.5% for HFR imaging methods with diagonal lines, 2.5% for D&S and 4.0% for HFR imaging methods with bisectors, 3.6% for D&S and 3.2% for HFR imaging methods when both diagonal and bisector lines are used, and 2.6% for D&S and 2.5% for HFR imaging methods based on the full kernel. In the experiment, two small glass beads (point scatterers), located at depths of around 10 and 70 mm with velocities of 0 and a fixed value respectively, were placed in a water tank. The average measurement errors are 15.5% for D&S and 11.4% for HFR imaging methods with diagonal lines, 10.7% for D&S and 12.5% for HFR imaging methods with bisectors, 13.2% for D&S and 9.3% for HFR imaging methods when both diagonal and bisector lines are used, and 10.3% for D&S and 8.7% for HFR imaging methods with the full kernel. These results were obtained with a kernel area of 1.8 × 1.8 mm (or 100 × 100=10000 pixels for the full kernel and 4 × 100=400 pixels for a combination of diagonal and bisector lines). In this condition, the computation time is 18.5 times smaller with the combined diagonal and bisector lines than that with the full kernel (excluding the fixed image reading time). As the size of the kernel is increased, there will be more reduction in computation time with the new method. The new speckle tracking method can achieve similar accuracies in velocity estimations while significantly reducing the computation time. {\textcopyright} 2012 IEEE.},
  doi           = {10.1109/ULTSYM.2012.0646},
  isbn          = {9781467345613},
  issn          = {19485719},
  keywords      = {- fast speckle tracking, Folder - Vector doppler, cross, fast speckle tracking, high frame rate, high frame rate imaging},
  mendeley-tags = {- fast speckle tracking,Folder - Vector doppler,cross,high frame rate},
  url           = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6562293},
}

@Article{ChristensenJeffries2015,
  author        = {Christensen-Jeffries, Kirsten and Browning, Richard J. and Tang, Meng Xing and Dunsby, Christopher and Eckersley, Robert J.},
  journal       = {IEEE Transactions on Medical Imaging},
  title         = {{In vivo acoustic super-resolution and super-resolved velocity mapping using microbubbles}},
  year          = {2015},
  issn          = {1558254X},
  number        = {2},
  pages         = {433--440},
  volume        = {34},
  abstract      = {The structure of microvasculature cannot be resolved using standard clinical ultrasound (US) imaging frequencies due to the fundamental diffraction limit of US waves. In this work, we use a standard clinical US system to perform in vivo sub-diffraction imaging on a CD1, female mouse aged eight weeks by localizing isolated US signals from microbubbles flowing within the ear microvasculature, and compare our results to optical microscopy. Furthermore, we develop a new technique to map blood velocity at super-resolution by tracking individual bubbles through the vasculature. Resolution is improved from a measured lateral and axial resolution of 112 $\mu$m and 94 $\mu$m respectively in original US data, to super-resolved images of microvasculature where vessel features as fine as 19 $\mu$m are clearly visualized. Velocity maps clearly distinguish opposing flow direction and separated speed distributions in adjacent vessels, thereby enabling further differentiation between vessels otherwise not spatially separated in the image. This technique overcomes the diffraction limit to provide a noninvasive means of imaging the microvasculature at super-resolution, to depths of many centimeters. In the future, this method could noninvasively image pathological or therapeutic changes in the microvasculature at centimeter depths in vivo.},
  doi           = {10.1109/TMI.2014.2359650},
  keywords      = {Biomedical imaging, Folder - Contrast agents applications, microbubbles, microvasculature, resolution, ultrasonic imaging, ultrasound},
  mendeley-tags = {Biomedical imaging,Folder - Contrast agents applications,microbubbles,microvasculature,resolution,ultrasonic imaging,ultrasound},
  pmid          = {25265604},
}

@inproceedings{Klibanov2005,
author = {Klibanov, Alexander L.},
booktitle = {Bioconjugate Chemistry},
doi = {10.1021/bc049898y},
issn = {10431802},
keywords = {Folder - Contrast agents applications},
mendeley-tags = {Folder - Contrast agents applications},
number = {1},
pages = {9--17},
pmid = {15656569},
title = {{Ligand-carrying gas-filled microbubbles: Ultrasound contrast agents for targeted molecular imaging}},
volume = {16},
year = {2005}
}

@Article{Bruce2004,
  author        = {Bruce, Matthew and Averkiou, Mike and Tiemann, Klaus and Lohmaier, Stefan and Powers, Jeff and Beach, Kirk},
  journal       = {Ultrasound in Medicine and Biology},
  title         = {{Vascular flow and perfusion imaging with ultrasound contrast agents}},
  year          = {2004},
  issn          = {03015629},
  month         = {jun},
  number        = {6},
  pages         = {735--743},
  volume        = {30},
  abstract      = {Current techniques for imaging ultrasound (US) contrast agents (UCA) make no distinction between low-velocity microbubbles in the microcirculation and higher-velocity microbubbles in the larger vasculature. A combination of radiofrequency (RF) and Doppler filtering on a low mechanical index (MI) pulse inversion acquisition is presented that differentiates low-velocity microbubbles (on the order of mm/s) associated with perfusion, from the higher-velocity microbubbles (on the order of cm/s) in larger vessels. In vitro experiments demonstrate the ability to separate vascular flow using both harmonic and fundamental Doppler signals. Fundamental and harmonic Doppler signals from microbubbles using a low-MI pulse-inversion acquisition are compared with conventional color Doppler signals in vivo. Due to the lower transmit amplitude and enhanced backscatter from microbubbles, the in vivo signal to clutter ratios for both the fundamental (-11 dB) and harmonic (-4 dB) vascular flow signals were greater than with conventional power Doppler (-51 dB) without contrast agent. The processing investigated here, in parallel with conventional pulse-inversion processing, enables the simultaneous display of both perfusion and vascular flow. In vivo results demonstrating the feasibility and potential utility of the real-time display of both perfusion and vascular flow using US contrast agents are presented and discussed. {\textcopyright} 2004 World Federation for Ultrasound in Medicine & Biology.},
  doi           = {10.1016/j.ultrasmedbio.2004.03.016},
  keywords      = {Blood flow, Color Doppler, Doppler, Folder - Contrast agents doppler, Ultrasound contrast agents},
  language      = {en},
  mendeley-tags = {Folder - Contrast agents doppler},
  pmid          = {15219953},
  url           = {http://linkinghub.elsevier.com/retrieve/pii/S0301562904001012},
}

@Article{Yildiz2015,
  author        = {Yildiz, Yesna O. and Eckersley, Robert J. and Senior, Roxy and Lim, Adrian K.P. and Cosgrove, David and Tang, Meng Xing},
  journal       = {Ultrasound in Medicine and Biology},
  title         = {{Correction of non-linear propagation artifact in contrast-enhanced ultrasound imaging of carotid arteries: Methods and in vitro evaluation}},
  year          = {2015},
  issn          = {1879291X},
  number        = {7},
  pages         = {1938--1947},
  volume        = {41},
  abstract      = {Non-linear propagation of ultrasound creates artifacts in contrast-enhanced ultrasound images that significantly affect both qualitative and quantitative assessments of tissue perfusion. This article describes the development and evaluation of a new algorithm to correct for this artifact. The correction is a post-processing method that estimates and removes non-linear artifact in the contrast-specific image using the simultaneously acquired B-mode image data. The method is evaluated on carotid artery flow phantoms with large and small vessels containing microbubbles of various concentrations at different acoustic pressures. The algorithm significantly reduces non-linear artifacts while maintaining the contrast signal from bubbles to increase the contrast-to-tissue ratio by up to 11 dB. Contrast signal from a small vessel 600 mm in diameter buried in tissue artifacts before correction was recovered after the correction.},
  doi           = {10.1016/j.ultrasmedbio.2015.03.014},
  keywords      = {Artifact correction, Contrast enhanced ultrasound, Folder - Contrast agents detection, Microbubbles, Non-linear propagation artifact, Perfusion quantification, artifact correction, contrast enhanced ultrasound, microbubbles, non-linear propagation artifact, perfusion quantification},
  mendeley-tags = {Folder - Contrast agents detection,artifact correction,contrast enhanced ultrasound,microbubbles,non-linear propagation artifact,perfusion quantification},
  pmid          = {25935597},
  url           = {http://linkinghub.elsevier.com/retrieve/pii/S0301562915002276},
}

@article{Jensen2004,
abstract = {A method for flow estimation using synthetic aperture imaging and focusing along the flow direction is presented. The method can find the correct velocity magnitude for any flow angle, and full color flow images can be measured using only 32 to 128 pulse emissions. The approach uses spherical wave emissions with a number of defocused elements and a linear frequency-modulated pulse (chirp) to improve the signal-to-noise ratio. The received signals are dynamically focused along the flow direction and these signals are used in a cross-correlation estimator for finding the velocity magnitude. The flow angle is manually determined from the B-mode image. The approach can be used for both tissue and blood velocity determination. The approach was investigated using both simulations and a flow system with a laminar flow. The flow profile was measured with a commercial 7.5 MHz linear array transducer. A plastic tube with an internal diameter of 17 mm was used with an EcoWatt 1 pump generating a laminar, stationary flow. The velocity profile was measured for flow angles of 90 and 60 degrees. The RASMUS research scanner was used for acquiring radio frequency (RF) data from 128 elements of the array, using 8 emissions with 11 elements in each emission. A 20-$\mu$s chirp was used during emission. The RF data were subsequently beamformed off-line and stationary echo canceling was performed. The 60-degree flow with a peak velocity of 0.15 m/s was determined using 16 groups of 8 emissions, and the relative standard deviation was 0.36% (0.65 mm/s). Using the same setup for purely transverse flow gave a standard deviation of 1.2% (2.1 mm/s). Variation of the different parameters revealed the sensitivity to number of lines, angle deviations, length of correlation interval, and sampling Interval. An in vivo image of the carotid artery and jugular vein of a healthy 29-year-old volunteer was acquired. A full color flow image using only 128 emissions could be made with a high-velocity precision.},
author = {Jensen, J{\o}rgen Arendt and Nikolov, Svetoslav Ivanov},
doi = {10.1109/TUFFC.2004.1334843},
issn = {08853010},
journal = {IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
keywords = {Folder - Vector doppler},
language = {en},
mendeley-tags = {Folder - Vector doppler},
month = {sep},
number = {9},
pages = {1107--1118},
pmid = {15478972},
title = {{Directional synthetic aperture flow imaging}},
url = {http://ieeexplore.ieee.org/document/1334843/},
volume = {51},
year = {2004}
}

@Article{Tortoli2005,
  author        = {Tortoli, Piero and Boni, Enrico and Corsi, Massimo and Arditi, Marcel and Frinking, Peter},
  journal       = {IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
  title         = {{Different effects of microbubble destruction and translation in Doppler measurements}},
  year          = {2005},
  issn          = {08853010},
  number        = {7},
  pages         = {1183--1188},
  volume        = {52},
  abstract      = {In flow measurements in which microbubbles are involved, the amplitude and phase of the received echo signal are noticeably influenced by the transmitted ultrasound intensity. Previous studies have shown that, when such intensity is progressively increased, the Doppler spectrum is accordingly distorted, i.e., it is asymmetrically broadened toward the negative frequency side. Such deformation has been attributed to radiation force, which pushes the microbubbles into the sound propagation direction, thus yielding additional phase delays in the received echoes. However, the possible contribution of microbubble destruction to this spectral deformation has not been considered yet. In this paper, this issue is investigated by analyzing the experimental spectra produced by two different types of microbubbles suspended in a moving fluid and insonified in pulsed wave (PW) mode at programmable pulse repetition frequency (PRF) and pressure. Conditions are created in which either the radiation force or the destruction mechanism is expected to be dominant. Effects produced by the two phenomena on the Doppler spectrum are shown to be different. When the PRF is low (2 kHz), so that, according to theoretical simulations, the radiation force effect is negligible, a 26 dB noise floor increase is observed for a 13 dB pressure increment. For a higher PRF (16 kHz), the same pressure increase not only affects the noise floor, but also causes the bubbles to deviate from their original streamlines, yielding a Doppler bandwidth increase by a factor of 5. It is concluded that asymmetrical spectral broadening is mainly due to radiation force, and microbubble destruction mainly results in an increased noise floor without affecting the spectral shape. {\textcopyright} 2005 IEEE.},
  doi           = {10.1109/TUFFC.2005.1504005},
  keywords      = {Algorithms, Computer-Assisted, Computer-Assisted: methods, Contrast Media, Doppler, Doppler: instrumentation, Doppler: methods, Echocardiography, Echocardiography: instrumentation, Echocardiography: methods, Folder - Contrast agents detection, Image Enhancement, Image Enhancement: methods, Image Interpretation, Imaging, Phantoms},
  mendeley-tags = {Algorithms,Computer-Assisted,Computer-Assisted: methods,Contrast Media,Doppler,Doppler: instrumentation,Doppler: methods,Echocardiography,Echocardiography: instrumentation,Echocardiography: methods,Folder - Contrast agents detection,Image Enhancement,Image Enhancement: methods,Image Interpretation,Imaging,Phantoms},
  pmid          = {16212258},
  url           = {http://www.ncbi.nlm.nih.gov/pubmed/16212258},
}

@Article{Ricci2014,
  author        = {Ricci, Stefano and Bassi, Luca and Tortoli, Piero},
  journal       = {IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
  title         = {{Real-time vector velocity assessment through multigate doppler and plane waves}},
  year          = {2014},
  issn          = {08853010},
  number        = {2},
  pages         = {314--324},
  volume        = {61},
  abstract      = {Several ultrasound (US) methods have been recently proposed to produce 2-D velocity vector fields with high temporal and spatial resolution. However, the real-time implementation in US scanners is heavily hampered by the high calculation power required. In this work, we report a real-time vector Doppler imaging method which has been integrated in an open research system. The proposed approach exploits the plane waves transmitted from two sub-arrays of a linear probe to estimate the velocity vectors in 512 sample volumes aligned along the probe axis. The method has been tested for accuracy and reproducibility through simulations and in vitro experiments. Simulations over a 0° to 90° angle range of a 0.5 m/s peak parabolic flow have yielded 0.75° bias and 1.1° standard deviation for direction measurement, and 0.6 cm/s bias with 3.1% coefficient of variation for velocity assessment. In vitro tests have supported the simulation results. Preliminary measurements on the carotid artery of a volunteer have highlighted the real-time system capability of imaging complex flow configurations in an intuitive, easy, and quick way, as shown in a sample supplementary movie. These features have allowed reproducible peak velocity measurements to be obtained, as needed for quantitative investigations on patients. {\textcopyright} 2014 IEEE.},
  doi           = {10.1109/TUFFC.2014.6722616},
  keywords      = {2-D velocity vector fields, Algorithms, Apertures, Blood Flow Velocity, Blood Flow Velocity: physiology, Carotid Arteries, Carotid Arteries: physiology, Carotid Arteries: ultrasonography, Computer Systems, Computer-Assisted, Computer-Assisted: instrumen, Computer-Assisted: methods, Doppler, Doppler effect, Doppler measurement, Doppler: instrumentation, Doppler: methods, Equipment Design, Equipment Failure Analysis, Folder - Vector doppler, Humans, Image Enhancement, Image Enhancement: instrumentation, Image Enhancement: methods, Image Interpretation, Image Interpretation- Computer-Assisted, Probes, Real-time systems, Reproducibility of Results, Rheology, Rheology: methods, Sensitivity and Specificity, Standards, US scanners, Ultrasonography, Ultrasonography- Doppler, Vectors, Velocity measurement, biomedical ultrasonics, blood flow measurement, blood vessels, carotid artery, coefficient of variation, complex flow configuration imaging, direction measurement, high calculation power requirement, high spatial resolution, high temporal resolution, in vitro experiments, linear probe subarrays, multigate Doppler waves, open research system, parabolic flow, plane waves, probe axis, real-time implementation, real-time system, real-time systems, real-time vector Doppler imaging method, real-time vector velocity assessment, reproducible peak velocity measurements, sample supplementary movie, standard deviation, ultrasound methods, velocity 0.5 m/s, velocity 0.6 cm/s},
  mendeley-tags = {2-D velocity vector fields,Algorithms,Apertures,Blood Flow Velocity,Blood Flow Velocity: physiology,Carotid Arteries,Carotid Arteries: physiology,Carotid Arteries: ultrasonography,Computer Systems,Computer-Assisted,Computer-Assisted: instrumen,Computer-Assisted: methods,Doppler,Doppler effect,Doppler measurement,Doppler: instrumentation,Doppler: methods,Equipment Design,Equipment Failure Analysis,Folder - Vector doppler,Humans,Image Enhancement,Image Enhancement: instrumentation,Image Enhancement: methods,Image Interpretation,Image Interpretation- Computer-Assisted,Probes,Real-time systems,Reproducibility of Results,Rheology,Rheology: methods,Sensitivity and Specificity,Standards,US scanners,Ultrasonography,Ultrasonography- Doppler,Vectors,Velocity measurement,biomedical ultrasonics,blood flow measurement,blood vessels,carotid artery,coefficient of variation,complex flow configuration imaging,direction measurement,high calculation power requirement,high spatial resolution,high temporal resolution,in vitro experiments,linear probe subarrays,multigate Doppler waves,open research system,parabolic flow,plane waves,probe axis,real-time implementation,real-time system,real-time systems,real-time vector Doppler imaging method,real-time vector velocity assessment,reproducible peak velocity measurements,sample supplementary movie,standard deviation,ultrasound methods,velocity 0.5 m/s,velocity 0.6 cm/s},
  pmid          = {24474137},
  url           = {http://www.ncbi.nlm.nih.gov/pubmed/24474137},
}

@misc{Cosgrove2009,
author = {Cosgrove, David and Harvey, Chris},
booktitle = {Medical and Biological Engineering and Computing},
doi = {10.1007/s11517-009-0434-3},
issn = {01400118},
keywords = {Folder - Contrast agents applications},
mendeley-tags = {Folder - Contrast agents applications},
number = {8},
pages = {813--826},
pmid = {19205774},
title = {{Clinical uses of microbubbles in diagnosis and treatment}},
volume = {47},
year = {2009}
}

@article{Udesen2008,
abstract = {Conventional ultrasound methods for acquiring color images of blood velocity are limited by a relatively low frame-rate and are restricted to give velocity estimates along the ultrasound beam direction only. To circumvent these limitations, the method presented in this paper uses 3 techniques: 1) The ultrasound is not focused during the transmissions of the ultrasound signals; 2) A 13-bit Barker code is transmitted simultaneously from each transducer element; and 3) The 2-D vector velocity of the blood is estimated using 2-D cross-correlation. A parameter study was performed using the Field II program, and performance of the method was investigated when a virtual blood vessel was scanned by a linear array transducer. An improved parameter set for the method was identified from the parameter study, and a flow rig measurement was performed using the same improved setup as in the simulations. Finally, the common carotid artery of a healthy male was scanned with a scan sequence that satisfies the limits set by the Food and Drug Administration. Vector velocity images were obtained with a frame-rate of 100 Hz where 40 speckle images are used for each vector velocity image. It was found that the blood flow approximately followed the vessel wall, and that maximum velocity was approximately 1 m/s, which is a normal value for a healthy person. To further evaluate the method, the test person was scanned with magnetic resonance (MR) angiography. The volume flow derived from the MR scanning was compared with that from the ultrasound scanning. A deviation of 9% between the 2 volume flow estimates was found. {\textcopyright} 2008 IEEE.},
author = {Udesen, Jesper and Gran, Fredrik and Hansen, Kristoffer Lindskov and Jensen, J{\o}rgen Arendt and Thomsen, Carsten and Nielsen, Michael Bachmann},
doi = {10.1109/TUFFC.2008.858},
issn = {08853010},
journal = {IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
keywords = {Folder - Vector doppler},
mendeley-tags = {Folder - Vector doppler},
number = {8},
pages = {1729--1743},
pmid = {18986917},
title = {{High frame-rate blood vector velocity imaging using plane waves: Simulations and preliminary experiments}},
volume = {55},
year = {2008}
}

@inproceedings{Bruce2003,
abstract = {Current techniques for imaging ultrasound contrast agents make no distinction between low velocity microbubbles in the microcirculation and higher velocity microbubbles in the larger vasculature. A combination of RF and Doppler filtering on a low-MI pulse inversion acquisition is presented that differentiates low velocity microbubbles, perfusion, from the higher velocity microbubbles in larger vessels. Both fundamental and harmonic Doppler signals from microbubbles are compared against conventional color Doppler signals. Due to the lower transmit amplitude and enhanced backscatter from microbubbles, the signal to clutter ratios for both the fundamental (-11 dB) and harmonic (-4 dB) vascular flow signals were greater than conventional power Doppler (-51 dB) without contrast agent. Clinical results demonstrated the feasibility and potential utility of displaying in real-time both perfusion and vascular flow using ultrasound contrast agents.},
address = {Honolulu, HI, USA},
author = {Bruce, Matthew and Averkiou, Mike and Jensen, Seth and Powers, Jeff and Beach, Kirk},
booktitle = {Proceedings of the IEEE Ultrasonics Symposium},
doi = {10.1109/ultsym.2003.1293434},
isbn = {978-0-7803-7922-0},
issn = {10510117},
keywords = {Folder - Contrast agents detection},
language = {en},
mendeley-tags = {Folder - Contrast agents detection},
pages = {411--415},
publisher = {IEEE},
title = {{Pulse inversion Doppler for blood flow detection in the macro- and micro- circulation}},
url = {http://ieeexplore.ieee.org/document/1293434/},
volume = {1},
year = {2003}
}

@inproceedings{Flynn2011,
abstract = {Vector Doppler Imaging (VDI) reveals the blood flow velocity vector at each pixel. We present a multiple-angle planewave transmission (PWT) scheme that enables vector velocity imaging at a high frame-rate. The method employs a fast, aliasing-resistant velocity vector estimator and captures transitory flow dynamics, as demonstrated on a carotid artery with a 5 MHz linear array using a novel synthetic particle flow visualization method. Conventional color Doppler processing applied to several PWT angles produces a set of Doppler images. These are combined into a small weighted least squares (WLS) problem for each pixel, conditioned for bias due to aliasing. Weights account for signal quality at each PWT angle. The WLS covariance provides metrics to qualify pixels. To visualize the resulting velocity vector image, we use a novel technique which synthesizes a moving field of points representing particles entrained in the fluid. Each particle is generated by Bernoulli trial at detected flow pixels, and given motion by the velocity vector estimate. The motion is scaled down so the viewer may easily perceive flow in "real-time slow-motion". Particles migrate across the image from frame to frame, under conservation rules mimicking fluid flow. The user controls displayed density of particles that overlay the detected flow regions, which are color-coded for velocity magnitude. Using a Verasonics VDAS acquisition system and a Philips L7-4 transducer, we demonstrate in vivo VDI on neck vasculature. PWT ensembles collected at seven angles are processed with the VDI algorithm giving an imaging rate of 30 fps. Video display reveals dynamics of the flow field and shows good detection of flow during diastole. {\textcopyright} 2011 IEEE.},
address = {Orlando, FL, USA},
author = {Flynn, John and Daigle, Ron and Pflugrath, Lauren and Linkhart, Ken and Kaczkowski, Peter},
booktitle = {IEEE International Ultrasonics Symposium, IUS},
doi = {10.1109/ULTSYM.2011.0099},
isbn = {9781457712531},
issn = {19485719},
keywords = {Folder - Vector doppler},
language = {en},
mendeley-tags = {Folder - Vector doppler},
month = {oct},
pages = {413--418},
publisher = {IEEE},
title = {{Estimation and display for vector Doppler imaging using planewave transmissions}},
url = {http://ieeexplore.ieee.org/document/6293682/},
year = {2011}
}

@InProceedings{DeJong2002,
  author        = {{De Jong}, Nico and Bouakaz, Ayache and {Ten Cate}, Folkert J.},
  booktitle     = {Ultrasonics},
  title         = {{Contrast harmonic imaging}},
  year          = {2002},
  month         = {may},
  number        = {1-8},
  pages         = {567--573},
  volume        = {40},
  abstract      = {The behavior of ultrasound contrast agents depends highly on the acoustic pressure of the insonified ultrasound wave. For low pressure the expansion and compression is linear to the pressure, for medium acoustic pressure nonlinear behavior starts to occur and for high pressures, but still in the diagnostic range transient scattering can be noticed, resulting in an enhanced scattering followed by a disappearance of the bubble. The nonlinear and transient regime can be utilized for imaging of the contrast agent in or nearby tissue. The magnitude of the nonlinear signal from the contrast has to compete with the nonlinear component of the ultrasound wave, which is generated during propagation. It is shown that contrast is superior to tissue when using low frequencies and imaging the third or fourth harmonic of the transmitted frequency. {\textcopyright} 2002 Elsevier Science B.V. All rights reserved.},
  doi           = {10.1016/S0041-624X(02)00171-3},
  issn          = {0041624X},
  keywords      = {Contrast agents, Diagnosis, Folder - Contrast agents detection, Harmonic, Medical, Ultrasound},
  language      = {en},
  mendeley-tags = {Folder - Contrast agents detection},
  url           = {http://linkinghub.elsevier.com/retrieve/pii/S0041624X02001713},
}

@Article{Cosgrove2006,
  author        = {Cosgrove, David},
  journal       = {European Journal of Radiology},
  title         = {{Ultrasound contrast agents: An overview}},
  year          = {2006},
  issn          = {0720048X},
  number        = {3},
  pages         = {324--330},
  volume        = {60},
  abstract      = {With the introduction of microbubble contrast agents, diagnostic ultrasound has entered a new era that allows the dynamic detection of tissue flow of both the macro and microvasculature. Underpinning this development is the fact that gases are compressible, and thus the microbubbles expand and contract in the alternating pressure waves of the ultrasound beam, while tissue is almost incompressible. Special software using multiple pulse sequences separates these signals from those of tissue and displays them as an overlay or on a split screen. This can be done at low acoustic pressures (MI < 0.3) so that the microbubbles are not destroyed and scanning can continue in real time. The clinical roles of contrast enhanced ultrasound scanning are expanding rapidly. They are established in echocardiography to improve endocardial border detection and are being developed for myocardial perfusion. In radiology, the most important application is the liver, especially for focal disease. The approach parallels that of dynamic CT or MRI but ultrasound has the advantages of high spatial and temporal resolution. Thus, small lesions that can be indeterminate on CT can often be studied with ultrasound, and situations where the flow is very rapid (e.g., focal nodular hyperplasia where the first few seconds of arterial perfusion may be critical to making the diagnosis) are readily studied. Microbubbles linger in the extensive sinusoidal space of normal liver for several minutes whereas they wash out rapidly from metastases, which have a low vascular volume and thus appear as filling defects. The method has been shown to be as sensitive as three-phase CT. Microbubbles have clinical uses in many other applications where knowledge of the microcirculation is important (the macrocirculation can usually be assessed adequately using conventional Doppler though there are a few important situations where the signal boost given by microbubbles is useful, e.g., transcranial Doppler for evaluating vasospasm after subarachnoid haemorrhage). An important situation where demonstrating tissue devitalisation is important is in interstitial ablation of focal liver lesions: using microbubble contrast agents at the end of a procedure allows immediate evaluation of the adequacy of the ablation which can be extended if needed; this is much more convenient and cost-saving than moving the patient to CT and perhaps needing an additional ablation session at a later date. Similar considerations suggest that contrast-enhanced ultrasound might have a role in abdominal trauma: injury to the liver, spleen and kidneys can be assessed rapidly and repeatedly if necessary. Its role here alongside dynamic CT remains to be evaluated. Infarcts or ischaemia and regions of abnormal vascularity, especially in malignancies, in the kidneys and spleen seem to be useful and improved detection of the neovascularisation of ovarian carcinomas is promising. Similar benefits in the head-and-neck and in the skin while the demonstration of the neovascularisation of atheromatous plaques and of aggressive joint inflammation offer interesting potentials. {\textcopyright} 2006.},
  doi           = {10.1016/j.ejrad.2006.06.022},
  keywords      = {Contrast agents, Focal liver lesions, Folder - Contrast agents detection, Microbubbles, Ovary, Trauma, Ultrasound},
  mendeley-tags = {Contrast agents,Focal liver lesions,Folder - Contrast agents detection,Microbubbles,Ovary,Trauma,Ultrasound},
  pmid          = {16938418},
}

@article{Tortoli1999,
abstract = {In this report, we consider the modifications yielded in the Doppler spectrum when acoustic fields of increasing intensities are applied to encapsulated gas bubbles. Our in vitro experimental results show that the spectrum bandwidth is nearly proportional to the incident acoustic pressure, when its amplitude is maintained below about 200 kPa. At higher pressure levels, it even may happen that, in a steady, unidirectional flow (which should generate only positive Doppler frequencies), the Doppler spectrum is enlarged up to the point that negative Doppler shifts also are produced. Possible explanations in terms of either radiation force or streaming are discussed for this asymmetrical bandwidth enlargement. {\textcopyright} 1999 IEEE.},
author = {Tortoli, Piero and Bagnai, Daniele and Righi, Daniele},
doi = {10.1109/58.741543},
issn = {08853010},
journal = {IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
keywords = {Folder - Contrast agents doppler},
mendeley-tags = {Folder - Contrast agents doppler},
number = {1},
pages = {247--252},
title = {{Quantitative analysis of doppler spectrum modifications yielded by contrast agents insonified at high pressure}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/18238421},
volume = {46},
year = {1999}
}

@Article{Demene2015,
  author        = {Demen{\'{e}}, Charlie and Deffieux, Thomas and Pernot, Mathieu and Osmanski, Bruno F{\'{e}}lix and Biran, Val{\'{e}}rie and Gennisson, Jean Luc and Sieu, Lim Anna and Bergel, Antoine and Franqui, St{\'{e}}phanie and Correas, Jean Michel and Cohen, Ivan and Baud, Olivier and Tanter, Mickael},
  journal       = {IEEE Transactions on Medical Imaging},
  title         = {{Spatiotemporal Clutter Filtering of Ultrafast Ultrasound Data Highly Increases Doppler and fUltrasound Sensitivity}},
  year          = {2015},
  issn          = {1558254X},
  number        = {11},
  pages         = {2271--2285},
  volume        = {34},
  abstract      = {Ultrafast ultrasonic imaging is a rapidly developing field based on the unfocused transmission of plane or diverging ultrasound waves. This recent approach to ultrasound imaging leads to a large increase in raw ultrasound data available per acquisition. Bigger synchronous ultrasound imaging datasets can be exploited in order to strongly improve the discrimination between tissue and blood motion in the field of Doppler imaging. Here we propose a spatiotemporal singular value decomposition clutter rejection of ultrasonic data acquired at ultrafast frame rate. The singular value decomposition (SVD) takes benefits of the different features of tissue and blood motion in terms of spatiotemporal coherence and strongly outperforms conventional clutter rejection filters based on high pass temporal filtering. Whereas classical clutter filters operate on the temporal dimension only, SVD clutter filtering provides up to a four-dimensional approach (3D in space and 1D in time). We demonstrate the performance of SVD clutter filtering with a flow phantom study that showed an increased performance compared to other classical filters (better contrast to noise ratio with tissue motion between 1 and 10mm/s and axial blood flow as low as 2.6 mm/s). SVD clutter filtering revealed previously undetected blood flows such as microvascular networks or blood flows corrupted by significant tissue or probe motion artifacts. We report in vivo applications including small animal fUltrasound brain imaging (blood flow detection limit of 0.5 mm/s) and several clinical imaging cases, such as neonate brain imaging, liver or kidney Doppler imaging.},
  doi           = {10.1109/TMI.2015.2428634},
  keywords      = {Blood, Blood flow, Clutter, Doppler effect, Doppler imaging, Folder - advanced doppler, Imaging, Matrix decomposition, Ultrasonic imaging, singular value decomposition, ultrafast imaging, ultrasound},
  mendeley-tags = {Blood,Blood flow,Clutter,Doppler effect,Doppler imaging,Folder - advanced doppler,Imaging,Matrix decomposition,Ultrasonic imaging,singular value decomposition,ultrafast imaging,ultrasound},
  pmid          = {25955583},
  url           = {http://www.ncbi.nlm.nih.gov/pubmed/25955583},
}

@article{Jensen1998,
abstract = {The paper describes a new method1 for determining the velocity vector of a remotely sensed object using either sound or electromagnetic radiation. The movement of the object is determined from a field with spatial oscillations in both the axial direction of the transducer and in one or two directions transverse to the axial direction. By using a number of pulse emissions, the inter-pulse movement can be estimated and the velocity found from the estimated movement and the time between pulses. The method is based on the principle of using transverse spatial modulation for making the received signal influenced by transverse motion. Such a transverse modulation can be generated by using apodization on individual transducer array elements together with a special focusing scheme. A method for making such a field is presented along with a suitable two-dimensional velocity estimator. An implementation usable in medical ultrasound is described, and simulated results are presented. Simulation results for a flow of 1 m/s in a tube rotated in the image plane at specific angles (0, 15, 35, 55, 75, and 90 degrees) are made and characterized by the estimated mean value, estimated angle, and the standard deviation in the lateral and longitudinal direction. The average performance of the estimates for all angles is: mean velocity 0.99 m/s, longitudinal S.D. 0.015 m/s, and lateral S.D. 0.196 m/s. For flow parallel to the transducer the results are: mean velocity 0.95 m/s, angle 0.1°, longitudinal S.D. 0.020 m/s, and lateral S.D. 0.172 m/s. {\textcopyright} 1998 IEEE.},
author = {Jensen, J{\o}rgen Arendt and Munk, Peter},
doi = {10.1109/58.677749},
issn = {08853010},
journal = {IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
keywords = {Folder - Vector doppler},
mendeley-tags = {Folder - Vector doppler},
number = {3},
pages = {837--851},
title = {{A new method for estimation of velocity vectors}},
volume = {45},
year = {1998}
}

@Article{TremblayDarveau2016a,
  author        = {Tremblay-Darveau, Charles and Williams, Ross and Sheeran, Paul S. and Milot, Laurent and Bruce, Matthew and Burns, Peter N.},
  journal       = {IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
  title         = {{Concepts and Tradeoffs in Velocity Estimation with Plane-Wave Contrast-Enhanced Doppler}},
  year          = {2016},
  issn          = {08853010},
  number        = {11},
  pages         = {1890--1905},
  volume        = {63},
  abstract      = {While long Doppler ensembles are, in principle, beneficial for velocity estimates, short acoustic pulses must be used in microbubble contrast-enhanced (CE) Doppler to mitigate microbubble destruction. This introduces inherent tradeoffs in velocity estimates with autocorrelators, which are studied here. A model of the autocorrelation function adapted to the microbubble Doppler signal accounting for transit time, the echo frequency uncertainty, and contrast-agent destruction is derived and validated in vitro. It is further demonstrated that a local measurement of the center frequency of the microbubble echo is essential in order to avoid significant bias in velocity estimates arising from the linear and nonlinear frequency-dependent scattering of microbubbles and compensate for the inherent speckle nature of the received echo frequency. For these reasons, broadband Doppler estimators (2-D autocorrelator and Radon projection) are better suited than simpler narrow-band estimators (1-D autocorrelator and 1-D Fourier transform) for CE flow assessment. A case study of perfusion in a VX-2 carcinoma using CE plane-wave Doppler is also shown. We demonstrate that even when considering all uncertainties associated with microbubble-related decorrelation (destruction, pulse bandwidth, transit time, and flow gradient) and the need for real-time imaging, a coefficient of variation of 4% on the axial velocity is achievable with plane-wave imaging.},
  doi           = {10.1109/TUFFC.2016.2596581},
  keywords      = {Autocorrelators, Doppler, Folder - Contrast agents doppler, blood velocity, microbubbles, plane-wave ultrasound},
  mendeley-tags = {Autocorrelators,Doppler,Folder - Contrast agents doppler,blood velocity,microbubbles,plane-wave ultrasound},
  pmid          = {27824566},
}

@Article{Ricci2014a,
  author        = {Ricci, Stefano and Matera, Riccardo and Tortoli, Piero},
  journal       = {Ultrasonics},
  title         = {{An improved Doppler model for obtaining accurate maximum blood velocities}},
  year          = {2014},
  issn          = {0041624X},
  number        = {7},
  pages         = {2006--2014},
  volume        = {54},
  abstract      = {Maximum blood velocity estimates are frequently required in diagnostic applications, including carotid stenosis evaluation, arteriovenous fistula inspection, and maternal-fetal examinations. However, the currently used methods for ultrasound measurements are inaccurate and often rely on applying heuristic thresholds to a Doppler power spectrum. A new method that uses a mathematical model to predict the correct threshold that should be used for maximum velocity measurements has recently been introduced. Although it is a valuable and deterministic tool, this method is limited to parabolic flows insonated by uniform pressure fields. In this work, a more generalized technique that overcomes such limitations is presented. The new approach, which uses an extended Doppler spectrum model, has been implemented in an experimental set-up based on a linear array probe that transmits defocused steered waves. The improved model has been validated by Field II simulations and phantom experiments on tubes with diameters between 2 mm and 8 mm. Using the spectral threshold suggested by the new model significantly higher accuracy estimates of the peak velocity can be achieved than are now clinically attained, including for narrow beams and non-parabolic velocity profiles. In particular, an accuracy of +1.2 ± 2.5 cm/s has been obtained in phantom measurements for velocities ranging from 20 to 80 cm/s. This result represents an improvement that can significantly affect the way maximum blood velocity is investigated today. {\textcopyright} 2014 Elsevier B.V. All rights reserved.},
  doi           = {10.1016/j.ultras.2014.05.012},
  keywords      = {Blood Flow Velocity, Blood Flow Velocity: physiology, Blood flow, Computer Simulation, Doppler, Doppler spectrum, Doppler: methods, Folder - 1D Doppler, Hemorheology, Hemorheology: physiology, Humans, Imaging, Maximum velocity measurement, Models, Phantoms, Regional Blood Flow, Theoretical, Transducers, Ultrasonography},
  mendeley-tags = {Blood Flow Velocity,Blood Flow Velocity: physiology,Computer Simulation,Doppler,Doppler: methods,Folder - 1D Doppler,Hemorheology,Hemorheology: physiology,Humans,Imaging,Models,Phantoms,Regional Blood Flow,Theoretical,Transducers,Ultrasonography},
  pmid          = {24934798},
  url           = {http://www.ncbi.nlm.nih.gov/pubmed/24934798},
}

@Article{Gorce2000,
  author        = {Gorce, Jean Marie and Arditi, Marcel and Schneider, Michel},
  journal       = {Investigative Radiology},
  title         = {{Influence of bubble size distribution on the echogenicity of ultrasound contrast agents: A study of sonovue(TM)}},
  year          = {2000},
  issn          = {00209996},
  number        = {11},
  pages         = {661--671},
  volume        = {35},
  abstract      = {RATIONALE AND OBJECTIVES. To study the relative contributions of different bubble size classes to SonoVue(TM)'s echogenicity in fundamental acoustic imaging modes. SonoVue(TM) is a contrast agent, previously known as BR1, with a bubble size distribution extending from approximately 0.7 to 10 $\mu$m. METHODS. A model for the acoustic response of SonoVue(TM) was determined and validated for a set of experimental data. This model was used to simulate the acoustic response of a standard batch of SonoVue(TM) as the sum of responses of non-overlapping bubble size classes. RESULTS. The simulation was first validated for a standard SonoVue(TM) bubble size distribution. When this distribution was considered as five size classes with equal numbers of bubbles, it was found that bubbles smaller than 2 $\mu$m accounted for 60% of the total number but contained only 5% of the total gas volume. The simulation results indicated marked differences in the acoustic contributions from these classes, with 80% of the acoustic efficacy provided by bubbles 3 to 9 $\mu$m in diameter. The study also compared bubble distributions in number, surface, and volume, with the distribution computed in terms of acoustic efficacy. CONCLUSIONS. This study shows why bubble volume is a much better indicator of SonoVue(TM)'s efficacy than is bubble count. A low threshold in diameter was found for SonoVue(TM) microbubbles at approximately 2 $\mu$m, under which size bubbles do not contribute appreciably to the echogenicity at medical ultrasound frequencies.},
  doi           = {10.1097/00004424-200011000-00003},
  keywords      = {Bubble size distribution, Contrast efficacy, Folder - Contrast agents detection, SonoVue(TM), Ultrasound contrast agents, bubble size distribution, contrast ef cacy, from bracco research sa, plan-les-ouates, sonovue, switzerland, ultrasound contrast agents},
  mendeley-tags = {Folder - Contrast agents detection,bubble size distribution,contrast ef cacy,from bracco research sa,plan-les-ouates,sonovue,switzerland,ultrasound contrast agents},
  pmid          = {11110302},
  url           = {http://content.wkhealth.com/linkback/openurl?sid=WKPTLP:landingpage&an=00004424-200011000-00003},
}

@InProceedings{Toulemonde2016,
  author        = {Toulemonde, M. and Li, Y. and Lin, S. and Tang, M. X. and Butler, M. and Sboros, V. and Eckersley, R. and Duncan, W. C.},
  booktitle     = {IEEE International Ultrasonics Symposium, IUS},
  title         = {{Cardiac imaging with high frame rate contrast enhanced ultrasound: In-vivo demonstration}},
  year          = {2016},
  pages         = {1--4},
  volume        = {2016-Novem},
  abstract      = {This work presents the first in-vivo High-frame rate Contrast Enhanced Ultrasound (HFR CEUS) for cardiac application. The in-vivo acquisition has been made on a sheep. A coherent compounding of diverging waves combined with Pulse Inversion (PI) transmission allow a frame rate of 250 frame per seconds which is 8 times faster than standard CEUS acquisition in cardiac application. The proposed method improves the image contrast compared to the CEUS and allows a better tracking of fast movement of the heart.},
  doi           = {10.1109/ULTSYM.2016.7728482},
  isbn          = {9781467398978},
  issn          = {19485727},
  keywords      = {Cardiac, Diverging, Folder - Cardiac, Image registration, In-vivo, Ultrafast imaging, cardiac, diverging, in-vivo, ultrafast imaging},
  mendeley-tags = {Folder - Cardiac,cardiac,diverging,in-vivo,ultrafast imaging},
}

@article{Couture2012,
abstract = {Background: Monitoring the accumulation of microbubbles within tissue vasculature with ultrasound allows both molecular and perfusion imaging. Unfortunately, conventional imaging with focused pulses can destroy a large fraction of the microbubbles it is trying to follow. Using coherent synthetic summation, ultrafast plane wave imaging could attain similar image quality, while reducing the peak acoustic pressure and bubble disruption. Method: In these experiments, microbubbles were flowed in a wall-less vessel phantom. Images were obtained on a programmable clinical scanner with a set of line-per-line focused pulses for conventional contrast imaging and with compounded plane wave transmission adapted for nonlinear imaging. Imaging was performed between 14 and 650 kPa peak negative pressure at 7.5 MHz. The disruption of the microbubbles was evaluated by comparing the microbubble intensity before and after acquisition of a set of 100 images at various pressures. Results: The acoustic intensity required to disrupt 50% of the microbubbles was 24 times higher with plane-wave imaging compared with conventional focused pulses. Although both imaging approaches yield similar resolution, at the same disruption level, plane-wave imaging showed better contrast. In particular, at similar disruption ratio (50% after 100 images), contrast-pulse sequencing (CPS) performed with plane waves displayed an improvement of 11 dB compared with conventional nonlinear imaging. Conclusion: In each resolution cell of the image, plane-wave imaging spread the spatial peak acoustic intensity over more pulses, reducing the peak pressure and, hence, preserving the microbubbles. This method could contribute to molecular imaging by allowing the continuous monitoring of the accumulation of microbubbles with improved contrast. {\textcopyright} 2012 IEEE.},
author = {Couture, Olivier and Fink, Mathias and Tanter, Mickael},
doi = {10.1109/TUFFC.2012.2508},
issn = {08853010},
journal = {IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
keywords = {Folder - Contrast agents detection},
mendeley-tags = {Folder - Contrast agents detection},
number = {12},
pages = {2676--2683},
pmid = {23221216},
title = {{Ultrasound contrast plane wave imaging}},
volume = {59},
year = {2012}
}

@Article{Demi2015a,
  author        = {Demi, Libertario and {Van Sloun}, Ruud J.G. and Wijkstra, Hessel and Mischi, Massimo},
  journal       = {Physics in Medicine and Biology},
  title         = {{Cumulative phase delay imaging for contrast-enhanced ultrasound tomography}},
  year          = {2015},
  issn          = {13616560},
  month         = {nov},
  number        = {21},
  pages         = {L26--L33},
  volume        = {60},
  abstract      = {Standard dynamic-contrast enhanced ultrasound (DCE-US) imaging detects and estimates ultrasound-contrast-agent (UCA) concentration based on the amplitude of the nonlinear (harmonic) components generated during ultrasound (US) propagation through UCAs. However, harmonic components generation is not specific to UCAs, as it also occurs for US propagating through tissue. Moreover, nonlinear artifacts affect standard DCE-US imaging, causing contrast to tissue ratio reduction, and resulting in possible misclassification of tissue and misinterpretation of UCA concentration. Furthermore, no contrast-specific modality exists for DCE-US tomography; in particular speed-of-sound changes due to UCAs are well within those caused by different tissue types. Recently, a new marker for UCAs has been introduced. A cumulative phase delay (CPD) between the second harmonic and fundamental component is in fact observable for US propagating through UCAs, and is absent in tissue. In this paper, tomographic US images based on CPD are for the first time presented and compared to speed-of-sound US tomography. Results show the applicability of this marker for contrast specific US imaging, with cumulative phase delay imaging (CPDI) showing superior capabilities in detecting and localizing UCA, as compared to speed-of-sound US tomography. Cavities (filled with UCA) which were down to 1 mm in diameter were clearly detectable. Moreover, CPDI is free of the above mentioned nonlinear artifacts. These results open important possibilities to DCE-US tomography, with potential applications to breast imaging for cancer localization.},
  doi           = {10.1088/0031-9155/60/21/L23},
  keywords      = {Folder - Contrast agents detection, contrast enhanced ultrasound imaging, ultrasound contrast agents, ultrasound tomography},
  language      = {en},
  mendeley-tags = {Folder - Contrast agents detection},
  pmid          = {26459771},
  url           = {http://stacks.iop.org/0031-9155/60/i=21/a=L23?key=crossref.9ce6836355c069241d98cfcb42430779},
}

@article{Lenge2014,
abstract = {Conventional ultrasound Doppler techniques estimate the blood velocity exclusively in the axial direction to produce the sonograms and color flow maps needed for diagnosis of cardiovascular diseases. In this paper, a novel method to produce bi-dimensional maps of 2-D velocity vectors is proposed. The region of interest (ROI) is illuminated by plane waves transmitted at the pulse repetition frequency (PRF) in a fixed direction. For each transmitted plane wave, the backscattered echoes are recombined offline to produce the radio-frequency image of the ROI. The local 2-D phase shifts between consecutive speckle images are efficiently estimated in the frequency domain, to produce vector maps up to 15 kHz PRF. Simulations and in vitro steady-flow experiments with different setup conditions have been conducted to thoroughly evaluate the method's performance. Bias is proved to be lower than 10% in most simulations and lower than 20% in experiments. Further simulations and in vivo experiments have been made to test the approach's feasibility in pulsatile flow conditions. It has been estimated that the computation of the frequency domain algorithm is more than 50 times faster than the computation of the reference 2-D cross-correlation algorithm. {\textcopyright} 2014 IEEE.},
author = {Lenge, Matteo and Ramalli, Alessandro and Boni, Enrico and Liebgott, Herv{\'{e}} and Cachard, Christian and Tortoli, Piero},
doi = {10.1109/TUFFC.2014.3064},
issn = {08853010},
journal = {IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
keywords = {Folder - Vector doppler},
mendeley-tags = {Folder - Vector doppler},
number = {9},
pages = {1504--1514},
pmid = {25167150},
title = {{High-frame-rate 2-D vector blood flow imaging in the frequency domain}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/25167150},
volume = {61},
year = {2014}
}

@Misc{Cikes2014,
  author        = {Cikes, Maja and Tong, Ling and Sutherland, George R. and D'Hooge, Jan},
  title         = {{Ultrafast cardiac ultrasound imaging: Technical principles, applications, and clinical benefits}},
  year          = {2014},
  abstract      = {Several recent technical advances in cardiac ultrasound allow data to be acquired at a very high frame rate. Retrospective gating, plane/diverging wave imaging, and multiline transmit imaging all improve the temporal resolution of the conventional ultrasound system. The main drawback of such high frame rate data acquisition is that it typically has reduced image quality. However, for given clinical applications, the acquisition of temporally-resolved data might outweigh the reduction in image quality. It is the aim of this paper to provide an overview of the technical principles behind these new ultrasound imaging modalities, to review the current evidence of their potential clinical added value, and to forecast how they might influence daily clinical practice. {\textcopyright} 2014 by the American College of Cardiology Foundation.},
  booktitle     = {JACC: Cardiovascular Imaging},
  doi           = {10.1016/j.jcmg.2014.06.004},
  issn          = {18767591},
  keywords      = {Folder - Cardiac, cardiovascular imaging, deformation, diverging wave imaging, high frame rate imaging, plane wave imaging, tissue Doppler imaging, ultrafast cardiac imaging},
  mendeley-tags = {Folder - Cardiac,cardiovascular imaging,deformation,diverging wave imaging,high frame rate imaging,plane wave imaging,tissue Doppler imaging,ultrafast cardiac imaging},
  number        = {8},
  pages         = {812--823},
  pmid          = {25124014},
  volume        = {7},
}

@Article{Mahue2011,
  author        = {Mahue, Veronique and Mari, Jean Martial and Eckersley, Robert J. and Tang, Meng Xing},
  journal       = {IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
  title         = {{Comparison of pulse subtraction doppler and pulse inversion doppler}},
  year          = {2011},
  issn          = {08853010},
  month         = {jan},
  number        = {1},
  pages         = {73--81},
  volume        = {58},
  abstract      = {In this paper, a new Doppler technique based on pulse subtraction imaging (PSD) is described and compared with pulse inversion Doppler (PID). Combining a nonlinear contrast agent imaging technique with a Doppler process provides a tool for detecting motion of both contrast agents and tissues. This has potential in targeted imaging in which attached microbubbles need to be separated from moving ones and surrounding tissues. The results from both simulation and experiment show that PSD is able to differentiate bubble motion from tissue motion. For Doppler processing conducted at the fundamental frequency, the contrast-to-tissue ratio (CTR) in PSD was 3.3 (±0.4) times higher on average than PID at a mechanical index (MI) of 0.1. At the harmonic frequency, PID was shown to have a 3.1 (±0.4) times higher CTR than PSD. Overall, taken in their optimum processing conditions, PID has a CTR up to 1.9 (±0.4) times higher than PSD. The CTRs for both techniques have also been shown to increase with increasing MI. However, for the same axial Doppler resolution. PSD also allows less energy to be transmitted into the medium, which makes it less disruptive. The relative performances of PSD and PID in terms of the bandwidth of the imaging system are also discussed. {\textcopyright} 2011 IEEE.},
  doi           = {10.1109/TUFFC.2011.1775},
  keywords      = {Acoustics, Computer Simulation, Computer-Assisted, Contrast Media, Demodulation, Doppler, Doppler effect, Doppler measurement, Folder - 1D Doppler, Harmonic analysis, Imaging, Mathematical model, Microbubbles, PID imaging, PSD imaging, Phantoms, Signal Processing, Subtraction Technique, Transducers, Ultrasonography, biomedical ultrasonics, mechanical index, microbubble, nonlinear contrast agent imaging, pulse inversion doppler imaging, pulse subtraction doppler imaging, ultrasonic imaging},
  mendeley-tags = {Acoustics,Computer Simulation,Computer-Assisted,Contrast Media,Demodulation,Doppler,Doppler effect,Doppler measurement,Folder - 1D Doppler,Harmonic analysis,Imaging,Mathematical model,Microbubbles,PID imaging,PSD imaging,Phantoms,Signal Processing,Subtraction Technique,Transducers,Ultrasonography,biomedical ultrasonics,mechanical index,microbubble,nonlinear contrast agent imaging,pulse inversion doppler imaging,pulse subtraction doppler imaging,ultrasonic imaging},
  pmid          = {21244976},
}

@Article{Demene2014,
  author        = {Demen{\'{e}}, Charlie and Pernot, Mathieu and Biran, Val{\'{e}}rie and Alison, Marianne and Fink, Mathias and Baud, Olivier and Tanter, Micka{\"{e}}l},
  journal       = {Journal of Cerebral Blood Flow and Metabolism},
  title         = {{Ultrafast Doppler reveals the mapping of cerebral vascular resistivity in neonates}},
  year          = {2014},
  issn          = {15597016},
  number        = {6},
  pages         = {1009--1017},
  volume        = {34},
  abstract      = {In vivo mapping of the full vasculature dynamics based on Ultrafast Doppler is showed noninvasively in the challenging case of the neonatal brain. Contrary to conventional pulsed-wave (PW) Doppler Ultrasound limited for >40 years to the estimation of vascular indices at a single location, the ultrafast frame rate (5,000 Hz) obtained using plane-wave transmissions leads to simultaneous estimation of full Doppler spectra in all pixels of wide field-of-view images within a single cardiac cycle and high sensitivity Doppler imaging. Consequently, 2D quantitative maps of the cerebro-vascular resistivity index (RI) are processed and found in agreement with local measurements obtained on large arteries of healthy neonates using conventional PW Doppler. Changes in 2D resistivity maps are monitored during recovery after therapeutic whole-body cooling of full-term neonates treated for hypoxic ischemic encephalopathy. Arterial and venous vessels are unambiguously differentiated on the basis of their distinct hemodynamics. The high spatial (250 × 250 $\mu$m 2) and temporal resolution (<1 ms) of Ultrafast Doppler imaging combined with deep tissue penetration enable precise quantitative mapping of deep brain vascular dynamics and RI, which is far beyond the capabilities of any other imaging modality. {\textcopyright} 2014 ISCBFM All rights reserved.},
  doi           = {10.1038/jcbfm.2014.49},
  keywords      = {Brain, Brain: physiopathology, Brain: ultrasonography, Cerebral Angiography, Cerebral Arteries, Cerebral Arteries: physiopathology, Cerebral Arteries: ultrasonography, Cerebrovascular Circulation, Color, Doppler, Female, Folder - advanced doppler, Humans, Hypoxia-Ischemia, Infant, Male, Newborn, Ultrasonography, Vascular Resistance, angiography, brain imaging, cerebral hemodynamics, neurosonology, ultrasound},
  mendeley-tags = {Brain,Brain: physiopathology,Brain: ultrasonography,Cerebral Angiography,Cerebral Arteries,Cerebral Arteries: physiopathology,Cerebral Arteries: ultrasonography,Cerebrovascular Circulation,Color,Doppler,Female,Folder - advanced doppler,Humans,Hypoxia-Ischemia,Infant,Male,Newborn,Ultrasonography,Vascular Resistance},
  pmid          = {24667916},
  url           = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=4050246&tool=pmcentrez&rendertype=abstract},
}

@InProceedings{Leow2017,
  author        = {Leow, Chee Hau and Marta, Braga and Stanziola, Antonio and Hernandez-Gil, Javier and Long, Nicholas J. and Aboagye, Eric O. and Tang, Meng Xing},
  booktitle     = {IEEE International Ultrasonics Symposium, IUS},
  title         = {{Multi-frame rate plane wave contrast-enhance ultrasound imaging for tumour vasculature imaging and perfusion quantification}},
  year          = {2017},
  abstract      = {A multi-frame rate plane wave imaging strategy is developed to simultaneously image tumor vasculature and quantify tumor perfusion. Customised imaging sequences interleaving a short but high frame rate (HFR) plane wave imaging sequence with a long but low frame rate imaging (LFR) sequence were implemented using a programmable ultrasound research platform. The results from a spatio-temporal coherence processing technique of ours demonstrated a significant improvement in the SNR and vasculature contrast when compared with the existing ultrafast Power Doppler (PD) using the same data. Initial perfusion quantification using LFR imaging was also demonstrated. Mean time intensity curve and some parametric measures were generated. Combining both structural and functional perfusion imaging using the multiframe rate sequences, a better evaluation of the tumour angiogenesis can be assessed.},
  doi           = {10.1109/ULTSYM.2017.8092706},
  isbn          = {9781538633830},
  issn          = {19485727},
  keywords      = {CEUS, Folder - Contrast agents detection, Microbubbles contrast agents, Microvascular flow and perfusion, Molecular imaging, Plane wave imaging},
  mendeley-tags = {CEUS,Folder - Contrast agents detection,Microbubbles contrast agents,Microvascular flow and perfusion,Molecular imaging,Plane wave imaging},
}

@Article{DOnofrio2015,
  author        = {D'Onofrio, Mirko and Crosara, Stefano and {De Robertis}, Riccardo and Canestrini, Stefano and Mucelli, Roberto Pozzi},
  journal       = {American Journal of Roentgenology},
  title         = {{Contrast-enhanced ultrasound of focal liver lesions}},
  year          = {2015},
  issn          = {15463141},
  month         = {jul},
  number        = {1},
  pages         = {W56--W66},
  volume        = {205},
  abstract      = {OBJECTIVE. The purpose of this article is to discuss the use of contrast-enhanced ultrasound (CEUS) in focal liver lesions. CONCLUSION. Focal liver lesions are usually detected incidentally during abdominal ultrasound. The injection of microbubble ultrasound contrast agents improves the characterization of focal liver lesions that are indeterminate on conventional ultrasound. The use of CEUS is recommended in official guidelines and suggested as a second diagnostic step after ultrasound detection of indeterminate focal liver lesions to immediately establish the diagnosis, especially for benign liver lesions, such as hemangiomas, avoiding further and more expensive examinations.},
  doi           = {10.2214/AJR.14.14203},
  keywords      = {Contrast-enhanced ultrasound (CEUS), Focal liver lesions, Folder - Contrast agents applications, HCC, Metastasis, Microbubbles},
  language      = {en},
  mendeley-tags = {Folder - Contrast agents applications},
  pmid          = {26102419},
  url           = {http://www.ajronline.org/doi/10.2214/AJR.14.14203},
}

@Article{Baker1970,
  author        = {Baker, Donald W.},
  journal       = {IEEE Transactions on Sonics and Ultrasonics},
  title         = {{Pulsed Ultrasonic Doppler Blood-Flow Sensing}},
  year          = {1970},
  issn          = {00189537},
  number        = {3},
  pages         = {170--184},
  volume        = {SU-17},
  abstract      = {Doppler detection of pulsed ultrasound is being used to map fluid flows in models and transcutaneously in blood vessels in man. A device has been developed and is being evaluated using 1-µs bursts of 5 MHz ultrasound that are projected into the stream under study. The Doppler shift of the backscattered signals is sensed in a phase detector. This Doppler signal corresponds to the mean velocity over a small region in space defined by the ultrasonic beam dimensions, transmitted pulse duration, and transducer bandwidth. By using a comb-type gate and sequential sampling, the flow velocity profile can be mapped at selected intervals over one period of pulsatile flow in a model or in man. From this information, a three-dimensional surface is generated as a function of velocity, tube diameter, and time. Volume flow, stroke volume, and flow acceleration can be derived directly from the data. Copyright {\textcopyright} 1970 by The Institute of Electrical and Electronics Engineers, Inc.},
  doi           = {10.1109/T-SU.1970.29558},
  keywords      = {Blood flow, Blood vessels, Cardiac disease, Cardiovascular diseases, Fluid flow, Folder - 1D Doppler, Heart, Motion detection, Phase detection, Ultrasonic imaging, Ultrasonic transducers},
  mendeley-tags = {Blood flow,Blood vessels,Cardiac disease,Cardiovascular diseases,Fluid flow,Folder - 1D Doppler,Heart,Motion detection,Phase detection,Ultrasonic imaging,Ultrasonic transducers},
  url           = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1538563},
}

@article{Lin2013,
abstract = {In ultrasound contrast imaging, many techniques based on multiple transmissions have been proposed to increase the contrast-to-tissue ratio (CTR). They are generally based on the response of static scatterers inside the imaged region. However, scatterer motion, for example in blood vessels, has an inevitable influence on multi-pulse techniques, which can either enhance or degrade the technique involved. This paper investigates the response of static nonlinear media insonated by multi-pulses with various phase shifts, and the influence of scatterer motion on multi-pulse techniques. Simulations and experimental results from a single bubble and clouds of bubbles show that the phase shift of the echoes backscattered from bubbles is dependent on the transmissions' phase shift, and that the bubble motion influences the efficiency of multi-pulse techniques: fundamental and second-harmonic amplitudes of the processed signal change periodically, exhibiting maximum or minimum values, according to scatterer motion. Furthermore, experimental results based on the second-harmonic inversion (SHI) technique reveal that bubble motion can be taken into account to regulate the pulse repetition frequency (PRF). With the optimal PRF, the CTR of SHI images can be improved by about 12 dB compared with second-harmonic images. {\textcopyright} 2013 IEEE.},
author = {Lin, Fanglue and Cachard, Christian and Mori, Riccardo and Varray, Francois and Guidi, Francesco and Basset, Olivier},
doi = {10.1109/TUFFC.2013.2797},
issn = {08853010},
journal = {IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
keywords = {Folder - Contrast agents detection},
mendeley-tags = {Folder - Contrast agents detection},
number = {10},
pages = {2065--2078},
pmid = {24081255},
title = {{Ultrasound contrast imaging: Influence of scatterer motion in multi-pulse techniques}},
volume = {60},
year = {2013}
}

@Article{Adler2019,
  author   = {Adler, Jonas and Oktem, Ozan},
  journal  = {Medical Imaging with Deep Learning},
  title    = {{Deep posterior sampling: Uncertainty quantification for large scale inverse problems}},
  year     = {2019},
  pages    = {1--4},
  abstract = {The goal in an inverse problem is to recover a hidden model parameter from noisy indirect observations. Such problems arise in several areas of science and industry and their solutions form the basis for decision making, like when imaging is used in medicine. Inverse problems are often ill-posed, meaning that there can be multiple solutions consistent with observations and small errors in data result in large errors in the solution. Hence, it is important to assess the uncertainty in the solution of an ill-posed problem and especially so when critical decisions are based on the solution. Bayesian inversion offers a coherent framework for both solving an ill-posed inverse problem and quantifying the uncertainty in its solution. Its applicability is however limited by the ability to select a sufficiently 'good' prior and capability to manage the computational burden. We show how a conditional Wasserstein GAN (WGAN) with a novel minibatch dis-criminator can be used to sample from the posterior in Bayesian inversion. The suggested approach is demonstrated for image-guided medical diagnostics using computed tomogra-phy. To formalise the task in an inverse problem, let x * ∈ X denote the unknown hidden model parameter we seek and y ∈ Y is the noisy indirect observations (data). Here, X and Y are appropriate (possibly infinite dimensional) vector spaces whose elements represent possible model parameters and data, respectively. Next, we also have access to a deterministic model A : X → Y that describes how a model parameter gives rise to data (forward operator) in the absence of noise. Furthermore, assume measured data y ∈ Y is a single sample of the conditional random variable (y | x = x *). Here, y = A(x) + e where e ∼ $\pi$ noise denotes a Y-valued random variable that represents the noise. Finally, the unknown model parameter x * ∈ X itself is assumed to be a sample of an X-valued random variable x ∼ $\pi$ 0. The ultimate task in Bayesian inversion is to recover the posterior, e.g. the probability distribution of the conditional random variable (x | y = y). This formulation comes with several desirable theoretical properties; it is stable with respect to changes in the data even when the inverse problem is ill-posed (Dashti and Stuart, 2017) and the posterior will for many priors concentrate around the true model parameter as noise level goes to zero (consistency & contraction rates) (Nickl, 2017). On the other hand, computations with},
  keywords = {Bayesian Inversion 1 Bayesian Inversion, CT, GAN, Image Reconstruction, Inverse Problem},
  language = {en},
}

@Article{Hauptmann2020,
  author        = {Hauptmann, Andreas and Adler, Jonas and Arridge, Simon and Oktem, Ozan},
  journal       = {IEEE Transactions on Computational Imaging},
  title         = {{Multi-Scale Learned Iterative Reconstruction}},
  year          = {2020},
  issn          = {23339403},
  month         = {apr},
  pages         = {843--856},
  volume        = {6},
  abstract      = {Model-based learned iterative reconstruction methods have recently been shown to outperform classical reconstruction algorithms. Applicability of these methods to large scale inverse problems is however limited by the available memory for training and extensive training times, the latter due to computationally expensive forward models. As a possible solution to these restrictions we propose a multi-scale learned iterative reconstruction scheme that computes iterates on discretisations of increasing resolution. This procedure does not only reduce memory requirements, it also considerably speeds up reconstruction and training times, but most importantly is scalable to large scale inverse problems with non-trivial forward operators, such as those that arise in many 3D tomographic applications. In particular, we propose a hybrid network that combines the multi-scale iterative approach with a particularly expressive network architecture which in combination exhibits excellent scalability in 3D. Applicability of the algorithm is demonstrated for 3D cone beam computed tomography from real measurement data of an organic phantom. Additionally, we examine scalability and reconstruction quality in comparison to established learned reconstruction methods in two dimensions for low dose computed tomography on human phantoms.},
  archiveprefix = {arXiv},
  arxivid       = {1908.00936},
  doi           = {10.1109/TCI.2020.2990299},
  eprint        = {1908.00936},
  keywords      = {Computer Science - Computer Vision and Pattern Rec, Computer Science - Neural and Evolutionary Computi, Electrical Engineering and Systems Science - Image, Mathematics - Numerical Analysis, Mathematics - Optimization and Control, Model-based learning, cone beam computed tomography, deep learning, inverse problems, iterative reconstruction},
  language      = {en},
  mendeley-tags = {Computer Science - Computer Vision and Pattern Rec,Computer Science - Neural and Evolutionary Computi,Electrical Engineering and Systems Science - Image,Mathematics - Numerical Analysis,Mathematics - Optimization and Control},
  url           = {http://arxiv.org/abs/1908.00936},
}

@Misc{Bar2019,
  author        = {Bar, Leah and Sochen, Nir},
  month         = {apr},
  title         = {{Unsupervised Deep Learning Algorithm for PDE-based Forward and Inverse Problems}},
  year          = {2019},
  abstract      = {We propose a neural network-based algorithm for solving forward and inverse problems for partial differential equations in unsupervised fashion. The solution is approximated by a deep neural network which is the minimizer of a cost function, and satisfies the PDE, boundary conditions, and additional regularizations. The method is mesh free and can be easily applied to an arbitrary regular domain. We focus on 2D second order elliptical system with non-constant coefficients, with application to Electrical Impedance Tomography. MSC Codes 3504},
  archiveprefix = {arXiv},
  arxivid       = {1904.05417},
  booktitle     = {arXiv},
  eprint        = {1904.05417},
  issn          = {23318422},
  keywords      = {3504, Computer Science - Machine Learning, Statistics - Machine Learning},
  language      = {en},
  mendeley-tags = {3504,Computer Science - Machine Learning,Statistics - Machine Learning},
  url           = {http://arxiv.org/abs/1904.05417},
}

@inproceedings{Zhang2018,
abstract = {A very deep convolutional neural network (CNN) has recently achieved great success for image super-resolution (SR) and offered hierarchical features as well. However, most deep CNN based SR models do not make full use of the hierarchical features from the original low-resolution (LR) images, thereby achieving relatively-low performance. In this paper, we propose a novel residual dense network (RDN) to address this problem in image SR. We fully exploit the hierarchical features from all the convolutional layers. Specifically, we propose residual dense block (RDB) to extract abundant local features via dense connected convolutional layers. RDB further allows direct connections from the state of preceding RDB to all the layers of current RDB, leading to a contiguous memory (CM) mechanism. Local feature fusion in RDB is then used to adaptively learn more effective features from preceding and current local features and stabilizes the training of wider network. After fully obtaining dense local features, we use global feature fusion to jointly and adaptively learn global hierarchical features in a holistic way. Experiments on benchmark datasets with different degradation models show that our RDN achieves favorable performance against state-of-the-art methods.},
author = {Zhang, Yulun and Tian, Yapeng and Kong, Yu and Zhong, Bineng and Fu, Yun},
booktitle = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2018.00262},
isbn = {9781538664209},
issn = {10636919},
keywords = {Computer Science - Computer Vision and Pattern Rec},
language = {en},
mendeley-tags = {Computer Science - Computer Vision and Pattern Rec},
month = {mar},
pages = {2472--2481},
title = {{Residual Dense Network for Image Super-Resolution}},
url = {http://arxiv.org/abs/1802.08797},
year = {2018}
}

@misc{DOro2020,
abstract = {Deterministic-policy actor-critic algorithms for continuous control improve the actor by plugging its actions into the critic and ascending the action-value gradient, which is obtained by chaining the actor's Jacobian matrix with the gradient of the critic w.r.t. input actions. However, instead of gradients, the critic is, typically, only trained to accurately predict expected returns, which, on their own, are useless for policy optimization. In this paper, we propose MAGE, a model-based actor-critic algorithm, grounded in the theory of policy gradients, which explicitly learns the action-value gradient. MAGE backpropagates through the learned dynamics to compute gradient targets in temporal difference learning, leading to a critic tailored for policy improvement. On a set of MuJoCo continuous-control tasks, we demonstrate the efficiency of the algorithm with respect to model-free and model-based state-of-the-art baselines.1},
archivePrefix = {arXiv},
arxivId = {2004.14309},
author = {D'Oro, Pierluca and Jaskowski, Wojciech},
booktitle = {arXiv},
eprint = {2004.14309},
issn = {23318422},
language = {en},
shorttitle = {How to Learn a Useful Critic?},
title = {{How to Learn a Useful Critic? Model-based Action-Gradient-Estimator Policy Optimization}},
url = {https://proceedings.neurips.cc/paper/2020/hash/03255088ed63354a54e0e5ed957e9008-Abstract.html},
volume = {33},
year = {2020}
}

@Misc{Leuschner2019,
  author        = {Leuschner, Johannes and Schmidt, Maximilian and Baguer, Daniel Otero and Maa{\ss}, Peter},
  month         = {may},
  title         = {{The LoDoPaB-CT dataset: A benchmark dataset for low-dose ct reconstruction methods}},
  year          = {2019},
  abstract      = {Deep Learning approaches for solving Inverse Problems in imaging have become very effective and are demonstrated to be quite competitive in the field. Comparing these approaches is a challenging task since they highly rely on the data and the setup that is used for training. We provide a public dataset of computed tomography images and simulated low-dose measurements suitable for training this kind of methods. With the LoDoPaB-CT Dataset we aim to create a benchmark that allows for a fair comparison. It contains over 40 000 scan slices from around 800 patients selected from the LIDC/IDRI Database. In this paper we describe how we processed the original slices and how we simulated the measurements. We also include first baseline results.},
  archiveprefix = {arXiv},
  arxivid       = {1910.01113},
  booktitle     = {arXiv},
  eprint        = {1910.01113},
  issn          = {23318422},
  keywords      = {Computer Science - Machine Learning, Electrical Engineering and Systems Science - Image, Statistics - Machine Learning},
  mendeley-tags = {Computer Science - Machine Learning,Electrical Engineering and Systems Science - Image,Statistics - Machine Learning},
  shorttitle    = {The LoDoPaB-CT Dataset},
  url           = {http://arxiv.org/abs/1910.01113},
}

@article{Arbabi1995,
abstract = {This book provides the first self-contained comprehensive exposition of the theory of dynamical systems as a core mathematical discipline closely intertwined with most of the main areas of mathematics. The authors introduce and rigorously develop the theory while providing researchers interested in applications with fundamental tools and paradigms. The book begins with a discussion of several elementary but fundamental examples. These are used to formulate a program for the general study of asymptotic properties and to introduce the principal theoretical concepts and methods. The main theme of the second part of the book is the interplay between local analysis near individual orbits and the global complexity of the orbit structure. The third and fourth parts develop the theories of low-dimensional dynamical systems and hyperbolic dynamical systems in depth. Over 400 systematic exercises are included in the text. The book is aimed at students and researchers in mathematics at all levels from advanced undergraduate up. Scientists and engineers working in applied dynamics, nonlinear science, and chaos will also find many fresh insights in this concrete and clear presentation.},
author = {Arbabi, Hassan},
isbn = {0521341876},
issn = {00361445},
journal = {Growth Lakeland},
language = {en},
number = {June},
pages = {xviii+802},
title = {{Introduction to Koopman operator theory of dynamical systems}},
url = {http://books.google.com/books?id=9nL7ZX8Djp4C&pgis=1},
volume = {54},
year = {1995}
}

@Misc{Rackauckas2020,
  author        = {Rackauckas, Christopher and Ma, Yingbo and Martensen, Julius and Warner, Collin and Zubov, Kirill and Supekar, Rohit and Skinner, Dominic and Ramadhan, Ali},
  month         = {aug},
  title         = {{Universal differential equations for scientific machine learning}},
  year          = {2020},
  abstract      = {In the context of science, the well-known adage “a picture is worth a thousand words” might well be “a model is worth a thousand datasets.” Scientific models, such as Newtonian physics or biological gene regulatory networks, are human-driven simplifications of complex phenomena that serve as surrogates for the countless experiments that validated the models. Recently, machine learning has been able to overcome the inaccuracies of approximate modeling by directly learning the entire set of nonlinear interactions from data. However, without any predetermined structure from the scientific basis behind the problem, machine learning approaches are flexible but data-expensive, requiring large databases of homogeneous labeled training data. A central challenge is reconciling data that is at odds with simplified models without requiring “big data”. In this work we develop a new methodology, universal differential equations (UDEs), which augments scientific models with machine-learnable structures for scientifically-based learning. We show how UDEs can be utilized to discover previously unknown governing equations, accurately extrapolate beyond the original data, and accelerate model simulation, all in a time and data-efficient manner. This advance is coupled with open-source software that allows for training UDEs which incorporate physical constraints, delayed interactions, implicitly-defined events, and intrinsic stochasticity in the model. Our examples show how a diverse set of computationally-difficult modeling issues across scientific disciplines, from automatically discovering biological mechanisms to accelerating climate simulations by 15,000x, can be handled by training UDEs.},
  archiveprefix = {arXiv},
  arxivid       = {2001.04385},
  booktitle     = {arXiv},
  eprint        = {2001.04385},
  issn          = {23318422},
  keywords      = {Computer Science - Machine Learning, Mathematics - Dynamical Systems, Quantitative Biology - Quantitative Methods, Statistics - Machine Learning},
  language      = {en},
  mendeley-tags = {Computer Science - Machine Learning,Mathematics - Dynamical Systems,Quantitative Biology - Quantitative Methods,Statistics - Machine Learning},
  url           = {http://arxiv.org/abs/2001.04385},
}

@Article{Li2016,
  author        = {Li, Ke and Malik, Jitendra},
  journal       = {arXiv:1606.01885 [cs, math, stat]},
  title         = {{Learning to Optimize Introduction}},
  year          = {2016},
  month         = {jun},
  abstract      = {Algorithm design is a laborious process and often requires many iterations of ideation and validation. In this paper, we explore automating algorithm design and present a method to learn an optimization algorithm, which we believe to be the ﬁrst method that can automatically discover a better algorithm. We approach this problem from a reinforcement learning perspective and represent any particular optimization algorithm as a policy. We learn an optimization algorithm using guided policy search and demonstrate that the resulting algorithm outperforms existing hand-engineered algorithms in terms of convergence speed and/or the ﬁnal objective value.},
  keywords      = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Mathematics - Optimization and Control, Statistics - Machine Learning},
  language      = {en},
  mendeley-tags = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning},
  url           = {http://arxiv.org/abs/1606.01885},
}

@Misc{Li2020b,
  author        = {Li, Zongyi and Kovachki, Nikola and Azizzadenesheli, Kamyar and Liu, Burigede and Bhattacharya, Kaushik and Stuart, Andrew and Anandkumar, Anima},
  month         = {mar},
  title         = {{Neural operator: Graph kernel network for partial differential equations}},
  year          = {2020},
  abstract      = {The classical development of neural networks has been primarily for mappings between a finite-dimensional Euclidean space and a set of classes, or between two finite-dimensional Euclidean spaces. The purpose of this work is to generalize neural networks so that they can learn mappings between infinite-dimensional spaces (operators). The key innovation in our work is that a single set of network parameters, within a carefully designed network architecture, may be used to describe mappings between infinite-dimensional spaces and between different finite-dimensional approximations of those spaces. We formulate approximation of the infinite-dimensional mapping by composing nonlinear activation functions and a class of integral operators. The kernel integration is computed by message passing on graph networks. This approach has substantial practical consequences which we will illustrate in the context of mappings between input data to partial differential equations (PDEs) and their solutions. In this context, such learned networks can generalize among different approximation methods for the PDE (such as finite difference or finite element methods) and among approximations corresponding to different underlying levels of resolution and discretization. Experiments confirm that the proposed graph kernel network does have the desired properties and show competitive performance compared to the state of the art solvers.},
  archiveprefix = {arXiv},
  arxivid       = {2003.03485},
  booktitle     = {arXiv},
  eprint        = {2003.03485},
  issn          = {23318422},
  keywords      = {Computer Science - Machine Learning, Mathematics - Numerical Analysis, Statistics - Machine Learning},
  language      = {en},
  mendeley-tags = {Computer Science - Machine Learning,Mathematics - Numerical Analysis,Statistics - Machine Learning},
  shorttitle    = {Neural Operator},
  url           = {http://arxiv.org/abs/2003.03485},
}

@Misc{Boehm2020,
  author        = {B{\"{o}}hm, Vanessa and Seljak, Uro{\v{s}}},
  month         = {jun},
  title         = {{Probabilistic Auto-Encoder}},
  year          = {2020},
  abstract      = {We introduce the Probabilistic Auto-Encoder (PAE), a generative model with a lower dimensional latent space that is based on an Auto-Encoder which is interpreted probabilistically after training using a Normalizing Flow. The PAE combines the advantages of an Auto-Encoder, i.e. it is fast and easy to train and achieves small reconstruction error, with the desired properties of a generative model, such as high sample quality and good performance in downstream tasks. Compared to a VAE and its common variants, the PAE trains faster, reaches lower reconstruction error and achieves state of the art samples without parameter fine-tuning or annealing schemes. We demonstrate that the PAE is further a powerful model for performing the downstream tasks of outlier detection and probabilistic image reconstruction: 1) Starting from the Laplace approximation to the marginal likelihood, we identify a PAE-based outlier detection metric which achieves state of the art results in Out-of-Distribution detection outperforming other likelihood based estimators. 2) Using posterior analysis in the PAE latent space we perform high dimensional data inpainting and denoising with uncertainty quantification.},
  archiveprefix = {arXiv},
  arxivid       = {2006.05479},
  booktitle     = {arXiv},
  eprint        = {2006.05479},
  issn          = {23318422},
  keywords      = {Computer Science - Machine Learning, Statistics - Machine Learning},
  language      = {en},
  mendeley-tags = {Computer Science - Machine Learning,Statistics - Machine Learning},
  url           = {http://arxiv.org/abs/2006.05479},
}

@Misc{Song2020a,
  author        = {Song, Yang and Meng, Chenlin and Liao, Renjie and Ermon, Stefano},
  month         = {feb},
  title         = {{Nonlinear equation solving: A faster alternative to feedforward computation}},
  year          = {2020},
  abstract      = {Feedforward computations, such as evaluating a neural network or sampling from an autoregressive model, are ubiquitous in machine learning. The sequential nature of feedforward computation, however, requires a strict order of execution and cannot be easily accelerated with parallel computing. To enable parrallelization, we frame the task of feedforward computation as solving a system of nonlinear equations. We then propose to find the solution using a Jacobi or Gauss-Seidel fixed-point iteration method, as well as hybrid methods of both. Crucially, Jacobi updates operate independently on each equation and can be executed in parallel. Our method is guaranteed to give exactly the same values as the original feedforward computation with a reduced (or equal) number of parallel iterations. Experimentally, we demonstrate the effectiveness of our approach in accelerating 1) the evaluation of DenseNets on ImageNet and 2) autoregressive sampling of MADE and PixelCNN. We are able to achieve between 1.2 and 33 speedup factors under various conditions and computation models.},
  archiveprefix = {arXiv},
  arxivid       = {2002.03629},
  booktitle     = {arXiv},
  eprint        = {2002.03629},
  issn          = {23318422},
  keywords      = {Computer Science - Machine Learning, Statistics - Machine Learning},
  language      = {en},
  mendeley-tags = {Computer Science - Machine Learning,Statistics - Machine Learning},
  shorttitle    = {Nonlinear Equation Solving},
  url           = {http://arxiv.org/abs/2002.03629},
}

@inproceedings{Kapturowski2019,
abstract = {Building on the recent successes of distributed training of RL agents, in this paper we investigate the training of RNN-based RL agents from distributed prioritized experience replay. We study the effects of parameter lag resulting in representational drift and recurrent state staleness and empirically derive an improved training strategy. Using a single network architecture and fixed set of hyper-parameters, the resulting agent, Recurrent Replay Distributed DQN, quadruples the previous state of the art on Atari-57, and matches the state of the art on DMLab-30. It is the first agent to exceed human-level performance in 52 of the 57 Atari games.},
author = {Kapturowski, Steven and Ostrovski, Georg and Quan, John and Munos, R{\'{e}}mi and Dabney, Will},
booktitle = {7th International Conference on Learning Representations, ICLR 2019},
language = {en},
pages = {19},
title = {{Recurrent experience replay in distributed reinforcement learning}},
year = {2019}
}

@Article{Wolpert1997,
  author   = {Wolpert, David H. and Macready, William G.},
  journal  = {IEEE Transactions on Evolutionary Computation},
  title    = {{No free lunch theorems for optimization}},
  year     = {1997},
  issn     = {1089778X},
  month    = {apr},
  number   = {1},
  pages    = {67--82},
  volume   = {1},
  abstract = {A framework is developed to explore the connection between effective optimization algorithms and the problems they are solving. A number of "no free lunch" (NFL) theorems are presented which establish that for any algorithm, any elevated performance over one class of problems is offset by performance over another class. These theorems result in a geometric interpretation of what it means for an algorithm to be well suited to an optimization problem. Applications of the NFL theorems to information-theoretic aspects of optimization and benchmark measures of performance are also presented. Other issues addressed include time-varying optimization problems and a priori "head-to-head" minimax distinctions between optimization algorithms, distinctions that result despite the NFL theorems' enforcing of a type of uniformity over all algorithms. {\textcopyright} 1997 IEEE.},
  doi      = {10.1109/4235.585893},
  keywords = {Evolutionary algorithms, Information theory, Optimization},
  language = {en},
  url      = {http://ieeexplore.ieee.org/document/585893/},
}

@Misc{Khan2018,
  author        = {Khan, Mohammad Emtiyaz and Nielsen, Didrik and Tangkaratt, Voot and Lin, Wu and Gal, Yarin and Srivastava, Akash},
  month         = {aug},
  title         = {{Fast and scalable bayesian deep learning by weight-perturbation in adam}},
  year          = {2018},
  abstract      = {Uncertainty computation in deep learning is essential to design robust and reliable systems. Variational inference (VI) is a promising approach for such computation, but requires more effort to implement and execute compared to maximumlikelihood methods. In this paper, we propose new natural-gradient algorithms to reduce such efforts for Gaussian mean-field VI. Our algorithms can be implemented within the Adam optimizer by perturbing the network weights during gradient evaluations, and uncertainty estimates can be cheaply obtained by using the vector that adapts the learning rate. This requires lower memory, computation, and implementation effort than existing VI methods, while obtaining uncertainty estimates of comparable quality. Our empirical results confirm this and further suggest that the weight-perturbation in our algorithm could be useful for exploration in reinforcement learning and stochastic optimization.},
  booktitle     = {arXiv},
  issn          = {23318422},
  keywords      = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Computation, Statistics - Machine Learning},
  language      = {en},
  mendeley-tags = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Computation,Statistics - Machine Learning},
  url           = {http://arxiv.org/abs/1806.04854},
}

@Article{Qin2020,
  author        = {Qin, Chongli and Wu, Yan and Springenberg, Jost Tobias and Brock, Andrew and Donahue, Jeff and Lillicrap, Timothy P. and Kohli, Pushmeet},
  journal       = {arXiv:2010.15040 [cs, stat]},
  title         = {{Training Generative Adversarial Networks by Solving Ordinary Differential Equations}},
  year          = {2020},
  month         = {nov},
  abstract      = {The instability of Generative Adversarial Network (GAN) training has frequently been attributed to gradient descent. Consequently, recent methods have aimed to tailor the models and training procedures to stabilise the discrete updates. In contrast, we study the continuous-time dynamics induced by GAN training. Both theory and toy experiments suggest that these dynamics are in fact surprisingly stable. From this perspective, we hypothesise that instabilities in training GANs arise from the integration error in discretising the continuous dynamics. We experimentally verify that well-known ODE solvers (such as Runge-Kutta) can stabilise training - when combined with a regulariser that controls the integration error. Our approach represents a radical departure from previous methods which typically use adaptive optimisation and stabilisation techniques that constrain the functional space (e.g. Spectral Normalisation). Evaluation on CIFAR-10 and ImageNet shows that our method outperforms several strong baselines, demonstrating its efficacy.},
  archiveprefix = {arXiv},
  arxivid       = {2010.15040},
  eprint        = {2010.15040},
  keywords      = {Computer Science - Machine Learning, Statistics - Machine Learning},
  language      = {en},
  mendeley-tags = {Computer Science - Machine Learning,Statistics - Machine Learning},
  url           = {http://arxiv.org/abs/2010.15040},
}

@Misc{Hyun2020,
  author        = {Hyun, Chang Min and Baek, Seong Hyeon and Lee, Mingyu and Lee, Sung Min and Seo, Jin Keun},
  month         = {jan},
  title         = {{Deep learning-based solvability of underdetermined inverse problems in medical imaging}},
  year          = {2020},
  abstract      = {Recently, with the significant developments in deep learning techniques, solving underdetermined inverse problems has become one of the major concerns in the medical imaging domain. Typical examples include undersampled magnetic resonance imaging, interior tomography, and sparse-view computed tomography, where deep learning techniques have achieved excellent performances. Although deep learning methods appear to overcome the limitations of existing mathematical methods when handling various underdetermined problems, there is a lack of rigorous mathematical foundations that would allow us to elucidate the reasons for the remarkable performance of deep learning methods. This study focuses on learning the causal relationship regarding the structure of the training data suitable for deep learning, to solve highly underdetermined inverse problems. We observe that a majority of the problems of solving underdetermined linear systems in medical imaging are highly non-linear. Furthermore, we analyze if a desired reconstruction map can be learnable from the training data and underdetermined system.},
  booktitle     = {arXiv},
  issn          = {23318422},
  keywords      = {Computed tomography, Computer Science - Machine Learning, Deep learning, Electrical Engineering and Systems Science - Image, Magnetic resonance imaging, Medical imaging, Statistics - Machine Learning, Underdetermined linear inverse problem},
  language      = {en},
  mendeley-tags = {Computer Science - Machine Learning,Electrical Engineering and Systems Science - Image,Statistics - Machine Learning},
  url           = {http://arxiv.org/abs/2001.01432},
}

@Article{Adler2018,
  author        = {Adler, Jonas and {\"{O}}ktem, Ozan},
  journal       = {arXiv:1811.05910 [cs, math, stat]},
  title         = {{Deep Bayesian Inversion}},
  year          = {2018},
  month         = {nov},
  abstract      = {Characterizing statistical properties of solutions of inverse problems is essential for decision making. Bayesian inversion offers a tractable framework for this purpose, but current approaches are computationally unfeasible for most realistic imaging applications in the clinic. We introduce two novel deep learning based methods for solving large-scale inverse problems using Bayesian inversion: a sampling based method using a WGAN with a novel mini-discriminator and a direct approach that trains a neural network using a novel loss function. The performance of both methods is demonstrated on image reconstruction in ultra low dose 3D helical CT. We compute the posterior mean and standard deviation of the 3D images followed by a hypothesis test to assess whether a "dark spot" in the liver of a cancer stricken patient is present. Both methods are computationally efficient and our evaluation shows very promising performance that clearly supports the claim that Bayesian inversion is usable for 3D imaging in time critical applications.},
  archiveprefix = {arXiv},
  arxivid       = {1811.05910},
  eprint        = {1811.05910},
  keywords      = {Computer Science - Machine Learning, Mathematics - Statistics Theory, Statistics - Machine Learning},
  language      = {en},
  mendeley-tags = {Computer Science - Machine Learning,Mathematics - Statistics Theory,Statistics - Machine Learning},
  url           = {http://arxiv.org/abs/1811.05910},
}

@article{Bar2019a,
abstract = {We introduce a novel neural network-based partial differential equations solver for forward and inverse problems. The solver is grid free, mesh free and shape free, and the solution is approximated by a neural network. We employ an unsu- pervised approach such that the input to the network is a points set in an arbitrary domain, and the output is the set of the corresponding function values. The net- work is trained to minimize deviations of the learned function from the strong PDE solution and satisfy the boundary conditions. The resulting solution in turn is an explicit smooth differentiable function with a known analytical form. Unlike other numerical methods such as finite differences and finite elements, the derivatives of the desired function can be analytically calculated to any order. This framework therefore, enables the solution of high order non-linear PDEs. The proposed algorithm is a unified formulation of both forward and inverse problems where the optimized loss function consists of few elements: fidelity terms of L2 and L∞ norms that unlike previous methods promote a strong solution. Robust boundary conditions constraints and additional regularizers are included as well. This setting is flexible in the sense that regularizers can be tailored to specific problems. We demonstrate our method on several free shape 2D second order systems with application to Electrical Impedance Tomography (EIT).},
archivePrefix = {arXiv},
arxivId = {arXiv:1904.05501v1},
author = {Bar, Leah and Sochen, Nir},
eprint = {arXiv:1904.05501v1},
journal = {Workshop on Integration of Deep Neural Models and Differential Equations (ICLR 2020)},
language = {en},
number = {1},
pages = {1--15},
title = {{Learning-Based Strong Solutions to Forward and Inverse Problems in PDEs}},
year = {2019}
}

@Misc{Zhang2019a,
  author        = {Zhang, Dinghuai and Zhang, Tianyuan and Lu, Yiping and Zhu, Zhanxing and Dong, Bin},
  month         = {nov},
  title         = {{You only propagate once: Accelerating adversarial training via maximal principle}},
  year          = {2019},
  abstract      = {Deep learning achieves state-of-the-art results in many tasks in computer vision and natural language processing. However, recent works have shown that deep networks can be vulnerable to adversarial perturbations, which raised a serious robustness issue of deep networks. Adversarial training, typically formulated as a robust optimization problem, is an effective way of improving the robustness of deep networks. A major drawback of existing adversarial training algorithms is the computational overhead of the generation of adversarial examples, typically far greater than that of the network training. This leads to the unbearable overall computational cost of adversarial training. In this paper, we show that adversarial training can be cast as a discrete time differential game. Through analyzing the Pontryagin's Maximum Principle (PMP) of the problem, we observe that the adversary update is only coupled with the parameters of the first layer of the network. This inspires us to restrict most of the forward and back propagation within the first layer of the network during adversary updates. This effectively reduces the total number of full forward and backward propagation to only one for each group of adversary updates. Therefore, we refer to this algorithm YOPO (You Only Propagate Once). Numerical experiments demonstrate that YOPO can achieve comparable defense accuracy with approximately 1/5 ∼ 1/4 GPU time of the projected gradient descent (PGD) algorithm[15].},
  archiveprefix = {arXiv},
  arxivid       = {1905.00877},
  booktitle     = {arXiv},
  eprint        = {1905.00877},
  issn          = {23318422},
  keywords      = {Computer Science - Machine Learning, Mathematics - Optimization and Control, Statistics - Machine Learning},
  language      = {en},
  mendeley-tags = {Computer Science - Machine Learning,Mathematics - Optimization and Control,Statistics - Machine Learning},
  shorttitle    = {You Only Propagate Once},
  url           = {http://arxiv.org/abs/1905.00877},
}

@article{Saad1986,
abstract = {We present an iterative method for solving linear systems, which has the property of minimizing at every step the norm of the residual vector over a Krylov subspace. The algorithm is derived from the Arnoldi process for constructing an /2-orthogonal basis of Krylov subspaces. It can be considered as a generalization of Paige and Saunders' MINRES algorithm and is theoretically equivalent to the Generalized Conjugate Residual (GCR) method and to ORTHODIR. The new algorithm presents several advantages over GCR and ORTHODIR.},
author = {Saad, Youcef and Schultz, Martin H.},
doi = {10.1137/0907058},
issn = {0196-5204},
journal = {SIAM Journal on Scientific and Statistical Computing},
language = {en},
month = {jul},
number = {3},
pages = {856--869},
shorttitle = {GMRES},
title = {{GMRES: A Generalized Minimal Residual Algorithm for Solving Nonsymmetric Linear Systems}},
url = {http://epubs.siam.org/doi/10.1137/0907058},
volume = {7},
year = {1986}
}

@InProceedings{Sedghi2019,
  author        = {Sedghi, Hanie and Gupta, Vineet and Long, Philip M.},
  booktitle     = {7th International Conference on Learning Representations, ICLR 2019},
  title         = {{The singular values of convolutional layers}},
  year          = {2019},
  month         = {mar},
  abstract      = {We characterize the singular values of the linear transformation associated with a standard 2D multi-channel convolutional layer, enabling their efficient computation. This characterization also leads to an algorithm for projecting a convolutional layer onto an operator-norm ball. We show that this is an effective regularizer; for example, it improves the test error of a deep residual network using batch normalization on CIFAR-10 from 6.2% to 5.3%.},
  keywords      = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
  language      = {en},
  mendeley-tags = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  url           = {http://arxiv.org/abs/1805.10408},
}

@article{Manneschi2020,
abstract = {Recurrent networks can be trained using a generalization of backpropagation, called backpropagation through time, but a gap exists between the mathematics of this learning algorithm and biological plausibility. E-prop is a biologically inspired alternative that opens up possibilities for a new generation of online training algorithms for recurrent networks.},
author = {Manneschi, Luca and Vasilaki, Eleni},
doi = {10.1038/s42256-020-0162-9},
issn = {2522-5839},
journal = {Nature Machine Intelligence},
language = {en},
month = {mar},
number = {3},
pages = {155--156},
title = {{An alternative to backpropagation through time}},
url = {http://www.nature.com/articles/s42256-020-0162-9},
volume = {2},
year = {2020}
}

@Misc{Karras2020,
  author        = {Karras, Tero and Aittala, Miika and Hellsten, Janne and Laine, Samuli and Lehtinen, Jaakko and Aila, Timo},
  month         = {jun},
  title         = {{Training Generative Adversarial Networks with Limited Data}},
  year          = {2020},
  abstract      = {Training generative adversarial networks (GAN) using too little data typically leads to discriminator overfitting, causing training to diverge. We propose an adaptive discriminator augmentation mechanism that significantly stabilizes training in limited data regimes. The approach does not require changes to loss functions or network architectures, and is applicable both when training from scratch and when fine-tuning an existing GAN on another dataset. We demonstrate, on several datasets, that good results are now possible using only a few thousand training images, often matching StyleGAN2 results with an order of magnitude fewer images. We expect this to open up new application domains for GANs. We also find that the widely used CIFAR-10 is, in fact, a limited data benchmark, and improve the record FID from 5.59 to 2.67.},
  archiveprefix = {arXiv},
  arxivid       = {2006.06676},
  booktitle     = {arXiv},
  eprint        = {2006.06676},
  issn          = {23318422},
  keywords      = {Computer Science - Computer Vision and Pattern Rec, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computi, Statistics - Machine Learning},
  language      = {en},
  mendeley-tags = {Computer Science - Computer Vision and Pattern Rec,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computi,Statistics - Machine Learning},
  url           = {http://arxiv.org/abs/2006.06676},
}

@InProceedings{Durkan2019,
  author        = {Durkan, Conor and Bekasov, Artur and Murray, Iain and Papamakarios, George},
  booktitle     = {Advances in Neural Information Processing Systems},
  title         = {{Neural spline flows}},
  year          = {2019},
  month         = {dec},
  volume        = {32},
  abstract      = {A normalizing flow models a complex probability density as an invertible transformation of a simple base density. Flows based on either coupling or autoregressive transforms both offer exact density evaluation and sampling, but rely on the parameterization of an easily invertible elementwise transformation, whose choice determines the flexibility of these models. Building upon recent work, we propose a fully-differentiable module based on monotonic rational-quadratic splines, which enhances the flexibility of both coupling and autoregressive transforms while retaining analytic invertibility. We demonstrate that neural spline flows improve density estimation, variational inference, and generative modeling of images.},
  issn          = {10495258},
  keywords      = {Computer Science - Machine Learning, Statistics - Machine Learning},
  language      = {en},
  mendeley-tags = {Computer Science - Machine Learning,Statistics - Machine Learning},
  url           = {http://arxiv.org/abs/1906.04032},
}

@Misc{2020,
  title         = {{Constrained neural ordinary differential equations with stability guarantees}},
  year          = {2020},
  abstract      = {Differential equations are frequently used in engineering domains, such as modeling and control of industrial systems, where safety and performance guarantees are of paramount importance. Traditional physics-based modeling approaches require domain expertise and are often difficult to tune or adapt to new systems. In this paper, we show how to model discrete ordinary differential equations (ODE) with algebraic nonlinearities as deep neural networks with varying degrees of prior knowledge. We derive the stability guarantees of the network layers based on the implicit constraints imposed on the weight's eigenvalues. Moreover, we show how to use barrier methods to generically handle additional inequality constraints. We demonstrate the prediction accuracy of learned neural ODEs evaluated on open-loop simulations compared to ground truth dynamics with bi-linear terms.},
  archiveprefix = {arXiv},
  arxivid       = {2004.10883},
  booktitle     = {arXiv},
  eprint        = {2004.10883},
  issn          = {23318422},
  language      = {en},
  pages         = {8},
}

@inproceedings{Silver2014,
abstract = {2014 In this paper we consider deterministic policy gradient algorithms for reinforcement learning with continuous actions. The deterministic policy gradient has a particularly appealing form: it is the expected gradient of the action-value function. This simple form means that the deterministic policy gradient can be estimated much more efficiently than the usual stochastic policy gradient. To ensure adequate exploration, we introduce an off-policy actor-critic algorithm that learns a deterministic target policy from an exploratory behaviour policy. We demonstrate that deterministic policy gradient algorithms can significantly outperform their stochastic counterparts in high-dimensional action spaces.},
author = {Silver, David and Lever, Guy and Heess, Nicolas and Degris, Thomas and Wierstra, Daan and Riedmiller, Martin},
booktitle = {31st International Conference on Machine Learning, ICML 2014},
isbn = {9781634393973},
language = {en},
pages = {605--619},
title = {{Deterministic policy gradient algorithms}},
volume = {1},
year = {2014}
}

@article{Zhang2020,
abstract = {Incompressible fluid flow around a cylinder is one of the classical problems in fluid-dynamics with strong relevance with many real-world engineering problems, for example, design of offshore structures or design of a pin-fin heat exchanger. Thus learning a high-accuracy surrogate for this problem can demonstrate the efficacy of a novel machine learning approach. In this work, we propose a physics-informed neural network (PINN) architecture for learning the relationship between simulation output and the underlying geometry and boundary conditions. In addition to using a physics-based regularization term, the proposed approach also exploits the underlying physics to learn a set of Fourier features, i.e. frequency and phase offset parameters, and then use them for predicting flow velocity and pressure over the spatio-temporal domain. We demonstrate this approach by predicting simulation results over out of range time interval and for novel design conditions. Our results show that incorporation of Fourier features improves the generalization performance over both temporal domain and design space.},
archivePrefix = {arXiv},
arxivId = {2011.01456},
author = {Zhang, Tongtao and Dey, Biswadip and Kakkar, Pratik and Dasgupta, Arindam and Chakraborty, Amit},
eprint = {2011.01456},
journal = {arXiv:2011.01456 [cs]},
keywords = {Computer Science - Machine Learning},
language = {en},
mendeley-tags = {Computer Science - Machine Learning},
month = {nov},
title = {{Frequency-compensated PINNs for Fluid-dynamic Design Problems}},
url = {http://arxiv.org/abs/2011.01456},
year = {2020}
}

@InProceedings{Ardizzone2019,
  author        = {Ardizzone, Lynton and Kruse, Jakob and Wirkert, Sebastian and Rahner, Daniel and Pellegrini, Eric W. and Klessen, Ralf S. and Maier-Hein, Lena and Rother, Carsten and K{\"{o}}the, Ullrich},
  booktitle     = {7th International Conference on Learning Representations, ICLR 2019},
  title         = {{Analyzing inverse problems with invertible neural networks}},
  year          = {2019},
  month         = {feb},
  abstract      = {For many applications, in particular in natural science, the task is to determine hidden system parameters from a set of measurements. Often, the forward process from parameter- to measurement-space is well-defined, whereas the inverse problem is ambiguous: multiple parameter sets can result in the same measurement. To fully characterize this ambiguity, the full posterior parameter distribution, conditioned on an observed measurement, has to be determined. We argue that a particular class of neural networks is well suited for this task - so-called Invertible Neural Networks (INNs). Unlike classical neural networks, which attempt to solve the ambiguous inverse problem directly, INNs focus on learning the forward process, using additional latent output variables to capture the information otherwise lost. Due to invertibility, a model of the corresponding inverse process is learned implicitly. Given a specific measurement and the distribution of the latent variables, the inverse pass of the INN provides the full posterior over parameter space. We prove theoretically and verify experimentally, on artificial data and real-world problems from medicine and astrophysics, that INNs are a powerful analysis tool to find multi-modalities in parameter space, uncover parameter correlations, and identify unrecoverable parameters.},
  keywords      = {68T01, Computer Science - Machine Learning, Statistics - Machine Learning},
  language      = {en},
  mendeley-tags = {68T01,Computer Science - Machine Learning,Statistics - Machine Learning},
  url           = {http://arxiv.org/abs/1808.04730},
}

@InProceedings{Zeng2020,
  author        = {Zeng, Yu and Lin, Zhe and Yang, Jimei and Zhang, Jianming and Shechtman, Eli and Lu, Huchuan},
  booktitle     = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  title         = {{High-Resolution Image Inpainting with Iterative Confidence Feedback and Guided Upsampling}},
  year          = {2020},
  month         = {may},
  pages         = {1--17},
  volume        = {12364 LNCS},
  abstract      = {Existing image inpainting methods often produce artifacts when dealing with large holes in real applications. To address this challenge, we propose an iterative inpainting method with a feedback mechanism. Specifically, we introduce a deep generative model which not only outputs an inpainting result but also a corresponding confidence map. Using this map as feedback, it progressively fills the hole by trusting only high-confidence pixels inside the hole at each iteration and focuses on the remaining pixels in the next iteration. As it reuses partial predictions from the previous iterations as known pixels, this process gradually improves the result. In addition, we propose a guided upsampling network to enable generation of high-resolution inpainting results. We achieve this by extending the Contextual Attention module [39] to borrow high-resolution feature patches in the input image. Furthermore, to mimic real object removal scenarios, we collect a large object mask dataset and synthesize more realistic training data that better simulates user inputs. Experiments show that our method significantly outperforms existing methods in both quantitative and qualitative evaluations. More results and Web APP are available at https://zengxianyu.github.io/iic.},
  archiveprefix = {arXiv},
  arxivid       = {2005.11742},
  doi           = {10.1007/978-3-030-58529-7_1},
  eprint        = {2005.11742},
  isbn          = {9783030585280},
  issn          = {16113349},
  keywords      = {Computer Science - Computer Vision and Pattern Rec, Computer Science - Multimedia},
  language      = {en},
  mendeley-tags = {Computer Science - Computer Vision and Pattern Rec,Computer Science - Multimedia},
  url           = {http://arxiv.org/abs/2005.11742},
}

@InProceedings{Milletari2016,
  author        = {Milletari, Fausto and Navab, Nassir and Ahmadi, Seyed Ahmad},
  booktitle     = {Proceedings - 2016 4th International Conference on 3D Vision, 3DV 2016},
  title         = {{V-Net: Fully convolutional neural networks for volumetric medical image segmentation}},
  year          = {2016},
  month         = {jun},
  pages         = {565--571},
  abstract      = {Convolutional Neural Networks (CNNs) have been recently employed to solve problems from both the computer vision and medical image analysis fields. Despite their popularity, most approaches are only able to process 2D images while most medical data used in clinical practice consists of 3D volumes. In this work we propose an approach to 3D image segmentation based on a volumetric, fully convolutional, neural network. Our CNN is trained end-to-end on MRI volumes depicting prostate, and learns to predict segmentation for the whole volume at once. We introduce a novel objective function, that we optimise during training, based on Dice coefficient. In this way we can deal with situations where there is a strong imbalance between the number of foreground and background voxels. To cope with the limited number of annotated volumes available for training, we augment the data applying random non-linear transformations and histogram matching. We show in our experimental evaluation that our approach achieves good performances on challenging test data while requiring only a fraction of the processing time needed by other previous methods.},
  archiveprefix = {arXiv},
  arxivid       = {1606.04797},
  doi           = {10.1109/3DV.2016.79},
  eprint        = {1606.04797},
  isbn          = {9781509054077},
  keywords      = {Computer Science - Computer Vision and Pattern Rec, Deep learning, convolutional neural networks, machine learning, prostate, segmentation},
  language      = {en},
  mendeley-tags = {Computer Science - Computer Vision and Pattern Rec},
  shorttitle    = {V-Net},
  url           = {http://arxiv.org/abs/1606.04797},
}

@Misc{Kim2020,
  author        = {Kim, Hyeongju and Lee, Hyeonseung and Kang, Woo Hyun and Lee, Joun Yeop and Kim, Nam Soo},
  month         = {nov},
  title         = {{SoftFlow: Probabilistic Framework for Normalizing Flow on Manifolds}},
  year          = {2020},
  abstract      = {Flow-based generative models are composed of invertible transformations between two random variables of the same dimension. Therefore, flow-based models cannot be adequately trained if the dimension of the data distribution does not match that of the underlying target distribution. In this paper, we propose SoftFlow, a probabilistic framework for training normalizing flows on manifolds. To sidestep the dimension mismatch problem, SoftFlow estimates a conditional distribution of the perturbed input data instead of learning the data distribution directly. We experimentally show that SoftFlow can capture the innate structure of the manifold data and generate high-quality samples unlike the conventional flow-based models. Furthermore, we apply the proposed framework to 3D point clouds to alleviate the difficulty of forming thin structures for flow-based models. The proposed model for 3D point clouds, namely SoftPointFlow, can estimate the distribution of various shapes more accurately and achieves state-of-the-art performance in point cloud generation.},
  archiveprefix = {arXiv},
  arxivid       = {2006.04604},
  booktitle     = {arXiv},
  eprint        = {2006.04604},
  issn          = {23318422},
  keywords      = {Computer Science - Computer Vision and Pattern Rec, Computer Science - Machine Learning},
  language      = {en},
  mendeley-tags = {Computer Science - Computer Vision and Pattern Rec,Computer Science - Machine Learning},
  shorttitle    = {SoftFlow},
  url           = {http://arxiv.org/abs/2006.04604},
}

@article{Brunton2018,
abstract = {The classical geometric and statistical perspectives on dynamical systems are being complemented by a third operator-theoretic perspective, based on the evolution of measurements of the system. This so-called Koopman operator theory is poised to capitalize on the increasing availability of measurement data from complex systems. Moreover, Koopman theory provides a path to identify intrinsic coordinate systems where non-linear dynamics appear linear. Obtaining linear representations of strongly nonlinear systems has the potential to revolutionize our ability to predict and control these systems. Sections of these notes are taken from the textbook Data-Driven Science and Engineering: Machine Learning, Dynamical Systems, and Control [12] by Brunton and Kutz.},
author = {Brunton, Steven L},
journal = {arXiv},
language = {en},
number = {3},
pages = {1--37},
title = {{Notes on Koopman Operator Theory}},
year = {2018}
}

@article{Treeby2010,
abstract = {A new, freely available third party MATLAB toolbox for the simulation and reconstruction of photoacoustic wave fields is described. The toolbox, named k-Wave, is designed to make realistic photoacoustic modeling simple and fast. The forward simulations are based on a k-space pseudo-spectral time domain solution to coupled first-order acoustic equations for homogeneous or heterogeneous media in one, two, and three dimensions. The simulation functions can additionally be used as a flexible time reversal image reconstruction algorithm for an arbitrarily shaped measurement surface. A one-step image reconstruction algorithm for a planar detector geometry based on the fast Fourier transform (FFT) is also included. The architecture and use of the toolbox are described, and several novel modeling examples are given. First, the use of data interpolation is shown to considerably improve time reversal reconstructions when the measurement surface has only a sparse array of detector points. Second, by comparison with one-step, FFT-based reconstruction, time reversal is shown to be sufficiently general that it can also be used for finite-sized planar measurement surfaces. Last, the optimization of computational speed is demonstrated through parallel execution using a graphics processing unit.},
author = {Treeby, Bradley E. and Cox, B. T.},
doi = {10.1117/1.3360308},
issn = {10833668},
journal = {Journal of Biomedical Optics},
language = {en},
number = {2},
pages = {021314},
pmid = {20459236},
shorttitle = {k-Wave},
title = {{k-Wave: MATLAB toolbox for the simulation and reconstruction of photoacoustic wave fields}},
url = {http://biomedicaloptics.spiedigitallibrary.org/article.aspx?doi=10.1117/1.3360308},
volume = {15},
year = {2010}
}

@Misc{Bubba2020,
  author        = {Bubba, Tatiana A. and Galinier, Mathilde and Lassas, Matti and Prato, Marco and Ratti, Luca and Siltanen, Samuli},
  month         = {jun},
  title         = {{Deep neural networks for inverse problems with pseudodifferential operators: An application to limited-angle tomography}},
  year          = {2020},
  abstract      = {We propose a novel convolutional neural network (CNN), called $\Psi$DONet, designed for learning pseudodifferential operators ($\Psi$DOs) in the context of linear inverse problems. Our starting point is the Iterative Soft Thresholding Algorithm (ISTA), a well-known algorithm to solve sparsity-promoting minimization problems. We show that, under rather general assumptions on the forward operator, the unfolded iterations of ISTA can be interpreted as the successive layers of a CNN, which in turn provides fairly general network architectures that, for a specific choice of the parameters involved, allow to reproduce ISTA, or a perturbation of ISTA for which we can bound the coefficients of the filters. Our case study is the limited-angle X-ray transform and its application to limited-angle computed tomography (LA-CT). In particular, we prove that, in the case of LA-CT, the operations of upscaling, downscaling and convolution, which characterize our $\Psi$DONet and most deep learning schemes, can be exactly determined by combining the convolutional nature of the limited angle X-ray transform and basic properties defining an orthogonal wavelet system. We test two different implementations of $\Psi$DONet on simulated data from limited angle geometry, generated from the ellipse data set. Both implementations provide equally good and noteworthy preliminary results, showing the potential of the approach we propose and paving the way to applying the same idea to other convolutional operators which are $\Psi$DOs or Fourier integral operators. MSC Codes 44A12, 68T07, 35S30, 58J40, 92C55},
  archiveprefix = {arXiv},
  arxivid       = {2006.01620},
  booktitle     = {arXiv},
  eprint        = {2006.01620},
  issn          = {23318422},
  keywords      = {44A12- 68T07- 35S30- 58J40- 92C55, Computer Science - Machine Learning, Convolutional neural networks, Deep neural networks, Electrical Engineering and Systems Science - Image, Fourier integral operators, Limited angle tomography, Mathematics - Optimization and Control, Microlocal analysis, Pseudodifferential operators, Sparse regularization, Wavelets, X-ray transform},
  language      = {en},
  mendeley-tags = {44A12- 68T07- 35S30- 58J40- 92C55,Computer Science - Machine Learning,Electrical Engineering and Systems Science - Image,Mathematics - Optimization and Control},
  shorttitle    = {Deep neural networks for inverse problems with pse},
  url           = {http://arxiv.org/abs/2006.01620},
}

@misc{Scieur2020,
abstract = {We consider the average-case runtime analysis of algorithms for minimizing quadratic objectives. In this setting, and contrary to the more classical worst-case analysis, non-asymptotic convergence rates and optimal algorithms depend on the full spectrum of the Hessian through its expected spectral distribution. Under mild assumptions, we show that these optimal methods converge asymptotically towards Polyak momentum independently of the expected spectral density. This makes Polyak momentum universally (i.e., independent of the spectral distribution) asymptotically average-case optimal.},
archivePrefix = {arXiv},
arxivId = {2002.04664},
author = {Scieur, Damien and Pedregosa, Fabian},
booktitle = {arXiv},
eprint = {2002.04664},
issn = {23318422},
keywords = {Mathematics - Optimization and Control},
language = {en},
mendeley-tags = {Mathematics - Optimization and Control},
month = {jul},
title = {{Universal average-case optimality of polyak momentum}},
url = {http://arxiv.org/abs/2002.04664},
year = {2020}
}

@InProceedings{Andrychowicz2016,
  author        = {Andrychowicz, Marcin and Denil, Misha and Colmenarejo, Sergio G{\'{o}}mez and Hoffman, Matthew W. and Pfau, David and Schaul, Tom and Shillingford, Brendan and {De Freitas}, Nando},
  booktitle     = {Advances in Neural Information Processing Systems},
  title         = {{Learning to learn by gradient descent by gradient descent}},
  year          = {2016},
  month         = {nov},
  pages         = {3988--3996},
  abstract      = {The move from hand-designed features to learned features in machine learning has been wildly successful. In spite of this, optimization algorithms are still designed by hand. In this paper we show how the design of an optimization algorithm can be cast as a learning problem, allowing the algorithm to learn to exploit structure in the problems of interest in an automatic way. Our learned algorithms, implemented by LSTMs, outperform generic, hand-designed competitors on the tasks for which they are trained, and also generalize well to new tasks with similar structure. We demonstrate this on a number of tasks, including simple convex problems, training neural networks, and styling images with neural art.},
  archiveprefix = {arXiv},
  arxivid       = {1606.04474},
  eprint        = {1606.04474},
  issn          = {10495258},
  keywords      = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computi},
  language      = {en},
  mendeley-tags = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computi},
  url           = {http://arxiv.org/abs/1606.04474},
}

@Misc{Zhang2019b,
  author        = {Zhang, Shunkang and Gao, Yuan and Jiao, Yuling and Liu, Jin and Wang, Yang and Yang, Can},
  month         = {dec},
  title         = {{Wasserstein-wasserstein auto-encoders}},
  year          = {2019},
  abstract      = {To address the challenges in learning deep generative models (e.g.,the blurriness of variational auto-encoder and the instability of training generative adversarial networks, we propose a novel deep generative model, named Wasserstein-Wasserstein auto-encoders (WWAE). We formulate WWAE as minimization of the penalized optimal transport between the target distribution and the generated distribution. By noticing that both the prior PZ and the aggregated posterior QZ of the latent code Z can be well captured by Gaussians, the proposed WWAE utilizes the closed-form of the squared Wasserstein-2 distance for two Gaussians in the optimization process. As a result, WWAE does not suffer from the sampling burden and it is computationally efficient by leveraging the reparameterization trick. Numerical results evaluated on multiple benchmark datasets including MNIST, fashion- MNIST and CelebA show that WWAE learns better latent structures than VAEs and generates samples of better visual quality and higher FID scores than VAEs and GANs.},
  archiveprefix = {arXiv},
  arxivid       = {1902.09323},
  booktitle     = {arXiv},
  eprint        = {1902.09323},
  file          = {:home/antonio/Documents/bibliography/files/Zhang et al. - 2019 - Wasserstein-wasserstein auto-encoders.pdf:pdf},
  issn          = {23318422},
  keywords      = {Computer Science - Machine Learning, Statistics - Machine Learning},
  language      = {en},
  mendeley-tags = {Computer Science - Machine Learning,Statistics - Machine Learning},
  url           = {http://arxiv.org/abs/1711.01558},
}

@InProceedings{Gregor2015,
  author        = {Gregor, Karol and Danihelka, Ivo and Graves, Alex and Rezende, Danilo Jimenez and Wierstra, Daan},
  booktitle     = {32nd International Conference on Machine Learning, ICML 2015},
  title         = {{DRAW: A recurrent neural network for image generation}},
  year          = {2015},
  month         = {may},
  pages         = {1462--1471},
  volume        = {2},
  abstract      = {This paper introduces the Deep Recurrent Attentive Writer (DRAW) neural network architecture for image generation. DRAW networks combine a novel spatial attention mechanism that mimics the foveation of the human eye, with a sequential variational auto-encoding framework that allows for the iterative construction of complex images. The system substantially improves on the state of the art for generative models on MNIST, and, when trained on the Street View House Numbers dataset, it generates images that cannot be distinguished from real data with the naked eye.},
  archiveprefix = {arXiv},
  arxivid       = {1502.04623},
  eprint        = {1502.04623},
  isbn          = {9781510810587},
  keywords      = {Computer Science - Computer Vision and Pattern Rec, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computi},
  language      = {en},
  mendeley-tags = {Computer Science - Computer Vision and Pattern Rec,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computi},
  shorttitle    = {DRAW},
  url           = {http://arxiv.org/abs/1502.04623},
}

@Misc{Tzen2019,
  author        = {Tzen, Belinda and Raginsky, Maxim},
  month         = {oct},
  title         = {{Neural stochastic differential equations: Deep latent gaussian models in the diffusion limit}},
  year          = {2019},
  abstract      = {In deep latent Gaussian models, the latent variable is generated by a time-inhomogeneous Markov chain, where at each time step we pass the current state through a parametric nonlinear map, such as a feedforward neural net, and add a small independent Gaussian perturbation. This work considers the diffusion limit of such models, where the number of layers tends to infinity, while the step size and the noise variance tend to zero. The limiting latent object is an It{\^{o}} diffusion process that solves a stochastic differential equation (SDE) whose drift and diffusion coefficient are implemented by neural nets. We develop a variational inference framework for these neural SDEs via stochastic backpropagation in Wiener space, where the variational approximations to the posterior are obtained by Girsanov (mean-shift) transformation of the standard Wiener process and the computation of gradients is based on the theory of stochastic flows. This permits the use of black-box SDE solvers and automatic differentiation for end-to-end inference. Experimental results with synthetic data are provided.},
  archiveprefix = {arXiv},
  arxivid       = {1905.09883},
  booktitle     = {arXiv},
  eprint        = {1905.09883},
  issn          = {23318422},
  keywords      = {Computer Science - Machine Learning, Statistics - Machine Learning},
  language      = {en},
  mendeley-tags = {Computer Science - Machine Learning,Statistics - Machine Learning},
  shorttitle    = {Neural Stochastic Differential Equations},
  url           = {http://arxiv.org/abs/1905.09883},
}

@Article{Luethi2009,
  author   = {L{\"{u}}thi, M. and Lerch, A. and Albrecht, T. and Krol, Z. and Vetter, T. and Marcel, L and Thomas, Lerch and Zdzislaw, Albrecht},
  journal  = {Computer},
  title    = {{A hierarchical, multi-resolution approach for model-based skull-segmentation in mri volumes}},
  year     = {2009},
  pages    = {1--8},
  abstract = {We present a model-based approach for segmentation of the skull from T1 weighted MR images of the human head. Segmentation is performed by ﬁtting a morphable skull model into a pre-segmented version of the image. This yields a segmentation result that is constrained to the normal skull anatomy and thus gives a statistically meaningful approximation of the skull, even in places where the bony structure cannot be distinguished from the surrounding tissue. We propose a multiresolution approach to model-ﬁtting that leads to an improved convergence rate. Further, we show how a hierarchy of statistical models can be used to increase the ﬂexibility of the statistical model and thus to obtain more accurate segmentation results. To validate our method, we present experimental result using a statistical model based on 17 example skulls acquired from segmented CTimages. The results show that a good approximation to the skull structure can be found. Our experiments conﬁrm that by incorporating strong prior knowledge even such diﬃcult segmentation tasks as skull-segmentation from MR images become feasible.},
  keywords = {model fitting, mri, multi-resolution, segmentation, statistical models},
  language = {en},
  url      = {http://gravis.cs.unibas.ch/publications/2008/3D-PhyHum08_Luethi.pdf},
}

@Article{Hauptmann2018,
  author        = {Hauptmann, Andreas and Lucka, Felix and Betcke, Marta and Huynh, Nam and Adler, Jonas and Cox, Ben and Beard, Paul and Ourselin, Sebastien and Arridge, Simon},
  journal       = {IEEE Transactions on Medical Imaging},
  title         = {{Model-Based Learning for Accelerated, Limited-View 3-D Photoacoustic Tomography}},
  year          = {2018},
  issn          = {1558254X},
  month         = {jun},
  number        = {6},
  pages         = {1382--1393},
  volume        = {37},
  abstract      = {Recent advances in deep learning for tomographic reconstructions have shown great potential to create accurate and high quality images with a considerable speed up. In this paper, we present a deep neural network that is specifically designed to provide high resolution 3-D images from restricted photoacoustic measurements. The network is designed to represent an iterative scheme and incorporates gradient information of the data fit to compensate for limited view artifacts. Due to the high complexity of the photoacoustic forward operator, we separate training and computation of the gradient information. A suitable prior for the desired image structures is learned as part of the training. The resulting network is trained and tested on a set of segmented vessels from lung computed tomography scans and then applied to in-vivo photoacoustic measurement data.},
  archiveprefix = {arXiv},
  arxivid       = {1708.09832},
  doi           = {10.1109/TMI.2018.2820382},
  eprint        = {1708.09832},
  keywords      = {Computational modeling, Deep learning, Image reconstruction, Machine learning, Propagation, TV, Three-dimensional displays, Tomography, acoustic tomography, biomedical optical imaging, blood vessels, convolutional neural networks, deep learning, deep neural network, gradient information, high quality images, high resolution 3-D images, image reconstruction, image segmentation, image structures, in-vivo photoacoustic measurement data, iterative methods, iterative reconstruction, iterative scheme, learning (artificial intelligence), limited view artifacts, limited-view 3-D photoacoustic tomography, lung, lung computed tomography scans, medical image processing, model-based learning, neural nets, optical tomography, photoacoustic effect, photoacoustic forward operator, photoacoustic tomography, restricted photoacoustic measurements, segmented vessels, tomographic reconstructions, tomography},
  mendeley-tags = {Computational modeling,Deep learning,Image reconstruction,Machine learning,Propagation,TV,Three-dimensional displays,Tomography,acoustic tomography,biomedical optical imaging,blood vessels,convolutional neural networks,deep learning,deep neural network,gradient information,high quality images,high resolution 3-D images,image reconstruction,image segmentation,image structures,in-vivo photoacoustic measurement data,iterative methods,iterative reconstruction,iterative scheme,learning (artificial intelligence),limited view artifacts,limited-view 3-D photoacoustic tomography,lung,lung computed tomography scans,medical image processing,model-based learning,neural nets,optical tomography,photoacoustic effect,photoacoustic forward operator,photoacoustic tomography,restricted photoacoustic measurements,segmented vessels,tomographic reconstructions,tomography},
  pmid          = {29870367},
}

@Misc{Thorpe2018,
  author        = {Thorpe, Matthew and Gennip, Yves Van},
  month         = {mar},
  title         = {{Deep Limits of Residual Neural Networks}},
  year          = {2018},
  abstract      = {Neural networks have been very successful in many applications; we often, however, lack a theoretical understanding of what the neural networks are actually learning. This problem emerges when trying to generalise to new data sets. The contribution of this paper is to show that, for the residual neural network model, the deep layer limit coincides with a parameter estimation problem for a nonlinear ordinary differential equation. In particular, whilst it is known that the residual neural network model is a discretisation of an ordinary differential equation, we show convergence in a variational sense. This implies that optimal parameters converge in the deep layer limit. This is a stronger statement than saying for a fixed parameter the residual neural network model converges (the latter does not in general imply the former). Our variational analysis provides a discrete-to-continuum $\Gamma$-convergence result for the objective function of the residual neural network training step to a variational problemconstrained by a system of ordinary differential equations; this rigorously connects the discrete setting to a continuum problem. 34E05, 39A30, 39A60, 49J45, 49J15},
  archiveprefix = {arXiv},
  arxivid       = {1810.11741},
  booktitle     = {arXiv},
  eprint        = {1810.11741},
  issn          = {23318422},
  keywords      = {34E05- 39A30- 39A60- 49J45- 49J15, Deep layer limits, Deep neural networks, Gamma-convergence, Mathematics - Classical Analysis and ODEs, Ordinary differential equations, Regularity, Variational convergence},
  language      = {en},
  mendeley-tags = {34E05- 39A30- 39A60- 49J45- 49J15,Mathematics - Classical Analysis and ODEs},
  url           = {http://arxiv.org/abs/1810.11741},
}

@Misc{Hammernik2019,
  author        = {Hammernik, Kerstin and Schlemper, Jo and Qin, Chen and Duan, Jinming and Summers, Ronald M. and Rueckert, Daniel},
  month         = {dec},
  title         = {{$\Sigma$-net: Systematic evaluation of iterative deep neural networks for fast parallel MR image reconstruction}},
  year          = {2019},
  abstract      = {Purpose To systematically investigate the influence of various data consistency layers, (semi-)supervised learning and ensembling strategies, defined in a $\Sigma$-net, for accelerated parallel MR image reconstruction using deep learning. Theory and Methods MR image reconstruction is formulated as learned unrolled optimization scheme with a Down-Up network as regularization and varying data consistency layers. The different architectures are split into sensitivity networks, which rely on explicit coil sensitivity maps, and parallel coil networks, which learn the combination of coils implicitly. Different content and adversarial losses, a semi-supervised fine-tuning scheme and model ensembling are investigated. Results Evaluated on the fastMRI multicoil validation set, architectures involving raw k-space data outperform image enhancement methods significantly. Semi-supervised fine-tuning adapts to new k-space data and provides, together with reconstructions based on adversarial training, the visually most appealing results although quantitative quality metrics are reduced. The $\Sigma$-net ensembles the benefits from different models and achieves similar scores compared to the single state-of-the-art approaches. Conclusion This work provides an open-source framework to perform a systematic wide-range comparison of state-of-the-art reconstruction approaches for parallel MR image reconstruction on the fastMRI knee dataset and explores the importance of data consistency. A suitable trade-off between perceptual image quality and quantitative scores are achieved with the ensembled $\Sigma$-net.},
  archiveprefix = {arXiv},
  arxivid       = {1912.09278},
  booktitle     = {arXiv},
  eprint        = {1912.09278},
  issn          = {23318422},
  keywords      = {Computer Science - Computer Vision and Pattern Rec, Computer Science - Machine Learning, Data Consistency, Deep Learning, Down-Up Networks, Electrical Engineering and Systems Science - Image, Ensembling, Iterative Image Reconstruction, Parallel Imaging},
  language      = {en},
  mendeley-tags = {Computer Science - Computer Vision and Pattern Rec,Computer Science - Machine Learning,Electrical Engineering and Systems Science - Image},
  shorttitle    = {$\Sigma$-net},
  url           = {http://arxiv.org/abs/1912.09278},
}

@Misc{Karkar2020,
  author        = {Karkar, Skander and Ayed, Ibrahhim and de B{\'{e}}zenac, Emmanuel and Gallinari, Patrick},
  month         = {sep},
  title         = {{A principle of least action for the training of neural networks}},
  year          = {2020},
  abstract      = {Neural networks have been achieving high generalization performance on many tasks despite being highly over-parameterized. Since classical statistical learning theory struggles to explain this behavior, much effort has recently been focused on uncovering the mechanisms behind it, in the hope of developing a more adequate theoretical framework and having a better control over the trained models. In this work, we adopt an alternate perspective, viewing the neural network as a dynamical system displacing input particles over time. We conduct a series of experiments and, by analyzing the network's behavior through its displacements, we show the presence of a low kinetic energy displacement bias in the transport map of the network, and link this bias with generalization performance. From this observation, we reformulate the learning problem as follows: finding neural networks which solve the task while transporting the data as efficiently as possible. This offers a novel formulation of the learning problem which allows us to provide regularity results for the solution network, based on Optimal Transport theory. From a practical viewpoint, this allows us to propose a new learning algorithm, which automatically adapts to the complexity of the given task, and leads to networks with a high generalization ability even in low data regimes.},
  archiveprefix = {arXiv},
  arxivid       = {2009.08372},
  booktitle     = {arXiv},
  eprint        = {2009.08372},
  issn          = {23318422},
  keywords      = {Computer Science - Machine Learning, Deep Learning, Dynamical Systems, Optimal Transport, Statistics - Machine Learning},
  language      = {en},
  mendeley-tags = {Computer Science - Machine Learning,Statistics - Machine Learning},
  url           = {http://arxiv.org/abs/2009.08372},
}

@Misc{Kelly2020,
  author        = {Kelly, Jacob and Bettencourt, Jesse and Johnson, Matthew James and Duvenaud, David},
  month         = {jul},
  title         = {{Learning differential equations that are easy to solve}},
  year          = {2020},
  abstract      = {Differential equations parameterized by neural networks become expensive to solve numerically as training progresses. We propose a remedy that encourages learned dynamics to be easier to solve. Specifically, we introduce a differentiable surrogate for the time cost of standard numerical solvers, using higher-order derivatives of solution trajectories. These derivatives are efficient to compute with Taylor-mode automatic differentiation. Optimizing this additional objective trades model performance against the time cost of solving the learned dynamics. We demonstrate our approach by training substantially faster, while nearly as accurate, models in supervised classification, density estimation, and time-series modelling tasks.},
  archiveprefix = {arXiv},
  arxivid       = {2007.04504},
  booktitle     = {arXiv},
  eprint        = {2007.04504},
  file          = {:home/antonio/Documents/bibliography/files/Kelly et al. - 2020 - Learning differential equations that are easy to solve.pdf:pdf},
  issn          = {23318422},
  keywords      = {Computer Science - Machine Learning, Statistics - Machine Learning},
  language      = {en},
  mendeley-tags = {Computer Science - Machine Learning,Statistics - Machine Learning},
  url           = {http://arxiv.org/abs/2007.04504},
}

@Misc{Kingma2019,
  author        = {Kingma, Diederik P. and Welling, Max},
  title         = {{An introduction to variational autoencoders}},
  year          = {2019},
  abstract      = {Variational autoencoders provide a principled framework for learning deep latent-variable models and corresponding inference models. In this work, we provide an introduction to variational autoencoders and some important extensions.},
  archiveprefix = {arXiv},
  arxivid       = {1906.02691},
  booktitle     = {Foundations and Trends in Machine Learning},
  doi           = {10.1561/2200000056},
  eprint        = {1906.02691},
  issn          = {19358245},
  keywords      = {Computer Science - Machine Learning, Statistics - Machine Learning},
  language      = {en},
  mendeley-tags = {Computer Science - Machine Learning,Statistics - Machine Learning},
  number        = {4},
  pages         = {307--392},
  url           = {http://arxiv.org/abs/1906.02691},
  volume        = {12},
}

@Misc{Weinan2019,
  author        = {Weinan, E. and Ma, Chao and Wu, Lei},
  month         = {dec},
  title         = {{Machine learning from a continuous viewpoint}},
  year          = {2019},
  abstract      = {We present a continuous formulation of machine learning, as a problem in the calculus of variations and differential-integral equations, very much in the spirit of classical numerical analysis and statistical physics. We demonstrate that conventional machine learning models and algorithms, such as the random feature model, the shallow neural network model and the residual neural network model, can all be recovered as particular discretizations of different continuous formulations. We also present examples of new models, such as the ow-based random feature model, and new algorithms, such as the smoothed particle method and spectral method, that arise naturally from this continuous formulation. We discuss how the issues of generalization error and implicit regularization can be studied under this framework.},
  booktitle     = {arXiv},
  issn          = {23318422},
  keywords      = {Mathematics - Numerical Analysis, Mathematics - Optimization and Control, Statistics - Machine Learning},
  language      = {en},
  mendeley-tags = {Mathematics - Numerical Analysis,Mathematics - Optimization and Control,Statistics - Machine Learning},
  url           = {http://arxiv.org/abs/1912.12777},
}

@Misc{Atkinson2020,
  author        = {Atkinson, Steven},
  month         = {jun},
  title         = {{Bayesian hidden physics models: uncertainty quantification for discovery of nonlinear partial differential operators from data}},
  year          = {2020},
  abstract      = {What do data tell us about physics—and what don't they tell us? There has been a surge of interest in using machine learning models to discover governing physical laws such as differential equations from data, but current methods lack uncertainty quantification to communicate their credibility. This work addresses this shortcoming from a Bayesian perspective. We introduce a novel model comprising “leaf” modules that learn to represent distinct experiments' spatiotemporal functional data as neural networks and a single “root” module that expresses a nonparametric distribution over their governing nonlinear differential operator as a Gaussian process. Automatic differentiation is used to compute the required partial derivatives from the leaf functions as inputs to the root. Our approach quantifies the reliability of the learned physics in terms of a posterior distribution over operators and propagates this uncertainty to solutions of novel initial-boundary value problem instances. Numerical experiments demonstrate the method on several nonlinear PDEs.},
  archiveprefix = {arXiv},
  arxivid       = {2006.04228},
  booktitle     = {arXiv},
  eprint        = {2006.04228},
  issn          = {23318422},
  keywords      = {Computer Science - Machine Learning, Statistics - Machine Learning},
  language      = {en},
  mendeley-tags = {Computer Science - Machine Learning,Statistics - Machine Learning},
  shorttitle    = {Bayesian Hidden Physics Models},
  url           = {http://arxiv.org/abs/2006.04228},
}

@Misc{Rani2018,
  author        = {Rani, Meenu and Dhok, S. B. and Deshmukh, R. B.},
  title         = {{A Systematic Review of Compressive Sensing: Concepts, Implementations and Applications}},
  year          = {2018},
  abstract      = {Compressive Sensing (CS) is a new sensing modality, which compresses the signal being acquired at the time of sensing. Signals can have sparse or compressible representation either in original domain or in some transform domain. Relying on the sparsity of the signals, CS allows us to sample the signal at a rate much below the Nyquist sampling rate. Also, the varied reconstruction algorithms of CS can faithfully reconstruct the original signal back from fewer compressive measurements. This fact has stimulated research interest toward the use of CS in several fields, such as magnetic resonance imaging, high-speed video acquisition, and ultrawideband communication. This paper reviews the basic theoretical concepts underlying CS. To bridge the gap between theory and practicality of CS, different CS acquisition strategies and reconstruction approaches are elaborated systematically in this paper. The major application areas where CS is currently being used are reviewed here. This paper also highlights some of the challenges and research directions in this field.},
  booktitle     = {IEEE Access},
  doi           = {10.1109/ACCESS.2018.2793851},
  issn          = {21693536},
  keywords      = {CS acquisition strategies, CS applications, CS reconstruction algorithms, Compressed sensing, Compressive sensing, Image reconstruction, Mathematical model, Nyquist sampling rate, OMP, Reconstruction algorithms, Sensors, Sparse matrices, Transforms, compressed sensing, compressible representation, compressive measurements, compressive sensing, random demodulator, sensing modality, signal reconstruction, signal representation, signal sampling, sparse representation, sparsity, systematic review, transform domain, transforms, varied reconstruction algorithms},
  mendeley-tags = {CS acquisition strategies,CS applications,CS reconstruction algorithms,Compressed sensing,Compressive sensing,Image reconstruction,Mathematical model,Nyquist sampling rate,OMP,Reconstruction algorithms,Sensors,Sparse matrices,Transforms,compressed sensing,compressible representation,compressive measurements,compressive sensing,random demodulator,sensing modality,signal reconstruction,signal representation,signal sampling,sparse representation,sparsity,systematic review,transform domain,transforms,varied reconstruction algorithms},
  pages         = {4875--4894},
  shorttitle    = {A Systematic Review of Compressive Sensing},
  volume        = {6},
}

@Misc{Liu2019,
  author        = {Liu, Xuanqing and Xiao, Tesi and Si, Si and Cao, Qin and Kumar, Sanjiv and Hsieh, Cho Jui},
  month         = {jun},
  title         = {{Neural SDE: Stabilizing neural ODE networks with stochastic noise}},
  year          = {2019},
  abstract      = {Neural Ordinary Differential Equation (Neural ODE) has been proposed as a continuous approximation to the ResNet architecture. Some commonly used regularization mechanisms in discrete neural networks (e.g. dropout, Gaussian noise) are missing in current Neural ODE networks. In this paper, we propose a new continuous neural network framework called Neural Stochastic Differential Equation (Neural SDE) network, which naturally incorporates various commonly used regularization mechanisms based on random noise injection. Our framework can model various types of noise injection frequently used in discrete networks for regularization purpose, such as dropout and additive/multiplicative noise in each block. We provide theoretical analysis explaining the improved robustness of Neural SDE models against input perturbations/adversarial attacks. Furthermore, we demonstrate that the Neural SDE network can achieve better generalization than the Neural ODE and is more resistant to adversarial and non-adversarial input perturbations.},
  archiveprefix = {arXiv},
  arxivid       = {1906.02355},
  booktitle     = {arXiv},
  eprint        = {1906.02355},
  issn          = {23318422},
  keywords      = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Rec, Computer Science - Machine Learning, Statistics - Machine Learning},
  language      = {en},
  mendeley-tags = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Rec,Computer Science - Machine Learning,Statistics - Machine Learning},
  shorttitle    = {Neural SDE},
  url           = {http://arxiv.org/abs/1906.02355},
}

@InProceedings{Mildenhall2020,
  author        = {Mildenhall, Ben and Srinivasan, Pratul P. and Tancik, Matthew and Barron, Jonathan T. and Ramamoorthi, Ravi and Ng, Ren},
  booktitle     = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  title         = {{NeRF: Representing Scenes as Neural Radiance Fields for View Synthesis}},
  year          = {2020},
  month         = {mar},
  pages         = {405--421},
  volume        = {12346 LNCS},
  abstract      = {We present a method that achieves state-of-the-art results for synthesizing novel views of complex scenes by optimizing an underlying continuous volumetric scene function using a sparse set of input views. Our algorithm represents a scene using a fully-connected (non-convolutional) deep network, whose input is a single continuous 5D coordinate (spatial location (x, y, z) and viewing direction (Formula Presented)) and whose output is the volume density and view-dependent emitted radiance at that spatial location. We synthesize views by querying 5D coordinates along camera rays and use classic volume rendering techniques to project the output colors and densities into an image. Because volume rendering is naturally differentiable, the only input required to optimize our representation is a set of images with known camera poses. We describe how to effectively optimize neural radiance fields to render photorealistic novel views of scenes with complicated geometry and appearance, and demonstrate results that outperform prior work on neural rendering and view synthesis. View synthesis results are best viewed as videos, so we urge readers to view our supplementary video for convincing comparisons.},
  archiveprefix = {arXiv},
  arxivid       = {2003.08934},
  doi           = {10.1007/978-3-030-58452-8_24},
  eprint        = {2003.08934},
  isbn          = {9783030584511},
  issn          = {16113349},
  keywords      = {3D deep learning, Computer Science - Computer Vision and Pattern Rec, Computer Science - Graphics, Image-based rendering, Scene representation, View synthesis, Volume rendering},
  language      = {en},
  mendeley-tags = {Computer Science - Computer Vision and Pattern Rec,Computer Science - Graphics},
  shorttitle    = {NeRF},
  url           = {http://arxiv.org/abs/2003.08934},
}

@Misc{Sitzmann2020,
  author        = {Sitzmann, Vincent and Martel, Julien N.P. and Bergman, Alexander W. and Lindell, David B. and Wetzstein, Gordon and University, Stanford},
  month         = {jun},
  title         = {{Implicit Neural Representations with Periodic Activation Functions}},
  year          = {2020},
  abstract      = {Implicitly defined, continuous, differentiable signal representations parameterized by neural networks have emerged as a powerful paradigm, offering many possible benefits over conventional representations. However, current network architectures for such implicit neural representations are incapable of modeling signals with fine detail, and fail to represent a signal's spatial and temporal derivatives, despite the fact that these are essential to many physical signals defined implicitly as the solution to partial differential equations. We propose to leverage periodic activation functions for implicit neural representations and demonstrate that these networks, dubbed sinusoidal representation networks or SIRENs, are ideally suited for representing complex natural signals and their derivatives. We analyze SIREN activation statistics to propose a principled initialization scheme and demonstrate the representation of images, wavefields, video, sound, and their derivatives. Further, we show how SIRENs can be leveraged to solve challenging boundary value problems, such as particular Eikonal equations (yielding signed distance functions), the Poisson equation, and the Helmholtz and wave equations. Lastly, we combine SIRENs with hypernetworks to learn priors over the space of SIREN functions. Please see the project website for a video overview of the proposed method and all applications.},
  archiveprefix = {arXiv},
  arxivid       = {2006.09661},
  booktitle     = {arXiv},
  eprint        = {2006.09661},
  file          = {:home/antonio/Documents/bibliography/files/Sitzmann et al. - 2020 - Implicit Neural Representations with Periodic Activation Functions.pdf:pdf},
  issn          = {23318422},
  keywords      = {Computer Science - Computer Vision and Pattern Rec, Computer Science - Machine Learning, Electrical Engineering and Systems Science - Image},
  language      = {en},
  mendeley-tags = {Computer Science - Computer Vision and Pattern Rec,Computer Science - Machine Learning,Electrical Engineering and Systems Science - Image},
  url           = {http://arxiv.org/abs/2006.09661},
}

@article{Polyak1964,
abstract = {For the solution of the functional equation P (x) = 0 (1) (where P is an operator, usually linear, from B into B, and B is a Banach space) iteration methods are generally used. These consist of the construction of a series x0, ..., xn, ..., which converges to the solution (see, for example [1]). Continuous analogues of these methods are also known, in which a trajectory x(t), 0 ≤ t ≤ ∞ is constructed, which satisfies the ordinary differential equation in B and is such that x(t) approaches the solution of (1) as t → ∞ (see [2]). We shall call the method a k-step method if for the construction of each successive iteration xn+1 we use k previous iterations xn, ..., xn-k+1. The same term will also be used for continuous methods if x(t) satisfies a differential equation of the k-th order or k-th degree. Iteration methods which are more widely used are one-step (e.g. methods of successive approximations). They are generally simple from the calculation point of view but often converge very slowly. This is confirmed both by the evaluation of the speed of convergence and by calculation in practice (for more details see below). Therefore the question of the rate of convergence is most important. Some multistep methods, which we shall consider further, which are only slightly more complicated than the corresponding one-step methods, make it possible to speed up the convergence substantially. Note that all the methods mentioned below are applicable also to the problem of minimizing the differentiable functional (x) in Hilbert space, so long as this problem reduces to the solution of the equation grad (x) = 0. {\textcopyright} 1964.},
author = {Polyak, B. T.},
doi = {10.1016/0041-5553(64)90137-5},
issn = {00415553},
journal = {USSR Computational Mathematics and Mathematical Physics},
language = {en},
month = {jan},
number = {5},
pages = {1--17},
title = {{Some methods of speeding up the convergence of iteration methods}},
url = {https://linkinghub.elsevier.com/retrieve/pii/0041555364901375},
volume = {4},
year = {1964}
}

@inproceedings{Ernst2012,
abstract = {In contrast to the positive definite Helmholtz equation, the deceivingly similar looking indefinite Helmholtz equation is difficult to solve using classical iterative methods. Simply using a Krylov method is much less effective, especially when the wave number in the Helmholtz operator becomes large, and also algebraic preconditioners such as incomplete LU factorizations do not remedy the situation. Even more powerful preconditioners such as classical domain decomposition and multigrid methods fail to lead to a convergent method, and often behave differently from their usual behavior for positive definite problems. For example increasing the overlap in a classical Schwarz method degrades its performance, as does increasing the number of smoothing steps in multigrid. The purpose of this review paper is to explain why classical iterative methods fail to be effective for Helmholtz problems, and to show different avenues that have been taken to address this difficulty.},
address = {Berlin, Heidelberg},
author = {Ernst, O. G. and Gander, M. J.},
booktitle = {Lecture Notes in Computational Science and Engineering},
doi = {10.1007/978-3-642-22061-6_10},
isbn = {9783642220609},
issn = {14397358},
language = {en},
pages = {325--363},
publisher = {Springer Berlin Heidelberg},
title = {{Why it is difficult to solve Helmholtz problems with classical iterative methods}},
url = {http://link.springer.com/10.1007/978-3-642-22061-6_10},
volume = {83},
year = {2012}
}

@article{Mnih2013,
abstract = {We present the first deep learning model to successfully learn control policies directly from high-dimensional sensory input using reinforcement learning. The model is a convolutional neural network, trained with a variant of Q-learning, whose input is raw pixels and whose output is a value function estimating future rewards. We apply our method to seven Atari 2600 games from the Arcade Learning Environment, with no adjustment of the architecture or learning algorithm. We find that it outperforms all previous approaches on six of the games and surpasses a human expert on three of them.},
archivePrefix = {arXiv},
arxivId = {1312.5602},
author = {Mnih, Volodymyr and Kavukcuoglu, Koray and Silver, David and Graves, Alex and Antonoglou, Ioannis and Wierstra, Daan and Riedmiller, Martin},
eprint = {1312.5602},
journal = {arXiv:1312.5602 [cs]},
keywords = {Computer Science - Machine Learning},
language = {en},
mendeley-tags = {Computer Science - Machine Learning},
month = {dec},
title = {{Playing Atari with Deep Reinforcement Learning}},
url = {http://arxiv.org/abs/1312.5602},
year = {2013}
}

@Article{Mirza2014,
  author        = {Mirza, Mehdi and Osindero, Simon},
  journal       = {arXiv:1411.1784 [cs, stat]},
  title         = {{Conditional Generative Adversarial Nets}},
  year          = {2014},
  month         = {nov},
  abstract      = {Generative Adversarial Nets [8] were recently introduced as a novel way to train generative models. In this work we introduce the conditional version of generative adversarial nets, which can be constructed by simply feeding the data, y, we wish to condition on to both the generator and discriminator. We show that this model can generate MNIST digits conditioned on class labels. We also illustrate how this model could be used to learn a multi-modal model, and provide preliminary examples of an application to image tagging in which we demonstrate how this approach can generate descriptive tags which are not part of training labels.},
  archiveprefix = {arXiv},
  arxivid       = {1411.1784},
  eprint        = {1411.1784},
  keywords      = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Rec, Computer Science - Machine Learning, Statistics - Machine Learning},
  language      = {en},
  mendeley-tags = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Rec,Computer Science - Machine Learning,Statistics - Machine Learning},
  url           = {http://arxiv.org/abs/1411.1784},
}

@Article{Du2019a,
  author        = {Du, Yilun and Mordatch, Igor},
  journal       = {arXiv:1903.08689 [cs, stat]},
  title         = {{Implicit Generation and Generalization in Energy-Based Models}},
  year          = {2019},
  month         = {jun},
  abstract      = {Energy based models (EBMs) are appealing due to their generality and simplicity in likelihood modeling, but have been traditionally difficult to train. We present techniques to scale MCMC based EBM training on continuous neural networks, and we show its success on the high-dimensional data domains of ImageNet32x32, ImageNet128x128, CIFAR-10, and robotic hand trajectories, achieving better samples than other likelihood models and nearing the performance of contemporary GAN approaches, while covering all modes of the data. We highlight some unique capabilities of implicit generation such as compositionality and corrupt image reconstruction and inpainting. Finally, we show that EBMs are useful models across a wide variety of tasks, achieving state-of-the-art out-of-distribution classification, adversarially robust classification, state-of-the-art continual online class learning, and coherent long term predicted trajectory rollouts.},
  archiveprefix = {arXiv},
  arxivid       = {1903.08689},
  eprint        = {1903.08689},
  keywords      = {Computer Science - Computer Vision and Pattern Rec, Computer Science - Machine Learning, Statistics - Machine Learning},
  language      = {en},
  mendeley-tags = {Computer Science - Computer Vision and Pattern Rec,Computer Science - Machine Learning,Statistics - Machine Learning},
  url           = {http://arxiv.org/abs/1903.08689},
}

@Misc{Tworld2019,
  author        = {Tworld},
  month         = {jan},
  title         = {{Pointer Networks}},
  year          = {2019},
  abstract      = {We introduce a new neural architecture to learn the conditional probability of an output sequence with elements that are discrete tokens corresponding to positions in an input sequence. Such problems cannot be trivially addressed by existent approaches such as sequence-to-sequence [1] and Neural Turing Machines [2], because the number of target classes in each step of the output depends on the length of the input, which is variable. Problems such as sorting variable sized sequences, and various combinatorial optimization problems belong to this class. Our model solves the problem of variable size output dictionaries using a recently proposed mechanism of neural attention. It differs from the previous attention attempts in that, instead of using attention to blend hidden units of an encoder to a context vector at each decoder step, it uses attention as a pointer to select a member of the input sequence as the output. We call this architecture a Pointer Net (Ptr-Net). We show Ptr-Nets can be used to learn approximate solutions to three challenging geometric problems – ﬁnding planar convex hulls, computing Delaunay triangulations, and the planar Travelling Salesman Problem – using training examples alone. Ptr-Nets not only improve over sequence-to-sequence with input attention, but also allow us to generalize to variable size output dictionaries. We show that the learnt models generalize beyond the maximum lengths they were trained on. We hope our results on these tasks will encourage a broader exploration of neural learning for discrete problems.},
  booktitle     = {arXiv:1506.03134 [cs, stat]},
  keywords      = {Computer Science - Computational Geometry, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computi, Natural language processing, Pointer Networks, Predicate argument structure analysis, Statistics - Machine Learning, 自然言語処理, 述語項構造解析},
  language      = {en},
  mendeley-tags = {Computer Science - Computational Geometry,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computi,Statistics - Machine Learning},
  pages         = {4Rin112--4Rin112},
  url           = {http://arxiv.org/abs/1506.03134},
  urldate       = {2020-11-03},
}

@Misc{Dupont2019,
  author        = {Dupont, Emilien and Doucet, Arnaud and Teh, Yee Whye},
  month         = {oct},
  title         = {{Augmented neural ODEs}},
  year          = {2019},
  abstract      = {We show that Neural Ordinary Differential Equations (ODEs) learn representations that preserve the topology of the input space and prove that this implies the existence of functions Neural ODEs cannot represent. To address these limitations, we introduce Augmented Neural ODEs which, in addition to being more expressive models, are empirically more stable, generalize better and have a lower computational cost than Neural ODEs.},
  archiveprefix = {arXiv},
  arxivid       = {1904.01681},
  booktitle     = {arXiv},
  eprint        = {1904.01681},
  issn          = {23318422},
  keywords      = {Computer Science - Machine Learning, Statistics - Machine Learning},
  language      = {en},
  mendeley-tags = {Computer Science - Machine Learning,Statistics - Machine Learning},
  url           = {http://arxiv.org/abs/1904.01681},
}

@Misc{Shukla2020,
  author        = {Shukla, Khemraj and {Di Leoni}, Patricio Clark and Blackshire, James and Karniadakis, George Em and Sparkman, Daniel},
  month         = {may},
  title         = {{Physics-informed neural network for ultrasound nondestructive quantification of surface breaking cracks}},
  year          = {2020},
  abstract      = {We introduce an optimized physics-informed neural network (PINN) trained to solve the problem of identifying and characterizing a surface breaking crack in a metal plate. PINNs are neural networks that can combine data and physics in the learning process by adding the residuals of a system of Partial Differential Equations to the loss function. Our PINN is supervised with realistic ultrasonic surface acoustic wave data acquired at a frequency of 5 MHz. The ultrasonic surface wave data is represented as a surface deformation on the top surface of a metal plate, measured by using the method of laser vibrometry. The PINN is physically informed by the acoustic wave equation and its convergence is sped up using adaptive activation functions. The adaptive activation function uses a scalable hyperparameter in the activation function, which is optimized to achieve best performance of the network as it changes dynamically the topology of the loss function involved in the optimization process. The usage of adaptive activation function significantly improves the convergence, notably observed in the current study. We use PINNs to estimate the speed of sound of the metal plate, which we do with an error of 1%, and then, by allowing the speed of sound to be space dependent, we identify and characterize the crack as the positions where the speed of sound has decreased. Our study also shows the effect of sub-sampling of the data on the sensitivity of sound speed estimates. More broadly, the resulting model shows a promising deep neural network model for ill-posed inverse problems.},
  archiveprefix = {arXiv},
  arxivid       = {2005.03596},
  booktitle     = {arXiv},
  eprint        = {2005.03596},
  issn          = {23318422},
  keywords      = {Computer Science - Machine Learning, Statistics - Machine Learning},
  language      = {en},
  mendeley-tags = {Computer Science - Machine Learning,Statistics - Machine Learning},
  url           = {http://arxiv.org/abs/2005.03596},
}

@misc{Putzky2019,
abstract = {Iterative learning to infer approaches have become popular solvers for inverse problems. However, their memory requirements during training grow linearly with model depth, limiting in practice model expressiveness. In this work, we propose an iterative inverse model with constant memory that relies on invertible networks to avoid storing intermediate activations. As a result, the proposed approach allows us to train models with 400 layers on 3D volumes in an MRI image reconstruction task. In experiments on a public data set, we demonstrate that these deeper, and thus more expressive, networks perform state-of-the-art image reconstruction.},
archivePrefix = {arXiv},
arxivId = {1911.10914},
author = {Putzky, Patrick and Welling, Max},
booktitle = {arXiv},
eprint = {1911.10914},
issn = {23318422},
language = {en},
pages = {11},
title = {{Invert to Learn to Invert}},
year = {2019}
}

@Misc{Li2019,
  author        = {Li, Wuchen and Ying, Lexing},
  month         = {may},
  title         = {{Hessian transport gradient flows}},
  year          = {2019},
  abstract      = {We derive new gradient flows of divergence functions in the probability space embedded with a class of Riemannian metrics. The Riemannian metric tensor is built from the transported Hessian operator of an entropy function. The new gradient flow is a generalized Fokker-Planck equation and is associated with a stochastic differential equation that depends on the reference measure. Several examples of Hessian transport gradient flows and the associated stochastic differential equations are presented, including the ones for the reverse Kullback–Leibler divergence, $\alpha$-divergence, Hellinger distance, Pearson divergence, and Jenson–Shannon divergence.},
  archiveprefix = {arXiv},
  arxivid       = {1905.04556},
  booktitle     = {arXiv},
  eprint        = {1905.04556},
  issn          = {23318422},
  keywords      = {Computer Science - Information Theory, Generalized de Bruijn identity, Hessian transport, Hessian transport stochastic differential equation, Information/Hessian geometry, Optimal transport},
  language      = {en},
  mendeley-tags = {Computer Science - Information Theory},
  url           = {http://arxiv.org/abs/1905.04556},
}

@misc{Dai2020,
abstract = {Activation functions and attention mechanisms are typically treated as having different purposes and have evolved differently. However, both concepts can be formulated as a nonlinear gating function. Inspired by their similarity, we propose a novel type of activation units called attentional activation (ATAC) units as a unification of activation functions and attention mechanisms. In particular, we propose a local channel attention module for the simultaneous non-linear activation and element-wise feature refinement, which locally aggregates point-wise cross-channel feature contexts. By replacing the well-known rectified linear units by such ATAC units in convolutional networks, we can construct fully attentional networks that perform significantly better with a modest number of additional parameters. We conducted detailed ablation studies on the ATAC units using several host networks with varying network depths to empirically verify the effectiveness and efficiency of the units. Furthermore, we compared the performance of the ATAC units against existing activation functions as well as other attention mechanisms on the CIFAR-10, CIFAR-100, and ImageNet datasets. Our experimental results show that networks constructed with the proposed ATAC units generally yield performance gains over their competitors given a comparable number of parameters.},
archivePrefix = {arXiv},
arxivId = {2007.07729},
author = {Dai, Yimian and Oehmcke, Stefan and Gieseke, Fabian and Wu, Yiquan and Barnard, Kobus},
booktitle = {arXiv},
eprint = {2007.07729},
issn = {23318422},
keywords = {Computer Science - Computer Vision and Pattern Rec},
language = {en},
mendeley-tags = {Computer Science - Computer Vision and Pattern Rec},
month = {aug},
title = {{Attention as Activation}},
url = {http://arxiv.org/abs/2007.07729},
year = {2020}
}

@Misc{Shen2020,
  author        = {Shen, Ziju and Wang, Yufei and Wu, Dufan and Yang, Xu and Dong, Bin},
  month         = {jun},
  title         = {{Learning to Scan: A Deep Reinforcement Learning Approach for Personalized Scanning in CT Imaging}},
  year          = {2020},
  abstract      = {Computed Tomography (CT) takes X-ray measurements on the subjects to reconstruct tomographic images. As X-ray is radioactive, it is desirable to control the total amount of dose of X-ray for safety concerns. Therefore, we can only select a limited number of measurement angles and assign each of them limited amount of dose. Traditional methods such as compressed sensing usually randomly select the angles and equally distribute the allowed dose on them. In most CT reconstruction models, the emphasize is on designing effective image representations, while much less emphasize is on improving the scanning strategy. The simple scanning strategy of random angle selection and equal dose distribution performs well in general, but they may not be ideal for each individual subject. It is more desirable to design a personalized scanning strategy for each subject to obtain better reconstruction result. In this paper, we propose to use Reinforcement Learning (RL) to learn a personalized scanning policy to select the angles and the dose at each chosen angle for each individual subject. We first formulate the CT scanning process as an MDP, and then use modern deep RL methods to solve it. The learned personalized scanning strategy not only leads to better reconstruction results, but also shows strong generalization to be combined with different reconstruction algorithms.},
  archiveprefix = {arXiv},
  arxivid       = {2006.02420},
  booktitle     = {arXiv},
  eprint        = {2006.02420},
  issn          = {23318422},
  keywords      = {Computer Science - Machine Learning, Electrical Engineering and Systems Science - Image, Physics - Medical Physics},
  language      = {en},
  mendeley-tags = {Computer Science - Machine Learning,Electrical Engineering and Systems Science - Image,Physics - Medical Physics},
  shorttitle    = {Learning to Scan},
  url           = {http://arxiv.org/abs/2006.02420},
}

@misc{Chu2020,
abstract = {We formalize an equivalence between two popular methods for Bayesian inference: Stein variational gradient descent (SVGD) and black-box variational inference (BBVI). In particular, we show that BBVI corresponds precisely to SVGD when the kernel is the neural tangent kernel. Furthermore, we interpret SVGD and BBVI as kernel gradient flows; we do this by leveraging the recent perspective that views SVGD as a gradient flow in the space of probability distributions and showing that BBVI naturally motivates a Riemannian structure on that space. We observe that kernel gradient flow also describes dynamics found in the training of generative adversarial networks (GANs). This work thereby unifies several existing techniques in variational inference and generative modeling and identifies the kernel as a fundamental object governing the behavior of these algorithms, motivating deeper analysis of its properties.},
archivePrefix = {arXiv},
arxivId = {2004.01822},
author = {Chu, Casey and Minami, Kentaro and Fukumizu, Kenji},
booktitle = {arXiv},
eprint = {2004.01822},
issn = {23318422},
language = {en},
pages = {5},
title = {{The equivalence between Stein variational gradient descent and black-box variational inference}},
year = {2020}
}

@InProceedings{Rezende2014,
  author        = {Rezende, Danilo Jimenez and Mohamed, Shakir and Wierstra, Daan},
  booktitle     = {31st International Conference on Machine Learning, ICML 2014},
  title         = {{Stochastic backpropagation and approximate inference in deep generative models}},
  year          = {2014},
  month         = {may},
  pages         = {3057--3070},
  volume        = {4},
  abstract      = {We marry ideas from deep neural networks and approximate Bayesian inference to derive a gen-eralised class of deep, directed generative models, endowed with a new algorithm for scalable inference and learning. Our algorithm introduces a recognition model to represent an approximate posterior distribution and uses this for optimisation of a variational lower bound. We develop stochastic backpropagation - rules for gradient backpropagation through stochastic variables - And derive an algorithm that allows for joint optimisation of the parameters of both the generative and recognition models. We demonstrate on several real-world data sets that by using stochastic backpropagation and variational inference, we obtain models that are able to generate realistic samples of data, allow for accurate imputations of missing data, and provide a useful tool for high-dimensional data visualisation.},
  archiveprefix = {arXiv},
  arxivid       = {1401.4082},
  eprint        = {1401.4082},
  isbn          = {9781634393973},
  keywords      = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Computation, Statistics - Machine Learning, Statistics - Methodology},
  language      = {en},
  mendeley-tags = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Computation,Statistics - Machine Learning,Statistics - Methodology},
  url           = {http://arxiv.org/abs/1401.4082},
}

@article{Li2018a,
abstract = {We link the reverse KL divergence with adversarial learning. This insight enables learning to synthesize realistic samples in two settings: (i) Given a set of samples from the true distribution, an adversarially learned likelihood-ratio and a new entropy bound are used to learn a GAN model, that improves synthesized sample quality relative to previous GAN variants. (ii) Given an unnormalized distribution, a reference-based framework is proposed to learn to draw samples, naturally yielding an adversarial scheme to amortize MCMC/SVGD samples. Experimental results show the improved performance of the derived algorithms. 1 BACKGROUND ON THE REVERSE KL DIVERGENCE Target Distribution Assume we are given a set of samples D = {x i } i=1,N , with each sample assumed drawn iid from an unknown distribution q(x). For x ∈ X , let S q ⊂ X represent the support of q, implying that S q is the smallest subset of X for which Sq q(x)dx = 1 (or Sq q(x)dx = 1 − , for → 0 +). Let S o q represent the complement set of S q , i.e., S q ∪ S o q = X and S q ∩ S o q = ∅.},
author = {Li, Chunyuan and Li, Jianqiao and Wang, Guoyin and Carin, Lawrence},
journal = {Iclr 2018},
language = {en},
number = {2},
pages = {1--6},
title = {{Learning to Sample with Adversarially Learned Likelihood-Ratio}},
url = {https://openreview.net/forum?id=S1eZGHkDM},
year = {2018}
}

@Misc{Papamakarios2017,
  author        = {Papamakarios, George and Pavlakou, Theo and Murray, Iain},
  month         = {jun},
  title         = {{Masked autoregressive flow for density estimation}},
  year          = {2017},
  abstract      = {Autoregressive models are among the best performing neural density estimators. We describe an approach for increasing the flexibility of an autoregressive model, based on modelling the random numbers that the model uses internally when generating data. By constructing a stack of autoregressive models, each modelling the random numbers of the next model in the stack, we obtain a type of normalizing flow suitable for density estimation, which we call Masked Autoregressive Flow. This type of flow is closely related to Inverse Autoregressive Flow and is a generalization of Real NVP. Masked Autoregressive Flow achieves state-of-the-art performance in a range of general-purpose density estimation tasks.},
  booktitle     = {arXiv},
  file          = {:home/antonio/Documents/bibliography/files/Papamakarios, Pavlakou, Murray - 2017 - Masked Autoregressive Flow for Density Estimation.pdf:pdf},
  issn          = {23318422},
  keywords      = {Computer Science - Machine Learning, Statistics - Machine Learning},
  language      = {en},
  mendeley-tags = {Computer Science - Machine Learning,Statistics - Machine Learning},
  url           = {http://arxiv.org/abs/1705.07057},
}

@Misc{Kersting2020,
  author        = {Kersting, Hans and Kr{\"{a}}mer, Nicholas and Schiegg, Martin and Daniel, Christian and Tiemann, Michael and Hennig, Philipp},
  month         = {jun},
  title         = {{Differentiable Likelihoods for Fast Inversion of ‘Likelihood-Free' Dynamical Systems}},
  year          = {2020},
  abstract      = {Likelihood-free (a.k.a. simulation-based) inference problems are inverse problems with expensive, or intractable, forward models. ODE inverse problems are commonly treated as likelihood-free, as their forward map has to be numerically approximated by an ODE solver. This, however, is not a fundamental constraint but just a lack of functionality in classic ODE solvers, which do not return a likelihood but a point estimate. To address this shortcoming, we employ Gaussian ODE filtering (a probabilistic numerical method for ODEs) to construct a local Gaussian approximation to the likelihood. This approximation yields tractable estimators for the gradient and Hessian of the (log-) likelihood. Insertion of these estimators into existing gradient-based optimization and sampling methods engenders new solvers for ODE inverse problems. We demonstrate that these methods outperform standard likelihood-free approaches on three benchmark-systems.},
  archiveprefix = {arXiv},
  arxivid       = {2002.09301},
  booktitle     = {arXiv},
  eprint        = {2002.09301},
  issn          = {23318422},
  keywords      = {Computer Science - Machine Learning, Mathematics - Numerical Analysis, Statistics - Machine Learning, Statistics - Methodology},
  language      = {en},
  mendeley-tags = {Computer Science - Machine Learning,Mathematics - Numerical Analysis,Statistics - Machine Learning,Statistics - Methodology},
  url           = {http://arxiv.org/abs/2002.09301},
}

@Misc{Tallec2017,
  author        = {Tallec, Corentin and Ollivier, Yann},
  month         = {may},
  title         = {{Unbiasing truncated backpropagation through time}},
  year          = {2017},
  abstract      = {Truncated Backpropagation Through Time (truncated BPTT, [Jae05]) is a widespread method for learning recurrent computational graphs. Truncated BPTT keeps the computational benefits of Backpropagation Through Time (BPTT [Wer90]) while relieving the need for a complete backtrack through the whole data sequence at every step. However, truncation favors short-term dependencies: the gradient estimate of truncated BPTT is biased, so that it does not benefit from the convergence guarantees from stochastic gradient theory. We introduce Anticipated Reweighted Truncated Backpropagation (ARTBP), an algorithm that keeps the computational benefits of truncated BPTT, while providing unbiasedness. ARTBP works by using variable truncation lengths together with carefully chosen compensation factors in the backpropagation equation. We check the viability of ARTBP on two tasks. First, a simple synthetic task where careful balancing of temporal dependencies at different scales is needed: truncated BPTT displays unreliable performance, and in worst case scenarios, divergence, while ARTBP converges reliably. Second, on Penn Treebank character-level language modelling [MSD+12], ARTBP slightly outperforms truncated BPTT.},
  archiveprefix = {arXiv},
  arxivid       = {1705.08209},
  booktitle     = {arXiv},
  eprint        = {1705.08209},
  issn          = {23318422},
  keywords      = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computi},
  language      = {en},
  mendeley-tags = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computi},
  url           = {http://arxiv.org/abs/1705.08209},
}

@inproceedings{Graves2007,
abstract = {Recurrent neural networks (RNNs) have proved effective at one dimensional sequence learning tasks, such as speech and online handwriting recognition. Some of the properties that make RNNs suitable for such tasks, for example robustness to input warping, and the ability to access contextual information, are also desirable in multi-dimensional domains. However, there has so far been no direct way of applying RNNs to data with more than one spatio-temporal dimension. This paper introduces multi-dimensional recurrent neural networks, thereby extending the potential applicability of RNNs to vision, video processing, medical imaging and many other areas, while avoiding the scaling problems that have plagued other multi-dimensional models. Experimental results are provided for two image segmentation tasks. {\textcopyright} Springer-Verlag Berlin Heidelberg 2007.},
address = {Berlin, Heidelberg},
archivePrefix = {arXiv},
arxivId = {0705.2011},
author = {Graves, Alex and Fern{\'{a}}ndez, Santiago and Schmidhuber, J{\"{u}}rgen},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-540-74690-4_56},
eprint = {0705.2011},
isbn = {9783540746898},
issn = {16113349},
language = {en},
number = {PART 1},
pages = {549--558},
publisher = {Springer Berlin Heidelberg},
title = {{Multi-dimensional recurrent neural networks}},
url = {http://link.springer.com/10.1007/978-3-540-74690-4_56},
volume = {4668 LNCS},
year = {2007}
}

@Article{Doersch2016,
  author        = {Doersch, Carl},
  journal       = {arXiv:1606.05908 [cs, stat]},
  title         = {{Tutorial on Variational Autoencoders}},
  year          = {2016},
  month         = {aug},
  abstract      = {In just three years, Variational Autoencoders (VAEs) have emerged as one of the most popular approaches to unsupervised learning of complicated distributions. VAEs are appealing because they are built on top of standard function approximators (neural networks), and can be trained with stochastic gradient descent. VAEs have already shown promise in generating many kinds of complicated data, including handwritten digits, faces, house numbers, CIFAR images, physical models of scenes, segmentation, and predicting the future from static images. This tutorial introduces the intuitions behind VAEs, explains the mathematics behind them, and describes some empirical behavior. No prior knowledge of variational Bayesian methods is assumed.},
  archiveprefix = {arXiv},
  arxivid       = {1606.05908},
  eprint        = {1606.05908},
  file          = {:home/antonio/Documents/bibliography/files/Doersch - 2016 - Tutorial on Variational Autoencoders.pdf:pdf},
  keywords      = {Computer Science - Machine Learning, Statistics - Machine Learning},
  language      = {en},
  mendeley-tags = {Computer Science - Machine Learning,Statistics - Machine Learning},
  url           = {http://arxiv.org/abs/1606.05908},
}

@Misc{Grathwohl2018,
  author        = {Grathwohl, Will and Chen, Ricky T.Q. and Bettencourt, Jesse and Sutskever, Ilya and Duvenaud, David},
  month         = {oct},
  title         = {{FFJORD: FREE-FORM CONTINUOUS DYNAMICS FOR SCALABLE REVERSIBLE GENERATIVE MODELS}},
  year          = {2018},
  abstract      = {A promising class of generative models maps points from a simple distribution to a complex distribution through an invertible neural network. Likelihood-based training of these models requires restricting their architectures to allow cheap computation of Jacobian determinants. Alternatively, the Jacobian trace can be used if the transformation is specified by an ordinary differential equation. In this paper, we use Hutchinson's trace estimator to give a scalable unbiased estimate of the log-density. The result is a continuous-time invertible generative model with unbiased density estimation and one-pass sampling, while allowing unrestricted neural network architectures. We demonstrate our approach on high-dimensional density estimation, image generation, and variational inference, achieving the state-of-the-art among exact likelihood methods with efficient sampling.},
  archiveprefix = {arXiv},
  arxivid       = {1810.01367},
  booktitle     = {arXiv},
  eprint        = {1810.01367},
  issn          = {23318422},
  keywords      = {Computer Science - Computer Vision and Pattern Rec, Computer Science - Machine Learning, Statistics - Machine Learning},
  language      = {en},
  mendeley-tags = {Computer Science - Computer Vision and Pattern Rec,Computer Science - Machine Learning,Statistics - Machine Learning},
  shorttitle    = {FFJORD},
  url           = {http://arxiv.org/abs/1810.01367},
}

@Article{He2019,
  author        = {He, Juncai and Xu, Jinchao},
  journal       = {Science China Mathematics},
  title         = {{MgNet: A unified framework of multigrid and convolutional neural network}},
  year          = {2019},
  issn          = {16747283},
  month         = {jul},
  number        = {7},
  pages         = {1331--1354},
  volume        = {62},
  abstract      = {We develop a unified model, known as MgNet, that simultaneously recovers some convolutional neural networks (CNN) for image classification and multigrid (MG) methods for solving discretized partial differential equations (PDEs). This model is based on close connections that we have observed and uncovered between the CNN and MG methodologies. For example, pooling operation and feature extraction in CNN correspond directly to restriction operation and iterative smoothers in MG, respectively. As the solution space is often the dual of the data space in PDEs, the analogous concept of feature space and data space (which are dual to each other) is introduced in CNN. With such connections and new concept in the unified model, the function of various convolution operations and pooling used in CNN can be better understood. As a result, modified CNN models (with fewer weights and hyperparameters) are developed that exhibit competitive and sometimes better performance in comparison with existing CNN models when applied to both CIFAR-10 and CIFAR-100 data sets.},
  archiveprefix = {arXiv},
  arxivid       = {1901.10415},
  doi           = {10.1007/s11425-019-9547-2},
  eprint        = {1901.10415},
  keywords      = {Computer Science - Computer Vision and Pattern Rec, Computer Science - Machine Learning, Mathematics - Numerical Analysis, convolutional neural network, multigrid, network architecture, unified framework},
  language      = {en},
  mendeley-tags = {Computer Science - Computer Vision and Pattern Rec,Computer Science - Machine Learning,Mathematics - Numerical Analysis},
  shorttitle    = {MgNet},
  url           = {http://arxiv.org/abs/1901.10415},
}

@Misc{Sidford2019,
  author        = {Sidford, Aaron and Wang, Mengdi and Yang, Lin F. and Ye, Yinyu},
  month         = {aug},
  title         = {{Solving discounted stochastic two-player games with near-optimal time and sample complexity}},
  year          = {2019},
  abstract      = {In this paper we settle the sampling complexity of solving discounted two-player turn-based zero-sum stochastic games up to polylogarithmic factors. Given a stochastic game with discount factor $\gamma$ ∈ (0, 1) we provide an algorithm that computes an Q-optimal strategy with highprobability given {\~{O}} ((1-$\gamma$)-3∈-2) samples from the transition function for each state-action-pair. Our algorithm runs in time nearly linear in the number of samples and uses space nearly linear in the number of state-action pairs. As stochastic games generalize Markov decision processes (MDPs) our runtime and sample complexities are optimal due to Azar et al. (2013). We achieve our results by showing how to generalize a near-optimal Q-learning based algorithms for MDP, in particular Sidford et al. (2018a), to two-player strategy computation algorithms. This overcomes limitations of standard Q-learning and strategy iteration or alternating minimization based approaches and we hope will pave the way for future reinforcement learning results by facilitating the extension of MDP results to multi-agent settings with little loss.},
  archiveprefix = {arXiv},
  arxivid       = {1908.11071},
  booktitle     = {arXiv},
  eprint        = {1908.11071},
  issn          = {23318422},
  keywords      = {Computer Science - Data Structures and Algorithms, Computer Science - Machine Learning, Statistics - Machine Learning},
  language      = {en},
  mendeley-tags = {Computer Science - Data Structures and Algorithms,Computer Science - Machine Learning,Statistics - Machine Learning},
  url           = {http://arxiv.org/abs/1908.11071},
}

@Article{Dastour2021,
  author   = {Dastour, Hatef and Liao, Wenyuan},
  journal  = {Numerical Algorithms},
  title    = {{An optimal 13-point finite difference scheme for a 2D Helmholtz equation with a perfectly matched layer boundary condition}},
  year     = {2021},
  issn     = {15729265},
  month    = {may},
  number   = {3},
  pages    = {1109--1141},
  volume   = {86},
  abstract = {Efficient and accurate numerical schemes for solving the Helmholtz equation are critical to the success of various wave propagation–related inverse problems, for instance, the full-waveform inversion problem. However, the numerical solution to a multi-dimensional Helmholtz equation is notoriously difficult, especially when a perfectly matched layer (PML) boundary condition is incorporated. In this paper, an optimal 13-point finite difference scheme for the Helmholtz equation with a PML in the two-dimensional domain is presented. An error analysis for the numerical approximation of the exact wavenumber is provided. Based on error analysis, the optimal 13-point finite difference scheme is developed so that the numerical dispersion is minimized. Two practical strategies for selecting optimal parameters are presented. Several numerical examples are solved by the new method to illustrate its accuracy and effectiveness in reducing numerical dispersion.},
  doi      = {10.1007/s11075-020-00926-5},
  keywords = {Helmholtz equation, Numerical dispersion, Optimal finite difference scheme, Perfectly matched layer},
  language = {en},
  url      = {http://link.springer.com/10.1007/s11075-020-00926-5},
}

@InProceedings{Choi2020,
  author        = {Choi, Yunjey and Uh, Youngjung and Yoo, Jaejun and Ha, Jung Woo},
  booktitle     = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
  title         = {{StarGAN v2: Diverse Image Synthesis for Multiple Domains}},
  year          = {2020},
  month         = {apr},
  pages         = {8185--8194},
  abstract      = {A good image-to-image translation model should learn a mapping between different visual domains while satisfying the following properties: 1) diversity of generated images and 2) scalability over multiple domains. Existing methods address either of the issues, having limited diversity or multiple models for all domains. We propose StarGAN v2, a single framework that tackles both and shows significantly improved results over the baselines. Experiments on CelebA-HQ and a new animal faces dataset (AFHQ) validate our superiority in terms of visual quality, diversity, and scalability. To better assess image-to-image translation models, we release AFHQ, high-quality animal faces with large inter-and intra-domain differences. The code, pretrained models, and dataset are available at https://github.com/clovaai/stargan-v2.},
  archiveprefix = {arXiv},
  arxivid       = {1912.01865},
  doi           = {10.1109/CVPR42600.2020.00821},
  eprint        = {1912.01865},
  issn          = {10636919},
  keywords      = {Computer Science - Computer Vision and Pattern Rec, Computer Science - Machine Learning},
  language      = {en},
  mendeley-tags = {Computer Science - Computer Vision and Pattern Rec,Computer Science - Machine Learning},
  shorttitle    = {StarGAN v2},
  url           = {http://arxiv.org/abs/1912.01865},
}

@inproceedings{Hausknecht2015,
abstract = {Deep Reinforcement Learning has yielded proficient controllers for complex tasks. However, these controllers have limited memory and rely on being able to perceive the complete game screen at each decision point. To address these shortcomings, this article investigates the effects of adding recurrency to a Deep Q-Network (DQN) by replacing the first post-convolutional fully-connected layer with a recurrent LSTM. The resulting Deep Recurrent Q-Network (DRQN), although capable of seeing only a single frame at each timestep, successfully integrates information through time and replicates DQN's performance on standard Atari games and partially observed equivalents featuring flickering game screens. Additionally, when trained with partial observations and evaluated with incrementally more complete observations, DRQN's performance scales as a function of observability. Conversely, when trained with full observations and evaluated with partial observations, DRQN's performance degrades less than DQN's. Thus, given the same length of history, recurrency is a viable alternative to stacking a history of frames in the DQN's input layer and while recurrency confers no systematic advantage when learning to play the game, the recurrent net can better adapt at evaluation time if the quality of observations changes.},
archivePrefix = {arXiv},
arxivId = {1507.06527},
author = {Hausknecht, Matthew and Stone, Peter},
booktitle = {AAAI Fall Symposium - Technical Report},
eprint = {1507.06527},
isbn = {9781577357520},
keywords = {Computer Science - Machine Learning},
language = {en},
mendeley-tags = {Computer Science - Machine Learning},
month = {jan},
pages = {29--37},
title = {{Deep recurrent q-learning for partially observable MDPs}},
url = {http://arxiv.org/abs/1507.06527},
volume = {FS-15-06},
year = {2015}
}

@inproceedings{Wang2018b,
abstract = {Both convolutional and recurrent operations are building blocks that process one local neighborhood at a time. In this paper, we present non-local operations as a generic family of building blocks for capturing long-range dependencies. Inspired by the classical non-local means method [4] in computer vision, our non-local operation computes the response at a position as a weighted sum of the features at all positions. This building block can be plugged into many computer vision architectures. On the task of video classification, even without any bells and whistles, our nonlocal models can compete or outperform current competition winners on both Kinetics and Charades datasets. In static image recognition, our non-local models improve object detection/segmentation and pose estimation on the COCO suite of tasks. Code will be made available.},
archivePrefix = {arXiv},
arxivId = {1711.07971},
author = {Wang, Xiaolong and Girshick, Ross and Gupta, Abhinav and He, Kaiming},
booktitle = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR.2018.00813},
eprint = {1711.07971},
isbn = {9781538664209},
issn = {10636919},
keywords = {Computer Science - Computer Vision and Pattern Rec},
language = {en},
mendeley-tags = {Computer Science - Computer Vision and Pattern Rec},
month = {apr},
pages = {7794--7803},
title = {{Non-local Neural Networks}},
url = {http://arxiv.org/abs/1711.07971},
year = {2018}
}

@Misc{Guedj2019,
  author        = {Guedj, Benjamin},
  month         = {may},
  title         = {{A PRIMER ON PAC-BAYESIAN LEARNING}},
  year          = {2019},
  abstract      = {Generalised Bayesian learning algorithms are increasingly popular in machine learning, due to their PAC generalisation properties and flexibility. The present paper aims at providing a self-contained survey on the resulting PAC-Bayes framework and some of its main theoretical and algorithmic developments.},
  archiveprefix = {arXiv},
  arxivid       = {1901.05353},
  booktitle     = {arXiv},
  eprint        = {1901.05353},
  issn          = {23318422},
  keywords      = {Computer Science - Machine Learning, Machine learning, PAC-Bayes, Statistical learning theory, Statistics - Machine Learning},
  language      = {en},
  mendeley-tags = {Computer Science - Machine Learning,Statistics - Machine Learning},
  url           = {http://arxiv.org/abs/1901.05353},
}

@Misc{Gomez2017,
  author        = {Gomez, Aidan N. and Ren, Mengye and Urtasun, Raquel and Grosse, Roger B.},
  month         = {jul},
  title         = {{The reversible residual network: Backpropagation without storing activations}},
  year          = {2017},
  abstract      = {Deep residual networks (ResNets) have significantly pushed forward the state-ofthe-art on image classification, increasing in performance as networks grow both deeper and wider. However, memory consumption becomes a bottleneck, as one needs to store the activations in order to calculate gradients using backpropagation. We present the Reversible Residual Network (RevNet), a variant of ResNets where each layer's activations can be reconstructed exactly from the next layer's. Therefore, the activations for most layers need not be stored in memory during backpropagation. We demonstrate the effectiveness of RevNets on CIFAR-10, CIFAR-100, and ImageNet, establishing nearly identical classification accuracy to equally-sized ResNets, even though the activation storage requirements are independent of depth.},
  booktitle     = {arXiv},
  issn          = {23318422},
  keywords      = {Computer Science - Computer Vision and Pattern Rec, Computer Science - Machine Learning},
  language      = {en},
  mendeley-tags = {Computer Science - Computer Vision and Pattern Rec,Computer Science - Machine Learning},
  shorttitle    = {The Reversible Residual Network},
  url           = {http://arxiv.org/abs/1707.04585},
}

@Misc{Gerlach2020,
  author        = {Gerlach, Adam R. and Leonard, Andrew and Rogers, Jonathan and Rackauckas, Christopher},
  month         = {aug},
  title         = {{The Koopman expectation: An operator theoretic method for efficient analysis and optimization of uncertain hybrid dynamical systems}},
  year          = {2020},
  abstract      = {For dynamical systems involving decision making, the success of the system greatly depends on its ability to make good decisions with incomplete and uncertain information. By leveraging the Koopman operator and its adjoint property, we introduce the Koopman Expectation, an efficient method for computing expectations as propagated through a dynamical system. Unlike other Koopman operator-based approaches in the literature, this is possible without an explicit representation of the Koopman operator. Furthermore, the efficiencies enabled by the Koopman Expectation are leveraged for optimization under uncertainty when expected losses and constraints are considered. We show how the Koopman Expectation is applicable to discrete, continuous, and hybrid non-linear systems driven by process noise with non-Gaussian initial condition and parametric uncertainties. We finish by demonstrating a 1700x acceleration for calculating probabilistic quantities of a hybrid dynamical system over the naive Monte Carlo approach with many orders of magnitudes improvement in accuracy.},
  archiveprefix = {arXiv},
  arxivid       = {2008.08737},
  booktitle     = {arXiv},
  eprint        = {2008.08737},
  file          = {:home/antonio/Documents/bibliography/files/Gerlach et al. - 2020 - The Koopman expectation An operator theoretic method for efficient analysis and optimization of uncertain hybrid.pdf:pdf},
  issn          = {23318422},
  keywords      = {Mathematics - Dynamical Systems, Mathematics - Optimization and Control, Mathematics - Probability},
  language      = {en},
  mendeley-tags = {Mathematics - Dynamical Systems,Mathematics - Optimization and Control,Mathematics - Probability},
  shorttitle    = {The Koopman Expectation},
  url           = {http://arxiv.org/abs/2008.08737},
}

@Misc{Bai2020,
  author        = {Bai, Yu and Jin, Chi and Yu, Tiancheng},
  month         = {jul},
  title         = {{Near-Optimal Reinforcement Learning with Self-Play}},
  year          = {2020},
  abstract      = {This paper considers the problem of designing optimal algorithms for reinforcement learning in two-player zero-sum games. We focus on self-play algorithms which learn the optimal policy by playing against itself without any direct supervision. In a tabular episodic Markov game with S states, A max-player actions and B min-player actions, the best existing algorithm for finding an approximate Nash equilibrium requires {\~{O}}(S2AB) steps of game playing, when only highlighting the dependency on (S, A, B). In contrast, the best existing lower bound scales as $\Omega$(S(A + B)) and has a significant gap from the upper bound. This paper closes this gap for the first time: we propose an optimistic variant of the Nash Q-learning algorithm with sample complexity {\~{O}}(SAB), and a new Nash V-learning algorithm with sample complexity {\~{O}}(S(A + B)). The latter result matches the information-theoretic lower bound in all problem-dependent parameters except for a polynomial factor of the length of each episode. Towards understanding learning objectives in Markov games other than finding the Nash equilibrium, we present a computational hardness result for learning the best responses against a fixed opponent. This also implies the computational hardness for achieving sublinear regret when playing against adversarial opponents.},
  archiveprefix = {arXiv},
  arxivid       = {2006.12007},
  booktitle     = {arXiv},
  eprint        = {2006.12007},
  issn          = {23318422},
  keywords      = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Statistics - Machine Learning},
  language      = {en},
  mendeley-tags = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  url           = {http://arxiv.org/abs/2006.12007},
}

@inproceedings{Liu2020,
abstract = {Neural Ordinary Differential Equation (Neural ODE) has been proposed as a continuous approximation to the ResNet architecture. Some commonly used regularization mechanisms in discrete neural networks (e.g., dropout, Gaussian noise) are missing in current Neural ODE networks. In this paper, we propose a new continuous neural network framework called Neural Stochastic Differential Equation (Neural SDE), which naturally incorporates various commonly used regularization mechanisms based on random noise injection. For regularization purposes, our framework includes multiple types of noise patterns, such as dropout, additive, and multiplicative noise, which are common in plain neural networks. We provide some theoretical analyses explaining the improved robustness of our models against input perturbations. Furthermore, we demonstrate that the Neural SDE network can achieve better generalization than the Neural ODE and is more resistant to adversarial and non-adversarial input perturbations.},
author = {Liu, Xuanqing and Xiao, Tesi and Si, Si and Cao, Qin and Kumar, Sanjiv and Hsieh, Cho Jui},
booktitle = {Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition},
doi = {10.1109/CVPR42600.2020.00036},
issn = {10636919},
language = {en},
pages = {279--287},
title = {{How does noise help robustness? Explanation and exploration under the neural SDE framework}},
year = {2020}
}

@InProceedings{Gregor2016,
  author        = {Gregor, Karol and Besse, Frederic and Rezende, Danilo Jimenez and Danihelka, Ivo and Wierstra, Daan},
  booktitle     = {Advances in Neural Information Processing Systems},
  title         = {{Towards conceptual compression}},
  year          = {2016},
  month         = {apr},
  pages         = {3556--3564},
  abstract      = {We introduce convolutional DRAW, a homogeneous deep generative model achieving state-of-the-art performance in latent variable image modeling. The algorithm naturally stratifies information into higher and lower level details, creating abstract features and as such addressing one of the fundamentally desired properties of representation learning. Furthermore, the hierarchical ordering of its latents creates the opportunity to selectively store global information about an image, yielding a high quality 'conceptual compression' framework.},
  archiveprefix = {arXiv},
  arxivid       = {1604.08772},
  eprint        = {1604.08772},
  issn          = {10495258},
  keywords      = {Computer Science - Computer Vision and Pattern Rec, Computer Science - Machine Learning, Statistics - Machine Learning},
  language      = {en},
  mendeley-tags = {Computer Science - Computer Vision and Pattern Rec,Computer Science - Machine Learning,Statistics - Machine Learning},
  url           = {http://arxiv.org/abs/1604.08772},
}

@article{Bogacz2017,
abstract = {This paper provides an easy to follow tutorial on the free-energy framework for modelling perception developed by Friston, which extends the predictive coding model of Rao and Ballard. These models assume that the sensory cortex infers the most likely values of attributes or features of sensory stimuli from the noisy inputs encoding the stimuli. Remarkably, these models describe how this inference could be implemented in a network of very simple computational elements, suggesting that this inference could be performed by biological networks of neurons. Furthermore, learning about the parameters describing the features and their uncertainty is implemented in these models by simple rules of synaptic plasticity based on Hebbian learning. This tutorial introduces the free-energy framework using very simple examples, and provides step-by-step derivations of the model. It also discusses in more detail how the model could be implemented in biological neural circuits. In particular, it presents an extended version of the model in which the neurons only sum their inputs, and synaptic plasticity only depends on activity of pre-synaptic and post-synaptic neurons.},
author = {Bogacz, Rafal},
doi = {10.1016/j.jmp.2015.11.003},
issn = {10960880},
journal = {Journal of Mathematical Psychology},
language = {en},
month = {feb},
pages = {198--211},
pmid = {28298703},
title = {{A tutorial on the free-energy framework for modelling perception and learning}},
url = {https://linkinghub.elsevier.com/retrieve/pii/S0022249615000759},
volume = {76},
year = {2017}
}

@Misc{Dogra2020a,
  author        = {Dogra, Akshunna S.},
  month         = {apr},
  title         = {{Dynamical Systems and Neural Networks}},
  year          = {2020},
  abstract      = {Neural Networks (NNs) have been identified as a potentially powerful tool in the study of complex dynamical systems. A good example is the NN differential equation (DE) solver, which provides closed form, differentiable, functional approximations for the evolution of a wide variety of dynamical systems. A major disadvantage of such NN solvers can be the amount of computational resources needed to achieve accuracy comparable to existing numerical solvers. We present new strategies for existing dynamical system NN DE solvers, making efficient use of the learnt information, to speed up their training process, while still pursuing a completely unsupervised approach. We establish a fundamental connection between NN theory and dynamical systems theory via Koopman Operator Theory (KOT), by showing that the usual training processes for Neural Nets are fertile ground for identifying multiple Koopman operators of interest. We end by illuminating certain applications that KOT might have for NNs in general.},
  archiveprefix = {arXiv},
  arxivid       = {2004.11826},
  booktitle     = {arXiv},
  eprint        = {2004.11826},
  issn          = {23318422},
  keywords      = {Electrical Engineering and Systems Science - Signa, Mathematics - Dynamical Systems},
  language      = {en},
  mendeley-tags = {Electrical Engineering and Systems Science - Signa,Mathematics - Dynamical Systems},
  url           = {http://arxiv.org/abs/2004.11826},
}

@Misc{Huot2019,
  author        = {Huot, Fantine and Chen, Yi Fan and Clapp, Robert and Boneti, Carlos and Anderson, John},
  month         = {dec},
  title         = {{High-resolution imaging on TPUs ?}},
  year          = {2019},
  abstract      = {The rapid evolution of artificial intelligence (AI) is leading to a new generation of hardware accelerators optimized for deep learning. Some of the designs of these accelerators are general enough to allow their use for other computationally intensive tasks beyond AI. Cloud tensor processing units (TPUs) are one such example. Here, we demonstrate a novel approach using TensorFlow on Cloud TPUs to implement a high-resolution imaging technique called full-waveform inversion. Higher-order numerical stencils leverage the efficient matrix multiplication offered by the Cloud TPU, and the halo exchange benefits from the dedicated high-speed interchip connection. The performance is competitive when compared with Tesla V100 graphics processing units and shows promise for future computation- and memory-intensive imaging applications.},
  archiveprefix = {arXiv},
  arxivid       = {1912.08063},
  booktitle     = {arXiv},
  eprint        = {1912.08063},
  issn          = {23318422},
  keywords      = {Computer Science - Computational Engineering- Fina, Computer Science - Distributed- Parallel- and Clus, Imaging {\textperiodcentered} TPU {\textperiodcentered} Full-waveform inversion, Physics - Computational Physics, Physics - Geophysics},
  language      = {en},
  mendeley-tags = {Computer Science - Computational Engineering- Fina,Computer Science - Distributed- Parallel- and Clus,Physics - Computational Physics,Physics - Geophysics},
  url           = {http://arxiv.org/abs/1912.08063},
}

@Article{Tronarp2019,
  author        = {Tronarp, Filip and Kersting, Hans and S{\"{a}}rkk{\"{a}}, Simo and Hennig, Philipp},
  journal       = {Statistics and Computing},
  title         = {{Probabilistic solutions to ordinary differential equations as nonlinear Bayesian filtering: a new perspective}},
  year          = {2019},
  issn          = {15731375},
  month         = {apr},
  number        = {6},
  pages         = {1297--1315},
  volume        = {29},
  abstract      = {We formulate probabilistic numerical approximations to solutions of ordinary differential equations (ODEs) as problems in Gaussian process (GP) regression with nonlinear measurement functions. This is achieved by defining the measurement sequence to consist of the observations of the difference between the derivative of the GP and the vector field evaluated at the GP—which are all identically zero at the solution of the ODE. When the GP has a state-space representation, the problem can be reduced to a nonlinear Bayesian filtering problem and all widely used approximations to the Bayesian filtering and smoothing problems become applicable. Furthermore, all previous GP-based ODE solvers that are formulated in terms of generating synthetic measurements of the gradient field come out as specific approximations. Based on the nonlinear Bayesian filtering problem posed in this paper, we develop novel Gaussian solvers for which we establish favourable stability properties. Additionally, non-Gaussian approximations to the filtering problem are derived by the particle filter approach. The resulting solvers are compared with other probabilistic solvers in illustrative experiments.},
  archiveprefix = {arXiv},
  arxivid       = {1810.03440},
  doi           = {10.1007/s11222-019-09900-1},
  eprint        = {1810.03440},
  keywords      = {Initial value problems, Nonlinear Bayesian filtering, Probabilistic numerics, Statistics - Computation, Statistics - Machine Learning, Statistics - Methodology},
  language      = {en},
  mendeley-tags = {Statistics - Computation,Statistics - Machine Learning,Statistics - Methodology},
  shorttitle    = {Probabilistic Solutions To Ordinary Differential E},
  url           = {http://arxiv.org/abs/1810.03440},
}

@inproceedings{Viola2005,
abstract = {For over thirty years adaptive beamforming (AB) algorithms have been applied in RADAR and SONAR signal processing. Higher resolution and contrast is attainable using those algorithms at the price of an increased computational load. In this paper we consider four beamformers (BFs): Frost BF, Duvall BF, SSB, and SPOC. These algorithms are well know in the RADAR/SONAR literature. We have performed a series of simulations using ultrasound data to test the performance of those algorithms and compare them to the conventional, data independent, beamforming. Every algorithm was applied on single channel ultrasonic data that was generated using Field II. For a 32 element linear array operating at 5 MHz, beamplot results show that while the Duvall and SSB beamformers reduce sidelobes by roughly 20 dB, the sidelobes using the Frost algorithm rise by 23dB. The -6dB resolution is improved by 38%, 83%, and 43% in the case of Duvall, Frost, and SSB algorithms, respectively. In the case of SPOC, the beamplot shows a super-resolution peak with noise floor at -110 dB. Similar results were obtained for an array consisting of 64 elements. {\textcopyright} 2005 IEEE.},
author = {Viola, Francesco and Walker, William F.},
booktitle = {Proceedings - IEEE Ultrasonics Symposium},
doi = {10.1109/ULTSYM.2005.1603264},
isbn = {0780393821},
issn = {10510117},
keywords = {Folder - Adaptive beamforming},
mendeley-tags = {Folder - Adaptive beamforming},
number = {c},
pages = {1980--1983},
title = {{Adaptive signal processing in medical ultrasound beamforming}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1603264},
volume = {4},
year = {2005}
}

@article{Harshman1970,
abstract = {Simple structure and other common principles of factor rotation do not in general provide strong grounds for attributing explanatory significance to the factors which they select. In contrast, it is shown that an extension of Cattell's principle of rotation to Proportional Profiles (PP) offers a basis for determining explanatory factors for three-way or higher order multi-mode data. Conceptual models are developed for two basic patterns of multi-mode data variation, system- and object-variation, and PP analysis is found to apply in the system-variation case. Although PP was originally formulated as a principle of rotation to be used with classic two-way factor analysis, it is shown to embody a latent three-mode factor model, which is here made explicit and generalized frown two to N "parallel occasions". As originally formulated, PP rotation was restricted to orthogonal factors. The generalized PP model is demonstrated to give unique "correct" solutions with oblique, non-simple structure, and even non-linear factor structures. A series of tests, conducted with synthetic data of known factor composition, demonstrate the capabilities of linear and non-linear versions of the model, provide data on the minimal necessary conditions of uniqueness, and reveal the properties of the analysis procedures when these minimal conditions are not fulfilled. In addition, a mathematical proof is presented for the uniqueness of the solution given certain conditions on the data. Three-mode PP factor analysis is applied to a three-way set of real data consisting of the fundamental and first three formant frequencies of 11 persons saying 8 vowels. A unique solution is extracted, consisting of three factors which are highly meaningful and consistent with prior knowledge and theory concerning vowel quality. The relationships between the three-mode PP model and Tucker's multi-modal model, McDonald's non-linear model and Carroll and Chang's multi-dimensional scaling model are explored.},
author = {Harshman, Richard a},
journal = {UCLA Working Papers in Phonetics},
number = {10},
pages = {1-- 84},
title = {{Foundations of the PARAFAC procedure: Models and conditions for an “explanatory” multimodal factor analysis}},
url = {http://www.psychology.uwo.ca/faculty/harshman/wpppfac0.pdf},
volume = {16},
year = {1970}
}

@InProceedings{Eilam2013,
  author        = {Eilam, Alon and Chernyakova, Tanya and Eldar, Yonina C. and Kempinski, Arcady},
  booktitle     = {2013 IEEE Global Conference on Signal and Information Processing, GlobalSIP 2013 - Proceedings},
  title         = {{Sub-Nyquist medical ultrasound imaging: En route to cloud processing}},
  year          = {2013},
  pages         = {1017--1020},
  abstract      = {In medical ultrasound imaging, a pulse of known shape is transmitted into the respective medium, and the received echoes are sampled and digitally processed in a way referred to as beamforming to form an ultrasound image. Applied spatially, beamforming allows to improve resolution and signal-to-noise ratio. The structure of medical ultrasound signals allow for significant reduction of both sampling and processing rates by relying on ideas of Xampling, sub-Nyquist sampling and frequency domain beamforming. In this paper we present an implementation on an ultrasound machine using sub-Nyquist sampling and processing and the obtained imaging results. The provided system configuration exploits the advantages of beamforming in the frequency domain, which is performed at a low-rate. Our results prove that the concept of porting heavy computational tasks to the cloud is feasible for medical ultrasound, leading to potential of considerable reduction in future ultrasound machines size, power consumption and cost. {\textcopyright} 2013 IEEE.},
  doi           = {10.1109/GlobalSIP.2013.6737066},
  isbn          = {9781479902484},
  keywords      = {Array Processing, Beamforming, Compressed Sensing, Folder - Beamforming special, Sub-Nyquist, Ultrasound},
  mendeley-tags = {Array Processing,Beamforming,Compressed Sensing,Folder - Beamforming special,Sub-Nyquist,Ultrasound},
}

@article{Galiuto1998,
abstract = {We designed the present study (1) to investigate the velocities of longitudinal movement of the human left ventricle by pulsed-wave tissue Doppler (PWTD) imaging; (2) to test the hypothesis that a heterogeneous pattern of longitudinal systolic and diastolic velocities exists among individual left ventricular wall segments; (3) to establish the range of this heterogeneity, and (4) to correlate the function of individual segments with the known orientation of myocardial fibers. PWTD is a novel ultrasound method to quantify myocardial contraction and relaxation velocities. In 27 young normal subjects, PWTD peak values of longitudinal systolic and diastolic velocities were measured for 12 left ventricular segments visualized from the apical window. The PWTD sampling of each myocardial segment resulted in a triphasic velocity curve during each cardiac cycle: a systolic velocity wave (S) directed toward the transducer, and an early diastolic (E) and a late diastolic (A) velocity wave away from the transducer. A heterogeneous pattern of systolic and diastolic myocardial velocities was observed between individual wall segments as well as for the basal and midsegments of each myocardial wall. The difference between the highest and lowest values for S was 38.4% in the basal segments and 56.3% in the midwall segments. The difference between low and high velocities for E was 61.4% in the basal and 38.2% in the midsegments; for A the difference was 29.5% in the basal and 32.6% in the midsegments. In general, lower velocity values were found in the septum with higher basal to midwall difference. The lateral and posterior walls had higher, but more uniform, velocities. PWTD enables the quantitative assessment of regional systolic and diastolic myocardial velocities. Substantial heterogeneity of velocities exists within individual myocardial segments, and must be taken into account in any clinical application. The observed heterogeneity in longitudinal function is consistent with the known spatial distribution of myocardial fibers.},
author = {Galiuto, Leonarda and Ignone, Gianfranco and DeMaria, Anthony N.},
doi = {10.1016/S0002-9149(97)00990-9},
issn = {00029149},
journal = {American Journal of Cardiology},
number = {5},
pages = {609--614},
pmid = {9514459},
title = {{Contraction and relaxation velocities of the normal left ventricle using pulsed-wave tissue Doppler echocardiography}},
volume = {81},
year = {1998}
}

@Article{Zhang2016,
  author        = {Zhang, Miaomiao and Varray, Francois and Besson, Adrien and Carrillo, Rafael E. and Viallon, Magalie and Garcia, Damien and Thiran, Jean Philippe and Friboulet, Denis and Liebgott, Herve and Bernard, Olivier},
  journal       = {IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
  title         = {{Extension of Fourier-Based Techniques for Ultrafast Imaging in Ultrasound with Diverging Waves}},
  year          = {2016},
  issn          = {08853010},
  number        = {12},
  pages         = {2125--2137},
  volume        = {63},
  abstract      = {Ultrafast ultrasound imaging has become an intensive area of research thanks to its capability in reaching high frame rates. In this paper, we propose a scheme that allows the extension of the current Fourier-based techniques derived for planar acquisition to the reconstruction of sectorial scan with wide angle using diverging waves. The flexibility of the proposed formulation was assessed through two different Fourier-based techniques. The performance of the derived approaches was evaluated in terms of resolution and contrast from both simulations and in vitro experiments. The comparisons of the current state-of-the-art method with the conventional delay-and-sum technique illustrated the potential of the derived methods for producing competitive results with lower computational complexity.},
  doi           = {10.1109/TUFFC.2016.2616300},
  keywords      = {Diverging waves (DWs), Folder - Classical beamforming, Folder - HFR US, Fourier-based method, ultrafast imaging},
  mendeley-tags = {Folder - Classical beamforming,Folder - HFR US},
  pmid          = {27740480},
}

@Article{Shin2016,
  author        = {Shin, Junseob and Chen, Yu and Malhi, Harshawn and Yen, Jesse T.},
  journal       = {IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
  title         = {{Ultrasonic Reverberation Clutter Suppression Using Multiphase Apodization With Cross Correlation}},
  year          = {2016},
  issn          = {08853010},
  number        = {11},
  pages         = {1947--1956},
  volume        = {63},
  abstract      = {Despite numerous recent advances in medical ultrasound imaging, reverberation clutter from near-field anatomical structures, such as the abdominal wall, ribs, and tissue layers, is one of the major sources of ultrasound image quality degradation. Reverberation clutter signals are undesirable echoes, which arise as a result of multiple reflections of acoustic waves between the boundaries of these structures, and cause fill-in to lower image contrast. In order to mitigate the undesirable reverberation clutter effects, we present, in this paper, a new beamforming technique called multiphase apodization with cross correlation (MPAX), which is an improved version of our previous technique, dual apodization with cross correlation (DAX). While DAX uses a single pair of complementary amplitude apodizations, MPAX utilizes multiple pairs of complementary sinusoidal phase apodizations to intentionally introduce grating lobes from which an improved weighting matrix can be produced to effectively suppress reverberation clutter. Our experimental sponge phantom and preliminary in vivo results from human subjects presented in this paper suggest that MPAX is a highly effective technique in suppressing reverberation clutter and has great potential for producing high contrast ultrasound images for more accurate diagnosis in clinics.},
  doi           = {10.1109/TUFFC.2016.2597124},
  keywords      = {Beamforming, Folder - Correlation approaches, Folder - Side and grating lobes reduction, clutter suppression, contrast enhancement, reverberation clutter},
  mendeley-tags = {Beamforming,Folder - Correlation approaches,Folder - Side and grating lobes reduction,clutter suppression,contrast enhancement,reverberation clutter},
  pmid          = {27824570},
}

@InProceedings{VanSloun2015,
  author        = {{Van Sloun}, Ruud Jg and Pandharipande, Ashish and Mischi, Massimo and Demi, Libertario},
  booktitle     = {2015 IEEE International Ultrasonics Symposium, IUS 2015},
  title         = {{Compressed sensing for beamformed Ultrasound computed tomography}},
  year          = {2015},
  pages         = {1--4},
  publisher     = {IEEE},
  abstract      = {Ultrasound computed tomography (UCT) allows reconstruction of quantitative tissue characteristics. Lowering the acquisition time would be beneficial; however, this is limited by the time of flight and the number of transmission events. Moreover, corruption of the measurements by noise may cause inverse scattering reconstruction methods such as the Born Iterative Method (BIM) to converge to a wrong solution. Beamforming using multiple elements to obtain a narrow beam has the potential to mitigate the effects of noise; however, spatial coverage per transmission event reduces in this case. To excite the full domain, more transmissions are required and the acquisition time increases even further. We therefore consider compressive acquisitions based on parallel randomized transmissions from a circular array. Relying on the assumption that the object is compressible, we combine the BIM with sparse reconstruction to obtain the estimated image.},
  doi           = {10.1109/ULTSYM.2015.0158},
  isbn          = {9781479981823},
  keywords      = {Born Iterative Method, Compressed Sensing, Folder - Beamforming special, Ultrasound Computed Tomography},
  mendeley-tags = {Folder - Beamforming special},
}

@article{Tanter2014,
abstract = {Although the use of ultrasonic plane-wave transmissions rather than line-per-line focused beam transmissions has been long studied in research, clinical application of this technology was only recently made possible through developments in graphical processing unit (GPU)-based platforms. Far beyond a technological breakthrough, the use of plane or diverging wave transmissions enables attainment of ultrafast frame rates (typically faster than 1000 frames per second) over a large field of view. This concept has also inspired the emergence of completely novel imaging modes which are valuable for ultrasound-based screening, diagnosis, and therapeutic monitoring. In this review article, we present the basic principles and implementation of ultrafast imaging. In particular, present and future applications of ultrafast imaging in biomedical ultrasound are illustrated and discussed.},
author = {Tanter, Mickael and Fink, Mathias},
doi = {10.1109/tuffc.2014.6689779},
issn = {0885-3010},
journal = {IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
number = {1},
pages = {102--119},
pmid = {24402899},
title = {{Ultrafast imaging in biomedical ultrasound}},
volume = {61},
year = {2014}
}

@book{Bruneau2010,
abstract = {The central theme of the chapters is acoustic propagation in fluid media, dissipative or non-dissipative, homogeneous or nonhomogeneous, infinite or limited, placing particular emphasis on the theoretical formulation of the problems considered. {\textcopyright} 2006 ISTE Ltd.},
author = {Bruneau, Michel},
booktitle = {Fundamentals of Acoustics},
doi = {10.1002/9780470612439},
isbn = {9781905209255},
pages = {560},
title = {{Fundamentals of Acoustics}},
year = {2010}
}

@Article{Tang2007,
  author        = {Tang, Meng Xing and Eckersley, Robert J.},
  journal       = {Ultrasound in Medicine and Biology},
  title         = {{Frequency and pressure dependent attenuation and scattering by microbubbles}},
  year          = {2007},
  issn          = {03015629},
  number        = {1},
  pages         = {164--168},
  volume        = {33},
  abstract      = {The aim of this study was to evaluate experimentally the degree of pressure dependence of attenuation and scattering by microbubbles at low acoustic pressures with an empirical nonlinear model. In addition, the pressure dependency over a range of frequencies (1 to 5 MHz) has been studied. A series of transmission and scattering measurements were made with the microbubble SonoVue™, using an automated system. Results show that, within the pressure range studied, attenuation as a result of the microbubble is pressure-dependent, whereas no such dependence of scattering was detectable. The pressure dependence of attenuation for SonoVue™ was found to be most significant at 1.5 MHz. The scattering is shown to be the highest at the lowest insonation frequency, around 1∼1.25 MHz, and then decreases with frequency. (E-mail: mtang@robots.ox.ac.uk). {\textcopyright} 2006 World Federation for Ultrasound in Medicine & Biology.},
  doi           = {10.1016/j.ultrasmedbio.2006.07.031},
  keywords      = {Attenuation, Folder - Contrast agent physics, Microbubbles, Multifrequency, Pressure dependency, Scattering, Ultrasound contrast agent},
  mendeley-tags = {Attenuation,Folder - Contrast agent physics,Microbubbles,Multifrequency,Pressure dependency,Scattering,Ultrasound contrast agent},
  pmid          = {17189060},
}

@article{Fan2018,
abstract = {Nowadays, many fields of study are have to deal with large and sparse data matrixes, but the most important issue is finding the inverse of these matrixes. Thankfully, Krylov subspace methods can be used in solving these types of problem. However, it is difficult to understand mathematical principles behind these methods. In the first part of the article, Krylov methods are discussed in detail. Thus, readers equipped with a basic knowledge of linear algebra should be able to understand these methods. In this part, the knowledge of Krylov methods are put into some examples for simple implementations of a commonly known Krylov method GMRES. In the second part, the article talks about CG iteration, a wildly known method which is very similar to Krylov methods. By comparison between CG iteration and Krylov methods, readers can get a better comprehension of Krylov methods based on CG iteration. In the third part of the article, aiming to improve the efficiency of Krylov methods, preconditioners are discussed. In addition, the restarting GMRES is briefly introduced to reduce the space consumption of Krylov methods in this part.},
archivePrefix = {arXiv},
arxivId = {1811.09025},
author = {Fan, Shitao},
eprint = {1811.09025},
journal = {arXiv:1811.09025 [math]},
keywords = {Mathematics - Optimization and Control},
language = {en},
mendeley-tags = {Mathematics - Optimization and Control},
month = {nov},
title = {{An Introduction to Krylov Subspace Methods}},
url = {http://arxiv.org/abs/1811.09025},
year = {2018}
}

@article{Romero2016,
abstract = {Compressed sensing deals with the reconstruction of signals from sub-Nyquist samples by exploiting the sparsity of their projections onto known subspaces. In contrast, this article is concerned with the reconstruction of second-order statistics, such as covariance and power spectrum, even in the absence of sparsity priors. The framework described here leverages the statistical structure of random processes to enable signal compression and offers an alternative perspective at sparsity-agnostic inference. Capitalizing on parsimonious representations, we illustrate how compression and reconstruction tasks can be addressed in popular applications such as power-spectrum estimation, incoherent imaging, direction-of-arrival estimation, frequency estimation, and wideband spectrum sensing.},
author = {Romero, Daniel and Ariananda, Dyonisius Dony and Tian, Zhi and Leus, Geert},
doi = {10.1109/MSP.2015.2486805},
issn = {10535888},
journal = {IEEE Signal Processing Magazine},
keywords = {Folder - Generic Signal Processing},
mendeley-tags = {Folder - Generic Signal Processing},
number = {1},
pages = {78--93},
title = {{Compressive Covariance Sensing: Structure-based compressive sensing beyond sparsity}},
volume = {33},
year = {2016}
}

@Article{Denarie2013,
  author        = {Denarie, Bastien and Tangen, Thor Andreas and Ekroll, Ingvild Kinn and Rolim, Natale and Torp, Hans and Bjastad, Tore and Lovstakken, Lasse},
  journal       = {IEEE Transactions on Medical Imaging},
  title         = {{Coherent plane wave compounding for very high frame rate ultrasonography of rapidly moving targets}},
  year          = {2013},
  issn          = {02780062},
  number        = {7},
  pages         = {1265--1276},
  volume        = {32},
  abstract      = {Coherent plane wave compounding is a promising technique for achieving very high frame rate imaging without compromising image quality or penetration. However, this approach relies on the hypothesis that the imaged object is not moving during the compounded scan sequence, which is not the case in cardiovascular imaging. This work investigates the effect of tissue motion on retrospective transmit focusing in coherent compounded plane wave imaging (PWI). Two compound scan sequences were studied based on a linear and alternating sequence of tilted plane waves, with different timing characteristics. Simulation studies revealed potentially severe degradations in the retrospective focusing process, where both radial and lateral resolution was reduced, lateral shifts of the imaged medium were introduced, and losses in signal-to-noise ratio (SNR) were inferred. For myocardial imaging, physiological tissue displacements were on the order of half a wavelength, leading to SNR losses up to 35 dB, and reductions of contrast by 40 dB. No significant difference was observed between the different tilt sequences. A motion compensation technique based on cross-correlation was introduced, which significantly recovered the losses in SNR and contrast for physiological tissue velocities. Worst case losses in SNR and contrast were recovered by 35 dB and 27-35 dB, respectively. The effects of motion were demonstrated in vivo when imaging a rat heart. Using PWI, very high frame rates up to 463 fps were achieved at high image quality, but a motion correction scheme was then required. {\textcopyright} 1982-2012 IEEE.},
  doi           = {10.1109/TMI.2013.2255310},
  keywords      = {Folder - HFR US, Motion compensation, plane wave compounding, small animal applications, ultra-fast imaging},
  mendeley-tags = {Folder - HFR US,Motion compensation,plane wave compounding,small animal applications,ultra-fast imaging},
  pmid          = {23549887},
}

@Article{Sprechmann2015,
  author        = {Sprechmann, P. and Bronstein, A. M. and Sapiro, G.},
  journal       = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
  title         = {{Learning Efficient Sparse and Low Rank Models}},
  year          = {2015},
  issn          = {01628828},
  month         = {dec},
  number        = {9},
  pages         = {1821--1833},
  volume        = {37},
  abstract      = {Parsimony, including sparsity and low rank, has been shown to successfully model data in numerous machine learning and signal processing tasks. Traditionally, such modeling approaches rely on an iterative algorithm that minimizes an objective function with parsimony-promoting terms. The inherently sequential structure and data-dependent complexity and latency of iterative optimization constitute a major limitation in many applications requiring real-Time performance or involving large-scale data. Another limitation encountered by these modeling techniques is the difficulty of their inclusion in discriminative learning scenarios. In this work, we propose to move the emphasis from the model to the pursuit algorithm, and develop a process-centric view of parsimonious modeling, in which a learned deterministic fixed-complexity pursuit process is used in lieu of iterative optimization. We show a principled way to construct learnable pursuit process architectures for structured sparse and robust low rank models, derived from the iteration of proximal descent algorithms. These architectures learn to approximate the exact parsimonious representation at a fraction of the complexity of the standard optimization methods. We also show that appropriate training regimes allow to naturally extend parsimonious models to discriminative settings. State-of-The-Art results are demonstrated on several challenging problems in image and audio processing with several orders of magnitude speed-up compared to the exact optimization algorithms.},
  archiveprefix = {arXiv},
  arxivid       = {1212.3631},
  doi           = {10.1109/TPAMI.2015.2392779},
  eprint        = {1212.3631},
  keywords      = {Computer Science - Machine Learning, Folder - Generic Signal Processing, NMF, big data, deep learning, parsimonious modeling, proximal methods, real-Time implementations, sparse and low-rank models},
  language      = {en},
  mendeley-tags = {Computer Science - Machine Learning,Folder - Generic Signal Processing},
  url           = {http://arxiv.org/abs/1212.3631},
}

@incollection{Verweij2014,
abstract = {An approach for simulating non-linear ultrasound imaging using Field II has been implemented using the operator splitting approach, where diffraction, attenuation, and non-linear propagation can be handled individually. The method uses the Earnshaw/Poisson solution to Burgcrs' equation for the non-linear propagation. The speed of sound is calculated from the instantaneous pressure of the pulse and the nonlinearity B/A parameter of the medium. The harmonic field is found by introducing a number of virtual planes in front of the aperture and then propagating the pulse using Burgers' solution between the planes. Simulations on the acoustical axis of an array transducer were performed and compared to measurements made in a water tank. A 3 MHz convex array transducer with a pitch of 0.53 mm and a height of 13 mm was used. The electronic focus was at 45 mm and 16 elements were used for emission. The emitted pressure was 1.4 MPa measured 6 mm from the aperture by a Force Institute MH25-5 needle hydrophone in a water bath. The build-up of higher harmonics can here be predicted accurately up to the 5th harmonic. The second harmonic is simulated with an accuracy of &plusmn;2.6 dB and the third harmonic with &plusmn;2 dB compared to the water bath measurements. Point spread functions (PSFs) were also calculated and measured. They all showed that the second and third harmonic PSFs are narrower than for the first harmonic, with a good resemblance between the measured and simulated PSFs. The approach can also be extended to simulate non-linear ultrasound imaging in 3D using filters or pulse inversion for any kind of transducer, focusing, apodization, pulse emission and scattering phantom. This is done by first simulating the non-linear emitted field and assuming that the scattered field is weak and linear. The received signal is then the spatial impulse response in receive convolved with the emitted field at the given point.},
author = {Verweij, M.D. and Treeby, B.E. and van Dongen, K.W.A. and Demi, L.},
booktitle = {Comprehensive Biomedical Physics},
doi = {10.1016/b978-0-444-53632-7.00221-5},
isbn = {978-0-444-53633-4},
language = {en},
pages = {465--500},
publisher = {Elsevier},
title = {{Simulation of Ultrasound Fields}},
url = {https://linkinghub.elsevier.com/retrieve/pii/B9780444536327002215},
year = {2014}
}

@Article{Xiao2019,
  author        = {Xiao, Lin and Li, Kenli and Tan, Zhiguo and Zhang, Zhijun and Liao, Bolin and Chen, Ke and Jin, Long and Li, Shuai},
  journal       = {Information Processing Letters},
  title         = {{Nonlinear gradient neural network for solving system of linear equations}},
  year          = {2019},
  issn          = {00200190},
  month         = {feb},
  pages         = {35--40},
  volume        = {142},
  abstract      = {For purpose of solving system of linear equations (SoLE) more efficiently, a fast convergent gradient neural network (FCGNN) model is designed and discussed in this paper. Different from the design of the conventional gradient neural network (CGNN), the design of the FCGNN model is based on a nonlinear activation function, and thus the better convergence speed can be reached. In addition, the convergence upper bound of the FCGNN model is estimated and provided in details. Simulative results validate the superiority of the FCGNN model, as compared to the CGNN model for finding SoLE.},
  doi           = {10.1016/j.ipl.2018.10.004},
  keywords      = {Fast convergence, Folder - solving_linear_systems, Gradient neural network (GNN), Nonlinear activation function, Performance evaluation, Systems of linear equations (SoLE)},
  language      = {en},
  mendeley-tags = {Folder - solving_linear_systems},
  url           = {https://linkinghub.elsevier.com/retrieve/pii/S0020019018301893},
}

@InProceedings{Senouf2019,
  author        = {Senouf, Ortal and Vedula, Sanketh and Weiss, Tomer and Bronstein, Alex and Michailovich, Oleg and Zibulevsky, Michael},
  booktitle     = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  title         = {{Self-supervised learning of inverse problem solvers in medical imaging}},
  year          = {2019},
  month         = {may},
  pages         = {111--119},
  volume        = {11795 LNCS},
  abstract      = {In the past few years, deep learning-based methods have demonstrated enormous success for solving inverse problems in medical imaging. In this work, we address the following question: Given a set of measurements obtained from real imaging experiments, what is the best way to use a learnable model and the physics of the modality to solve the inverse problem and reconstruct the latent image? Standard supervised learning based methods approach this problem by collecting data sets of known latent images and their corresponding measurements. However, these methods are often impractical due to the lack of availability of appropriately sized training sets, and, more generally, due to the inherent difficulty in measuring the “groundtruth” latent image. In light of this, we propose a self-supervised approach to training inverse models in medical imaging in the absence of aligned data. Our method only requiring access to the measurements and the forward model at training. We showcase its effectiveness on inverse problems arising in accelerated magnetic resonance imaging (MRI).},
  archiveprefix = {arXiv},
  arxivid       = {1905.09325},
  doi           = {10.1007/978-3-030-33391-1_13},
  eprint        = {1905.09325},
  isbn          = {9783030333904},
  issn          = {16113349},
  keywords      = {Accelerated MRI, Computer Science - Computer Vision and Pattern Rec, Deep learning, Electrical Engineering and Systems Science - Image, Electrical Engineering and Systems Science - Signa, Inverse problems, Self-supervised learning},
  language      = {en},
  mendeley-tags = {Computer Science - Computer Vision and Pattern Rec,Electrical Engineering and Systems Science - Image,Electrical Engineering and Systems Science - Signa},
  url           = {http://arxiv.org/abs/1905.09325},
}

@InProceedings{Dinh2017,
  author        = {Dinh, Laurent and Sohl-Dickstein, Jascha and Bengio, Samy},
  booktitle     = {5th International Conference on Learning Representations, ICLR 2017 - Conference Track Proceedings},
  title         = {{Density estimation using real NVP}},
  year          = {2017},
  month         = {feb},
  abstract      = {Unsupervised learning of probabilistic models is a central yet challenging problem in machine learning. Specifically, designing models with tractable learning, sampling, inference and evaluation is crucial in solving this task. We extend the space of such models using real-valued non-volume preserving (real NVP) transformations, a set of powerful, stably invertible, and learnable transformations, resulting in an unsupervised learning algorithm with exact log-likelihood computation, exact and efficient sampling, exact and efficient inference of latent variables, and an interpretable latent space. We demonstrate its ability to model natural images on four datasets through sampling, log-likelihood evaluation, and latent variable manipulations.},
  archiveprefix = {arXiv},
  arxivid       = {1605.08803},
  eprint        = {1605.08803},
  keywords      = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computi, Statistics - Machine Learning},
  language      = {en},
  mendeley-tags = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computi,Statistics - Machine Learning},
  url           = {http://arxiv.org/abs/1605.08803},
}

@article{Krolik1991,
abstract = {In recent research, coherent focusing of wideband data received by a linear array of sensors has been achieved by adjusting the spatial sampling rate, or “spatially resampling” the array outputs, as a function of temporal frequency. Spatial resampling permits each wideband source in multigroup multiple source scenarios to be represented by a rank-one model without preliminary estimates of the spatial distribution of the sources. This correspondence examines the design and performance of linear shift-variant filters for coherent wideband processing via spatial resampling. In particular, a minimax error criterion is used to obtain realizable resampling filters and an approximate statistical analysis of wideband spatially resampled minimum variance spatial spectral estimation is presented. Simulation results indicate that spatial resampling provides a computationally efficient means of reducing the threshold observation time required to obtain high resolution estimates of source location. {\textcopyright} 1991 IEEE},
author = {Krolik, Jeffrey and Swingler, David},
doi = {10.1109/78.91162},
issn = {19410476},
journal = {IEEE Transactions on Signal Processing},
number = {8},
pages = {1899--1903},
title = {{The Performance of Minimax Spatial Resampling Filters for Focusing Wide-Band Arrays}},
volume = {39},
year = {1991}
}

@article{Camacho2009,
abstract = {A new method for grating and side lobes suppression in ultrasound images is presented. It is based on an analysis of the phase diversity at the aperture data. Two coherence factors, namely the phase coherence factor (PCF) and the sign coherence factor (SCF), are proposed to weight the coherent sum output. Different from other approaches, phase rather than amplitude information is used to perform the correction action.Besides achieving the main goal, the method obtains improvements in lateral resolution and SNR. Implementation of the SCF technique is quite straightforward, operating in realtime,and can be added to any virtually existing beamformer to improve the resolution, contrast, SNR, and dynamic range of the images. A programmable parameter allows adjusting the sensitivity of the method to out-of-phase signals, from zero to a strict coherence criterion. The theoretical basis for the 2 methods are given and their performances evaluated by simulation. Then, experiments are conducted to provide results that are in good agreement with those expected from theory and simulation. {\textcopyright} 2006 IEEE.},
author = {Camacho, Jorge and Parrilla, Montserrat and Fritsch, Carlos},
doi = {10.1109/TUFFC.2009.1128},
issn = {08853010},
journal = {IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
keywords = {Folder - Correlation approaches},
mendeley-tags = {Folder - Correlation approaches},
number = {5},
pages = {958--974},
pmid = {19473914},
title = {{Phase coherence imaging}},
volume = {56},
year = {2009}
}

@misc{Su2018,
abstract = {In this paper, we integrate VAEs and flow-based generative models successfully and get f-VAEs. Compared with VAEs, f-VAEs generate more vivid images, solved the blurred-image problem of VAEs. Compared with flow-based models such as Glow, f-VAE is more lightweight and converges faster, achieving the same performance under smaller-size architecture.},
archivePrefix = {arXiv},
arxivId = {1809.05861},
author = {Su, Jianlin and Wu, Guang},
booktitle = {arXiv},
eprint = {1809.05861},
issn = {23318422},
language = {en},
pages = {7},
title = {{F-VAEs: Improve VAEs with conditional flows}},
year = {2018}
}

@Article{Li2003a,
  author        = {Li, Jian and Stoica, Petre and Wang, Zhisong},
  journal       = {IEEE Transactions on Signal Processing},
  title         = {{On robust Capon beamforming and diagonal loading}},
  year          = {2003},
  issn          = {1053587X},
  month         = {jul},
  number        = {7},
  pages         = {1702--1715},
  volume        = {51},
  abstract      = {The Capon beamformer has better resolution and much better interference rejection capability than the standard (data-independent) beamformer, provided that the array steering vector corresponding to the signal of interest (SOI) is accurately known. However, whenever the knowledge of the SOI steering vector is imprecise (as is often the case in practice), the performance of the Capon beamformer may become worse than that of the standard beamformer. Diagonal loading (including its extended versions) has been a popular approach to improve the robustness of the Capon beamformer. In this paper, we show that a natural extension of the Capon beamformer to the case of uncertain steering vectors also belongs to the class of diagonal loading approaches, but the amount of diagonal loading can be precisely calculated based on the uncertainty set of the steering vector. The proposed robust Capon beamformer can be efficiently computed at a comparable cost with that of the standard Capon beamformer. Its excellent performance for SOI power estimation is demonstrated via a number of numerical examples.},
  doi           = {10.1109/TSP.2003.812831},
  keywords      = {Adaptive arrays, Array errors, Diagonal loading, Folder - Adaptive beamforming, Robust Capon beamforming, Robust adaptive beamforming, Signal power estimation, Steering vector uncertainty},
  language      = {en},
  mendeley-tags = {Folder - Adaptive beamforming},
  url           = {http://ieeexplore.ieee.org/document/1206680/},
}

@article{Morgan2000,
abstract = {Ultrasound contrast agents provide new opportunities to image vascular volume and flow rate directly. To accomplish this goal, new pulse sequences can be developed to detect specifically the presence of a microbubble or group of microbubbles. Here, we consider a new scheme to detect the presence of contrast agents in the body by examining the effect of transmitted phase on the received echoes from single bubbles. In this study, three tools are uniquely combined to aid in the understanding of the effects of transmission parameters and bubble radius on the received echo. These tools allow for optical measurement of radial oscillations of single bubbles during insonation, acoustical study of echoes from single contrast agent bubbles, and the comparison of these experimental observations with theoretical predictions. A modified Herring equation with shell terms is solved for the time-dependent bubble radius and wall velocity, and these outputs are used to formulate the predicted echo from a single encapsulated bubble. The model is validated by direct comparison of the predicted radial oscillations with those measured optically. The transient bubble response is evaluated with a transducer excitation consisting of one-cycle pulses with a center frequency of 2.4-MHz. The experimental and theoretical results are in good agreement and predict that the transmission of two pulses with opposite polarity will yield similar time domain echoes with the first significant portion of the echo generated when the rarefactional half-cycle reaches the bubble. In addition, both the experimental and theoretical results confirm that the 2.4 MHz pulse with rarefaction first (180°) produces an echo with a mean frequency that is 0.8 MHz higher than the compression-first response (0°), where 0.8 MHz represents a mean over an ensemble of echoes from small (<1.0 $\mu$m radius) lipid-shelled bubbles. This shift in the mean frequency decreases with increasing equilibrium radius and is negligible for larger (> 1.8 $\mu$m radius) bubbles. We have found other significant differences between the echoes from bubbles with a difference in radius of approx. 0.6 $\mu$m. Specifically, for a 2.4 MHz transmitted frequency, larger bubbles (e.g., 1.3 $\mu$m radius) produce stronger echoes with a slower ring-down as compared with the smaller bubbles (e.g., 0.7 $\mu$m radius). For this transmitted frequency, a radius of 1.4 $\mu$m is the calculated linear resonance size.},
author = {Morgan, Karen E.},
doi = {10.1109/58.883539},
issn = {08853010},
journal = {IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
keywords = {Folder - Contrast agent physics},
mendeley-tags = {Folder - Contrast agent physics},
number = {6},
pages = {1494--1509},
title = {{Experimental and theoretical evaluation of microbubble behavior: effect of transmitted phase and bubble size}},
volume = {47},
year = {2000}
}

@article{Murino1994,
abstract = {The purpose of this paper is to describe a noncoherent correlation technique for the formation of 3-D acoustic images, mainly for underwater applications. This technique is applied to the envelope of signals received by a 2-D array. The performances of the technique are compared with those of the coherent technique of focused beamforming in terms of angular resolution, depth of field, beam pattern, and accuracy in range determination. Moreover, special attention is given to the modalities for an efficient implementation on a digital computer. The complete absence of grating lobes, for whatever arrangement of the transducers, and the much higher speed of the imaging process, as compared with that of beamforming in the time domain, are the two major advantages of this technique. A reduction in the speckle effect, the possibility of creating a virtual depth of field, the feasibility of using square-law transducers, and the implementation simplicity are additional interesting characteristics. The results of some simulations are reported and compared with those obtained by the beamforming process. {\textcopyright} 1994 IEEE},
author = {Murino, Vittorio and Regazzoni, Carlo S. and Trucco, Andrea and Vernazza, Gianni},
doi = {10.1109/58.308497},
issn = {08853010},
journal = {IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
number = {5},
pages = {621--630},
title = {{A Noncoherent Correlation Technique and Focused Beamforming for Ultrasonic Underwater Imaging: A Comparative Analysis}},
volume = {41},
year = {1994}
}

@Article{Baranger2018,
  author        = {Baranger, Jerome and Arnal, Bastien and Perren, Fabienne and Baud, Olivier and Tanter, Mickael and Demene, Charlie},
  journal       = {IEEE Transactions on Medical Imaging},
  title         = {{Adaptive Spatiotemporal SVD Clutter Filtering for Ultrafast Doppler Imaging Using Similarity of Spatial Singular Vectors}},
  year          = {2018},
  issn          = {1558254X},
  month         = {jul},
  number        = {7},
  pages         = {1574--1586},
  volume        = {37},
  abstract      = {Singular value decomposition of ultrafast imaging ultrasonic data sets has recently been shown to build a vector basis far more adapted to the discrimination of tissue and blood flow than the classical Fourier basis, improving by large factor clutter filtering and blood flow estimation. However, the question of optimally estimating the boundary between the tissue subspace and the blood flow subspace remained unanswered. Here, we introduce an efficient estimator for automatic thresholding of subspaces and compare it to an exhaustive list of thirteen estimators that could achieve this task based on the main characteristics of the singular components, namely the singular values, the temporal singular vectors, and the spatial singular vectors. The performance of those fourteen estimators was tested in vitro in a large set of controlled experimental conditions with different tissue motion and flow speeds on a phantom. The estimator based on the degree of resemblance of spatial singular vectors outperformed all others. Apart from solving the thresholding problem, the additional benefit with this estimator was its denoising capabilities, strongly increasing the contrast to noise ratio and lowering the noise floor by at least 5 dB. This confirms that, contrary to conventional clutter filtering techniques that are almost exclusively based on temporal characteristics, efficient clutter filtering of ultrafast Doppler imaging cannot overlook space. Finally, this estimator was applied in vivo on various organs (human brain, kidney, carotid, and thyroid) and showed efficient clutter filtering and noise suppression, improving largely the dynamic range of the obtained ultrafast power Doppler images.},
  doi           = {10.1109/TMI.2018.2789499},
  keywords      = {Blood, Blood flow, Clutter, Doppler effect, Doppler imaging, Doppler measurement, Filtering, Imaging, Matrix decomposition, adaptive spatiotemporal SVD clutter filtering, automatic thresholding, biomedical ultrasonics, blood flow estimation, blood flow subspace, blood vessels, classical Fourier basis, factor clutter filtering, flow speeds, haemodynamics, image denoising, image filtering, image segmentation, medical image processing, noise suppression, parameter estimation, phantoms, singular value decomposition, spatial singular vectors, temporal singular vectors, tissue motion, tissue subspace, ultrafast Doppler imaging, ultrafast imaging, ultrafast imaging ultrasonic data sets, ultrafast power Doppler images, ultrasound, vector basis},
  mendeley-tags = {Blood,Blood flow,Clutter,Doppler effect,Doppler imaging,Doppler measurement,Filtering,Imaging,Matrix decomposition,adaptive spatiotemporal SVD clutter filtering,automatic thresholding,biomedical ultrasonics,blood flow estimation,blood flow subspace,blood vessels,classical Fourier basis,factor clutter filtering,flow speeds,haemodynamics,image denoising,image filtering,image segmentation,medical image processing,noise suppression,parameter estimation,phantoms,singular value decomposition,spatial singular vectors,temporal singular vectors,tissue motion,tissue subspace,ultrafast Doppler imaging,ultrafast imaging,ultrafast imaging ultrasonic data sets,ultrafast power Doppler images,ultrasound,vector basis},
  pmid          = {29969408},
}

@Misc{Vedula2018,
  author        = {Vedula, Sanketh and Senouf, Ortal and Zurakhov, Grigoriy and Bronstein, Alex and Michailovich, Oleg and Zibulevsky, Michael},
  title         = {{Learning beamforming in ultrasound imaging}},
  year          = {2018},
  abstract      = {Medical ultrasound (US) is a widespread imaging modality owing its popularity to cost efficiency, portability, speed, and lack of harmful ionizing radiation. In this paper, we demonstrate that replacing the traditional ultrasound processing pipeline with a data-driven, learnable counterpart leads to significant improvement in image quality. Moreover, we demonstrate that greater improvement can be achieved through a learning-based design of the transmitted beam patterns simultaneously with learning an image reconstruction pipeline. We evaluate our method on an in-vivo first-harmonic cardiac ultrasound dataset acquired from volunteers and demonstrate the significance of the learned pipeline and transmit beam patterns on the image quality when compared to standard transmit and receive beamformers used in high frame-rate US imaging. We believe that the presented methodology provides a fundamentally different perspective on the classical problem of ultrasound beam pattern design.},
  archiveprefix = {arXiv},
  arxivid       = {1812.08043},
  booktitle     = {arXiv},
  eprint        = {1812.08043},
  file          = {:home/antonio/Documents/bibliography/files/Vedula et al. - 2018 - Learning beamforming in ultrasound imaging.pdf:pdf},
  issn          = {23318422},
  keywords      = {Beamforming, Deep Learning, Ultrasound Imaging},
  language      = {en},
  pages         = {19},
}

@article{Lu1997a,
abstract = {A new 2D (two-dimensional) and 3D (three-dimensional) pulse-echo imaging method (Fourier method) has been developed with limited diffraction beams. In this method, a plane wave pulse (broadband) is used to transmit and limited diffraction beams of different parameters are used to receive. Signals received are processed to obtain spatial Fourier transform of object functions and images are constructed with an inverse Fourier transform. Because only one transmission is required to construct images, this method may achieve a high frame rate (up to 3750 frames/s for biological soft tissues at a depth of 200 mm). To demonstrate the efficacy of the method, both 2D C-mode and 3D images have been simulated using conditions that are typical for medical ultrasound. Results show that images of high resolutions (about 6 wavelengths at 200 mm) and low sidelobes (around -60 dB) can be constructed over a large depth of interest (30 to 200 mm) with a 50 mm diameter aperture. Experiments with the new method have also been carried out. 2D B-mode images have been constructed with conventional linear arrays. In the experiment, an ATS 539 tissue-equivalent phantom and two linear arrays were used. The first array had a center frequency of 2.25 MHz, dimension of 18.288 mm × 12.192 mm, and 48 elements. The second had a center frequency of 2.5 MHz, 38.4 mm × 10 mm in dimension, and 64 elements. Images of different fields of views were constructed from RF data acquired with these arrays using both the new and conventional dynamic focusing (delay-and-sum) methods. Results show that qualities of images constructed are almost identical with the two methods in terms of sidelobes, contrast, and lateral and axial resolutions. Phase aberration has also been assessed for the two methods, and results show that its influence is about the same on both methods. In addition, a practical imaging system to implement the new method is suggested and potential applications of the method are discussed. {\textcopyright} 1997 IEEE.},
author = {Lu, Jian Yu},
doi = {10.1109/58.655200},
issn = {08853010},
journal = {IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
keywords = {Folder - HFR US},
mendeley-tags = {Folder - HFR US},
number = {4},
pages = {839--856},
title = {{2D and 3D High Frame Rate Imaging with Limited Diffraction Beams}},
volume = {44},
year = {1997}
}

@Article{Misra2017,
  author        = {Misra, Prasant and Hu, Wen and Yang, Mingrui and Duarte, Marco and Jha, Sanjay},
  journal       = {IEEE Transactions on Mobile Computing},
  title         = {{Sparsity Based Efficient Cross-Correlation Techniques in Sensor Networks}},
  year          = {2017},
  issn          = {15361233},
  number        = {7},
  pages         = {2037--2050},
  volume        = {16},
  abstract      = {Cross-correlation is a popular signal processing technique used in numerous location tracking systems for obtaining reliable range information. However, its efficient design and practical implementation has not yet been achieved on mote platforms that are typical in wireless sensor network due to resource constrains. In this paper, we propose StructS-XCorr: cross-correlation via structured sparse representation, a new computing framework for ranging based on ℓ11 -norm minimization [1] and structured sparsity. The key idea is to compress the ranging signal samples on the mote by efficient random projections and transfer them to a central device; where a convex optimization process estimates the range by exploiting the sparse signal structure in the proposed correlation dictionary. Through theoretical validation, extensive empirical studies and experiments on an end-to-end acoustic ranging system implemented on resource limited off-the-shelf sensor nodes, we show that the proposed framework can achieve up to two orders of magnitude better performance compared to other approaches such as working on DCT domain and downsampling. Compared to the standard cross-correlation, it is able to obtain range estimates with a bias of 2-6 cm with 30 percent and approximately 100 cm with 5 percent compressed measurements. Its structured sparsity model is able to improve the ranging accuracy by 40 percent under challenging recovery conditions (such as high compression factor and low signal-to-noise ratio) by overcoming limitations due to dictionary coherence.},
  archiveprefix = {arXiv},
  arxivid       = {1501.06473},
  doi           = {10.1109/TMC.2016.2605689},
  eprint        = {1501.06473},
  keywords      = {Ranging, compressed sensing, cross-correlation, location sensing, positioning, sparse approximation, structured sparsity, ℓ1-norm minimization},
}

@Article{Xiao2018,
  author        = {Xiao, Lin and Liao, Bolin and Li, Shuai and Zhang, Zhijun and Ding, Lei and Jin, Long},
  journal       = {IEEE Transactions on Industrial Informatics},
  title         = {{Design and Analysis of FTZNN Applied to the Real-Time Solution of a Nonstationary Lyapunov Equation and Tracking Control of a Wheeled Mobile Manipulator}},
  year          = {2018},
  issn          = {15513203},
  month         = {jan},
  number        = {1},
  pages         = {98--105},
  volume        = {14},
  abstract      = {The Lyapunov equation is widely employed in the engineering field to analyze stability of dynamic systems. In this paper, based on a new evolution formula, a novel finite-time recurrent neural network (termed finite-time Zhang neural network, FTZNN) is proposed and studied for solving a nonstationary Lyapunov equation. In comparison with the original Zhang neural network (ZNN) model for a nonstationary Lyapunov equation, the convergence performance has a remarkable improvement for the proposed FTZNN model and can be accelerated to finite time. Besides, by solving the differential inequality, the time upper bound of the FTZNN model is computed theoretically and analytically. Simulations are conducted and compared to validate the superiority of the FTZNN model to the original ZNN model for solving the nonstationary Lyapunov equation. At last, the FTZNN model is successfully applied to online tracking control of a wheeled mobile manipulator.},
  doi           = {10.1109/TII.2017.2717020},
  keywords      = {Finite-time convergence, Folder - solving_linear_systems, Zhang neural network (ZNN), nonstationary Lyapunov equation, tracking control, upper bound, wheeled mobile manipulator},
  language      = {en},
  mendeley-tags = {Folder - solving_linear_systems},
  url           = {https://ieeexplore.ieee.org/document/7953678/},
}

@article{Capon1969,
abstract = {The output of an array of sensors is considered to be a homogeneous random field. In this case there is a spectral representation for this field, similar to that for stationary random processes, which consists of a superposition of traveling waves. The frequency-wavenumber power spectral density provides the mean-square value for the amplitudes of these waves and is of considerable importance in the analysis of propagating waves by means of an array of sensors. The conventional method of frequency-wavenumber power spectral density estimation uses a fixed wavenumber window and its resolution is determined esserytially by/the beam pattern of the array of sensors. A high-resolution method. of estimation is introduced which employs a wavenumber window whose shape changes and is a function of the wavenumber at which an estimate is obtained. It is shown that the wavenumber resolution of this method is considerably better than that of the conventional method. Application of these results is given to seismic data obtained from the large aperture seismic array located in eastern Montana In addition, the application of the high-resolution method to otherareas such as radar, sonar, and radio astronomy, is indicated. Copyright {\textcopyright} 1969 by The Institute of Electrical and Electronics Engineers, Inc.},
author = {Capon, J.},
doi = {10.1109/PROC.1969.7278},
issn = {15582256},
journal = {Proceedings of the IEEE},
keywords = {Folder - Adaptive beamforming},
mendeley-tags = {Folder - Adaptive beamforming},
number = {8},
pages = {1408--1418},
title = {{High-Resolution Frequency-Wavenumber Spectrum Analysis}},
volume = {57},
year = {1969}
}

@article{Pisarenko1972,
abstract = {The estimation of spectra of random stationary processes is an important part of the statistics of random processes. There are several books on spectral analysis, e.g. Blackman & Tukey, Hannan, and Jenkins & Watts. As a rule, spectral estimators are quadratic functions of the realizations. Recently Capon suggested a new method for estimation of spectra of random fields, in which a non‐quadratic function of the realization is used: he considered a homogeneous random field $\zeta$(t,x1,x2), i.e. one which is stationary in time and space and a random function of the time and space co‐ordinates t, x1, x2. For the sake of expository convenience we shall consider ordinary stationary processes of time only, $\zeta$(t); the generalization of our results to the case of random fields is easy. Comparison of the conventional spectral estimator and the ‘high‐resolution' estimator for an artificial example showed that the latter has less smoothing effect on the true spectrum (Capon). This was later confirmed by examples using real data (Capon). However, it was not clear whether for a finite realization the high‐resolution estimator distorted the true spectrum, i.e. whether it behaved for example like a conventional estimator raised to some power. In the present paper we introduce and study a new class of spectral estimators which are generally non‐linear and non‐quadratic functionals of the realizations. These estimators include the conventional and high‐resolution ones, for which we shall give the approximate distributions. We derive under rather general conditions the limiting distribution of the new class of estimators, and illustrate them with several examples. As a matter of fact, these new estimators are weighted means of the eigenvalues of the covariance matrix, e.g. the arithmetic mean, geometric mean, and so on. Copyright {\textcopyright} 1972, Wiley Blackwell. All rights reserved},
author = {Pisarenko, V. F.},
doi = {10.1111/j.1365-246X.1972.tb06146.x},
issn = {1365246X},
journal = {Geophysical Journal of the Royal Astronomical Society},
language = {en},
month = {jun},
number = {5},
pages = {511--531},
title = {{On the Estimation of Spectra by Means of Non‐linear Functions of the Covariance Matrix}},
url = {https://academic.oup.com/gji/article-lookup/doi/10.1111/j.1365-246X.1972.tb06146.x},
volume = {28},
year = {1972}
}

@article{Deane1997,
abstract = {A clear, extensively illustrated treatment of ultrasound systems used in estimating blood velocities.},
author = {Deane, Colin},
doi = {10.1016/s1350-4533(97)88564-5},
issn = {13504533},
journal = {Medical Engineering & Physics},
number = {2},
pages = {200},
publisher = {Cambridge University Press},
title = {{Estimation of blood velocities using ultrasound: a signal processing approach}},
volume = {19},
year = {1997}
}

@Misc{Goh2019,
  author        = {Goh, Hwan and Sheriffdeen, Sheroze and Bui-Thanh, Tan},
  month         = {jan},
  title         = {{Solving forward and inverse problems using autoencoders}},
  year          = {2019},
  abstract      = {This work develops a model-aware autoencoder networks as a new method for solving scientific forward and inverse problems. Autoencoders are unsupervised neural networks that are able to learn new representations of data through appropriately selected architecture and regularization. The resulting mappings to and from the latent representation can be used to encode and decode the data. In our work, we set the data space to be the parameter space of a parameter of interest we wish to invert for. Further, as a way to encode the underlying physical model into the autoencoder, we enforce the latent space of an autoencoder to be the space of observations of physically-governed phenomena. In doing so, we leverage the well known capability of a deep neural network as a universal function approximator to simultaneously obtain both the parameter-to-observation and observation-to-parameter map. The results suggest that this simultaneous learning interacts synergistically to improve the inversion capability of the autoencoder.},
  booktitle     = {arXiv},
  issn          = {23318422},
  keywords      = {Computer Science - Machine Learning, Electrical Engineering and Systems Science - Image, Statistics - Machine Learning},
  language      = {en},
  mendeley-tags = {Computer Science - Machine Learning,Electrical Engineering and Systems Science - Image,Statistics - Machine Learning},
  url           = {http://arxiv.org/abs/1912.04212},
}

@inproceedings{Guenther2007,
abstract = {In the first part of this work, we introduced a novel general ultrasound apodization design method using constrained least squares (CLS). The technique allows for the design of system spatial impulse responses with narrow mainlobes and low sidelobes. In the linear constrained least squares (LCLS) formulation, the energy of the point spread function (PSF) outside a certain mainlobe boundary was minimized while maintaining a peak gain at the focus. In the quadratic constrained least squares (QCLS) formulation, the energy of the PSF outside a certain boundary was minimized, and the energy of the PSF inside the boundary was held constant. In this paper, we present simulation results that demonstrate the application of the CLS methods to obtain optimal system responses. We investigate the stability of the CLS apodization design methods with respect to errors in the assumed wave propagation speed. We also present simulation results that implement the CLS design techniques to improve cystic resolution. According to novel performance metrics, our apodization profiles improve cystic resolution by 3 dB to 10 dB over conventional apodizations such as the fiat, Hamming, and Nuttall windows. We also show results using the CLS techniques to improve conventional depth of field (DOF). {\textcopyright} 2007 IEEE.},
author = {Guenther, Drake A. and Walker, William F.},
booktitle = {IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
doi = {10.1109/TUFFC.2007.248},
issn = {08853010},
number = {2},
pages = {343--358},
pmid = {17328331},
title = {{Optimal apodization design for medical ultrasound using constrained least squares Part II: Simulation results}},
volume = {54},
year = {2007}
}

@inproceedings{Birchfield2015,
abstract = {Recent advances in acoustic localization have combined the advantages of the traditional methods of beamforming and time-delay estimation, leading to techniques that are both accurate and fast. We present a unifying framework that reveals the relationships between beamforming, time-delay estimation, Bayesian formulation, hemisphere sampling, and accumulated correlation. We then experimentally compare the algorithms, on both compact and distributed microphone arrays, showing that the recent technique of accumulated correlation, although much less computationally expensive, exhibits performance comparable to that of beamforming.},
author = {Birchfield, Stanley T.},
booktitle = {European Signal Processing Conference},
isbn = {9783200001657},
issn = {22195491},
keywords = {Folder - BSS and acoustic source localization},
mendeley-tags = {Folder - BSS and acoustic source localization},
number = {September},
pages = {1127--1130},
title = {{A unifying framework for acoustic localization}},
volume = {06-10-Sept},
year = {2015}
}

@Article{Wang2005,
  author        = {Wang, Zhisong and Li, Jian and Wu, Renbiao},
  journal       = {IEEE Transactions on Medical Imaging},
  title         = {{Time-delay- And time-reversal-based robust Capon beamformers for ultrasound imaging}},
  year          = {2005},
  issn          = {02780062},
  number        = {10},
  pages         = {1308--1322},
  volume        = {24},
  abstract      = {Currently, the nonadaptive delay-and-sum (DAS) beamformer is extensively used for ultrasound imaging, despite the fact that it has lower resolution and worse interference suppression capability than the adaptive standard Capon beamformer (SCB) if the steering vector corresponding to the signal of interest (SOI) is accurately known. The main problem which restricts the use of SCB, however, is that SCB lacks robustness against steering vector errors that are inevitable in practice. Whenever this happens, the performance of SCB may become worse than that of DAS. Therefore, a robust adaptive beamformer is desirable to maintain the robustness of DAS and adaptivity of SCB. In this paper we consider a recent promising robust Capon beamformer (RCB) for ultrasound imaging. We propose two ways of implementing RCB, one based on time delay and the other based on time reversal. RCB extends SCB by allowing the array steering vector to be within an uncertainty set. Hence, it restores the appeal of SCB including its high resolution and superb interference suppression capabilities, and also retains the attractiveness of DAS including its robustness against steering vector errors. The time-delay-based RCB can tolerate the misalignment of data samples and the time-reversal-based RCB can withstand the uncertainty of the Green's function. Both time-delay-based RCB and time-reversal-based RCB can be efficiently computed at a comparable cost to SCB. The excellent performances of the proposed robust adaptive beamforming approaches are demonstrated via a number of simulated and experimental examples. {\textcopyright} 2005 IEEE.},
  doi           = {10.1109/TMI.2005.857222},
  keywords      = {Adaptive arrays, Array errors, Folder - Adaptive beamforming, Interference suppression, Robust Capon beamforming, Robust adaptive beamforming, Time delay, Time reversal, Ultrasound imaging},
  mendeley-tags = {Adaptive arrays,Array errors,Folder - Adaptive beamforming,Interference suppression,Robust Capon beamforming,Robust adaptive beamforming,Time delay,Time reversal,Ultrasound imaging},
  pmid          = {16229417},
}

@InProceedings{Synnevaag2005,
  author        = {Synnev{\aa}g, Johan Fredrik and Austeng, Andreas and Holm, Sverre},
  booktitle     = {Proceedings - IEEE Ultrasonics Symposium},
  title         = {{Minimum variance adaptive beamforming applied to medical ultrasound imaging}},
  year          = {2005},
  number        = {4},
  pages         = {1199--1202},
  volume        = {2},
  abstract      = {We have applied the minimum variance beam-former to medical ultrasound imaging and shown significant improvement in image quality compared to delay-and-sum. Reduced mainlobe width and suppression of sidelobes is demonstrated on both simulated and experimental RF data of closely spaced wire targets, resulting in increased resolution and contrast. The method has been applied to experimental RF data from a heart-phantom, demonstrating improved definition of the ventricular walls. We have evaluated the beamformers sensitivity to velocity errors and shown that reliable amplitude estimates are achieved if proper regularization is applied. {\textcopyright} 2005 IEEE.},
  doi           = {10.1109/ULTSYM.2005.1603066},
  isbn          = {0780393821},
  issn          = {10510117},
  keywords      = {Folder - Adaptive beamforming},
  mendeley-tags = {Folder - Adaptive beamforming},
  url           = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1603066},
}

@Article{Madsen1998,
  author        = {Madsen, Ernest L. and Frank, Gary R. and Dong, Fang},
  journal       = {Ultrasound in Medicine and Biology},
  title         = {{Liquid or solid ultrasonically tissue-mimicking materials with very low scatter}},
  year          = {1998},
  issn          = {03015629},
  number        = {4},
  pages         = {535--542},
  volume        = {24},
  abstract      = {A new tissue-mimicking material for ultrasound, using evaporated milk as the primary absorption component, is described. It has very low backscatter but still exhibits the 1540 m s-1 propagation speed and proportionality of attenuation coefficient and frequency over the diagnostic frequency range. The material can be produced in solid or liquid form with attenuation coefficient slopes spanning the range 0.1-0.7 dB cm-1 MHz-1. The liquid form is useful in phantoms where detailed beam patterns are to be determined, either involving translation of measurement devices in the liquid or phantoms with fibers present for causing the only detectable echoes. In the latter case, the liquid quality allows removal of liquid with one attenuation coefficient slope and replacement with another. The solid form may be more useful than the liquid for two reasons. First, many simulated lesions (including ones that produce essentially no internal echoes) can lie in the scan slice with positions extending over the entire image area without enhancement or shadowing effects being of concern. Second, the lack of significant backscatter from the material in the absence of added scatterers allows the backscatter coefficient to be varied over a considerable range. A critical result is that intrinsic material contrast between targets and surroundings can be accurately predicted in terms of the concentrations of added scatterers and, assuming all scatterers are of the same type, the contrast will be completely independent of frequency. Use of the fungicide thimerosal eliminates deterioration, and ultrasonic properties have been shown to be stable over 2.5 years.},
  doi           = {10.1016/S0301-5629(98)00013-1},
  keywords      = {Folder - General US, Low echo, Low scatter, Phantoms, Tissue-mimicking, Ultrasound imaging},
  mendeley-tags = {Folder - General US,Low echo,Low scatter,Phantoms,Tissue-mimicking,Ultrasound imaging},
  pmid          = {9651963},
}

@inproceedings{Byram2015,
abstract = {Image quality continues to be a challenge for medical ultrasound. Recent evidence implicates wavefront distortion from sound speed inhomogeneity and reverberation. To target the reverberation problem, we developed an algorithm called Aperture Domain Model Image REconstruction (ADMIRE). ADMIRE explicitly models, identifies and suppresses acoustic clutter resulting from multipath or off-axis scattering. Also because multipath scattering can be hard to study, we introduce a new method for obtaining pulse-echo measures of reverberation from ex vivo tissue samples. We demonstrate that ADMIRE improves contrast and CNR by 7.1±2.5 dB and 0.86±0.92 dB, respectively. We also apply ADMIRE to multipath scattering from a porcine abdominal wall layer and show that we can reduce the relative clutter level by 13 dB compared to standard beamforming.},
author = {Byram, Brett and Shu, Jasmine and Dei, Kazuyuki},
booktitle = {2015 IEEE International Ultrasonics Symposium, IUS 2015},
doi = {10.1109/ULTSYM.2015.0174},
isbn = {9781479981823},
pages = {1--6},
publisher = {IEEe},
title = {{Nonlinear beamforming of aperture domain signals}},
year = {2015}
}

@Misc{Zhou2018,
  author        = {Zhou, Jie and Cui, Ganqu and Zhang, Zhengyan and Yang, Cheng and Liu, Zhiyuan and Wang, Lifeng and Li, Changcheng and Sun, Maosong},
  month         = {jul},
  title         = {{Graph Neural Networks: A Review of Methods and Applications}},
  year          = {2018},
  abstract      = {—Lots of learning tasks require dealing with graph data which contains rich relation information among elements. Modeling physics system, learning molecular fingerprints, predicting protein interface, and classifying diseases require a model to learn from graph inputs. In other domains such as learning from non-structural data like texts and images, reasoning on extracted structures, like the dependency tree of sentences and the scene graph of images, is an important research topic which also needs graph reasoning models. Graph neural networks (GNNs) are connectionist models that capture the dependence of graphs via message passing between the nodes of graphs. Unlike standard neural networks, graph neural networks retain a state that can represent information from its neighborhood with arbitrary depth. Although the primitive GNNs have been found difficult to train for a fixed point, recent advances in network architectures, optimization techniques, and parallel computation have enabled successful learning with them. In recent years, systems based on variants of graph neural networks such as graph convolutional network (GCN), graph attention network (GAT), gated graph neural network (GGNN) have demonstrated ground-breaking performance on many tasks mentioned above. In this survey, we provide a detailed review over existing graph neural network models, systematically categorize the applications, and propose four open problems for future research.},
  archiveprefix = {arXiv},
  arxivid       = {1812.08434},
  booktitle     = {arXiv},
  eprint        = {1812.08434},
  issn          = {23318422},
  keywords      = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Deep Learning, Graph Neural Network, Statistics - Machine Learning},
  language      = {en},
  mendeley-tags = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Statistics - Machine Learning},
  shorttitle    = {Graph Neural Networks},
  url           = {http://arxiv.org/abs/1812.08434},
}

@article{Lu2000,
abstract = {Limited diffraction beams such as X waves can propagate to an infinite distance without spreading if they are produced with an infinite aperture and energy. In practice, when the aperture and energy are finite, these beams have a large depth of field with only limited diffraction. Because of this property, limited diffraction beams could have applications in medical imaging, tissue characterization, blood flow velocity vector imaging, nondestructive evaluation (NDE) of materials, communications, and other areas such as optics and electromagnetics. In this paper, a new transform, called X wave transform, is developed. In the transform, any well behaved solutions to the isotropic-homogeneous wave equation or limited diffraction beams can be expanded using X waves as basis functions. The coefficients of the expansions can be calculated with the properties that X waves are orthogonal. Examples are given to demonstrate the efficacy of the X wave transform. The X wave transform reveals an intrinsic relationship between any well behaved solutions to the wave equation and X waves, including limited diffraction beams. This provides a theoretical foundation to develop new limited diffraction beams or solutions to the wave equation that may have practical usefulness. {\textcopyright} 2000 IERE.},
author = {Lu, Jian Yu},
doi = {10.1109/58.883537},
issn = {08853010},
journal = {IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
language = {en},
month = {nov},
number = {6},
pages = {1472--1481},
title = {{An X wave transform}},
url = {http://ieeexplore.ieee.org/document/883537/},
volume = {47},
year = {2000}
}

@article{Stanziola2019,
author = {Stanziola, Antonio},
language = {en},
pages = {128},
title = {{Advanced Beamforming for High Frame Rate Ultrasound Vascular Imaging}},
year = {2019}
}

@Article{Jagtap2020,
  author        = {Jagtap, Ameya D. and Kawaguchi, Kenji and Karniadakis, George Em},
  journal       = {Journal of Computational Physics},
  title         = {{Adaptive activation functions accelerate convergence in deep and physics-informed neural networks}},
  year          = {2020},
  issn          = {10902716},
  month         = {mar},
  pages         = {109136},
  volume        = {404},
  abstract      = {We employ adaptive activation functions for regression in deep and physics-informed neural networks (PINNs) to approximate smooth and discontinuous functions as well as solutions of linear and nonlinear partial differential equations. In particular, we solve the nonlinear Klein-Gordon equation, which has smooth solutions, the nonlinear Burgers equation, which can admit high gradient solutions, and the Helmholtz equation. We introduce a scalable hyper-parameter in the activation function, which can be optimized to achieve best performance of the network as it changes dynamically the topology of the loss function involved in the optimization process. The adaptive activation function has better learning capabilities than the traditional one (fixed activation) as it improves greatly the convergence rate, especially at early training, as well as the solution accuracy. To better understand the learning process, we plot the neural network solution in the frequency domain to examine how the network captures successively different frequency bands present in the solution. We consider both forward problems, where the approximate solutions are obtained, as well as inverse problems, where parameters involved in the governing equation are identified. Our simulation results show that the proposed method is a very simple and effective approach to increase the efficiency, robustness and accuracy of the neural network approximation of nonlinear functions as well as solutions of partial differential equations, especially for forward problems. We theoretically prove that in the proposed method, gradient descent algorithms are not attracted to suboptimal critical points or local minima. Furthermore, the proposed adaptive activation functions are shown to accelerate the minimization process of the loss values in standard deep learning benchmarks using CIFAR-10, CIFAR-100, SVHN, MNIST, KMNIST, Fashion-MNIST, and Semeion datasets with and without data augmentation.},
  archiveprefix = {arXiv},
  arxivid       = {1906.01170},
  doi           = {10.1016/j.jcp.2019.109136},
  eprint        = {1906.01170},
  keywords      = {Bad minima, Deep learning benchmarks, Inverse problems, Machine learning, Partial differential equations, Physics-informed neural networks},
  language      = {en},
  url           = {https://linkinghub.elsevier.com/retrieve/pii/S0021999119308411},
}

@Article{Stanimirovic2018,
  author        = {Stanimirovi{\'{c}}, Predrag S. and Petkovi{\'{c}}, Marko D.},
  journal       = {Neurocomputing},
  title         = {{Gradient neural dynamics for solving matrix equations and their applications}},
  year          = {2018},
  issn          = {18728286},
  month         = {sep},
  pages         = {200--212},
  volume        = {306},
  abstract      = {We are concerned with the solution of the matrix equation AXB=D in real time by means of the gradient based neural network (GNN) model, called GNN(A, B, D). The convergence analysis shows that the result of global asymptotic convergence is determined by the choice of the initial state and coincides with the general solution of the matrix equation AXB=D. Several applications of the GNN(A, B, D) model in online approximation of various inner and outer inverses with prescribed range and/or null space are considered. An appropriate adaptation of proposed models for finding an online solution of a set of linear equations Ax=b is defined and investigated. The influence of various nonlinear activation functions on the convergence of GNN(A, B, D) is investigated both theoretically as well as using computer-simulation results.},
  doi           = {10.1016/j.neucom.2018.03.058},
  keywords      = {Activation function, Drazin inverse, Dynamic equation, Folder - solving_linear_systems, Matrix equation, Moore–Penrose inverse, Recurrent neural network},
  language      = {en},
  mendeley-tags = {Folder - solving_linear_systems},
  url           = {https://linkinghub.elsevier.com/retrieve/pii/S0925231218304521},
}

@Misc{Siahkoohi2020,
  author        = {Siahkoohi, Ali and Rizzuti, Gabrio and Herrmann, Felix J.},
  month         = {jan},
  title         = {{A deep-learning based Bayesian approach to seismic imaging and uncertainty quantification}},
  year          = {2020},
  abstract      = {Uncertainty quantification is essential when dealing with ill-conditioned inverse problems due to the inherent nonuniqueness of the solution. Bayesian approaches allow us to determine how likely an estimation of the unknown parameters is via formulating the posterior distribution. Unfortunately, it is often not possible to formulate a prior distribution that precisely encodes our prior knowledge about the unknown. Furthermore, adherence to handcrafted priors may greatly bias the outcome of the Bayesian analysis. To address this issue, we propose to use the functional form of a randomly initialized convolutional neural network as an implicit structured prior, which is shown to promote natural images and excludes images with unnatural noise. In order to incorporate the model uncertainty into the final estimate, we sample the posterior distribution using stochastic gradient Langevin dynamics and perform Bayesian model averaging on the obtained samples. Our synthetic numerical experiment verifies that deep priors combined with Bayesian model averaging are able to partially circumvent imaging artifacts and reduce the risk of overfitting in the presence of extreme noise. Finally, we present pointwise variance of the estimates as a measure of uncertainty, which coincides with regions that are more difficult to image.},
  archiveprefix = {arXiv},
  arxivid       = {2001.04567},
  booktitle     = {arXiv},
  doi           = {10.3997/2214-4609.202010770},
  eprint        = {2001.04567},
  issn          = {23318422},
  keywords      = {Computer Science - Machine Learning, Physics - Geophysics, Statistics - Machine Learning},
  language      = {en},
  mendeley-tags = {Computer Science - Machine Learning,Physics - Geophysics,Statistics - Machine Learning},
  url           = {http://arxiv.org/abs/2001.04567},
}

@Article{Bang2003,
  author        = {Bang, Jon and Dahl, Torbj{\o}rn and Bruinsma, Annemarieke and Kaspersen, Jon Harald and Hernes, Toril A.Nagelhus and Myhre, Hans Olav},
  journal       = {Ultrasound in Medicine and Biology},
  title         = {{A new method for analysis of motion of carotid plaques from RF ultrasound images}},
  year          = {2003},
  issn          = {03015629},
  number        = {7},
  pages         = {967--976},
  volume        = {29},
  abstract      = {Motion of carotid artery plaques during the cardiac cycle may contribute to plaque disruption and embolism. We have developed a computerized method that objectively analyzes such motion from a sequence of ultrasound (US) radiofrequency (RF) images. A displacement vector map is obtained by 2-D correlation of local areas in consecutive images. From this map, motion dynamics can be quantified and presented as function of time, spatial (image) coordinates or as single numbers. Correct functionality has been verified on laboratory data. Applied to patient data, the method gives temporal results that correlate well with ECG data and the calculated peak systolic velocities of typically 10 mm/s agree well with values reported in the literature. The spatial analysis demonstrates that different plaque regions may exhibit different motion patterns that may cause internal stress, leading to fissures and plaque disruption. Thus, the motion analysis method may provide new and important information about the plaque characteristics and the prospective risk of cerebrovascular events. {\textcopyright} 2003 World Federation for Ultrasound in Medicine & Biology.},
  doi           = {10.1016/S0301-5629(03)00904-9},
  keywords      = {*atherosclerotic plaque, *echography, Carotid artery stenosis, Embolism, Motion dynamics, Plaque characterization, Ultrasonography, adult, aged, analytic method, article, blood flow velocity, cardiovascular risk, carotid artery, carotid artery obstruction, cerebrovascular accident, clinical article, computer, controlled study, correlation analysis, electrocardiogram, electrocardiography, female, human, image analysis, male, priority journal, risk, risk assessment, systole},
  mendeley-tags = {*atherosclerotic plaque,*echography,adult,aged,analytic method,article,blood flow velocity,cardiovascular risk,carotid artery,carotid artery obstruction,cerebrovascular accident,clinical article,computer,controlled study,correlation analysis,electrocardiogram,electrocardiography,female,human,image analysis,male,priority journal,risk,risk assessment,systole},
  pmid          = {12878242},
  url           = {http://ovidsp.ovid.com/ovidweb.cgi?T=JS&PAGE=reference&D=emed6&NEWS=N&AN=2003293428},
}

@Article{Bach2011,
  author        = {Bach, Francis and Jenatton, Rodolphe and Mairal, Julien and Obozinski, Guillaume},
  journal       = {Foundations and Trends in Machine Learning},
  title         = {{Optimization with sparsity-inducing penalties}},
  year          = {2011},
  issn          = {19358237},
  month         = {aug},
  number        = {1},
  pages         = {1--106},
  volume        = {4},
  abstract      = {Sparse estimation methods are aimed at using or obtaining parsimonious representations of data or models. They were first dedicated to linear variable selection but numerous extensions have now emerged such as structured sparsity or kernel selection. It turns out that many of the related estimation problems can be cast as convex optimization problems by regularizing the empirical risk with appropriate nonsmooth norms. The goal of this monograph is to present from a general perspective optimization tools and techniques dedicated to such sparsity-inducing penalties. We cover proximal methods, block-coordinate descent, reweighted ℓ2-penalized techniques, workingset and homotopy methods, as well as non-convex formulations and extensions, and provide an extensive set of experiments to compare various algorithms from a computational point of view. {\textcopyright} 2012 F. Bach, R. Jenatton, J. Mairal.},
  archiveprefix = {arXiv},
  arxivid       = {1108.0775},
  doi           = {10.1561/2200000015},
  eprint        = {1108.0775},
  keywords      = {Computer Science - Machine Learning, Folder - Compressed Sensing, Mathematics - Optimization and Control, Statistics - Machine Learning},
  language      = {en},
  mendeley-tags = {Computer Science - Machine Learning,Folder - Compressed Sensing,Mathematics - Optimization and Control,Statistics - Machine Learning},
  url           = {http://arxiv.org/abs/1108.0775},
}

@article{PINTO2010,
author = {PINTO, Francisco PEREIRA CORREIA},
journal = {{\'{E}}COLE POLYTECHNIQUE F{\'{E}}D{\'{E}}RALE DE LAUSANNE},
keywords = {Folder - Generic Signal Processing},
mendeley-tags = {Folder - Generic Signal Processing},
title = {{Signal Processing in Space and Time - A Multidimensional Fourier Approach [PhD Thesis]}},
volume = {4871},
year = {2010}
}

@Misc{LezcanoCasado2019,
  author    = {Lezcano-Casado, Mario and Mart{\'{i}}nez-Rubio, David},
  title     = {{Cheap orthogonal constraints in neural networks: A simple parametrization of the orthogonal and unitary group}},
  year      = {2019},
  abstract  = {We introduce a novel approach to perform firstorder optimization with orthogonal and unitary constraints. This approach is based on a parametrization stemming from Lie group theory through the exponential map. The parametrization transforms the constrained optimization problem into an unconstrained one over a Euclidean space, for which common first-order optimization methods can be used. The theoretical results presented are general enough to cover the special orthogonal group, the unitary group and, in general, any connected compact Lie group. We discuss how this and other parametrizations can be computed efficiently through an implementation trick, making numerically complex parametrizations usable at a negligible runtime cost in neural networks. In particular, we apply our results to RNNs with orthogonal recurrent weights, yielding a new architecture called EXPRNN. We demonstrate how our method constitutes a more robust approach to optimization with orthogonal constraints, showing faster, accurate, and more stable convergence in several tasks designed to test RNNs.},
  booktitle = {arXiv},
  issn      = {23318422},
  language  = {en},
  pages     = {10},
}

@Article{Nikolov2000a,
  author        = {Nikolov, Svetoslav Ivanov and Jensen, J{\o}rgen Arendt},
  journal       = {Ultrasonics},
  title         = {{Application of different spatial sampling patterns for sparse array transducer design}},
  year          = {2000},
  issn          = {0041624X},
  number        = {10},
  pages         = {667--671},
  volume        = {37},
  abstract      = {In the last few years, the efforts of many researchers have been focused on developing 3D real-time scanners. The use of 2D phased-array transducers makes it possible to steer the ultrasonic beam in all directions in the scanned volume. An unacceptably large amount of transducer channels (more than 4000) must be used, if the conventional phased array transducers are extrapolated to the 2D case. To decrease the number of channels, sparse arrays with different aperture apodization functions in transmit and receive apertures have to be designed. The design is usually carried out in 1D, and then transferred to a 2D rectangular grid. In this paper, five different 2D array transducers have been considered and their performance was compared with respect to spatial and contrast resolution. An optimization of the element placement along the diagonals using vernier arrays is suggested. The simulation results of the ultrasound fields show a decrease in the grating-lobe level of 10 dB for the diagonally optimized 2D array transducers compared to the previously designed 2D arrays which did not consider the diagonals.},
  doi           = {10.1016/S0041-624X(00)00013-5},
  keywords      = {Folder - Beamforming special, array, s, sparse, transducer, two-dimensional},
  mendeley-tags = {Folder - Beamforming special,array,s,sparse,transducer,two-dimensional},
  pmid          = {10950348},
}

@InProceedings{MohammadzadehAsl2009,
  author        = {{Mohammadzadeh Asl}, Babak and Mahloojifar, Ali},
  booktitle     = {Proceedings - IEEE Ultrasonics Symposium},
  title         = {{Contrast enhancement of adaptive ultrasound imaging using eigenspace-based minimum variance beamfoming}},
  year          = {2009},
  pages         = {349--352},
  abstract      = {Recently, adaptive beamforming methods have been successfully applied to medical ultrasound imaging, resulting in significant improvement in image quality compared to nonadaptive delay-and-sum (DAS) beamformer. Most of the adaptive beamformers presented in the ultrasound imaging literature are based on the minimum variance (MV) beamformer which can improve the imaging resolution while retaining the contrast. The main objective of this research is to present a beamformer which could improve the imaging resolution and contrast, at the same time. In this paper, we have applied the eigenspacebased MV (EIBMV) beamformer to medical ultrasound imaging and shown the simultaneous improvement in imaging resolution and contrast. EIBMV beamformer utilizes the eigenstructure of the covariance matrix to enhance the performance of the MV beamformer. The weight vector of the EIBMV is found by projecting the obtained MV weight vector onto a vector subspace constructed from the eigenstructure of the covariance matrix. EIBMV beamformer shows a significant reduction in the sidelobe levels while representing the same mainlobe width as the MV. Specifically, in the point targets phantom, the proposed method decreases the sidelobes about 22 dB and 29 dB compared to MV and DAS, respectively. Furthermore, the proposed method increases the contrast of simulated cyst phantom about 8.6 dB and 14.1 dB and also improves the contrast-to-noise ratio about 31% and 61%, compared to MV and DAS, respectively. {\textcopyright}2009 IEEE.},
  doi           = {10.1109/ULTSYM.2009.5442051},
  isbn          = {9781424443895},
  issn          = {10510117},
  keywords      = {Adaptive beamforming, Folder - Adaptive beamforming, contrast enhancement, eigenspace-based minimum variance beamforming, ultrasound imaging},
  mendeley-tags = {Adaptive beamforming,Folder - Adaptive beamforming,contrast enhancement,eigenspace-based minimum variance beamforming,ultrasound imaging},
}

@Article{Montaldo2009,
  author        = {Montaldo, Gabriel and Tanter, Micka{\"{e}}l and Bercoff, J{\'{e}}r{\'{e}}my and Benech, Nicolas and Fink, Mathias},
  journal       = {IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
  title         = {{Coherent plane-wave compounding for very high frame rate ultrasonography and transient elastography}},
  year          = {2009},
  issn          = {08853010},
  number        = {3},
  pages         = {489--506},
  volume        = {56},
  abstract      = {The emergence of ultrafast frame rates in ultrasonic imaging has been recently made possible by the development of new imaging modalities such as transient elastography. Data acquisition rates reaching more than thousands of images per second enable the real-time visualization of shear mechanical waves propagating in biological tissues, which convey information about local viscoelastic properties of tissues. The first proposed approach for reaching such ultrafast frame rates consists of transmitting plane waves into the medium. However, because the beamforming process is then restricted to the receive mode, the echographic images obtained in the ultrafast mode suffer from a low quality in terms of resolution and contrast and affect the robustness of the transient elastography mode. It is here proposed to improve the beamforming process by using a coherent recombination of compounded plane-wave transmissions to recover high-quality echographic images without degrading the high frame rate capabilities. A theoretical model is derived for the comparison between the proposed method and the conventional B-mode imaging in terms of contrast, signal-to-noise ratio, and resolution. Our model predicts that a significantly smaller number of insonifications, 10 times lower, is sufficient to reach an image quality comparable to conventional B-mode. Theoretical predictions are confirmed by in vitro experiments performed in tissue-mimicking phantoms. Such results raise the appeal of coherent compounds for use with standard imaging modes such as B-mode or color flow. Moreover, in the context of transient elastography, ultrafast frame rates can be preserved while increasing the image quality compared with flat insonifications. Improvements on the transient elastography mode are presented and discussed. {\textcopyright} 2006 IEEE.},
  doi           = {10.1109/TUFFC.2009.1067},
  keywords      = {Algorithms, Array signal processing, Biological tissues, Computer-Assisted, Data acquisition, Data visualization, Elasticity, Elasticity Imaging Techniques, Female, Folder - HFR US, Humans, Image Enhancement, Image quality, Image resolution, Mammary, Models, Signal Processing, Statistical, Theoretical, Ultrasonic imaging, Ultrasonography, Viscosity, beamforming process, biological tissues, biomedical ultrasonics, coherent plane-wave compounding, coherent recombination, compounded plane-wave transmissions, conventional B-mode imaging, echographic images, insonifications, phantoms, tissue-mimicking phantoms, transient elastography, ultrafast frame, ultrasonography},
  mendeley-tags = {Algorithms,Array signal processing,Biological tissues,Computer-Assisted,Data acquisition,Data visualization,Elasticity,Elasticity Imaging Techniques,Female,Folder - HFR US,Humans,Image Enhancement,Image quality,Image resolution,Mammary,Models,Signal Processing,Statistical,Theoretical,Ultrasonic imaging,Ultrasonography,Viscosity,beamforming process,biological tissues,biomedical ultrasonics,coherent plane-wave compounding,coherent recombination,compounded plane-wave transmissions,conventional B-mode imaging,echographic images,insonifications,phantoms,tissue-mimicking phantoms,transient elastography,ultrafast frame,ultrasonography},
  pmid          = {19411209},
  url           = {http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=4816058},
}

@Misc{Mueller2019,
  author        = {M{\"{u}}ller, Johannes},
  month         = {jan},
  title         = {{Universal flow approximation with deep residual networks}},
  year          = {2019},
  abstract      = {Residual networks (ResNets) are a deep learning architecture that substantially improved the state of the art performance in certain supervised learning tasks (cf. [He et al., 2016]). Since then, they have received continuously growing attention. ResNets have a recursive structure xk+1 = xk + Rk(xk) where Rk is a neural network and the copying of the input xk is called a skip connection. This structure can be seen as the explicit Euler discretisation of an associated ordinary differential equation (ODE) and this inspired intensive research. However, all of those works only consider the connection of ResNets to a relatively small class of ODEs. We show that by simultaneously increasing the number of skip connection as well as the expressivity of the networks Rk the flow for an arbitrary right hand side f ∈ L1 ( I; Cb0,1(Rd; Rd) ) can be approximated uniformly by deep ReLU ResNets on compact sets. Further, we derive estimates on the number of parameters needed to do this up to a prescribed accuracy under temporal regularity assumptions. We also give a self-contained introduction to the preliminaries regarding neural networks and differential equations. Here, we give an elementary proof for a quantitative universal approximation theorem for deep ReLU networks and see that weak ODEs with right hand side in L1(I; Cb0,1(Rd; Rd)) are globally well posed. Finally, we discuss the possibility of using ResNets for diffeomorphic matching problems and propose some next steps in the theoretical foundation of this approach.},
  booktitle     = {arXiv},
  issn          = {23318422},
  keywords      = {Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computi, Mathematics - Numerical Analysis, Statistics - Machine Learning},
  language      = {en},
  mendeley-tags = {Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computi,Mathematics - Numerical Analysis,Statistics - Machine Learning},
  url           = {http://arxiv.org/abs/1910.09599},
}

@Misc{Bertsekas2017,
  author        = {Bertsekas, Dimitri P.},
  month         = {jan},
  title         = {{Proper Policies in Infinite-State Stochastic Shortest Path Problems}},
  year          = {2017},
  abstract      = {—We consider stochastic shortest path problems with infinite state and control spaces, a nonnegative cost per stage, and a termination state. We extend the notion of a proper policy, a policy that terminates within a finite expected number of steps, from the context of finite state space to the context of infinite state space. We consider the optimal cost function J∗, and the optimal cost function Ĵover just the proper policies. We show that J∗ and Ĵ are the smallest and largest solutions of Bellman's equation, respectively, within a suitable class of Lyapounov-like functions. If the cost per stage is bounded, these functions are those that are bounded over the effective domain of Ĵ. The standard value iteration algorithm may be attracted to either J∗ or Ĵ, depending on the initial condition. In the favorable case where J∗ = Ĵ, strong analytical and algorithmic results are obtained.},
  booktitle     = {arXiv},
  issn          = {23318422},
  keywords      = {Folder - RL and Dynamic Programming, Index Terms—Dynamic programming, Mathematics - Optimization and Control, Proper policies, Shortest path, Stochastic optimal control},
  language      = {en},
  mendeley-tags = {Folder - RL and Dynamic Programming,Mathematics - Optimization and Control},
  url           = {http://arxiv.org/abs/1711.10129},
}

@article{Selfridge1980,
abstract = {An important criterion in the design of transducer array elements for acoustic imaging is the angular response, or the far-field radiation pattern, of a single element. In this letter, we show that the widely accepted formula for the angular response function is inadequate and must be multiplied by cos. Good agreement with experiment is then obtained.},
author = {Selfridge, A. R. and Kino, G. S. and Khuri-Yakub, B. T.},
doi = {10.1063/1.91692},
issn = {00036951},
journal = {Applied Physics Letters},
month = {jul},
number = {1},
pages = {35--36},
title = {{A theory for the radiation pattern of a narrow-strip acoustic transducer}},
url = {https://aip.scitation.org/doi/abs/10.1063/1.91692},
volume = {37},
year = {1980}
}

@Article{Kodama2004,
  author        = {Kodama, Ichiro and Niida, Shumpei and Sanada, Mitsuhiro and Yoshiko, Yuji and Tsuda, Mikio and Maeda, Norihiko and Ohama, Koso},
  journal       = {Journal of Bone and Mineral Research},
  title         = {{Estrogen Regulates the Production of VEGF for Osteoclast Formation and Activity in op/op Mice}},
  year          = {2004},
  issn          = {08840431},
  number        = {2},
  pages         = {200--206},
  volume        = {19},
  abstract      = {op/op mice have a severe deficiency of osteoclasts because of lacking functional M-CSF that is an essential factor of osteoclast differentiation and function. We now report that OVX induces osteoclast formation and cures osteopetrosis by increasing the VEGF that regulates osteoclast formation in these mice. Introduction: We have found that estrogen deficiency induced by ovariectomy (OVX) upregulated osteoclast formation in op/op mice. We have recently demonstrated that vascular endothelial growth factor (VEGF) could substitute for macrophage colony-stimulating factor (M-CSF) in the support of osteoclastic bone resorption in these mice. Therefore, in this study, we wished to assess the effects of VEGF on bone loss induced by OVX in these mice. Materials and Methods: Eight-week-old op/op mice were bilateral OVX or sham-operated. Mice were killed at 8, 10, and 12 weeks of age, and femurs were removed for preparations. Some OVX mice were treated with three consecutive injections of 120 $\mu$l/body of VEGF-neutralizing antibody at 12-h intervals starting from 36 h before death at 4 weeks after OVX. VEGFR-1/Fc chimeric protein (600 $\mu$g/kg/day) or 17$\beta$-estradiol (0.16 $\mu$g/day) was administered in a dorsal subcutaneous pocket of the mice at the time of OVX. These mice were killed 2 weeks after surgery. Changes of serum levels of VEGF were measured by ELISA. Changes of mRNA levels of VEGF, Flt-1, interleukin-6, and osteoclast differentiation factor (ODF/TRANCE/RANKL) in bone tissue were measured by reverse transcriptase-polymerase chain reaction. Results: In OVX op/op mice, trabecular bone volume of the femur was decreased, and the number of osteoclasts was significantly increased. Serum levels of VEGF were demonstrated to be higher in OVX mice than in sham-operated mice. VEGF mRNA, Flt-1 mRNA, interleukin-6 mRNA, and RANKL mRNA levels in bone tissue were elevated in OVX mice over that in sham-operated mice. The increase in osteoclast number was inhibited by VEGF antagonist treatment in OVX mice. Conclusions: In this study, we have demonstrated that the production of VEGF and RANKL stimulated by OVX results in increased osteoclast formation in op/op mice.},
  doi           = {10.1359/JBMR.0301229},
  keywords      = {Bone resorption, Estrogen, Osteoclast, Osteopetrosis, Vascular endothelial growth factor, elastic net, lasso, logistic regression},
  mendeley-tags = {elastic net,lasso,logistic regression},
  pmid          = {14969389},
}

@inproceedings{Schiebinger2015,
abstract = {This paper provides a theoretical analysis of diffraction-limited superresolution, demonstrating that arbitrarily close point sources can be resolved in ideal situations. Precisely, we assume that the incoming signal is a linear combination of M shifted copies of a known waveform with unknown shifts and amplitudes, and one only observes a finite collection of evaluations of this signal. We characterize properties of the base waveform such that the exact translations and amplitudes can be recovered from 2M + 1 observations. This recovery is achieved by solving a a weighted version of basis pursuit over a continuous dictionary. Our methods combine classical polynomial interpolation techniques with contemporary tools from compressed sensing.},
author = {Schiebinger, Geoffrey and Robeva, Elina and Recht, Benjamin},
booktitle = {2015 IEEE 6th International Workshop on Computational Advances in Multi-Sensor Adaptive Processing, CAMSAP 2015},
doi = {10.1109/CAMSAP.2015.7383732},
isbn = {9781479919635},
pages = {45--48},
title = {{Superresolution without separation}},
year = {2015}
}

@article{Wagner1986,
abstract = {Second order statistics have been derived for the speckle in diagnostic ultrasound that arises from diffuse (incoherent) scattering in the presence of distributed and organized specular (coherent) scattering. They serve as the basis for a three-dimensional feature space in which tissue textures can be classified. The covariance matrix of the measurements in this space is a generalization of the speckle spot number or sampling concept that arises in the study of signal or lesion detectability.},
author = {Wagner, Robert F. and Insana, Michael F. and Brown, David G.},
doi = {10.1117/12.7973899},
issn = {0091-3286},
journal = {Optical Engineering},
number = {6},
pages = {256738},
title = {{Unified Approach To The Detection And Classification Of Speckle Texture In Diagnostic Ultrasound}},
url = {http://cat.inist.fr/?aModele=afficheN&cpsidt=8786306},
volume = {25},
year = {1986}
}

@book{Watanabe2014,
abstract = {Summary: In this book mathematical techniques for integral transforms are described in detail but concisely. The techniques are applied to the standard partial differential equations, such as the Laplace equation, the wave equation and elasticity equations. The Green's functions for beams, plates and acoustic media are also shown along with their mathematical derivations. Lists of Green's functions are presented for the future use. The Cagniard's-de Hoop method for the double inversion is described in detail, and 2D and 3D elasto-dynamics problems are fully treated.},
author = {Watanabe, Kazumi},
booktitle = {Integral Transform Techniques for Green's Functions},
isbn = {978-3-319-00878-3},
pages = {93--106},
title = {{Integral Transform Techniques for Green's Function}},
url = {http://link.springer.com/10.1007/978-3-319-00879-0},
volume = {71},
year = {2014}
}

@InProceedings{Shin2014,
  author        = {Shin, Junseob and Chen, Yu and Nguyen, Man and Yen, Jesse T.},
  booktitle     = {IEEE International Ultrasonics Symposium, IUS},
  title         = {{Robust ultrasonic reverberation clutter suppression using Multi-Apodization with Cross-correlation}},
  year          = {2014},
  pages         = {543--546},
  abstract      = {Dual Apodization with Cross-correlation (DAX) is a novel beamforming technique that utilizes a pair of complementary receive apodizations for clutter suppression in ultrasound imaging. The effectiveness of DAX in-vivo is often reduced because of the strong reverberation clutter signals caused by near-field structures. In this work, we propose a modified version of DAX, known as Multi-Apodization with Cross-correlation (MAX), which suppresses reverberation clutter in a highly robust manner by utilizing multiple pairs of receive apodizations followed by normalized cross-correlation. Our simulation, experimental and initial clinical results show that MAX achieves a large improvement over DAX in terms of image contrast and shows great potential for more accurate diagnosis in clinics.},
  doi           = {10.1109/ULTSYM.2014.0134},
  isbn          = {9781479970490},
  issn          = {19485727},
  keywords      = {Folder - Correlation approaches, beamforming, clutter suppression, contrast enhancement, dual apodiztion, grating lobes, multi-apodization, reverberation},
  mendeley-tags = {Folder - Correlation approaches,beamforming,clutter suppression,contrast enhancement,dual apodiztion,grating lobes,multi-apodization,reverberation},
}

@InProceedings{Li2015a,
  author        = {Li, You Leo and Dahl, Jeremy J.},
  booktitle     = {2015 IEEE International Ultrasonics Symposium, IUS 2015},
  title         = {{Small-diameter vasculature detection with coherent flow Power Doppler imaging}},
  year          = {2015},
  pages         = {1--4},
  abstract      = {Power Doppler (PD) imaging is a widely used technique for flow detection in clinics, and is utilized as an adjunct tool for prenatal/placental vessel evaluation. However, the sensitivity of PD in small vessel detection is limited by the small-diameter and slow flow of the placental vasculature, where abnormalities are indicative of disorders including preeclampsia, fetal growth restriction, and early pregnancy loss. In order to provide more sensitive detection of placental vasculature, a coherent flow imaging technique, termed coherent flow power Doppler (CFPD), is characterized and evaluated with both simulation and flow-phantom experiment studies. The results from both studies suggest that CFPD is able to provide 15-25 dB increase in the signal-to-noise ratio (SNR) of Doppler images. Due to the increase in SNR, CFPD is able to detect small vessels in high channel noise cases, for which PD was unable to generate enough contrast on the vessel. Such cases are not uncommon among people with high body mass index. The results indicate that the CFPD method is a promising candidate for small vessel imaging.},
  doi           = {10.1109/ULTSYM.2015.0012},
  isbn          = {9781479981823},
  keywords      = {Doppler imaging, Folder - Correlation approaches, Medical ultrasound, spatial coherence},
  mendeley-tags = {Folder - Correlation approaches},
}

@Misc{Behrmann2018,
  author        = {Behrmann, Jens and Grathwohl, Will and Chen, Ricky T.Q. and Duvenaud, David and Jacobsen, J{\"{o}}rn Henrik},
  title         = {{Invertible residual networks}},
  year          = {2018},
  abstract      = {We show that standard ResNet architectures can be made invertible, allowing the same model to be used for classification, density estimation, and generation. Typically, enforcing invertibility requires partitioning dimensions or restricting network architectures. In contrast, our approach only requires adding a simple normalization step during training, already available in standard frameworks. Invertible ResNets define a generative model which can be trained by maximum likelihood on unlabeled data. To compute likelihoods, we introduce a tractable approximation to the Jacobian log-determinant of a residual block. Our empirical evaluation shows that invertible ResNets perform competitively with both state-of-the-art image classifiers and flow-based generative models, something that has not been previously achieved with a single architecture.},
  booktitle     = {arXiv},
  issn          = {23318422},
  keywords      = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Rec, Computer Science - Machine Learning, Statistics - Machine Learning},
  language      = {en},
  mendeley-tags = {Computer Science - Artificial Intelligence,Computer Science - Computer Vision and Pattern Rec,Computer Science - Machine Learning,Statistics - Machine Learning},
  pages         = {10},
}

@article{Cai2016,
abstract = {Medical ultrasound echo signals provide the basic information for obtaining the ultrasonic image in medical ultrasound technology. The statistics of the ultrasound echo signals reveals the systematic structure of the medical ultrasonic image via analyzing the corresponding statistical distributions. A novel statistical distribution, the ascending order K distribution, was proposed here to model the medical ultrasound echo signals. The ascending order K distribution was developed in light of the statistical analysis of the sequential waveforms in the echo signals. Comparison with the previous statistical distributions was made to verify the superiority of the ascending order K distribution. Further discussion showed the determination of the statistical principles for the ultrasound signals can enhance our understanding of the statistical principles of the ultrasound imaging, and thus, facilitate the optimization of the ultrasound image and the tissue identification in the ultrasound diagnosis.},
author = {Cai, Runqiu},
doi = {10.1038/srep39379},
issn = {20452322},
journal = {Scientific Reports},
number = {1},
pages = {39379},
pmid = {27991564},
title = {{Statistical Characterization of the Medical Ultrasound Echo Signals}},
url = {http://www.nature.com/articles/srep39379},
volume = {6},
year = {2016}
}

@Article{VanSloun2020,
  author        = {{Van Sloun}, Ruud J.G. and Cohen, Regev and Eldar, Yonina C.},
  journal       = {Proceedings of the IEEE},
  title         = {{Deep Learning in Ultrasound Imaging}},
  year          = {2020},
  issn          = {15582256},
  month         = {jul},
  number        = {1},
  pages         = {11--29},
  volume        = {108},
  abstract      = {In this article, we consider deep learning strategies in ultrasound systems, from the front end to advanced applications. Our goal is to provide the reader with a broad understanding of the possible impact of deep learning methodologies on many aspects of ultrasound imaging. In particular, we discuss methods that lie at the interface of signal acquisition and machine learning, exploiting both data structure (e.g., sparsity in some domain) and data dimensionality (big data) already at the raw radio-frequency channel stage. As some examples, we outline efficient and effective deep learning solutions for adaptive beamforming and adaptive spectral Doppler through artificial agents, learn compressive encodings for the color Doppler, and provide a framework for structured signal recovery by learning fast approximations of iterative minimization problems, with applications to clutter suppression and super-resolution ultrasound. These emerging technologies may have a considerable impact on ultrasound imaging, showing promise across key components in the receive processing chain.},
  archiveprefix = {arXiv},
  arxivid       = {1907.02994},
  doi           = {10.1109/JPROC.2019.2932116},
  eprint        = {1907.02994},
  keywords      = {Beamforming, Computer Science - Machine Learning, Doppler, Electrical Engineering and Systems Science - Image, Electrical Engineering and Systems Science - Signa, compression, deep learning, deep unfolding, image reconstruction, super resolution, ultrasound imaging},
  language      = {en},
  mendeley-tags = {Computer Science - Machine Learning,Electrical Engineering and Systems Science - Image,Electrical Engineering and Systems Science - Signa},
  url           = {http://arxiv.org/abs/1907.02994},
}

@article{Asl2011,
abstract = {In adaptive ultrasound imaging, accurate estimation of the array covariance matrix is of great importance, and biases the performance of the adaptive beamformer. The more accurately the covariance matrix can be estimated, the better the resolution and contrast can be achieved in the ultrasound image. To this end, in this paper, we have used the forwardbackward spatial averaging for array covariance matrix estimation, which is then employed in minimum variance (MV) weights calculation. The performance of the proposed forwardbackward MV (FBMV) beamformer is tested on simulated data obtained using Field II. Data for two closely located point targets surrounded by speckle pattern are simulated showing the higher amplitude resolution of the FBMV beamformer in comparison to the forward-only (F-only) MV beamformers, without the need for diagonal loading. A circular cyst with a diameter of 6 mm and a phantom containing wire targets and two cysts with different diameters of 8 mm and 6 mm are also simulated. The simulations show that the FBMV beamformer, in contrast to the F-only MV, could estimate the background speckle statistics without the need for temporal smoothing, resulting in higher contrast for the FBMV-resulted image in comparison to the MV images. In addition, the effect of steering vector errors is investigated by applying an error of the sound speed estimate to the ultrasound data. The simulations show that the proposed FBMV beamformer presents a satisfactory robustness against data misalignment resulted from steering vector errors, outperforming the regularized F-only MV beamformer. These improvements are achieved without compromising the good resolution of the MV beamformer and resulted from more accurate estimation of the covariance matrix and consequently, the more accurate setting of the MV weights. {\textcopyright} 2006 IEEE.},
author = {Asl, Babak Mohammadzadeh and Mahloojifar, Ali},
doi = {10.1109/TUFFC.2011.1880},
issn = {08853010},
journal = {IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
keywords = {Folder - Adaptive beamforming},
language = {en},
mendeley-tags = {Folder - Adaptive beamforming},
month = {apr},
number = {4},
pages = {858--867},
pmid = {21507765},
title = {{Contrast enhancement and robustness improvement of adaptive ultrasound imaging using forward-backward minimum variance beamforming}},
url = {http://ieeexplore.ieee.org/document/5750109/},
volume = {58},
year = {2011}
}

@InProceedings{Mardani2018,
  author        = {Mardani, Morteza and Sun, Qingyun and Vasawanala, Shreyas and Papyan, Vardan and Monajemi, Hatef and Pauly, John and Donoho, David},
  booktitle     = {Advances in Neural Information Processing Systems},
  title         = {{Neural proximal gradient descent for compressive imaging}},
  year          = {2018},
  month         = {jun},
  pages         = {9573--9583},
  volume        = {2018-Decem},
  abstract      = {Recovering high-resolution images from limited sensory data typically leads to a serious ill-posed inverse problem, demanding inversion algorithms that effectively capture the prior information. Learning a good inverse mapping from training data faces severe challenges, including: (i) scarcity of training data; (ii) need for plausible reconstructions that are physically feasible; (iii) need for fast reconstruction, especially in real-time applications. We develop a successful system solving all these challenges, using as basic architecture the recurrent application of proximal gradient algorithm. We learn a proximal map that works well with real images based on residual networks. Contraction of the resulting map is analyzed, and incoherence conditions are investigated that drive the convergence of the iterates. Extensive experiments are carried out under different settings: (a) reconstructing abdominal MRI of pediatric patients from highly undersampled Fourier-space data and (b) superresolving natural face images. Our key findings include: 1. a recurrent ResNet with a single residual block unrolled from an iterative algorithm yields an effective proximal which accurately reveals MR image details. 2. Our architecture significantly outperforms conventional non-recurrent deep ResNets by 2dB SNR; it is also trained much more rapidly. 3. It outperforms state-of-the-art compressed-sensing Wavelet-based methods by 4dB SNR, with 100x speedups in reconstruction time.},
  archiveprefix = {arXiv},
  arxivid       = {1806.03963},
  eprint        = {1806.03963},
  issn          = {10495258},
  keywords      = {Computer Science - Computer Vision and Pattern Rec, Computer Science - Machine Learning, Folder - Compressed Sensing},
  language      = {en},
  mendeley-tags = {Computer Science - Computer Vision and Pattern Rec,Computer Science - Machine Learning,Folder - Compressed Sensing},
  url           = {http://arxiv.org/abs/1806.03963},
}

@InProceedings{Szasz2014,
  author        = {Szasz, Teodora and Basarab, Adrian and Vaida, Mircea Florin and Kouam{\'{e}}, Denis},
  booktitle     = {IEEE International Ultrasonics Symposium, IUS},
  title         = {{Beamforming with sparse prior in ultrasound medical imaging}},
  year          = {2014},
  pages         = {1077--1080},
  abstract      = {Nowadays the classical Delay-and-Sum (DAS) beamformer is extensively used in ultrasound imaging due to its low computational characteristics. However, it suffers from high sidelobe level, poor resolution and low contrast. An alternative is the Minimum-Variance (MV) beamformer which results in a higher image quality both in terms of spatial resolution and contrast. Even so, these benefits come at the expense of a higher computation complexity that limits its real-time capabilities. One solution that recently gained noticeable interest is the exploit of the sparsity of the scanned medium. Based on this assumption, we extend the DAS method to yield sparse results by using the Bayesian Information Criterion (BIC). Our realistic simulations demonstrate that the proposed beamforming (BF) method shows better performance than the classical DAS and MV in terms of lateral resolution, sidelobe reduction and contrast.},
  doi           = {10.1109/ULTSYM.2014.0264},
  isbn          = {9781479970490},
  issn          = {19485727},
  keywords      = {Adaptive beamforming, Bayesian Information Criterion, Folder - Beamforming special, sparse prior, synthetic aperture imaging},
  mendeley-tags = {Folder - Beamforming special},
}

@incollection{Gutknecht2007,
abstract = {With respect to the “influence on the development and practice of science and engineering in the 20th century”, Krylov space methods are considered as one of the ten most important classes of numerical methods [1]. Large sparse linear systems of equations or large sparse matrix eigenvalue problems appear in most applications of scientific computing. Sparsity means that most elements of the matrix involved are zero. In particular, discretization of PDEs with the finite element method (FEM) or with the finite difference method (FDM) leads to such problems. In case the original problem is nonlinear, linearization by Newton's method or a Newton-type method leads again to a linear problem. We will treat here systems of equations only, but many of the numerical methods for large eigenvalue problems are based on similar ideas as the related solvers for equations.},
address = {Berlin, Heidelberg},
author = {Gutknecht, Martin H.},
booktitle = {Frontiers of Computational Science},
doi = {10.1007/978-3-540-46375-7_5},
isbn = {978-3-540-46373-3 978-3-540-46375-7},
language = {en},
pages = {53--62},
publisher = {Springer Berlin Heidelberg},
title = {{A Brief Introduction to Krylov Space Methods for Solving Linear Systems}},
url = {http://link.springer.com/10.1007/978-3-540-46375-7_5},
year = {2007}
}

@InCollection{Combettes2011,
  author        = {Combettes, Patrick L. and Pesquet, Jean Christophe},
  booktitle     = {Springer Optimization and Its Applications},
  publisher     = {Springer New York},
  title         = {{Proximal splitting methods in signal processing}},
  year          = {2011},
  address       = {New York, NY},
  isbn          = {978-1-4419-9568-1 978-1-4419-9569-8},
  pages         = {185--212},
  volume        = {49},
  abstract      = {The proximity operator of a convex function is a natural extension of the notion of a projection operator onto a convex set. This tool, which plays a central role in the analysis and the numerical solution of convex optimization problems, has recently been introduced in the arena of inverse problems and, especially, in signal processing, where it has become increasingly important. In this paper, we review the basic properties of proximity operators which are relevant to signal processing and present optimization methods based on these operators. These proximal splitting methods are shown to capture and extend several well-known algorithms in a unifying framework. Applications of proximal methods in signal recovery and synthesis are discussed.},
  archiveprefix = {arXiv},
  arxivid       = {0912.3522},
  doi           = {10.1007/978-1-4419-9569-8_10},
  eprint        = {0912.3522},
  issn          = {19316836},
  keywords      = {Alternating-direction method of multipliers, Backward–backward algorithm, Convex optimization, Denoising, Douglas–Rachford algorithm, Forward–backward algorithm, Frame, Iterative thresholding, Landweber method, Parallel computing, Peaceman–Rachford algorithm, Proximal algorithm, Restoration and reconstruction, Sparsity, Splitting},
  language      = {en},
  url           = {http://link.springer.com/10.1007/978-1-4419-9569-8_10},
}

@inproceedings{Hasegawa2014a,
abstract = {High-frame-rate echocardiography using unfocused transmit beams and parallel receive beamforming is a promising method for evaluation of cardiac function, such as imaging of rapid propagation of the heart wall vibration. In this technique, high temporal resolution is realized at the expense of spatial resolution and contrast. The phase coherence factor has been developed to improve spatial resolution and contrast in ultrasonography. It evaluates the variance in phases of echo signals received by individual transducer elements after delay compensation as in the conventional delay and sum beamforming process. However, the phase coherence factor suppresses speckle echoes because phases of speckle echoes fluctuate due to their mutual interference. In the present study, total receiving aperture was divided into several sub-apertures, and conventional delay and sum beamforming was performed with respect to each sub-aperture to suppress echoes from scatterers except for that from a focal point. After sub-aperture beamforming, the phase coherence factor was obtained from beamformed RF signals from respective sub-apertures. By means of this procedure, undesirable echoes, which can interfere with the echo from a focal point, can be suppressed by sub-aperture beamforming, and the degradation of the phase coherence factor due to phase fluctuation caused by such interference can be avoided. Effects of sub-aperture beamforming were evaluated using a phantom. By sub-aperture beamforming, the average intensity of speckle echoes from a diffuse scattering medium was significantly higher (-39.9 dB) than that obtained without sub-aperture beamforming (-48.7 dB). As for spatial resolution, the width at half maximum of the lateral echo amplitude profile obtained without the phase coherence factor was 1.06 mm. Using the phase coherence factor, spatial resolution was improved significantly, and sub-aperture beamforming achieved a better spatial resolution of 0.75 mm than that of 0.78 mm obtained without sub-aperture beamforming. Using sub-aperture beamforming in estimation of coherence factor, better visualization of speckle echoes and spatial resolution could be realized simultaneously by suppressing out-of-focus echoes.},
author = {Hasegawa, Hideyuki and Kanai, Hiroshi},
booktitle = {IEEE International Ultrasonics Symposium, IUS},
doi = {10.1109/ULTSYM.2014.0133},
isbn = {9781479970490},
issn = {19485727},
keywords = {Folder - Correlation approaches},
mendeley-tags = {Folder - Correlation approaches},
pages = {539--542},
title = {{Phase coherence factor with sub-aperture beamforming}},
year = {2014}
}

@article{Stolt1978,
abstract = {Wave equation migration is known to be simpler in principle when the horizontal coordinate or coordinates are replaced by their Fourier conjugates. Two practical migration schemes utilizing this concept are developed in this paper. One scheme extends the Claerbout finite difference method, greatly reducing dispersion problems usually associated with this method at higher dips and frequencies. The second scheme effects a Fourier transform in both space and time; by using the full scalar wave equation in the conjugate space, the method eliminates (up to the aliasing frequency) dispersion altogether. The second method in particular appears adaptable to three-dimensional migration and migration before stack.},
author = {Stolt, R. H.},
doi = {10.1190/1.1440826},
issn = {00168033},
journal = {Geophysics},
keywords = {Folder - Classical beamforming},
language = {en},
mendeley-tags = {Folder - Classical beamforming},
month = {feb},
number = {1},
pages = {23--48},
title = {{MIGRATION BY FOURIER TRANSFORM.}},
url = {http://library.seg.org/doi/10.1190/1.1440826},
volume = {43},
year = {1978}
}

@Article{Peng2016,
  author        = {Peng, Wujian and Lin, Qun},
  journal       = {Numerical Mathematics},
  title         = {{A Non-Krylov Subspace Method for Solving Large and Sparse Linear System of Equations}},
  year          = {2016},
  issn          = {20797338},
  month         = {nov},
  number        = {2},
  pages         = {289--314},
  volume        = {9},
  abstract      = {Most current prevalent iterative methods can be classified into the socalled extended Krylov subspace methods, a class of iterative methods which do not fall into this category are also proposed in this paper. Comparing with traditional Krylov subspace methods which always depend on the matrix-vector multiplication with a fixed matrix, the newly introduced methods (the so-called (progressively) accumulated projection methods, or AP (PAP) for short) use a projection matrix which varies in every iteration to form a subspace from which an approximate solution is sought. More importantly an accelerative approach (called APAP) is introduced to improve the convergence of PAP method. Numerical experiments demonstrate some surprisingly improved convergence behavior. Comparison between benchmark extended Krylov subspace methods (Block Jacobi and GMRES) are made and one can also see remarkable advantage of APAP in some examples. APAP is also used to solve systems with extremely ill-conditioned coefficient matrix (the Hilbert matrix) and numerical experiments shows that it can bring very satisfactory results even when the size of system is up to a few thousands.},
  doi           = {10.4208/nmtma.2016.y14014},
  keywords      = {Accumulated projection, Iterative method, Krylov subspace, Mathematics - Numerical Analysis},
  language      = {en},
  mendeley-tags = {Mathematics - Numerical Analysis},
  url           = {http://arxiv.org/abs/1511.08042},
}

@Article{Ding2018,
  author        = {Ding, Lei and Xiao, Lin and Zhou, Kaiqing and Lan, Yonghong and Zhang, Yongsheng},
  journal       = {IEEE Access},
  title         = {{A new RNN model with a modified nonlinear activation function applied to complex-valued linear equations}},
  year          = {2018},
  issn          = {21693536},
  pages         = {62954--62962},
  volume        = {6},
  abstract      = {In this paper, an improved Zhang neural network (IZNN) is proposed by using a kind of novel nonlinear activation function to solve the complex-valued systems of linear equation. Compared with the previous ZNN models, the convergence rate of the IZNN model has been accelerated. To do so, a kind of novel nonlinear activation function is first proposed to establish the novel recurrent neural network. Then, the corresponding maximum convergent time is given according to the randomly generated initial error vector, and the theoretical proof is described in detail in this paper. Finally, the experiment results illustrate that the new recurrent neural network using the proposed activation function has higher convergence rate than the previous neural networks using the linear activation function or the tunable activation function.},
  doi           = {10.1109/ACCESS.2018.2876665},
  keywords      = {Folder - wavefield_representation, Recurrent neural network, complex-valued systems of linear equation, convergence rate, finite time, novel nonlinear activation function},
  language      = {en},
  mendeley-tags = {Folder - wavefield_representation},
  url           = {https://ieeexplore.ieee.org/document/8496754/},
}

@Article{Sandrin1999,
  author        = {Sandrin, L. and Catheline, S. and Tanter, M. and Hennequin, X. and Fink, M.},
  journal       = {Ultrasonic Imaging},
  title         = {{Time-resolved pulsed elastography with ultrafast ultrasonic imaging}},
  year          = {1999},
  issn          = {01617346},
  number        = {4},
  pages         = {259--272},
  volume        = {21},
  abstract      = {In this paper, a new elastographic method is proposed. Using this method, the propagation of a low-frequency transient shear wave can be imaged by means of an ultrafast imaging system (up to 10,000 frames/s) that we have developed. Ultrafast ultrasonic imaging is obtained with a linear array of transducers (3.5 MHz) connected to electronics that have 64 channels sampled at 30 MHz and 128 Kbytes for storing the backscattered signals. Displacements are measured using cross-correlation of the ultrasonic signals. Movies of the low central frequency (200 Hz) shear wave propagation through homogeneous and heterogeneous phantoms have been obtained with 1,000 and 2,000 frames per second.},
  doi           = {10.1177/016173469902100402},
  keywords      = {Elasticity, Elastography, Imaging, Phantoms, Shear wave, Ultrafast ultrasonic imaging, Ultrasonography, Ultrasonography: methods},
  mendeley-tags = {Elasticity,Imaging,Phantoms,Ultrasonography,Ultrasonography: methods},
  pmid          = {10801211},
  url           = {http://uix.sagepub.com/content/21/4/259.abstract},
}

@article{Jensen1992,
abstract = {A method for the simulation of pulsed pressure fields from arbitrarily shaped, apodized and excited ultrasound transducers is suggested. It relies on the Tupholme-Stepanishen method for calculating pulsed pressure fields, and can also handle the continuous wave and pulse-echo case. The field is calculated by dividing the surface into small rectangles and then summing their response. A fast calculation is obtained by using the farfield approximation. Examples of the accuracy of the approach and actual calculation times are given. {\textcopyright} 1992 IEEE},
author = {Jensen, J$\Phi$rgen Arendt and Svendsen, Niels Bruun},
doi = {10.1109/58.139123},
issn = {08853010},
journal = {IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
number = {2},
pages = {262--267},
title = {{Calculation of Pressure Fields from Arbitrarily Shaped, Apodized, and Excited Ultrasound Transducers}},
volume = {39},
year = {1992}
}

@InProceedings{Grover2018,
  author        = {Grover, Aditya and Dhar, Manik and Ermon, Stefano},
  booktitle     = {32nd AAAI Conference on Artificial Intelligence, AAAI 2018},
  title         = {{Flow-GaN: Combining maximum likelihood and adversarial learning in generative models}},
  year          = {2018},
  month         = {jan},
  pages         = {3069--3076},
  abstract      = {Adversarial learning of probabilistic models has recently emerged as a promising alternative to maximum likelihood. Implicit models such as generative adversarial networks (GAN) often generate better samples compared to explicit models trained by maximum likelihood. Yet, GANs sidestep the characterization of an explicit density which makes quantitative evaluations challenging. To bridge this gap, we propose Flow-GANs, a generative adversarial network for which we can perform exact likelihood evaluation, thus supporting both adversarial and maximum likelihood training. When trained adversarially, Flow-GANs generate high-quality samples but attain extremely poor log-likelihood scores, inferior even to a mixture model memorizing the training data; the opposite is true when trained by maximum likelihood. Results on MNIST and CIFAR-10 demonstrate that hybrid training can attain high held-out likelihoods while retaining visual fidelity in the generated samples.},
  archiveprefix = {arXiv},
  arxivid       = {1705.08868},
  eprint        = {1705.08868},
  isbn          = {9781577358008},
  keywords      = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computi, Statistics - Machine Learning},
  language      = {en},
  mendeley-tags = {Computer Science - Artificial Intelligence,Computer Science - Machine Learning,Computer Science - Neural and Evolutionary Computi,Statistics - Machine Learning},
  shorttitle    = {Flow-GAN},
  url           = {http://arxiv.org/abs/1705.08868},
}

@Article{Yang2018,
  author        = {Yang, Qingsong and Yan, Pingkun and Zhang, Yanbo and Yu, Hengyong and Shi, Yongyi and Mou, Xuanqin and Kalra, Mannudeep K. and Zhang, Yi and Sun, Ling and Wang, Ge},
  journal       = {IEEE Transactions on Medical Imaging},
  title         = {{Low-Dose CT Image Denoising Using a Generative Adversarial Network With Wasserstein Distance and Perceptual Loss}},
  year          = {2018},
  issn          = {1558254X},
  month         = {jun},
  number        = {6},
  pages         = {1348--1357},
  volume        = {37},
  abstract      = {The continuous development and extensive use of computed tomography (CT) in medical practice has raised a public concern over the associated radiation dose to the patient. Reducing the radiation dose may lead to increased noise and artifacts, which can adversely affect the radiologists' judgment and confidence. Hence, advanced image reconstruction from low-dose CT data is needed to improve the diagnostic performance, which is a challenging problem due to its ill-posed nature. Over the past years, various low-dose CT methods have produced impressive results. However, most of the algorithms developed for this application, including the recently popularized deep learning techniques, aim for minimizing the mean-squared error (MSE) between a denoised CT image and the ground truth under generic penalties. Although the peak signal-to-noise ratio is improved, MSE- or weighted-MSE-based methods can compromise the visibility of important structural details after aggressive denoising. This paper introduces a new CT image denoising method based on the generative adversarial network (GAN) with Wasserstein distance and perceptual similarity. The Wasserstein distance is a key concept of the optimal transport theory and promises to improve the performance of GAN. The perceptual loss suppresses noise by comparing the perceptual features of a denoised output against those of the ground truth in an established feature space, while the GAN focuses more on migrating the data noise distribution from strong to weak statistically. Therefore, our proposed method transfers our knowledge of visual perception to the image denoising task and is capable of not only reducing the image noise level but also trying to keep the critical information at the same time. Promising results have been obtained in our experiments with clinical CT images.},
  archiveprefix = {arXiv},
  arxivid       = {1708.00961},
  doi           = {10.1109/TMI.2018.2827462},
  eprint        = {1708.00961},
  keywords      = {Computer Science - Computer Vision and Pattern Rec, Low dose CT, WGAN, deep learning, image denoising, perceptual loss},
  language      = {en},
  mendeley-tags = {Computer Science - Computer Vision and Pattern Rec},
  pmid          = {29870364},
  url           = {http://arxiv.org/abs/1708.00961},
}

@Misc{Heek2019,
  author        = {Heek, Jonathan and Kalchbrenner, Nal},
  month         = {aug},
  title         = {{Bayesian Inference for Large Scale Image Classification}},
  year          = {2019},
  abstract      = {Bayesian inference promises to ground and improve the performance of deep neural networks. It promises to be robust to overfitting, to simplify the training procedure and the space of hyperparameters, and to provide a calibrated measure of uncertainty that can enhance decision making, agent exploration and prediction fairness. Markov Chain Monte Carlo (MCMC) methods enable Bayesian inference by generating samples from the posterior distribution over model parameters. Despite the theoretical advantages of Bayesian inference and the similarity between MCMC and optimization methods, the performance of sampling methods has so far lagged behind optimization methods for large scale deep learning tasks. We aim to fill this gap and introduce ATMC, an adaptive noise MCMC algorithm that estimates and is able to sample from the posterior of a neural network. ATMC dynamically adjusts the amount of momentum and noise applied to each parameter update in order to compensate for the use of stochastic gradients. We use a ResNet architecture without batch normalization to test ATMC on the Cifar10 benchmark and the large scale ImageNet benchmark and show that, despite the absence of batch normalization, ATMC outperforms a strong optimization baseline in terms of both classification accuracy and test log-likelihood. We show that ATMC is intrinsically robust to overfitting on the training data and that ATMC provides a better calibrated measure of uncertainty compared to the optimization baseline.},
  archiveprefix = {arXiv},
  arxivid       = {1908.03491},
  booktitle     = {arXiv},
  eprint        = {1908.03491},
  issn          = {23318422},
  keywords      = {Computer Science - Computer Vision and Pattern Rec, Computer Science - Machine Learning, Statistics - Machine Learning},
  language      = {en},
  mendeley-tags = {Computer Science - Computer Vision and Pattern Rec,Computer Science - Machine Learning,Statistics - Machine Learning},
  url           = {http://arxiv.org/abs/1908.03491},
}

@Article{Mayer1990,
  author        = {Mayer, K. and Marklein, R. and Langenberg, K. J. and Kreutter, T.},
  journal       = {Ultrasonics},
  title         = {{Three-dimensional imaging system based on Fourier transform synthetic aperture focusing technique}},
  year          = {1990},
  issn          = {0041624X},
  number        = {4},
  pages         = {241--255},
  volume        = {28},
  abstract      = {For planar scan surfaces, digitized ultrasonic RF-data can be adequately processed in terms of the Fourier transform synthetic aperture focusing technique algorithm, i.e. in terms of synthetic aperture pulse-echo backpropagation utilizing Fourier transforms only, to yield a quantitative three-dimensional image of defects residing in the homogeneous and isotropic bulk material. The implementation of this algorithm into an ultrasonic imaging system is described, which mainly comprises an array processor and high-resolution graphics to display the three-dimensional reconstruction volume as a walk-through along three orthogonal planes. To enhance the signal-to-noise ratio and the axial resolution of the system, controlled ultrasonic signals are transmitted as complementary Golay-sequences, cross-correlated with the received signals and deconvolved with similarly obtained reference signals. {\textcopyright} 1990.},
  doi           = {10.1016/0041-624X(90)90091-2},
  keywords      = {Folder - HFR US, Fourier transforms, imaging system, synthetic aperture focusing technique},
  mendeley-tags = {Folder - HFR US},
}

@Article{Zhu2019,
  author        = {Zhu, Yinhao and Zabaras, Nicholas and Koutsourelakis, Phaedon Stelios and Perdikaris, Paris},
  journal       = {Journal of Computational Physics},
  title         = {{Physics-constrained deep learning for high-dimensional surrogate modeling and uncertainty quantification without labeled data}},
  year          = {2019},
  issn          = {10902716},
  month         = {oct},
  pages         = {56--81},
  volume        = {394},
  abstract      = {Surrogate modeling and uncertainty quantification tasks for PDE systems are most often considered as supervised learning problems where input and output data pairs are used for training. The construction of such emulators is by definition a small data problem which poses challenges to deep learning approaches that have been developed to operate in the big data regime. Even in cases where such models have been shown to have good predictive capability in high dimensions, they fail to address constraints in the data implied by the PDE model. This paper provides a methodology that incorporates the governing equations of the physical model in the loss/likelihood functions. The resulting physics-constrained, deep learning models are trained without any labeled data (e.g. employing only input data)and provide comparable predictive responses with data-driven models while obeying the constraints of the problem at hand. This work employs a convolutional encoder-decoder neural network approach as well as a conditional flow-based generative model for the solution of PDEs, surrogate model construction, and uncertainty quantification tasks. The methodology is posed as a minimization problem of the reverse Kullback-Leibler (KL)divergence between the model predictive density and the reference conditional density, where the later is defined as the Boltzmann-Gibbs distribution at a given inverse temperature with the underlying potential relating to the PDE system of interest. The generalization capability of these models to out-of-distribution input is considered. Quantification and interpretation of the predictive uncertainty is provided for a number of problems.},
  archiveprefix = {arXiv},
  arxivid       = {1901.06314},
  doi           = {10.1016/j.jcp.2019.05.024},
  eprint        = {1901.06314},
  keywords      = {Computer Science - Computer Vision and Pattern Rec, Computer Science - Machine Learning, Conditional generative model, Normalizing flow, Physics - Computational Physics, Physics-constrained, Reverse KL divergence, Statistics - Machine Learning, Surrogate modeling, Uncertainty quantification},
  language      = {en},
  mendeley-tags = {Computer Science - Computer Vision and Pattern Rec,Computer Science - Machine Learning,Physics - Computational Physics,Statistics - Machine Learning},
  url           = {http://arxiv.org/abs/1901.06314},
}

@InProceedings{Villaverde2016,
  author        = {Villaverde, Eduardo Lopez and Robert, S{\'{e}}bastien and Prada, Claire},
  booktitle     = {IEEE International Ultrasonics Symposium, IUS},
  title         = {{Ultrasonic imaging in highly attenuating materials with Walsh-Hadamard codes and the decomposition of the time reversal operator}},
  year          = {2016},
  pages         = {0--3},
  volume        = {2016-Novem},
  abstract      = {In this work, the total focusing method is used to image defects in a high density polyethylene pipe. The viscoelastic attenuation of this material corrupts the images with a high electronic noise. To improve the image quality, the decomposition of the time reversal operator method is combined with spatial Walsh-Hadamard coded transmissions before calculating the images.},
  doi           = {10.1109/ULTSYM.2016.7728744},
  isbn          = {9781467398978},
  issn          = {19485727},
  keywords      = {6, array ultrasonic imaging, at 5 mhz, attenuating material, base material of a, defect characterization, hdpe pipe, immersed in, is around 1 db, mm, non-destructive testing, the same probe is, the wave attenuation, then, time reversal},
  mendeley-tags = {6,array ultrasonic imaging,at 5 mhz,attenuating material,base material of a,defect characterization,hdpe pipe,immersed in,is around 1 db,mm,non-destructive testing,the same probe is,the wave attenuation,then,time reversal},
}

@Article{Tanya2014,
  author        = {Tanya, Chernyakova and {Yonina C.}, Eldar},
  journal       = {IEEE Transactions on Ultrasonics Ferroelectrics and Frequency Control},
  title         = {{Fourier Domain Beamforming: The Path to Compressed Ultrasound Imaging}},
  year          = {2014},
  issn          = {0002-7979},
  number        = {8},
  pages         = {1252--1267},
  volume        = {61},
  abstract      = {Sonography techniques use multiple transducer elements for tissue visualization. Signals detected at each element are sampled prior to digital beamforming. The sampling rates required to perform high resolution digital beamforming are significantly higher than the Nyquist rate of the signal and result in considerable amount of data, that needs to be stored and processed. A recently developed technique, compressed beamforming, based on the finite rate of innovation model, compressed sensing (CS) and Xampling ideas, allows to reduce the number of samples needed to reconstruct an image comprised of strong reflectors. A drawback of this method is its inability to treat speckle, which is of significant importance in medical imaging. Here we build on previous work and extend it to a general concept of beamforming in frequency. This allows to exploit the low bandwidth of the ultrasound signal and bypass the oversampling dictated by digital implementation of beamforming in time. Using beamforming in frequency, the same image quality is obtained from far fewer samples. We next present a CS-technique that allows for further rate reduction, using only a portion of the beamformed signal's bandwidth. We demonstrate our methods on in vivo cardiac data and show that reductions up to 1/28 over standard beamforming rates are possible. Finally, we present an implementation on an ultrasound machine using sub-Nyquist sampling and processing. Our results prove that the concept of sub-Nyquist processing is feasible for medical ultrasound, leading to the potential of considerable reduction in future ultrasound machines size, power consumption and cost.},
  archiveprefix = {arXiv},
  arxivid       = {1307.6345},
  eprint        = {1307.6345},
  keywords      = {Folder - Beamforming special, article, dental education, human, management, methodology, organization and management},
  mendeley-tags = {Folder - Beamforming special},
  url           = {http://arxiv.org/abs/1307.6345 http://www.embase.com/search/results?subaction=viewrecord&from=export&id=L47315300%5Cnhttp://pm6mt7vg3j.search.serialssolutions.com?sid=EMBASE&issn=00027979&id=doi:&atitle=My+passion.&stitle=J+Am+Coll+Dent&title=The+Journal+},
}

@Article{BarZion2017,
  author        = {Bar-Zion, Avinoam and Tremblay-Darveau, Charles and Solomon, Oren and Adam, Dan and Eldar, Yonina C.},
  journal       = {IEEE Transactions on Medical Imaging},
  title         = {{Fast Vascular Ultrasound Imaging with Enhanced Spatial Resolution and Background Rejection}},
  year          = {2017},
  issn          = {1558254X},
  number        = {1},
  pages         = {169--180},
  volume        = {36},
  abstract      = {Ultrasound super-localization microscopy techniques presented in the last few years enable non-invasive imaging of vascular structures at the capillary level by tracking the flow of ultrasound contrast agents (gas microbubbles). However, these techniques are currently limited by low temporal resolution and long acquisition times. Super-resolution optical fluctuation imaging (SOFI) is a fluorescence microscopy technique enabling sub-diffraction limit imaging with high temporal resolution by calculating high order statistics of the fluctuating optical signal. The aim of this work is to achieve fast acoustic imaging with enhanced resolution by applying the tools used in SOFI to contrast-enhance ultrasound (CEUS) plane-wave scans. The proposed method was tested using numerical simulations and evaluated using two in-vivo rabbit models: scans of healthy kidneys and VX-2 tumor xenografts. Improved spatial resolution was observed with a reduction of up to 50% in the full width half max of the point spread function. In addition, substantial reduction in the background level was achieved compared to standard mean amplitude persistence images, revealing small vascular structures within tumors. The scan duration of the proposed method is less than a second while current super-localization techniques require acquisition duration of several minutes. As a result, the proposed technique may be used to obtain scans with enhanced spatial resolution and high temporal resolution, facilitating flow-dynamics monitoring. Our method can also be applied during a breath-hold, reducing the sensitivity to motion artifacts.},
  archiveprefix = {arXiv},
  arxivid       = {1601.05710},
  doi           = {10.1109/TMI.2016.2600372},
  eprint        = {1601.05710},
  keywords      = {Animals, Contrast Media, Contrast enhanced ultrasound, Fluctuations, Fluorescence, High order statistics, Microbubbles, Microscopy, Optical Imaging, Rabbits, Signal resolution, Spatial resolution, Super-localization microscopy, Super-resolution, Super-resolution optical fluctuation imaging, Ultrasonic imaging, Ultrasonography, VX-2 tumor xenografts, acoustic microscopy, acquisition duration, acquisition times, background rejection, biomedical optical imaging, biomedical ultrasonics, breath holding, cancer, capillary level, contrast-enhance ultrasound plane-wave scans, enhanced spatial resolution, fast acoustic imaging, fast vascular ultrasound imaging, flow tracking, flow-dynamics monitoring, fluctuating optical signal, fluorescence, fluorescence microscopy, full width half maximum, gas microbubbles, healthy kidneys, high-order statistics, image enhancement, image motion analysis, image resolution, in-vivo rabbit models, kidney, motion artifacts, noninvasive imaging, numerical simulations, optical transfer function, patient monitoring, pneumodynamics, point spread function, scan duration, standard mean amplitude persistence images, subdiffraction limit imaging, super-resolution optical fluctuation imaging, temporal resolution, tumors, tumours, ultrasound contrast agents, ultrasound super-localization microscopy, vascular structures},
  mendeley-tags = {Animals,Contrast Media,Contrast enhanced ultrasound,Fluctuations,Fluorescence,High order statistics,Microbubbles,Microscopy,Optical Imaging,Rabbits,Signal resolution,Spatial resolution,Super-localization microscopy,Super-resolution,Super-resolution optical fluctuation imaging,Ultrasonic imaging,Ultrasonography,VX-2 tumor xenografts,acoustic microscopy,acquisition duration,acquisition times,background rejection,biomedical optical imaging,biomedical ultrasonics,breath holding,cancer,capillary level,contrast-enhance ultrasound plane-wave scans,enhanced spatial resolution,fast acoustic imaging,fast vascular ultrasound imaging,flow tracking,flow-dynamics monitoring,fluctuating optical signal,fluorescence,fluorescence microscopy,full width half maximum,gas microbubbles,healthy kidneys,high-order statistics,image enhancement,image motion analysis,image resolution,in-vivo rabbit models,kidney,motion artifacts,noninvasive imaging,numerical simulations,optical transfer function,patient monitoring,pneumodynamics,point spread function,scan duration,standard mean amplitude persistence images,subdiffraction limit imaging,super-resolution optical fluctuation imaging,temporal resolution,tumors,tumours,ultrasound contrast agents,ultrasound super-localization microscopy,vascular structures},
  pmid          = {27541629},
}

@Article{Godara1997,
  author        = {Godara, Lal C.},
  journal       = {Proceedings of the IEEE},
  title         = {{Application of antenna arrays to mobile communications, part II: Beam-forming and direction-of-arrival considerations}},
  year          = {1997},
  issn          = {00189219},
  number        = {8},
  pages         = {1195--1245},
  volume        = {85},
  abstract      = {Array processing involves manipulation of signals induced on various antenna elements. Its capabilities of steering nulls to reduce cochannel interferences and pointing independent beams toward various mobiles, as well as its ability to provide estimates of directions of radiating sources, make it attractive to a mobile communications system designer. Array processing is expected to play an important role in fulfilling the increased demands of various mobile communications services. Pan I of this paper showed how an array could be utilized in different configurations to improve the performance of mobile communications systems, with references to various studies where feasibility of an array system for mobile communications is considered. This paper provides a comprehensive and detailed treatment of different beam-forming schemes, adaptive algorithms to adjust the required weighting on antennas, direction-of-arrival estimation methods - including their performance comparison-and effects of errors on the performance of an array system, as well as schemes to alleviate them. This paper brings together almost all aspects of array signal processing. It is presented at a level appropriate to nonexperts in the field and contains a large reference list to probe further. {\textcopyright} 1997 IEEE.},
  doi           = {10.1109/5.622504},
  keywords      = {Beam fanning, Conjugate gradient method, ESPRIT, Eigenstnicture methods, Folder - BSS and acoustic source localization, Least square algorithm, Linear prediction method, Maximum entropy, Maximum likelihood method, Minimum norm, Mobile communications, Multipath arrivals},
  mendeley-tags = {Beam fanning,Conjugate gradient method,ESPRIT,Eigenstnicture methods,Folder - BSS and acoustic source localization,Least square algorithm,Linear prediction method,Maximum entropy,Maximum likelihood method,Minimum norm,Mobile communications,Multipath arrivals},
}

@inproceedings{David2015,
abstract = {In this contribution we refined our previously introduced time domain compressive beamforming algorithm (t-CBF). Our aim was to make t-CBF less greedy in terms of memory usage to be able to adapt it to real life images. Along the way, we also introduced necessary adjustments to further sparsify our images and make the reconstruction more robust in the presence of speckle. The wavelet transform was implemented in t-CBF in different flavors both in terms of wavelet family and decimated/undecimated algorithm. The cardiac dataset used in this contribution corresponds theoretically to a single diverging wave insonification. Compared to the performance of classic DAS in the same setting, t-CBF yielded better contrast, less sidelobes, and cleaner images.},
author = {David, Guillaume and Robert, Jean Luc and Zhang, Bo and Laine, Andrew F.},
booktitle = {2015 IEEE International Ultrasonics Symposium, IUS 2015},
doi = {10.1109/ULTSYM.2015.0176},
isbn = {9781479981823},
pages = {1--4},
publisher = {IEEE},
title = {{Time domain compressive beamforming: Application to in-vivo echocardiography}},
year = {2015}
}

@Article{Carrillo2013,
  author        = {Carrillo, Rafael E. and McEwen, Jason D. and {Van De Ville}, Dimitri and Thiran, Jean Philippe and Wiaux, Yves},
  journal       = {IEEE Signal Processing Letters},
  title         = {{Sparsity averaging for compressive imaging}},
  year          = {2013},
  issn          = {10709908},
  month         = {jun},
  number        = {6},
  pages         = {591--594},
  volume        = {20},
  abstract      = {We discuss a novel sparsity prior for compressive imaging in the context of the theory of compressed sensing with coherent redundant dictionaries, based on the observation that natural images exhibit strong average sparsity over multiple coherent frames. We test our prior and the associated algorithm, based on an analysis reweighted ℓ 1 formulation, through extensive numerical simulations on natural images for spread spectrum and random Gaussian acquisition schemes. Our results show that average sparsity outperforms state-of-the-art priors that promote sparsity in a single orthonormal basis or redundant frame, or that promote gradient sparsity. Code and test data are available at https://github.com/basp-group/sopt. {\textcopyright} 1994-2012 IEEE.},
  archiveprefix = {arXiv},
  arxivid       = {1208.2330},
  doi           = {10.1109/LSP.2013.2259813},
  eprint        = {1208.2330},
  keywords      = {Compressed sensing, Folder - Compressed Sensing, sparse approximation},
  language      = {en},
  mendeley-tags = {Folder - Compressed Sensing},
  url           = {http://ieeexplore.ieee.org/document/6507650/},
}

@Article{Jensen1992a,
  author   = {Jensen, J¸rgen Arendt},
  journal  = {Ultrasonic Imaging},
  title    = {{Deconvolution of ultrasound images}},
  year     = {1992},
  issn     = {01617346},
  number   = {1},
  pages    = {1--15},
  volume   = {14},
  abstract = {Based on physical models, it is indicated that the received pressure field in ultrasound B-mode images can be described by a convolution between a tissue reflection signal and the emitted pressure field. This result is used in a description of current image formation and in formulating a new processing scheme. The suggested estimator can take into account the dispersive attenuation, the temporal and spatial variation of the pulse, and the change in reflection strength and signal-to-noise ratio. Details of the algorithm and the estimation of parameters to be used are given. The performance is indicated by two examples. One is for a synthetic signal and the other is for data measured from a tissue mimicking phantom. The last example shows a finer speckle pattern, giving an increased resolution. {\textcopyright} 1992, SAGE Publications. All rights reserved.},
  doi      = {10.1177/016173469201400101},
  keywords = {Deconvolution, estimation, image improvement, signal processing},
  pmid     = {1549893},
  url      = {http://uix.sagepub.com/lookup/doi/10.1177/016173469201400101},
}

@Article{ODonnell1982,
  author        = {O'Donnell, M},
  journal       = {Ultrasonic Imaging},
  title         = {{Phase-insensitive pulse-echo imaging}},
  year          = {1982},
  issn          = {01617346},
  number        = {4},
  pages         = {321--335},
  volume        = {4},
  doi           = {10.1016/0161-7346(82)90016-5},
  keywords      = {Arrays, Folder - HFR US, nonlinear processing, phase insensitive, speckle, ultrasound imaging},
  mendeley-tags = {Arrays,Folder - HFR US,nonlinear processing,phase insensitive,speckle,ultrasound imaging},
}

@phdthesis{Yildiz2015a,
author = {Yildiz, Yesna Oyku},
number = {October},
pages = {1--157},
title = {{Nonlinear Propagation Artefact Correction in Contrast Enhanced Ultrasound Imaging}},
year = {2015}
}

@article{Saito1993,
author = {Saito, Riichiro},
pages = {494--500},
title = {{(SPOC) SINGLE SNAPSHOT SPATIAL PROCESSING: OPTIMIZED AND CONSTRAINED}},
year = {1993}
}

@Misc{Andrew1998,
  author        = {Andrew, Alex M.},
  title         = {{Reinforcement Learning: An Introduction}},
  year          = {1998},
  address       = {Cambridge, Mass},
  booktitle     = {Kybernetes},
  doi           = {10.1108/k.1998.27.9.1093.3},
  isbn          = {978-0-262-19398-6},
  issn          = {0368492X},
  keywords      = {Folder - RL and Dynamic Programming, Reinforcement learning},
  language      = {en},
  mendeley-tags = {Folder - RL and Dynamic Programming,Reinforcement learning},
  number        = {9},
  pages         = {1093--1096},
  publisher     = {MIT Press},
  series        = {Adaptive computation and machine learning},
  shorttitle    = {Reinforcement learning},
  volume        = {27},
}

@Article{Ramirez2013,
  author        = {Ramirez, Carlos and Kreinovich, Vladik and Argaez, Miguel},
  journal       = {Journal of Uncertain Systems},
  title         = {{Why l1 is a good approximation to l0: A geometric explanation}},
  year          = {2013},
  issn          = {17528909},
  number        = {3},
  pages         = {203--207},
  volume        = {7},
  abstract      = {In practice, we usually have partial information; as a result, we have several different possibilities consistent with the given measurements and the given knowledge. For example, in geosciences, several possible density distributions are consistent with the measurement results. It is reasonable to select the simplest among such distributions. A general solution can be described, e.g., as a linear combination of basic functions. A natural way to define the simplest solution is to select one for which the number of the non-zero coefficients ci is the smallest. The corresponding "l0-optimization" problem is non-convex and therefore, difficult to solve. As a good approximation to this problem, Cand_es and Tao proposed to use a solution to the convex l1 optimization problem $\sigma$|ci|→ min. In this paper, we provide a geometric explanation of why l1 is indeed the best convex approximation to lo. {\textcopyright} 2013 World Academic Press, UK. All rights reserved.},
  keywords      = {L0-norm, L1-norm, Ockham razor, Sparse representation, ockham razor, sparse representation, ℓ 0 -norm, ℓ 1 -norm},
  mendeley-tags = {ockham razor,sparse representation,ℓ 0 -norm,ℓ 1 -norm},
}

@article{James2012,
abstract = {Motivated by applications in areas as diverse as finance, image reconstruction, and curve estimation, we introduce the constrained lasso problem, where the underlying parameters satisfy a collection of linear constraints. We show that many statistical methods, such as the fused lasso, monotone curve estimation and the generalized lasso, are all special cases of the constrained lasso. Computing the constrained lasso poses some technical challenges but we develop an efficient algorithm for fitting it over a grid of tuning parameters. Non-asymptotic error bounds are developed which suggest that the constrained lasso should outperform the lasso in situations where the true parameters satisfy the underlying constraints. Extensive numerical experiments show that our method performs well, both computationally and statistically. Finally, we apply the constrained lasso to a real data set to estimate the demand curve for a particular type of auto loan as a function of interest rate, and demonstrate that it can outperform more standard approaches.},
author = {James, Gareth M and Paulson, Courtney and Rusmevichientong, Paat},
journal = {Refereed Conference Proceedings},
pages = {4945--4950},
title = {{The constrained lasso}},
url = {http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.306.8795&rep=rep1&type=pdf},
volume = {31},
year = {2012}
}

@incollection{Nocedal2006,
address = {New York},
author = {Nocedal, Jorge and Wright, Stephen J.},
booktitle = {Springer Series in Operations Research and Financial Engineering},
doi = {10.1201/b19115-11},
edition = {2nd ed},
isbn = {978-0-387-30303-1},
issn = {21971773},
keywords = {Mathematical optimization},
language = {en},
mendeley-tags = {Mathematical optimization},
pages = {1--664},
publisher = {Springer},
series = {Springer series in operations research},
title = {{Numerical optimization}},
year = {2006}
}

@article{Tupholme1969,
author = {Tupholme, G. E.},
doi = {10.1112/S0025579300008184},
issn = {20417942},
journal = {Mathematika},
keywords = {Folder - Ultrasound modeling},
language = {en},
mendeley-tags = {Folder - Ultrasound modeling},
month = {dec},
number = {2},
pages = {209--224},
title = {{Generation of acoustic pulses by baffled plane pistons}},
url = {http://www.journals.cambridge.org/abstract_S0025579300008184},
volume = {16},
year = {1969}
}

@Article{Besson2016b,
  author        = {Besson, Adrien and Zhang, Miaomiao and Varray, Francois and Liebgott, Herve and Friboulet, Denis and Wiaux, Yves and Thiran, Jean Philippe and Carrillo, Rafael E. and Bernard, Olivier},
  journal       = {IEEE Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
  title         = {{A Sparse Reconstruction Framework for Fourier-Based Plane-Wave Imaging}},
  year          = {2016},
  issn          = {08853010},
  number        = {12},
  pages         = {2092--2106},
  volume        = {63},
  abstract      = {Ultrafast imaging based on plane-wave (PW) insonification is an active area of research due to its capability of reaching high frame rates. Among PW imaging methods, Fourier-based approaches have demonstrated to be competitive compared with traditional delay and sum methods. Motivated by the success of compressed sensing techniques in other Fourier imaging modalities, like magnetic resonance imaging, we propose a new sparse regularization framework to reconstruct highquality ultrasound (US) images. The framework takes advantage of both the ability to formulate the imaging inverse problem in the Fourier domain and the sparsity of US images in a sparsifying domain. We show, by means of simulations, in vitro and in vivo data, that the proposed framework significantly reduces image artifacts, i.e., measurement noise and sidelobes, compared with classical methods, leading to an increase of the image quality.},
  doi           = {10.1109/TUFFC.2016.2614996},
  keywords      = {Folder - Beamforming special, Folder - Compressed Sensing, Fourier imaging, sparse representation, ultrafast imaging, ℓ1-minimzation},
  mendeley-tags = {Folder - Beamforming special,Folder - Compressed Sensing},
  pmid          = {27913327},
}

@Article{Radha2019,
  author        = {Radha, R. and Sarvesh, K. and Sivananthan, S.},
  journal       = {Numerical Functional Analysis and Optimization},
  title         = {{Sampling and Reconstruction in a Shift Invariant Space with Multiple Generators}},
  year          = {2019},
  issn          = {15322467},
  month         = {oct},
  number        = {4},
  pages         = {365--385},
  volume        = {40},
  abstract      = {The aim of this paper is to study sampling and reconstruction in a shift invariant space with multiple generators. On contrary to the classical case of a shift invariant space with a single generator, it is shown that Z cannot be a stable set of sampling for V($\Phi$) where $\Phi$=$\Phi${ 1 , 2 ,..., n } when r ≥ 2. Further the problems of perturbation of a stable set of sampling and local reconstruction method are discussed along with an illustration and implementation.},
  doi           = {10.1080/01630563.2018.1501701},
  keywords      = {Folder - Generic Signal Processing, Frames, Laurent operator, Moore–Penrose inverse, Riesz basis, Wiener amalgam space, shift invariant space},
  language      = {en},
  mendeley-tags = {Folder - Generic Signal Processing},
  url           = {https://www.tandfonline.com/doi/full/10.1080/01630563.2018.1501701},
}

@incollection{Colton2019,
address = {Cham},
author = {Colton, David and Kress, Rainer},
booktitle = {Applied Mathematical Sciences (Switzerland)},
isbn = {978-3-030-30350-1 978-3-030-30351-8},
issn = {2196968X},
language = {en},
pages = {1--514},
publisher = {Springer International Publishing},
series = {Applied Mathematical Sciences},
title = {{Inverse acoustic and electromagnetic scattering theory: Fourth edition}},
url = {http://link.springer.com/10.1007/978-3-030-30351-8},
volume = {93},
year = {2019}
}

@article{Viti2012,
author = {Viti, Jacopo and Mori, Riccardo and Guidi, Francesco and Versluis, Michel and Jong, Nico De and Tortoli, Piero},
journal = {Ieee Transactions on Ultrasonics, Ferroelectrics, and Frequency Control},
keywords = {Folder - Contrast agent physics},
mendeley-tags = {Folder - Contrast agent physics},
number = {12},
pages = {2818--2824},
title = {{Nonlinear Oscillations of Deflating Bubbles}},
volume = {59},
year = {2012}
}

@Misc{Kincaid1996,
  author        = {Kincaid, David and Cheney, Ward},
  title         = {{Numerical Analysis: Mathematics of Scientific Computing (2nd ed.)}},
  year          = {1996},
  address       = {Providence, R.I},
  edition       = {3rd ed},
  isbn          = {978-0-8218-4788-6},
  keywords      = {Folder - wavefield_representation, Numerical analysis},
  language      = {en},
  mendeley-tags = {Folder - wavefield_representation,Numerical analysis},
  pages         = {xii, 804 p.},
  publisher     = {American Mathematical Society},
  series        = {The Sally series},
  shorttitle    = {Numerical analysis},
}

@misc{Helmke1996,
author = {Helmke, U. and Moore, J.},
booktitle = {IEEE Transactions on Automatic Control},
doi = {10.1109/TAC.1996.489224},
issn = {15582523},
language = {en},
number = {5},
pages = {769},
title = {{Optimization and Dynamical Systems}},
volume = {41},
year = {1996}
}

@Misc{Boehm2019,
  author        = {B{\"{o}}hm, Vanessa and Lanusse, Fran{\c{c}}ois and Seljak, Uro{\v{s}}},
  month         = {oct},
  title         = {{Uncertainty Quantification with Generative Models}},
  year          = {2019},
  abstract      = {We develop a generative model-based approach to Bayesian inverse problems, such as image reconstruction from noisy and incomplete images. Our framework addresses two common challenges of Bayesian reconstructions: 1) It makes use of complex, data-driven priors that comprise all available information about the uncorrupted data distribution. 2) It enables computationally tractable uncertainty quantification in the form of posterior analysis in latent and data space. The method is very efficient in that the generative model only has to be trained once on an uncorrupted data set, after that, the procedure can be used for arbitrary corruption types.},
  archiveprefix = {arXiv},
  arxivid       = {1910.10046},
  booktitle     = {arXiv},
  eprint        = {1910.10046},
  issn          = {23318422},
  keywords      = {Astrophysics - Cosmology and Nongalactic Astrophys, Computer Science - Machine Learning, Statistics - Machine Learning},
  language      = {en},
  mendeley-tags = {Astrophysics - Cosmology and Nongalactic Astrophys,Computer Science - Machine Learning,Statistics - Machine Learning},
  url           = {http://arxiv.org/abs/1910.10046},
}

@InProceedings{Xiang2019,
  author        = {Xiang, Jiaqi and Li, Qingdong and Dong, Xiwang and Ren, Zhang},
  booktitle     = {Proceedings - 2019 Chinese Automation Congress, CAC 2019},
  title         = {{Continuous Control with Deep Reinforcement Learning for Mobile Robot Navigation}},
  year          = {2019},
  month         = {jul},
  pages         = {1501--1506},
  abstract      = {Autonomous navigation is one of the focuses in the field of mobile robot research. The traditional method usually consists of two parts: building the map of environment, localization of mobile robot and path planning. However, these traditional methods usually rely on high-precision sensor information. At the same time, mobile robots have no intelligent understanding of autonomous navigation. In this article, a deep reinforcement learning method, i.e. soft actor critic, is used to navigate in a mapless environment. It takes laser scanning data and information of the target as input, outputs linear velocity and angular velocity in continuous space. The simulation shows that this learning-based end-to-end autonomous navigation method can accomplish tasks as well as traditional methods.},
  doi           = {10.1109/CAC48633.2019.8996652},
  isbn          = {9781728140940},
  keywords      = {Autonomous navigation, Computer Science - Machine Learning, Deep Reinforcement Learning, Mobile Robot, Soft Actor Critic, Statistics - Machine Learning},
  language      = {en},
  mendeley-tags = {Computer Science - Machine Learning,Statistics - Machine Learning},
  url           = {http://arxiv.org/abs/1509.02971},
}

@Misc{Lu2019a,
  author        = {Lu, You and Huang, Bert},
  month         = {feb},
  title         = {{Structured Output Learning with Conditional Generative Flows}},
  year          = {2019},
  abstract      = {Traditional structured prediction models try to learn the conditional likelihood, i.e., p(y|x), to capture the relationship between the structured output y and the input features x. For many models, computing the likelihood is intractable. These models are therefore hard to train, requiring the use of surrogate objectives or variational inference to approximate likelihood. In this paper, we propose conditional Glow (c-Glow), a conditional generative flow for structured output learning. C-Glow benefits from the ability of flow-based models to compute p(y|x) exactly and efficiently. Learning with c-Glow does not require a surrogate objective or performing inference during training. Once trained, we can directly and efficiently generate conditional samples to do structured prediction. We evaluate this approach on different structured prediction tasks and find c-Glow's structured outputs comparable in quality with state-of-the-art deep structured prediction approaches.},
  archiveprefix = {arXiv},
  arxivid       = {1905.13288},
  booktitle     = {arXiv},
  doi           = {10.1609/aaai.v34i04.5940},
  eprint        = {1905.13288},
  issn          = {23318422},
  keywords      = {Computer Science - Machine Learning, Statistics - Machine Learning},
  language      = {en},
  mendeley-tags = {Computer Science - Machine Learning,Statistics - Machine Learning},
  url           = {http://arxiv.org/abs/1905.13288},
}

@InProceedings{Bai2019,
  author        = {Bai, Shaojie and {Zico Kolter}, J. and Koltun, Vladlen},
  booktitle     = {Advances in Neural Information Processing Systems},
  title         = {{Deep equilibrium models}},
  year          = {2019},
  month         = {oct},
  volume        = {32},
  abstract      = {We present a new approach to modeling sequential data: the deep equilibrium model (DEQ). Motivated by an observation that the hidden layers of many existing deep sequence models converge towards some fixed point, we propose the DEQ approach that directly finds these equilibrium points via root-finding. Such a method is equivalent to running an infinite depth (weight-tied) feedforward network, but has the notable advantage that we can analytically backpropagate through the equilibrium point using implicit differentiation. Using this approach, training and prediction in these networks require only constant memory, regardless of the effective “depth” of the network. We demonstrate how DEQs can be applied to two state-of-the-art deep sequence models: self-attention transformers and trellis networks. On large-scale language modeling tasks, such as the WikiText-103 benchmark, we show that DEQs 1) often improve performance over these state-of-the-art models (for similar parameter counts); 2) have similar computational requirements to existing models; and 3) vastly reduce memory consumption (often the bottleneck for training large sequence models), demonstrating an up-to 88% memory reduction in our experiments.},
  file          = {:home/antonio/Documents/bibliography/files/Bai, Zico Kolter, Koltun - 2019 - Deep equilibrium models.pdf:pdf},
  issn          = {10495258},
  keywords      = {Computer Science - Machine Learning, Statistics - Machine Learning},
  language      = {en},
  mendeley-tags = {Computer Science - Machine Learning,Statistics - Machine Learning},
  url           = {http://arxiv.org/abs/1909.01377},
}

@article{Siahkoohi2019,
abstract = {Accurate forward modeling is important for solving inverse problems. An inaccurate wave-equation simulation, as a forward operator, will offset the results obtained via inversion. In this work, we consider the case where we deal with incomplete physics. One proxy of incomplete physics is an inaccurate discretization of Laplacian in simulation of wave equation via finite-difference method. We exploit intrinsic one-to-one similarities between timestepping algorithm with Convolutional Neural Networks (CNNs), and propose to intersperse CNNs between low-fidelity timesteps. Augmenting neural networks with low-fidelity timestepping algorithms may allow us to take large timesteps while limiting the numerical dispersion artifacts. While simulating the wave-equation with low-fidelity timestepping algorithm, by correcting the wavefield several time during propagation, we hope to limit the numerical dispersion artifact introduced by a poor discretization of the Laplacian. As a proof of concept, we demonstrate this principle by correcting for numerical dispersion by keeping the velocity model fixed, and varying the source locations to generate training and testing pairs for our supervised learning algorithm.},
archivePrefix = {arXiv},
arxivId = {1910.00925},
author = {Siahkoohi, Ali and Louboutin, Mathias and Herrmann, Felix J.},
eprint = {1910.00925},
file = {:home/antonio/Documents/bibliography/files/Siahkoohi, Louboutin, Herrmann - 2019 - Neural network augmented wave-equation simulation.pdf:pdf},
title = {{Neural network augmented wave-equation simulation}},
url = {http://arxiv.org/abs/1910.00925},
year = {2019}
}

@Article{Qin2019a,
  author        = {Qin, Tong and Wu, Kailiang and Xiu, Dongbin},
  journal       = {Journal of Computational Physics},
  title         = {{Data driven governing equations approximation using deep neural networks}},
  year          = {2019},
  issn          = {10902716},
  pages         = {620--635},
  volume        = {395},
  abstract      = {We present a numerical framework for approximating unknown governing equations using observation data and deep neural networks (DNN). In particular, we propose to use residual network (ResNet) as the basic building block for equation approximation. We demonstrate that the ResNet block can be considered as a one-step method that is exact in temporal integration. We then present two multi-step methods, recurrent ResNet (RT-ResNet) method and recursive ReNet (RS-ResNet) method. The RT-ResNet is a multi-step method on uniform time steps, whereas the RS-ResNet is an adaptive multi-step method using variable time steps. All three methods presented here are based on integral form of the underlying dynamical system. As a result, they do not require time derivative data for equation recovery and can cope with relatively coarsely distributed trajectory data. Several numerical examples are presented to demonstrate the performance of the methods.},
  archiveprefix = {arXiv},
  arxivid       = {1811.05537},
  doi           = {10.1016/j.jcp.2019.06.042},
  eprint        = {1811.05537},
  file          = {:home/antonio/Documents/bibliography/files/Qin, Wu, Xiu - 2019 - Data driven governing equations approximation using deep neural networks.pdf:pdf},
  keywords      = {Deep neural network, Governing equation discovery, Recurrent neural network, Residual network},
}

@article{Lutter2019,
abstract = {Deep learning has achieved astonishing results on many tasks with large amounts of data and generalization within the proximity of training data. For many important real-world applications, these requirements are unfeasible and additional prior knowledge on the task domain is required to overcome the resulting problems. In particular, learning physics models for model-based control requires robust extrapolation from fewer samples - often collected online in real-time - and model errors may lead to drastic damages of the system. Directly incorporating physical insight has enabled us to obtain a novel deep model learning approach that extrapolates well while requiring fewer samples. As a first example, we propose Deep Lagrangian Networks (DeLaN) as a deep network structure upon which Lagrangian Mechanics have been imposed. DeLaN can learn the equations of motion of a mechanical system (i.e., system dynamics) with a deep network efficiently while ensuring physical plausibility. The resulting DeLaN network performs very well at robot tracking control. The proposed method did not only outperform previous model learning approaches at learning speed but exhibits substantially improved and more robust extrapolation to novel trajectories and learns online in real-time.},
archivePrefix = {arXiv},
arxivId = {1907.04490},
author = {Lutter, Michael and Ritter, Christian and Peters, Jan},
eprint = {1907.04490},
file = {:home/antonio/Documents/bibliography/files/Lutter, Ritter, Peters - 2019 - Deep Lagrangian networks Using physics as model prior for deep learning.pdf:pdf},
journal = {7th International Conference on Learning Representations, ICLR 2019},
pages = {1--17},
title = {{Deep Lagrangian networks: Using physics as model prior for deep learning}},
year = {2019}
}

@Article{Rudd2015,
  author    = {Rudd, Keith and Ferrari, Silvia},
  journal   = {Neurocomputing},
  title     = {{A constrained integration (CINT) approach to solving partial differential equations using artificial neural networks}},
  year      = {2015},
  issn      = {18728286},
  pages     = {277--285},
  volume    = {155},
  abstract  = {This paper presents a novel constrained integration (CINT) method for solving initial boundary value partial differential equations (PDEs). The CINT method combines classical Galerkin methods with a constrained backpropogation training approach to obtain an artificial neural network representation of the PDE solution that approximately satisfies the boundary conditions at every integration step. The advantage of CINT over existing methods is that it is readily applicable to solving PDEs on irregular domains, and requires no special modification for domains with complex geometries. Furthermore, the CINT method provides a semi-analytical solution that is infinitely differentiable. In this paper the CINT method is demonstrated on two hyperbolic and one parabolic initial boundary value problems with a known analytical solutions that can be used for performance comparison. The numerical results show that, when compared to the most efficient finite element methods, the CINT method achieves significant improvements both in terms of computational time and accuracy.},
  doi       = {10.1016/j.neucom.2014.11.058},
  file      = {:home/antonio/Documents/bibliography/files/Rudd, Ferrari - 2015 - A constrained integration (CINT) approach to solving partial differential equations using artificial neural netwo.pdf:pdf},
  keywords  = {Galerkin methods, Initial-boundary value problem, Irregular domains, Neural networks, Partial differential equations, Spectral methods},
  publisher = {Elsevier},
  url       = {http://dx.doi.org/10.1016/j.neucom.2014.11.058},
}

@article{Beck2019,
abstract = {In this paper we introduce a numerical method for parabolic PDEs that combines operator splitting with deep learning. It divides the PDE approximation problem into a sequence of separate learning problems. Since the computational graph for each of the subproblems is comparatively small, the approach can handle extremely high-dimensional PDEs. We test the method on different examples from physics, stochastic control, and mathematical finance. In all cases, it yields very good results in up to 10,000 dimensions with short run times.},
archivePrefix = {arXiv},
arxivId = {1907.03452},
author = {Beck, Christian and Becker, Sebastian and Cheridito, Patrick and Jentzen, Arnulf and Neufeld, Ariel},
eprint = {1907.03452},
file = {:home/antonio/Documents/bibliography/files/Beck et al. - 2019 - Deep splitting method for parabolic PDEs.pdf:pdf},
title = {{Deep splitting method for parabolic PDEs}},
url = {http://arxiv.org/abs/1907.03452},
year = {2019}
}

@Article{Kutyniok2019,
  author        = {Kutyniok, Gitta and Petersen, Philipp and Raslan, Mones and Schneider, Reinhold},
  title         = {{A Theoretical Analysis of Deep Neural Networks and Parametric PDEs}},
  year          = {2019},
  abstract      = {We derive upper bounds on the complexity of ReLU neural networks approximating the solution maps of parametric partial differential equations. In particular, without any knowledge of its concrete shape, we use the inherent low-dimensionality of the solution manifold to obtain approximation rates which are significantly superior to those provided by classical approximation results. We use this low dimensionality to guarantee the existence of a reduced basis. Then, for a large variety of parametric partial differential equations, we construct neural networks that yield approximations of the parametric maps not suffering from a curse of dimension and essentially only depending on the size of the reduced basis.},
  archiveprefix = {arXiv},
  arxivid       = {1904.00377},
  eprint        = {1904.00377},
  file          = {:home/antonio/Documents/bibliography/files/Kutyniok et al. - 2019 - A Theoretical Analysis of Deep Neural Networks and Parametric PDEs.pdf:pdf},
  keywords      = {approximation rates, curse of dimension, deep neural networks, parametric pdes, reduced basis},
  url           = {http://arxiv.org/abs/1904.00377},
}

@article{Dockhorn2019,
abstract = {Can neural networks learn to solve partial differential equations (PDEs)? We investigate this question for two (systems of) PDEs, namely, the Poisson equation and the steady Navier--Stokes equations. The contributions of this paper are five-fold. (1) Numerical experiments show that small neural networks (< 500 learnable parameters) are able to accurately learn complex solutions for systems of partial differential equations. (2) It investigates the influence of random weight initialization on the quality of the neural network approximate solution and demonstrates how one can take advantage of this non-determinism using ensemble learning. (3) It investigates the suitability of the loss function used in this work. (4) It studies the benefits and drawbacks of solving (systems of) PDEs with neural networks compared to classical numerical methods. (5) It proposes an exhaustive list of possible directions of future work.},
archivePrefix = {arXiv},
arxivId = {1904.07200},
author = {Dockhorn, Tim},
eprint = {1904.07200},
file = {:home/antonio/Documents/bibliography/files/Dockhorn - 2019 - A Discussion on Solving Partial Differential Equations using Neural Networks.pdf:pdf},
title = {{A Discussion on Solving Partial Differential Equations using Neural Networks}},
url = {http://arxiv.org/abs/1904.07200},
year = {2019}
}

@Article{Lichtenstein2019,
  author        = {Lichtenstein, Moshe and Pai, Gautam and Kimmel, Ron},
  journal       = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  title         = {{Deep Eikonal Solvers}},
  year          = {2019},
  issn          = {16113349},
  pages         = {38--50},
  volume        = {11603 LNCS},
  abstract      = {A deep learning approach to numerically approximate the solution to the Eikonal equation is introduced. The proposed method is built on the fast marching scheme which comprises of two components: a local numerical solver and an update scheme. We replace the formulaic local numerical solver with a trained neural network to provide highly accurate estimates of local distances for a variety of different geometries and sampling conditions. Our learning approach generalizes not only to flat Euclidean domains but also to curved surfaces enabled by the incorporation of certain invariant features in the neural network architecture. We show a considerable gain in performance, validated by smaller errors and higher orders of accuracy for the numerical solutions of the Eikonal equation computed on different surfaces. The proposed approach leverages the approximation power of neural networks to enhance the performance of numerical algorithms, thereby, connecting the somewhat disparate themes of numerical geometry and learning.},
  archiveprefix = {arXiv},
  arxivid       = {1903.07973},
  doi           = {10.1007/978-3-030-22368-7_4},
  eprint        = {1903.07973},
  file          = {:home/antonio/Documents/bibliography/files/Lichtenstein, Pai, Kimmel - 2019 - Deep Eikonal Solvers.pdf:pdf},
  isbn          = {9783030223670},
  keywords      = {Deep learning for PDE, Geodesic distance, The Eikonal equation},
}

@Article{Li2020c,
  author        = {Li, Yixin and Hu, Xianliang},
  title         = {{An artificial neural network approximation for Cauchy inverse problems}},
  year          = {2020},
  pages         = {1--32},
  abstract      = {A novel artificial neural network method is proposed for solving Cauchy inverse problems. It allows multiple hidden layers with arbitrary width and depth, which theoretically yields better approximations to the inverse problems. In this research, the existence and convergence are shown to establish the well-posedness of neural network method for Cauchy inverse problems, and various numerical examples are presented to illustrate its accuracy and stability. The numerical examples are from different points of view, including time-dependent and time-independent cases, high spatial dimension cases up to 8D, and cases with noisy boundary data and singular computational domain. Moreover, numerical results also show that neural networks with wider and deeper hidden layers could lead to better approximation for Cauchy inverse problems.},
  archiveprefix = {arXiv},
  arxivid       = {2001.01413},
  eprint        = {2001.01413},
  file          = {:home/antonio/Documents/bibliography/files/Li, Hu - 2020 - An artificial neural network approximation for Cauchy inverse problems.pdf:pdf},
  keywords      = {artificial neural network, cauchy inverse problem, dimension, high, irregular domain, well-posedness},
  url           = {http://arxiv.org/abs/2001.01413},
}

@Article{KhodayiMehr2019,
  author        = {Khodayi-Mehr, Reza and Zavlanos, Michael M.},
  title         = {{VarNet: Variational Neural Networks for the Solution of Partial Differential Equations}},
  year          = {2019},
  abstract      = {In this paper we propose a new model-based unsupervised learning method, called VarNet, for the solution of partial differential equations (PDEs) using deep neural networks (NNs). Particularly, we propose a novel loss function that relies on the variational (integral) form of PDEs as apposed to their differential form which is commonly used in the literature. Our loss function is discretization-free, highly parallelizable, and more effective in capturing the solution of PDEs since it employs lower-order derivatives and trains over measure non-zero regions of space-time. Given this loss function, we also propose an approach to optimally select the space-time samples, used to train the NN, that is based on the feedback provided from the PDE residual. The models obtained using VarNet are smooth and do not require interpolation. They are also easily differentiable and can directly be used for control and optimization of PDEs. Finally, VarNet can straight-forwardly incorporate parametric PDE models making it a natural tool for model order reduction (MOR) of PDEs. We demonstrate the performance of our method through extensive numerical experiments for the advection-diffusion PDE as an important case-study.},
  archiveprefix = {arXiv},
  arxivid       = {1912.07443},
  eprint        = {1912.07443},
  file          = {:home/antonio/Documents/bibliography/files/Khodayi-Mehr, Zavlanos - 2019 - VarNet Variational Neural Networks for the Solution of Partial Differential Equations.pdf:pdf},
  groups        = {PDEs and neural networks},
  url           = {http://arxiv.org/abs/1912.07443},
}

@article{Simeoni2019a,
author = {Simeoni, Matthieu and Hurley, Paul and Vetterli, Martin},
file = {:home/antonio/Documents/bibliography/files/Simeoni, Hurley, Vetterli - 2019 - DeepWave A Recurrent Neural-Network for Real-Time Acoustic Imaging Supplementary Material.pdf:pdf},
number = {200021},
pages = {1--13},
title = {{DeepWave : A Recurrent Neural-Network for Real-Time Acoustic Imaging Supplementary Material}},
year = {2019}
}

@Article{Berg2018,
  author        = {Berg, Jens and Nystr{\"{o}}m, Kaj},
  journal       = {Neurocomputing},
  title         = {{A unified deep artificial neural network approach to partial differential equations in complex geometries}},
  year          = {2018},
  issn          = {18728286},
  month         = {nov},
  pages         = {28--41},
  volume        = {317},
  abstract      = {In this paper, we use deep feedforward artificial neural networks to approximate solutions to partial differential equations in complex geometries. We show how to modify the backpropagation algorithm to compute the partial derivatives of the network output with respect to the space variables which is needed to approximate the differential operator. The method is based on an ansatz for the solution which requires nothing but feedforward neural networks and an unconstrained gradient based optimization method such as gradient descent or a quasi-Newton method. We show an example where classical mesh based methods cannot be used and neural networks can be seen as an attractive alternative. Finally, we highlight the benefits of deep compared to shallow neural networks and device some other convergence enhancing techniques.},
  archiveprefix = {arXiv},
  arxivid       = {1711.06464},
  doi           = {10.1016/j.neucom.2018.06.056},
  eprint        = {1711.06464},
  groups        = {PDEs and neural networks},
  keywords      = {Advection, Complex geometries, Deep neural networks, Diffusion, Partial differential equations},
  publisher     = {Elsevier B.V.},
}

@article{Han2020,
abstract = {We introduce a deep neural network based method for solving a class of elliptic partial differential equations. We approximate the solution of the PDE with a deep neural network which is trained under the guidance of a probabilistic representation of the PDE in the spirit of the Feynman-Kac formula. The solution is given by an expectation of a martingale process driven by a Brownian motion. As Brownian walkers explore the domain, the deep neural network is iteratively trained using a form of reinforcement learning. Our method is a 'Derivative-Free Loss Method' since it does not require the explicit calculation of the derivatives of the neural network with respect to the input neurons in order to compute the training loss. The advantages of our method are showcased in a series of test problems: a corner singularity problem, an interface problem, and an application to a chemotaxis population model.},
archivePrefix = {arXiv},
arxivId = {2001.06145},
author = {Han, Jihun and Nica, Mihai and Stinchcombe, Adam R},
eprint = {2001.06145},
file = {:home/antonio/Documents/bibliography/files/Han, Nica, Stinchcombe - 2020 - A Derivative-Free Method for Solving Elliptic Partial Differential Equations with Deep Neural Networks.pdf:pdf},
month = {jan},
title = {{A Derivative-Free Method for Solving Elliptic Partial Differential Equations with Deep Neural Networks}},
url = {http://arxiv.org/abs/2001.06145},
year = {2020}
}

@Article{Yang2019,
  author        = {Yang, Yibo and Perdikaris, Paris},
  journal       = {Journal of Computational Physics},
  title         = {{Adversarial uncertainty quantification in physics-informed neural networks}},
  year          = {2019},
  issn          = {10902716},
  pages         = {136--152},
  volume        = {394},
  abstract      = {We present a deep learning framework for quantifying and propagating uncertainty in systems governed by non-linear differential equations using physics-informed neural networks. Specifically, we employ latent variable models to construct probabilistic representations for the system states, and put forth an adversarial inference procedure for training them on data, while constraining their predictions to satisfy given physical laws expressed by partial differential equations. Such physics-informed constraints provide a regularization mechanism for effectively training deep generative models as surrogates of physical systems in which the cost of data acquisition is high, and training data-sets are typically small. This provides a flexible framework for characterizing uncertainty in the outputs of physical systems due to randomness in their inputs or noise in their observations that entirely bypasses the need for repeatedly sampling expensive experiments or numerical simulators. We demonstrate the effectiveness of our approach through a series of examples involving uncertainty propagation in non-linear conservation laws, and the discovery of constitutive laws for flow through porous media directly from noisy data.},
  archiveprefix = {arXiv},
  arxivid       = {1811.04026},
  doi           = {10.1016/j.jcp.2019.05.027},
  eprint        = {1811.04026},
  file          = {:home/antonio/Documents/bibliography/files/Yang, Perdikaris - 2019 - Adversarial uncertainty quantification in physics-informed neural networks.pdf:pdf;:home/antonio/Downloads/1811.04026.pdf:pdf},
  keywords      = {Data-driven modeling, Generative adversarial networks, Probabilistic deep learning, Probabilistic scientific computing, Variational inference},
  publisher     = {Elsevier Inc.},
  url           = {https://doi.org/10.1016/j.jcp.2019.05.027},
}

@article{Nowozin2016,
abstract = {Generative neural samplers are probabilistic models that implement sampling using feedforward neural networks: they take a random input vector and produce a sample from a probability distribution defined by the network weights. These models are expressive and allow efficient computation of samples and derivatives, but cannot be used for computing likelihoods or for marginalization. The generative-adversarial training method allows to train such models through the use of an auxiliary discriminative neural network. We show that the generative-adversarial approach is a special case of an existing more general variational divergence estimation approach. We show that any f-divergence can be used for training generative neural samplers. We discuss the benefits of various choices of divergence functions on training complexity and the quality of the obtained generative models.},
archivePrefix = {arXiv},
arxivId = {1606.00709},
author = {Nowozin, Sebastian and Cseke, Botond and Tomioka, Ryota},
eprint = {1606.00709},
file = {:home/antonio/Documents/bibliography/files/Nowozin, Cseke, Tomioka - 2016 - f-GAN Training generative neural samplers using variational divergence minimization.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
pages = {271--279},
title = {{f-GAN: Training generative neural samplers using variational divergence minimization}},
year = {2016}
}

@article{Bezenac,
archivePrefix = {arXiv},
arxivId = {arXiv:1711.07970v2},
author = {B{\'{e}}zenac, Emmanuel De and Pajot, Arthur and Gallinari, Patrick},
eprint = {arXiv:1711.07970v2},
file = {:home/antonio/Documents/bibliography/files/B{\'{e}}zenac, Pajot, Gallinari - Unknown - Deep Learning for Physical Processes Incorporating Prior Scientific Knowledge.pdf:pdf},
title = {{Deep Learning for Physical Processes : Incorporating Prior Scientific Knowledge}}
}

@Article{Article2018,
  author   = {Article, Original},
  title    = {{Diagnostic Accuracy of a Machine-Learning Approach to Coronary Computed Tomographic Angiography–Based Fractional Flow Reserve}},
  year     = {2018},
  number   = {June},
  pages    = {1--11},
  doi      = {10.1161/CIRCIMAGING.117.007217},
  file     = {:home/antonio/Documents/bibliography/files/Article - 2018 - Diagnostic Accuracy of a Machine-Learning Approach to Coronary Computed Tomographic Angiography–Based Fractional Flow.pdf:pdf},
  keywords = {area under curve, computed tomography angiography, coronary artery disease, hemodynamics, machine learning},
}

@article{Itu2019,
author = {Itu, Lucian and Rapaka, Saikiran and Passerini, Tiziano and Georgescu, Bogdan and Schwemmer, Chris and Schoebinger, Max and Flohr, Thomas and Sharma, Puneet and Comaniciu, Dorin},
doi = {10.1152/japplphysiol.00752.2015},
file = {:home/antonio/Documents/bibliography/files/Itu et al. - 2019 - A machine-learning approach for computation of fractional flow reserve from coronary computed tomography.pdf:pdf},
pages = {42--52},
title = {{A machine-learning approach for computation of fractional flow reserve from coronary computed tomography}},
year = {2019}
}

@article{Lu2017a,
archivePrefix = {arXiv},
arxivId = {arXiv:1707.03351v2},
author = {Lu, Jianfeng},
eprint = {arXiv:1707.03351v2},
file = {:home/antonio/Documents/bibliography/files/Lu - 2017 - Solving parametric PDE problems with artificial neural networks.pdf:pdf},
pages = {1--12},
title = {{Solving parametric PDE problems with artificial neural networks}},
year = {2017}
}

@article{Choromanska2015,
author = {Choromanska, Anna and Henaff, Mikael and Mathieu, Michael},
file = {:home/antonio/Documents/bibliography/files/Choromanska, Henaff, Mathieu - 2015 - The Loss Surfaces of Multilayer Networks.pdf:pdf},
title = {{The Loss Surfaces of Multilayer Networks}},
volume = {38},
year = {2015}
}

@Article{Oymak2017,
  author        = {Oymak, Samet and Soltanolkotabi, Mahdi},
  journal       = {SIAM Journal on Optimization},
  title         = {{Fast and reliable parameter estimation from nonlinear observations}},
  year          = {2017},
  issn          = {10526234},
  number        = {4},
  pages         = {2276--2300},
  volume        = {27},
  abstract      = {In this paper we study the problem of recovering a structured but unknown parameter $\theta$∗ from n nonlinear observations of the form yi = f(xi, $\theta$∗) for i = 1, 2, . . ., n. We develop a framework for characterizing time-data trade-offs for a variety of parameter estimation algorithms when the nonlinear function f is unknown. This framework includes many popular heuristics such as projected/proximal gradient descent and stochastic schemes. For example, we show that a projected gradient descent scheme converges at a linear rate to a reliable solution with a near minimal number of samples. We provide a sharp characterization of the convergence rate of such algorithms as a function of sample size, amount of a priori knowledge available about the parameter, and a measure of the nonlinearity of the function f. These results provide a precise understanding of the various trade-offs involved between statistical and computational resources as well as a priori side information available for such nonlinear parameter estimation problems.},
  archiveprefix = {arXiv},
  arxivid       = {1610.07108},
  doi           = {10.1137/17M1113874},
  eprint        = {1610.07108},
  file          = {:home/antonio/Documents/bibliography/files/Oymak, Soltanolkotabi - 2017 - Fast and reliable parameter estimation from nonlinear observations.pdf:pdf},
  keywords      = {Nonlinear estimation, Projected gradient descent, Quantization, Sparsity},
}

@article{Sapiro2018,
author = {Sapiro, Guillermo},
file = {:home/antonio/Documents/bibliography/files/Sapiro - 2018 - Tradeoffs Between Convergence Speed and Reconstruction Accuracy in Inverse Problems.pdf:pdf},
number = {7},
pages = {1676--1690},
title = {{Tradeoffs Between Convergence Speed and Reconstruction Accuracy in Inverse Problems}},
volume = {66},
year = {2018}
}

@article{Curtis2017,
archivePrefix = {arXiv},
arxivId = {arXiv:1706.10207v1},
author = {Curtis, Frank E and Scheinberg, Katya},
eprint = {arXiv:1706.10207v1},
file = {:home/antonio/Documents/bibliography/files/Curtis, Scheinberg - 2017 - Optimization Methods for Supervised Machine Learning From Linear Models to Deep Learning.pdf:pdf},
pages = {1--27},
title = {{Optimization Methods for Supervised Machine Learning : From Linear Models to Deep Learning}},
year = {2017}
}

@article{Cranmer2019,
archivePrefix = {arXiv},
arxivId = {arXiv:1909.05862v2},
author = {Cranmer, Miles D and Battaglia, Peter},
eprint = {arXiv:1909.05862v2},
file = {:home/antonio/Documents/bibliography/files/Cranmer, Battaglia - 2019 - Learning Symbolic Physics with Graph Networks.pdf:pdf},
number = {NeurIPS},
title = {{Learning Symbolic Physics with Graph Networks}},
year = {2019}
}

@article{Qin,
archivePrefix = {arXiv},
arxivId = {arXiv:1806.04066v1},
author = {Qin, Chen and Bai, Wenjia and Schlemper, Jo and Petersen, Steffen E and Stefan, K and Jun, C V},
eprint = {arXiv:1806.04066v1},
file = {:home/antonio/Documents/bibliography/files/Qin et al. - Unknown - Joint Learning of Motion Estimation and Segmentation for Cardiac MR Image Sequences.pdf:pdf},
title = {{Joint Learning of Motion Estimation and Segmentation for Cardiac MR Image Sequences}}
}

@article{Coskun,
archivePrefix = {arXiv},
arxivId = {arXiv:1708.01885v1},
author = {Coskun, Huseyin and Achilles, Felix and Dipietro, Robert and Navab, Nassir and Tombari, Federico},
eprint = {arXiv:1708.01885v1},
file = {:home/antonio/Documents/bibliography/files/Coskun et al. - Unknown - Long Short-Term Memory Kalman Filters Recurrent Neural Estimators for Pose Regularization.pdf:pdf},
title = {{Long Short-Term Memory Kalman Filters : Recurrent Neural Estimators for Pose Regularization}}
}

@inproceedings{DeCruyenaere2003,
author = {DeCruyenaere, J.P. and Hafez, H.M.},
doi = {10.1109/ijcnn.1992.227334},
file = {:home/antonio/Documents/bibliography/files/DeCruyenaere, Hafez - 2003 - A comparison between Kalman filters and recurrent neural networks.pdf:pdf},
pages = {247--251},
title = {{A comparison between Kalman filters and recurrent neural networks}},
year = {2003}
}

@Article{Davoli2016,
  author   = {Davoli, Elisa},
  title    = {{OPTIMAL PARAMETERS AND REGULARIZERS FOR IMAGE}},
  year     = {2016},
  pages    = {1--20},
  file     = {:home/antonio/Documents/bibliography/files/Davoli - 2016 - OPTIMAL PARAMETERS AND REGULARIZERS FOR IMAGE.pdf:pdf},
  keywords = {and phrases, computer, fractional derivative, infimal convolution, optimization and control, vision and pattern recognition},
}

@article{Optimization2013,
author = {Optimization, Nonsmooth Pde-constrained},
doi = {10.3934/ipi.2013.7.1183},
file = {:home/antonio/Documents/bibliography/files/Optimization - 2013 - Image denoising Learning the noise model via nonsmooth PDE-constrained optimization.pdf:pdf},
number = {November},
title = {{Image denoising : Learning the noise model via nonsmooth PDE-constrained optimization}},
year = {2013}
}

@article{Reyes2016,
author = {Reyes, J C De Los and Sch{\"{o}}nlieb, C and Valkonen, T},
doi = {10.1016/j.jmaa.2015.09.023},
file = {:home/antonio/Documents/bibliography/files/Reyes, Sch{\"{o}}nlieb, Valkonen - 2016 - The structure of optimal parameters for image restoration problems.pdf:pdf},
issn = {0022-247X},
journal = {Journal of Mathematical Analysis and Applications},
number = {1},
pages = {464--500},
publisher = {Elsevier Inc.},
title = {{The structure of optimal parameters for image restoration problems}},
url = {http://dx.doi.org/10.1016/j.jmaa.2015.09.023},
volume = {434},
year = {2016}
}

@book{Profile2015,
archivePrefix = {arXiv},
arxivId = {arXiv:1508.07243v1},
author = {Profile, S E E},
doi = {10.1007/s10851-016-0662-8},
eprint = {arXiv:1508.07243v1},
file = {:home/antonio/Documents/bibliography/files/Profile - 2015 - Bilevel Parameter Learning for Higher-Order Total Variation Regularisation.pdf:pdf},
isbn = {1085101606},
number = {August},
title = {{Bilevel Parameter Learning for Higher-Order Total Variation Regularisation}},
year = {2015}
}

@Article{Kunisch2013,
  author   = {Kunisch, Karl and Pock, Thomas},
  title    = {{A Bilevel Optimization Approach for Parameter Learning in Variational Models ∗}},
  year     = {2013},
  number   = {2},
  pages    = {938--983},
  volume   = {6},
  file     = {:home/antonio/Documents/bibliography/files/Kunisch, Pock - 2013 - A Bilevel Optimization Approach for Parameter Learning in Variational Models ∗.pdf:pdf},
  keywords = {10, 1137, 120882706, 49j52, 49n45, 68u10, ams subject classifications, bilevel, doi, image denoising, learning theory, nondifferentiable optimization, optimization, regularization parameter, semismooth newton algorithm},
}

@Article{Grohs2017,
  author        = {Grohs, Philipp and Kutyniok, Gitta and Petersen, Philipp},
  title         = {{Networks}},
  year          = {2017},
  pages         = {1--29},
  archiveprefix = {arXiv},
  arxivid       = {arXiv:1705.01714v1},
  eprint        = {arXiv:1705.01714v1},
  file          = {:home/antonio/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Grohs, Kutyniok, Petersen - 2017 - Networks.pdf:pdf},
  keywords      = {41a25, 41a46, 42c15, 42c40, 68t05, 82c32, 94a12, 94a34, ams subject classification, connectivity, deep neural networks, function approximation, optimal sparse approximation, shearlets, sparse},
}

@article{Chang,
archivePrefix = {arXiv},
arxivId = {arXiv:1703.09912v1},
author = {Chang, J H Rick and Li, Chun-liang and Sankaranarayanan, Aswin C},
eprint = {arXiv:1703.09912v1},
file = {:home/antonio/Documents/bibliography/files/Chang, Li, Sankaranarayanan - Unknown - One Network to Solve Them All — Solving Linear Inverse Problems using Deep Projection Models.pdf:pdf},
pages = {1--12},
title = {{One Network to Solve Them All — Solving Linear Inverse Problems using Deep Projection Models}}
}

@article{Smith2018,
author = {Smith, Samuel L and Le, Quoc V},
file = {:home/antonio/Documents/bibliography/files/Smith, Le - 2018 - A B AYESIAN P ERSPECTIVE ON G ENERALIZATION AND.pdf:pdf},
number = {2016},
pages = {1--13},
title = {{A B AYESIAN P ERSPECTIVE ON G ENERALIZATION AND}},
year = {2018}
}

@Article{Cohen2009,
  author   = {Cohen, Albert and Dahmen, Wolfgang and Devore, Ronald},
  title    = {{AND BEST k -TERM APPROXIMATION}},
  year     = {2009},
  number   = {1},
  pages    = {211--231},
  volume   = {22},
  file     = {:home/antonio/Documents/bibliography/files/Cohen, Dahmen, Devore - 2009 - AND BEST k -TERM APPROXIMATION.pdf:pdf},
  keywords = {1 -minimization, and phrases, best k -term approximation, coders, compressed sensing, gauss-, gelfand width, ian and bernoulli ensembles, instance optimal de-, instance optimality in, mixed instance optimality, null space property, random matrices, restricted isometry property},
}

@article{Ravishankar,
archivePrefix = {arXiv},
arxivId = {arXiv:1904.02816v1},
author = {Ravishankar, Saiprasad and Ye, Jong Chul and Member, Senior and Fessler, Jeffrey A},
eprint = {arXiv:1904.02816v1},
file = {:home/antonio/Documents/bibliography/files/Ravishankar et al. - Unknown - Image Reconstruction From Sparsity to Data-adaptive Methods and Machine Learning.pdf:pdf},
pages = {1--20},
title = {{Image Reconstruction : From Sparsity to Data-adaptive Methods and Machine Learning}}
}

@article{Schmidt2009,
author = {Schmidt, Michael and Lipson, Hod},
file = {:home/antonio/Documents/bibliography/files/Schmidt, Lipson - 2009 - Distilling Free-Form Natural Laws.pdf:pdf},
number = {April},
pages = {81--86},
title = {{Distilling Free-Form Natural Laws}},
volume = {324},
year = {2009}
}

@article{Welling,
archivePrefix = {arXiv},
arxivId = {arXiv:1312.6114v10},
author = {Welling, Max},
eprint = {arXiv:1312.6114v10},
file = {:home/antonio/Documents/bibliography/files/Welling - Unknown - Auto-Encoding Variational Bayes arXiv 1312 . 6114v10 stat . ML 1 May 2014.pdf:pdf},
number = {Ml},
pages = {1--14},
title = {{Auto-Encoding Variational Bayes arXiv : 1312 . 6114v10 [ stat . ML ] 1 May 2014}}
}

@article{Embeddings,
archivePrefix = {arXiv},
arxivId = {arXiv:1301.1942v2},
author = {Embeddings, Random and Wang, Ziyu and Hutter, Frank and Matheson, David},
eprint = {arXiv:1301.1942v2},
file = {:home/antonio/Documents/bibliography/files/Embeddings et al. - Unknown - Bayesian Optimization in a Billion Dimensions via Random Embeddings.pdf:pdf},
number = {1},
pages = {1--33},
title = {{Bayesian Optimization in a Billion Dimensions via Random Embeddings}}
}

@article{Gal2016,
author = {Gal, Yarin},
file = {:home/antonio/Documents/bibliography/files/Gal - 2016 - Uncertainty in Deep Learning.pdf:pdf},
number = {September},
title = {{Uncertainty in Deep Learning}},
year = {2016}
}

@Article{Calatroni,
  author        = {Calatroni, Luca and Road, Wilberforce and Chung, Cao and Reyes, Juan Carlos De Los and Road, Wilberforce and Valkonen, Tuomo and Road, Wilberforce},
  title         = {{Bilevel approaches for learning of variational imaging models}},
  number        = {1},
  pages         = {1--24},
  archiveprefix = {arXiv},
  arxivid       = {arXiv:1505.02120v1},
  eprint        = {arXiv:1505.02120v1},
  file          = {:home/antonio/Documents/bibliography/files/Calatroni et al. - Unknown - Bilevel approaches for learning of variational imaging models.pdf:pdf},
  keywords      = {49j21, 49j40, 49k20, 65k10, 68t05, 68u10, 90c53, bilevel optimisation, classification, image denoising, supervised learning, variational methods},
}

@article{Calatroni2014,
archivePrefix = {arXiv},
arxivId = {arXiv:1403.1278v1},
author = {Calatroni, Luca},
doi = {10.1007/978-3-662-45504-3},
eprint = {arXiv:1403.1278v1},
file = {:home/antonio/Documents/bibliography/files/Calatroni - 2014 - Dynamic Sampling Schemes for Optimal Noise Learning Under Multiple Nonsmooth Constraints.pdf:pdf},
isbn = {9783662455043},
number = {March},
title = {{Dynamic Sampling Schemes for Optimal Noise Learning Under Multiple Nonsmooth Constraints}},
year = {2014}
}

@article{Bengio2015,
abstract = {Many signal categories in vision and auditory problems are invariant to the action of transformation groups, such as translations, rotations or frequency transpositions. This propertymotivates the study of signal representations which are also invariant to the action of these transformation groups. For instance, translation invariance can be achievedwith a registration orwith auto-correlationmeasures.},
archivePrefix = {arXiv},
arxivId = {1411.4555v1},
author = {Bengio, Yoshua and Goodfellow, Ian J. and Courville, Aaron},
eprint = {1411.4555v1},
file = {:home/antonio/Documents/bibliography/files/Bengio, Goodfellow, Courville - 2015 - CHAPTER 9. Convolutional Networks.pdf:pdf},
isbn = {9780262035613},
issn = {15284972},
journal = {Mit Press},
pages = {334--376},
title = {{CHAPTER 9. Convolutional Networks}},
year = {2015}
}

@article{Bengio2015a,
abstract = {One of the early ideas found in machine learning and statistical models of the 80's is that of sharing parameters 1 across different parts of a model, allowing to extend and apply the model to examples of different forms and generalize across them, e.g. with examples of different lengths, in the case of sequential data. This can be found in hidden Markov models (HMMs) (Rabiner and Juang, 1986), which were the dominant technique for speech recognition for about 30 years. These models of sequences are described a bit more in Section 10.9.3 and involve parameters, such as the state-to-state transition matrix P (s t | s t−1), which are re-used for every time step t, i.e., the above probability depends only on the value of s t and s t−1 but not on t as such. This allows one to model variable length sequences, whereas if we had specific parameters for each value of t, we could not generalize to sequence lengths not seen during training, nor share statistical strength across different sequence lengths and across different positions in time. Such sharing is particularly important when, like in speech, the input sequence can be stretched non-linearly, i.e., some parts (like vowels) may last longer in different examples. It means that the absolute time step at which an event occurs is meaningless: it only makes sense to consider the event in some context that somehow captures what has happened before. This sharing across time can also be found in a recurrent neural network (Rumelhart et al., 1986c) or RNN 2 : the same weights are used for different instances of the artificial neurons at different time steps, allowing us to apply the network to input sequences of different lengths. This idea is made more 1 see Section 7.8 for an introduction to the concept of parameter sharing 2 Unfortunately, the RNN acronym is sometimes also used for denoting Recursive Neural Networks. However, since the RNN acronym has been around for much longer, we suggest keeping this acronym for Recurrent Neural Networks. 308 CHAPTER 10. SEQUENCE MODELING: RECURRENT AND RECURSIVE NETS explicit in the early work on time-delay neural networks (Lang and Hinton, 1988; Waibel et al., 1989), where a fully connected network is replaced by one with local connections that are shared across different temporal instances of the hidden units. Such networks are among the ancestors of convolutional neural networks, covered in more detail in Section 9. Recurrent nets are covered below in Section 10.2. As shown in Section 10.},
author = {Bengio, Yoshua and Goodfellow, Ian J. and Courville, Aaron},
file = {:home/antonio/Documents/bibliography/files/Bengio, Goodfellow, Courville - 2015 - Sequence Modeling Recurrent and Recursive Nets.pdf:pdf},
journal = {Deep Learning},
pages = {324--365},
title = {{Sequence Modeling : Recurrent and Recursive Nets}},
year = {2015}
}

@incollection{Posarnentier1999,
abstract = {Successfully applying deep learning techniques requires more than just a good knowledge of what algorithms exist and the principles that explain how they work. A good machine learning practitioner also needs to know how to choose an algorithm for a particular application and how to monitor and respond to feedback obtained from experiments in order to improve a machine learning system. During day to day development of machine learning systems, practitioners need to decide whether to gather more data, increase or decrease model capacity, add or remove regularizing features, improve the optimization of a model, improve approximate inference in a model, or debug the software implementation of the model. All of these operations are at the very least time-consuming to try out, so it is important to be able to determine the right course of action rather than blindly guessing. Most of this book is about different machine learning models, training algo-rithms, and objective functions. This may give the impression that the most important ingredient to being a machine learning expert is knowing a wide variety of machine learning techniques and being good at different kinds of math. In prac-tice, one can usually do much better with a correct application of a commonplace algorithm than by sloppily applying an obscure algorithm. Correct application of an algorithm depends on mastering some fairly simple methodology. Many of the recommendations in this chapter are adapted from (). Ng 2015 We recommend the following practical design process:},
author = {Posarnentier, Henry W. and Allen, George P.},
booktitle = {Siliciclastic Sequence Stratigraphy},
doi = {10.2110/csp.99.07.0175},
file = {:home/antonio/Documents/bibliography/files/Posarnentier, Allen - 1999 - Practical Methodology.pdf:pdf},
pages = {175--184},
title = {{Practical Methodology}},
year = {1999}
}

@article{Learning,
author = {Learning, Large-scale Deep},
file = {:home/antonio/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Learning - Unknown - Applications.pdf:pdf},
pages = {443--485},
title = {{Applications}}
}

@article{Glorot2011,
author = {Glorot, Xavier and Bordes, Antoine},
file = {:home/antonio/Documents/bibliography/files/Glorot, Bordes - 2011 - Deep Sparse Rectifier Neural Networks.pdf:pdf},
pages = {315--323},
title = {{Deep Sparse Rectifier Neural Networks}},
volume = {15},
year = {2011}
}

@article{Goodfellowa,
author = {Goodfellow, Ian},
file = {:home/antonio/Documents/bibliography/files/Goodfellow - Unknown - Deep Learning.pdf:pdf},
title = {{Deep Learning}}
}

@article{Lecun2015,
author = {Lecun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
doi = {10.1038/nature14539},
file = {:home/antonio/Documents/bibliography/files/Lecun, Bengio, Hinton - 2015 - Deep learning.pdf:pdf},
title = {{Deep learning}},
year = {2015}
}

@Article{Samek,
  author        = {Samek, Wojciech},
  title         = {{Methods for Interpreting and Understanding Deep Neural Networks}},
  archiveprefix = {arXiv},
  arxivid       = {arXiv:1706.07979v1},
  eprint        = {arXiv:1706.07979v1},
  file          = {:home/antonio/Documents/bibliography/files/Samek - Unknown - Methods for Interpreting and Understanding Deep Neural Networks.pdf:pdf},
  keywords      = {activation maximization, deep neural networks, layer-wise, relevance propagation, sensitivity analysis, taylor decomposition},
}

@article{Goodfellow2016a,
abstract = {The panoramic history of this book is described in the prefaces of its Russian editions. It has taken to a chequered and not customary course of development; to start with it was a small elementary book for teenagers based on a lecture delivered by one of us 23 years ago to a group of Moscow high school students. The primary aim of the book was to expose the relationship of certain mathematical recreation exercises with rather serious and very interesting mathematical methods developed recently in engineering sciences in order to stimulate young readers' interest in modern mathematics. Later, however, the book began to live independently of our wishes. We received a lot of letters and comments from our readers and almost all of them turned out to be grown-ups having no leisure for recreations but seriously interested in the information theory. Therefore, we changed considerably the scope of our book in the second and third editions in an effort to meet the demands of the new (and, as we discovered, the predominant) category of our readers. As a result, the book developed into a thick volume intended for a wide community of people interested in various applications of the modern information theory, but having no special mathematical background (in fact, even the requirement of the knowledge of elementary differential calculus is dispensed with in our book).\nThe book scored a remarkable success in other countries also, and this was obviously caused by a widespread interest in the ideas of information theory all over the world. The book was translated into at least 10 foreign languages and some of the translations underwent several editions which differed from each other (and also from all the corresponding Russian editions since, wherever possible, we tried to send to the publishers some supplementary material). However, for a long time the opportunity of the publication of English translation kept on eluding us. We received twice letters from publishers of repute (one in the U.S.A. and the other in U.K.), seeking our permission to publish the English edition of the book. In both the cases, we gave the permission and even sent some corrections and supplements. It seems to us that on both the occasions the translation work was started but then some technical difficulties thwarted the completion of the work. Therefore, we are happy that Hindustan Publishing Corporation have finally published the English translation of our book and thus made it accessible to a wide circle of new readers.\nThe English edition differs from all the previous ones. Besides the minor corrections and improvements, we have completely revised (and considerably extended) Section 4.3, for it is clear that the discussion of the amount of information contained in the spoken and written text messages must now be based on the data related to the English (and not Russian) language. We have also enlarged the concluding Section 4.5 by supplementing it with a description of the method of constructing the practically important Bose-Chandhuri-Hocquenghem error-correcting codes. This necessitated the inclusion of some additional material in Appendix II at the end of the book, since the role of this appendix was widened further in comparison to the Russian edition. In order to update the book, Section 4.3 has been further reinforced by inclusion of the description of some latest works though, of course, it is not possible to claim that we have covered all recent papers, which are too numerous to cater for. We have also added a new Appendix IV which contains a short table of the function h(p) = — p log p — (1 — p) log (1 — p), keeping in view the usefulness of such table for educational purposes, which is one of the avowed objectives of the book.\nWe are glad to express here our appreciation to Hindustan Publishing Corporation for production of the book and to Drs. B. Mandelbrot, T. M. Cover and T. Nemetz who have sent us some new material used in the preparation of the present edition.},
author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
file = {:home/antonio/Documents/bibliography/files/Goodfellow, Bengio, Courville - 2016 - Chapter 3 Probability and Information Theory.pdf:pdf},
isbn = {9780511755262},
issn = {1422-6405},
journal = {http://www.deeplearningbook.org/},
pages = {34--53},
title = {{Chapter 3: Probability and Information Theory}},
url = {http://www.deeplearningbook.org/},
volume = {3},
year = {2016}
}

@incollection{Wong2009,
author = {Wong, Alfred Kwok-Kit},
booktitle = {Optical Imaging in Projection Microlithography},
doi = {10.1117/3.612961.ch8},
file = {:home/antonio/Documents/bibliography/files/Wong - 2009 - Numerical Computation.pdf:pdf},
pages = {151--163},
title = {{Numerical Computation}},
year = {2009}
}

@article{Goodfellow2016b,
abstract = {Deep feedforward networks, also often called feedforward neural networks, or multilayer perceptrons (MLPs), are the quintessential deep learning models. The goal of a feedforward network is to approximate some function f * . For example, for a classifier, y = f * (x) maps an input x to a category y. A feedforward network defines a mapping y = f (x; $\theta$) and learns the value of the parameters $\theta$ that result in the best function approximation. These models are called feedforward because information flows through the function being evaluated from x, through the intermediate computations used to define f , and finally to the output y. There are no feedback connections in which outputs of the model are fed back into itself. When feedforward neural networks are extended to include feedback connections, they are called recurrent neural networks, presented in chapter . 10 Feedforward networks are of extreme importance to machine learning practi-tioners. They form the basis of many important commercial applications. For example, the convolutional networks used for object recognition from photos are a specialized kind of feedforward network. Feedforward networks are a conceptual stepping stone on the path to recurrent networks, which power many natural language applications.},
author = {Goodfellow, Ian},
file = {:home/antonio/Documents/bibliography/files/Goodfellow - 2016 - Deep Feedforward Networks Roadmap.pdf:pdf},
journal = {Deep Learning Book},
number = {1},
pages = {169--229},
title = {{Deep Feedforward Networks Roadmap}},
year = {2016}
}

@article{Learninga,
author = {Learning, Machine and Discussion, H A S and Notes, Group and Gupta, Hoshin},
file = {:home/antonio/Documents/bibliography/files/Learning et al. - Unknown - Chapter 7 Regularization for Machine Learning.pdf:pdf},
pages = {228--273},
title = {{Chapter 7 Regularization for Machine Learning}}
}

@article{Bengio2015b,
abstract = {Deep learning algorithms involve optimization in many contexts. For example, we often solve optimization problems analytically in order to prove that an algorithm has a certain property. Inference in a probabilistic model can be cast as an optimization problem. Of all of the many optimization problems involved in deep learning, the most difficult is neural network training. It is quite common to invest days to months of time on hundreds on machines in order to solve even a single instance of the neural network training problem. Because this problem is so important and so expensive, a specialized set of optimization techniques have been developed for solving it. This chapter presents these optimization techniques for neural network training. If you're unfamiliar with the basic principles of gradient-based optimization, we suggest reviewing Chapter 4. That chapter includes a brief overview of nu-merical optimization in general. This chapter focuses on one particular case of optimization: minimizing an objective function J(X (train) , $\theta$) with respect to the model parameters $\theta$. 8.1 Optimization for Model Training Optimization algorithms used for training of deep models differ from traditional optimization algorithms in several ways. Machine learning usually acts indirectly— we care about some performance measure P that we do not know how to directly influence, so instead we reduce some objective function J ($\theta$) in hope that it will improve P . This is in contrast to pure optimization, where minimizing J is a goal in and of itself. Optimization algorithms for training deep models also typically include some specialization on the specific structure of machine learning objective 236},
author = {Bengio, Yoshua and Goodfellow, Ian J and Courville, Aaron},
file = {:home/antonio/Documents/bibliography/files/Bengio, Goodfellow, Courville - 2015 - Optimization for training deep models.pdf:pdf},
journal = {Deep Learning},
pages = {238--290},
title = {{Optimization for training deep models}},
year = {2015}
}

@article{Goodfellow2016c,
author = {Goodfellow, Ian and Brain, Google},
file = {:home/antonio/Documents/bibliography/files/Goodfellow, Brain - 2016 - Tutorial on Optimization for Deep Networks.pdf:pdf},
title = {{Tutorial on Optimization for Deep Networks}},
year = {2016}
}

@article{Goodfellow2016d,
author = {Goodfellow, Ian},
file = {:home/antonio/Documents/bibliography/files/Goodfellow - 2016 - Batch Normalization.pdf:pdf},
title = {{Batch Normalization}},
year = {2016}
}

@article{Learning2016,
author = {Learning, Deep},
file = {:home/antonio/Documents/bibliography/files/Learning - 2016 - Convolutional Networks Convolutional Networks.pdf:pdf},
title = {{Convolutional Networks Convolutional Networks}},
year = {2016}
}

@article{Learning2016a,
author = {Learning, Deep},
file = {:home/antonio/Documents/bibliography/files/Learning - 2016 - Sequence Modeling Recurrent and Recursive Nets.pdf:pdf},
title = {{Sequence Modeling : Recurrent and Recursive Nets}},
year = {2016}
}

@article{Goodfellow2016e,
author = {Goodfellow, Ian},
file = {:home/antonio/Documents/bibliography/files/Goodfellow - 2016 - What drives success in ML What drives success in ML.pdf:pdf},
title = {{What drives success in ML ? What drives success in ML ?}},
year = {2016}
}

@article{Learning2016b,
author = {Learning, Deep},
file = {:home/antonio/Documents/bibliography/files/Learning - 2016 - Linear Factor Models.pdf:pdf},
title = {{Linear Factor Models}},
year = {2016}
}

@article{Learning2016c,
author = {Learning, Deep},
file = {:home/antonio/Documents/bibliography/files/Learning - 2016 - Autoencoders of an Autoencoder sible Structure.pdf:pdf},
title = {{Autoencoders of an Autoencoder sible Structure}},
year = {2016}
}

@article{Goodfellow2016g,
author = {Goodfellow, Ian},
file = {:home/antonio/Documents/bibliography/files/Goodfellow - 2016 - Lecture slides for Chapter 1 of.pdf:pdf},
title = {{Lecture slides for Chapter 1 of}},
year = {2016}
}

@article{Learning2016d,
author = {Learning, Deep},
file = {:home/antonio/Documents/bibliography/files/Learning - 2016 - Linear Algebra.pdf:pdf},
title = {{Linear Algebra}},
year = {2016}
}

@article{Goodfellow2016h,
author = {Goodfellow, Ian},
file = {:home/antonio/Documents/bibliography/files/Goodfellow - 2016 - Probability and Information Theory Probability Mass Function.pdf:pdf},
title = {{Probability and Information Theory Probability Mass Function}},
year = {2016}
}

@article{Learning2016e,
author = {Learning, Deep},
file = {:home/antonio/Documents/bibliography/files/Learning - 2016 - Numerical Computation.pdf:pdf},
title = {{Numerical Computation}},
year = {2016}
}

@article{Learning2016f,
author = {Learning, Deep},
file = {:home/antonio/Documents/bibliography/files/Learning - 2016 - Deep Feedforward Networks Solving XOR.pdf:pdf},
title = {{Deep Feedforward Networks Solving XOR}},
year = {2016}
}

@article{Learning2016g,
author = {Learning, Deep},
file = {:home/antonio/Documents/bibliography/files/Learning - 2016 - Regularization for Deep Learning.pdf:pdf},
title = {{Regularization for Deep Learning}},
year = {2016}
}

@article{Goodfellow2015,
author = {Goodfellow, Ian},
file = {:home/antonio/Documents/bibliography/files/Goodfellow - 2015 - Gradient Descent and the Structure of Neural Network Cost Functions Optimization.pdf:pdf},
title = {{Gradient Descent and the Structure of Neural Network Cost Functions Optimization}},
year = {2015}
}

@article{Huang,
archivePrefix = {arXiv},
arxivId = {arXiv:1608.06993v5},
author = {Huang, Gao and Weinberger, Kilian Q},
eprint = {arXiv:1608.06993v5},
file = {:home/antonio/Documents/bibliography/files/Huang, Weinberger - Unknown - Densely Connected Convolutional Networks.pdf:pdf},
title = {{Densely Connected Convolutional Networks}}
}

@article{Pelt2017,
author = {Pelt, M and Sethian, James A},
file = {:home/antonio/Documents/bibliography/files/Pelt, Sethian - 2017 - A mixed-scale dense convolutional neural network for image analysis.pdf:pdf},
title = {{A mixed-scale dense convolutional neural network for image analysis}},
year = {2017}
}

@article{Greff2015,
archivePrefix = {arXiv},
arxivId = {arXiv:1505.00387v2},
author = {Greff, Klaus},
eprint = {arXiv:1505.00387v2},
file = {:home/antonio/Documents/bibliography/files/Greff - 2015 - Highway Networks.pdf:pdf},
title = {{Highway Networks}},
year = {2015}
}

@article{Bach2017,
author = {Bach, Francis},
file = {:home/antonio/Documents/bibliography/files/Bach - 2017 - Breaking the Curse of Dimensionality with Convex Neural Networks.pdf:pdf},
pages = {1--53},
title = {{Breaking the Curse of Dimensionality with Convex Neural Networks}},
volume = {18},
year = {2017}
}

@article{Bishop1994,
author = {Bishop, Christopher M},
file = {:home/antonio/Documents/bibliography/files/Bishop - 1994 - Mixture Density Networks.pdf:pdf},
title = {{Mixture Density Networks}},
year = {1994}
}

@article{Curtis2018,
archivePrefix = {arXiv},
arxivId = {arXiv:1606.04838v3},
author = {Curtis, Frank E and Feb, M L},
eprint = {arXiv:1606.04838v3},
file = {:home/antonio/Documents/bibliography/files/Curtis, Feb - 2018 - Optimization Methods for Large-Scale Machine Learning.pdf:pdf},
title = {{Optimization Methods for Large-Scale Machine Learning}},
year = {2018}
}

@Article{Burger2000,
  author   = {Burger, Martin and Engl, Heinz W},
  title    = {{Training neural networks with noisy data as an ill-posed problem}},
  year     = {2000},
  pages    = {335--354},
  volume   = {2},
  file     = {:home/antonio/Documents/bibliography/files/Burger, Engl - 2000 - Training neural networks with noisy data as an ill-posed problem.pdf:pdf},
  keywords = {ill-posed problems, least-squares collocation, network training, neural networks},
}

@Article{Tezcan2019,
  author        = {Tezcan, Kerem C. and Baumgartner, Christian F. and Luechinger, Roger and Pruessmann, Klaas P. and Konukoglu, Ender},
  journal       = {IEEE Transactions on Medical Imaging},
  title         = {{MR Image Reconstruction Using Deep Density Priors}},
  year          = {2019},
  issn          = {1558254X},
  number        = {7},
  pages         = {1633--1642},
  volume        = {38},
  abstract      = {Algorithms for magnetic resonance (MR) image reconstruction from undersampled measurements exploit prior information to compensate for missing k-space data. Deep learning (DL) provides a powerful framework for extracting such information from existing image datasets, through learning, and then using it for reconstruction. Leveraging this, recent methods employed DL to learn mappings from undersampled to fully sampled images using paired datasets, including undersampled and corresponding fully sampled images, integrating prior knowledge implicitly. In this letter, we propose an alternative approach that learns the probability distribution of fully sampled MR images using unsupervised DL, specifically variational autoencoders (VAE), and use this as an explicit prior term in reconstruction, completely decoupling the encoding operation from the prior. The resulting reconstruction algorithm enjoys a powerful image prior to compensate for missing k-space data without requiring paired datasets for training nor being prone to associated sensitivities, such as deviations in undersampling patterns used in training and test time or coil settings. We evaluated the proposed method with T1 weighted images from a publicly available dataset, multi-coil complex images acquired from healthy volunteers ( ${N}=8$ ), and images with white matter lesions. The proposed algorithm, using the VAE prior, produced visually high quality reconstructions and achieved low RMSE values, outperforming most of the alternative methods on the same dataset. On multi-coil complex data, the algorithm yielded accurate magnitude and phase reconstruction results. In the experiments on images with white matter lesions, the method faithfully reconstructed the lesions.},
  archiveprefix = {arXiv},
  arxivid       = {1711.11386},
  doi           = {10.1109/TMI.2018.2887072},
  eprint        = {1711.11386},
  file          = {:home/antonio/Documents/bibliography/files/Tezcan et al. - 2019 - MR Image Reconstruction Using Deep Density Priors.pdf:pdf},
  keywords      = {MRI, Reconstruction, deep learning, density estimation, machine learning, prior probability, unsupervised learning},
}

@Article{Weinan2017,
  author        = {Weinan, E. and Han, Jiequn and Jentzen, Arnulf},
  journal       = {Communications in Mathematics and Statistics},
  title         = {{Deep Learning-Based Numerical Methods for High-Dimensional Parabolic Partial Differential Equations and Backward Stochastic Differential Equations}},
  year          = {2017},
  issn          = {2194671X},
  number        = {4},
  pages         = {349--380},
  volume        = {5},
  abstract      = {We study a new algorithm for solving parabolic partial differential equations (PDEs) and backward stochastic differential equations (BSDEs) in high dimension, which is based on an analogy between the BSDE and reinforcement learning with the gradient of the solution playing the role of the policy function, and the loss function given by the error between the prescribed terminal condition and the solution of the BSDE. The policy function is then approximated by a neural network, as is done in deep reinforcement learning. Numerical results using TensorFlow illustrate the efficiency and accuracy of the studied algorithm for several 100-dimensional nonlinear PDEs from physics and finance such as the Allen–Cahn equation, the Hamilton–Jacobi–Bellman equation, and a nonlinear pricing model for financial derivatives.},
  archiveprefix = {arXiv},
  arxivid       = {1706.04702},
  doi           = {10.1007/s40304-017-0117-6},
  eprint        = {1706.04702},
  file          = {:home/antonio/Documents/bibliography/files/Weinan, Han, Jentzen - 2017 - Deep Learning-Based Numerical Methods for High-Dimensional Parabolic Partial Differential Equations and Ba.pdf:pdf},
  keywords      = {Backward stochastic differential equations, Control, Deep learning, Feynman-Kac, High dimension, PDEs},
}

@Article{Wuerfl2016,
  author   = {W{\"{u}}rfl, Tobias and Ghesu, Florin C. and Christlein, Vincent and Maier, Andreas},
  journal  = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  title    = {{Deep learning computed tomography}},
  year     = {2016},
  issn     = {16113349},
  pages    = {432--440},
  volume   = {9902 LNCS},
  abstract = {In this paper,we demonstrate that image reconstruction can be expressed in terms of neural networks. We show that filtered backprojection can be mapped identically onto a deep neural network architecture. As for the case of iterative reconstruction,the straight forward realization as matrix multiplication is not feasible. Thus,we propose to compute the back-projection layer efficiently as fixed function and its gradient as projection operation. This allows a data-driven approach for joint optimization of correction steps in projection domain and image domain. As a proof of concept,we demonstrate that we are able to learn weightings and additional filter layers that consistently reduce the reconstruction error of a limited angle reconstruction by a factor of two while keeping the same computational complexity as filtered back-projection. We believe that this kind of learning approach can be extended to any common CT artifact compensation heuristic and will outperform handcrafted artifact correction methods in the future.},
  doi      = {10.1007/978-3-319-46726-9_50},
  file     = {:home/antonio/Documents/bibliography/files/W{\"{u}}rfl et al. - 2016 - Deep learning computed tomography.pdf:pdf},
  isbn     = {9783319467252},
}

@article{Yoo2019,
abstract = {Diffuse optical tomography (DOT) has been investigated as an alternative imaging modality for breast cancer detection thanks to its excellent contrast to hemoglobin oxidization level. However, due to the complicated non-linear photon scattering physics and ill-posedness, the conventional reconstruction algorithms are sensitive to imaging parameters such as boundary conditions. To address this, here we propose a novel deep learning approach that learns non-linear photon scattering physics and obtains an accurate three dimensional (3D) distribution of optical anomalies. In contrast to the traditional black-box deep learning approaches, our deep network is designed to invert the Lippman-Schwinger integral equation using the recent mathematical theory of deep convolutional framelets. As an example of clinical relevance, we applied the method to our prototype DOT system. We show that our deep neural network, trained with only simulation data, can accurately recover the location of anomalies within biomimetic phantoms and live animals without the use of an exogenous contrast agent.},
archivePrefix = {arXiv},
arxivId = {1712.00912},
author = {Yoo, Jaejun and Sabir, Sohail and Heo, Duchang and Kim, Kee Hyun and Wahab, Abdul and Choi, Yoonseok and Lee, Seul-I and Chae, Eun Young and Kim, Hak Hee and Bae, Young Min and Choi, Young-Wook and Cho, Seungryong and Ye, Jong Chul},
doi = {10.1109/tmi.2019.2936522},
eprint = {1712.00912},
file = {:home/antonio/Documents/bibliography/files/Yoo et al. - 2019 - Deep Learning Diffuse Optical Tomography.pdf:pdf},
issn = {0278-0062},
journal = {IEEE Transactions on Medical Imaging},
number = {Xx},
pages = {1--1},
title = {{Deep Learning Diffuse Optical Tomography}},
volume = {XXX},
year = {2019}
}

@article{Zhu2017a,
abstract = {Extending state-of-the-art object detectors from image to video is challenging. The accuracy of detection suffers from degenerated object appearances in videos, e.g., motion blur, video defocus, rare poses, etc. Existing work attempts to exploit temporal information on box level, but such methods are not trained end-to-end. We present flow-guided feature aggregation, an accurate and end-to-end learning framework for video object detection. It leverages temporal coherence on feature level instead. It improves the per-frame features by aggregation of nearby features along the motion paths, and thus improves the video recognition accuracy. Our method significantly improves upon strong singleframe baselines in ImageNet VID [33], especially for more challenging fast moving objects. Our framework is principled, and on par with the best engineered systems winning the ImageNet VID challenges 2016, without additional bells-and-whistles. The code would be released.},
archivePrefix = {arXiv},
arxivId = {1703.10025},
author = {Zhu, Xizhou and Wang, Yujie and Dai, Jifeng and Yuan, Lu and Wei, Yichen},
doi = {10.1109/ICCV.2017.52},
eprint = {1703.10025},
file = {:home/antonio/Documents/bibliography/files/Zhu et al. - 2017 - Flow-Guided Feature Aggregation for Video Object Detection.pdf:pdf},
isbn = {9781538610329},
issn = {15505499},
journal = {Proceedings of the IEEE International Conference on Computer Vision},
pages = {408--417},
title = {{Flow-Guided Feature Aggregation for Video Object Detection}},
volume = {2017-Octob},
year = {2017}
}

@article{Gilton2019,
abstract = {Many challenging image processing tasks can be described by an ill-posed linear inverse problem: deblurring, deconvolution, inpainting, compressed sensing, and superresolution all lie in this framework. Traditional inverse problem solvers minimize a cost function consisting of a data-fit term, which measures how well an image matches the observations, and a regularizer, which reflects prior knowledge and promotes images with desirable properties like smoothness. Recent advances in machine learning and image processing have illustrated that it is often possible to learn a regularizer from training data that can outperform more traditional regularizers. We present an end-to-end, data-driven method of solving inverse problems inspired by the Neumann series, which we call a Neumann network. Rather than unroll an iterative optimization algorithm, we truncate a Neumann series which directly solves the linear inverse problem with a data-driven nonlinear regularizer. The Neumann network architecture outperforms traditional inverse problem solution methods, model-free deep learning approaches, and state-of-the-art unrolled iterative methods on standard datasets. Finally, when the images belong to a union of subspaces and under appropriate assumptions on the forward model, we prove there exists a Neumann network configuration that well-approximates the optimal oracle estimator for the inverse problem and demonstrate empirically that the trained Neumann network has the form predicted by theory.},
archivePrefix = {arXiv},
arxivId = {1901.03707},
author = {Gilton, Davis and Ongie, Greg and Willett, Rebecca},
doi = {10.1109/tci.2019.2948732},
eprint = {1901.03707},
file = {:home/antonio/Documents/bibliography/files/Gilton, Ongie, Willett - 2019 - Neumann Networks for Linear Inverse Problems in Imaging.pdf:pdf},
issn = {2573-0436},
journal = {IEEE Transactions on Computational Imaging},
pages = {1--1},
title = {{Neumann Networks for Linear Inverse Problems in Imaging}},
year = {2019}
}

@Article{Pelt2013,
  author   = {Pelt, Daniel Maria and Batenburg, Kees Joost},
  journal  = {IEEE Transactions on Image Processing},
  title    = {{Fast tomographic reconstruction from limited data using artificial neural networks}},
  year     = {2013},
  issn     = {10577149},
  number   = {12},
  pages    = {5238--5251},
  volume   = {22},
  abstract = {Image reconstruction from a small number of projections is a challenging problem in tomography. Advanced algorithms that incorporate prior knowledge can sometimes produce accurate reconstructions, but they typically require long computation times. Furthermore, the required prior knowledge can be very specific, limiting the type of images that can be reconstructed. Here, we present a reconstruction method that automatically learns prior knowledge using an artificial neural network. We show that this method can be viewed as a combination of filtered backprojection steps, and, therefore, has a relatively low computational cost. Results for two different cases show that the new method is able to use the learned information to produce high quality reconstructions in a short time, even when presented with a small number of projections. {\textcopyright} 2013 IEEE.},
  doi      = {10.1109/TIP.2013.2283142},
  file     = {:home/antonio/Documents/bibliography/files/Pelt, Batenburg - 2013 - Fast tomographic reconstruction from limited data using artificial neural networks.pdf:pdf},
  keywords = {Tomography, filtered backprojection, machine learning},
}

@Article{Gong2019,
  author        = {Gong, Kuang and Guan, Jiahui and Kim, Kyungsang and Zhang, Xuezhu and Yang, Jaewon and Seo, Youngho and {El Fakhri}, Georges and Qi, Jinyi and Li, Quanzheng},
  journal       = {IEEE Transactions on Medical Imaging},
  title         = {{Iterative PET image reconstruction using convolutional neural network representation}},
  year          = {2019},
  issn          = {1558254X},
  number        = {3},
  pages         = {675--685},
  volume        = {38},
  abstract      = {PET image reconstruction is challenging due to the ill-poseness of the inverse problem and limited number of detected photons. Recently, the deep neural networks have been widely and successfully used in computer vision tasks and attracted growing interests in medical imaging. In this paper, we trained a deep residual convolutional neural network to improve PET image quality by using the existing inter-patient information. An innovative feature of the proposed method is that we embed the neural network in the iterative reconstruction framework for image representation, rather than using it as a post-processing tool. We formulate the objective function as a constrained optimization problem and solve it using the alternating direction method of multipliers algorithm. Both simulation data and hybrid real data are used to evaluate the proposed method. Quantification results show that our proposed iterative neural network method can outperform the neural network denoising and conventional penalized maximum likelihood methods.},
  archiveprefix = {arXiv},
  arxivid       = {1710.03344},
  doi           = {10.1109/TMI.2018.2869871},
  eprint        = {1710.03344},
  file          = {:home/antonio/Documents/bibliography/files/Gong et al. - 2019 - Iterative PET image reconstruction using convolutional neural network representation.pdf:pdf},
  keywords      = {Positron emission tomography, convolutional neural network, iterative reconstruction},
}

@article{Gong2018,
abstract = {Recently deep neural networks have been widely and successfully applied in computer vision tasks and attracted growing interests in medical imaging. One barrier for the application of deep neural networks to medical imaging is the need of large amounts of prior training pairs, which is not always feasible in clinical practice. In this work we propose a personalized representation learning framework where no prior training pairs are needed, but only the patient's own prior images. The representation is expressed using a deep neural network with the patient's prior images as network input. We then applied this novel image representation to inverse problems in medical imaging in which the original inverse problem was formulated as a constraint optimization problem and solved using the alternating direction method of multipliers (ADMM) algorithm. Anatomically guided brain positron emission tomography (PET) image reconstruction and image denoising were employed as examples to demonstrate the effectiveness of the proposed framework. Quantification results based on simulation and real datasets show that the proposed personalized representation framework outperform other widely adopted methods.},
archivePrefix = {arXiv},
arxivId = {1807.01759},
author = {Gong, Kuang and Kim, Kyungsang and Cui, Jianan and Guo, Ning and Catana, Ciprian and Qi, Jinyi and Li, Quanzheng},
eprint = {1807.01759},
file = {:home/antonio/Documents/bibliography/files/Gong et al. - 2018 - Learning Personalized Representation for Inverse Problems in Medical Imaging Using Deep Neural Network.pdf:pdf},
pages = {1--11},
title = {{Learning Personalized Representation for Inverse Problems in Medical Imaging Using Deep Neural Network}},
url = {http://arxiv.org/abs/1807.01759},
year = {2018}
}

@article{Gong,
author = {Gong, Kuang},
file = {:home/antonio/Documents/bibliography/files/Gong - Unknown - Software aspects of applying deep learning to PET image reconstruction.pdf:pdf},
title = {{Software aspects of applying deep learning to PET image reconstruction}}
}

@article{Lim2019,
abstract = {Image reconstruction in low-count PET is particularly challenging because gammas from natural radioactivity in Lu-based crystals cause high random fractions that lower the measurement signal-to-noise-ratio (SNR). In model-based image reconstruction (MBIR), using more iterations of an unregularized method may increase the noise, so incorporating regularization into the image reconstruction is desirable to control the noise. New regularization methods based on learned convolutional operators are emerging in MBIR. We modify the architecture of a variational neural network, BCD-Net, for PET MBIR, and demonstrate the efficacy of the trained BCD-Net using XCAT phantom data that simulates the low true coincidence count-rates with high random fractions typical for Y-90 PET patient imaging after Y-90 microsphere radioembolization. Numerical results show that the proposed BCD-Net significantly improves PET reconstruction performance compared to MBIR methods using non-trained regularizers, total variation (TV) and non-local means (NLM), and a non-MBIR method using a single forward pass deep neural network, U-Net. BCD-Net improved activity recovery for a hot sphere significantly and reduced noise, whereas non-trained regularizers had a trade-off between noise and quantification. BCD-Net improved CNR and RMSE by 43.4% (85.7%) and 12.9% (29.1%) compared to TV (NLM) regularized MBIR. Moreover, whereas the image reconstruction results show that the non-MBIR U-Net over-fits the training data, BCD-Net successfully generalizes to data that differs from training data. Improvements were also demonstrated for the clinically relevant phantom measurement data where we used training and testing datasets having very different activity distribution and count-level.},
archivePrefix = {arXiv},
arxivId = {1906.02327},
author = {Lim, Hongki and Chun, Il Yong and Dewaraja, Yuni K. and Fessler, Jeffrey A.},
eprint = {1906.02327},
file = {:home/antonio/Documents/bibliography/files/Lim et al. - 2019 - Improved low-count quantitative PET reconstruction with a variational neural network.pdf:pdf},
pages = {1--10},
title = {{Improved low-count quantitative PET reconstruction with a variational neural network}},
url = {http://arxiv.org/abs/1906.02327},
year = {2019}
}

@article{Gong2018a,
abstract = {Positron emission tomography (PET) is a functional imaging modality widely used in clinical diagnosis. In this paper, we trained a deep convolutional neural network to improve PET image quality. Perceptual loss based on features derived from a pretrained VGG network, instead of the conventional mean squared error, was employed as the training loss function to preserve image details. As the number of real patient data set for training is limited, we propose to pretrain the network using simulation data and fine-tune the last few layers of the network using real data sets. Results from simulation, real brain, and lung data sets show that the proposed method is more effective in removing noise than the traditional Gaussian filtering method.},
author = {Gong, Kuang and Guan, Jiahui and Liu, Chih-Chieh and Qi, Jinyi},
doi = {10.1109/trpms.2018.2877644},
file = {:home/antonio/Documents/bibliography/files/Gong et al. - 2018 - PET Image Denoising Using a Deep Neural Network Through Fine Tuning.pdf:pdf},
issn = {2469-7311},
journal = {IEEE Transactions on Radiation and Plasma Medical Sciences},
number = {2},
pages = {153--161},
title = {{PET Image Denoising Using a Deep Neural Network Through Fine Tuning}},
volume = {3},
year = {2018}
}

@article{Yang2018a,
abstract = {Deep convolutional neural networks (DCNN) have demonstrated its capability to convert MR image to pseudo CT for PET attenuation correction in PET/MRI. Conventionally, attenuated events are corrected in sinogram space using attenuation maps derived from CT or MR-derived pseudo CT. Separately, scattered events are iteratively estimated by a 3D model-based simulation using down-sampled attenuation and emission sinograms. However, no studies have investigated joint correction of attenuation and scatter using DCNN in image space. Therefore, we aim to develop and optimize a DCNN model for attenuation and scatter correction (ASC) simultaneously in PET image space without additional anatomical imaging or time-consuming iterative scatter simulation. For the first time, we demonstrated the feasibility of directly producing PET images corrected for attenuation and scatter using DCNN (PET-DCNN) from noncorrected PET (PET-NC) images.},
archivePrefix = {arXiv},
arxivId = {1811.11852},
author = {Yang, Jaewon and Park, Dookun and Sohn, Jae Ho and Wang, Zhen Jane and Gullberg, Grant T. and Seo, Youngho},
eprint = {1811.11852},
file = {:home/antonio/Documents/bibliography/files/Yang et al. - 2018 - Joint Correction of Attenuation and Scatter Using Deep Convolutional Neural Networks (DCNN) for Time-of-Flight PET.pdf:pdf},
pages = {16--19},
title = {{Joint Correction of Attenuation and Scatter Using Deep Convolutional Neural Networks (DCNN) for Time-of-Flight PET}},
url = {http://arxiv.org/abs/1811.11852},
year = {2018}
}

@Article{Rakotosaona2019,
  author        = {Rakotosaona, Marie Julie and {La Barbera}, Vittorio and Guerrero, Paul and Mitra, Niloy J. and Ovsjanikov, Maks},
  journal       = {Computer Graphics Forum},
  title         = {{PointCleanNet: Learning to Denoise and Remove Outliers from Dense Point Clouds}},
  year          = {2019},
  issn          = {14678659},
  abstract      = {Point clouds obtained with 3D scanners or by image-based reconstruction techniques are often corrupted with significant amount of noise and outliers. Traditional methods for point cloud denoising largely rely on local surface fitting (e.g. jets or MLS surfaces), local or non-local averaging or on statistical assumptions about the underlying noise model. In contrast, we develop a simple data-driven method for removing outliers and reducing noise in unordered point clouds. We base our approach on a deep learning architecture adapted from PCPNet, which was recently proposed for estimating local 3D shape properties in point clouds. Our method first classifies and discards outlier samples, and then estimates correction vectors that project noisy points onto the original clean surfaces. The approach is efficient and robust to varying amounts of noise and outliers, while being able to handle large densely sampled point clouds. In our extensive evaluation, both on synthetic and real data, we show an increased robustness to strong noise levels compared to various state-of-the-art methods, enabling accurate surface reconstruction from extremely noisy real data obtained by range scans. Finally, the simplicity and universality of our approach makes it very easy to integrate in any existing geometry processing pipeline. Both the code and pre-trained networks can be found on the project page (https://github.com/mrakotosaon/pointcleannet).},
  archiveprefix = {arXiv},
  arxivid       = {1901.01060},
  doi           = {10.1111/cgf.13753},
  eprint        = {1901.01060},
  file          = {:home/antonio/Documents/bibliography/files/Rakotosaona et al. - 2019 - PointCleanNet Learning to Denoise and Remove Outliers from Dense Point Clouds.pdf:pdf},
  keywords      = {Neural networks, Shape analysis, [Computing Methodologies]: Point-based models, methods and applications, modeling, point-based graphics, point-based methods, signal processing},
}

@article{Schlemper2019,
abstract = {AUTOMAP is a promising generalized reconstruction approach, however, it is not scalable and hence the practicality is limited. We present dAUTOMAP, a novel way for decomposing the domain transformation of AUTOMAP, making the model scale linearly. We show dAUTOMAP outperforms AUTOMAP with significantly fewer parameters.},
archivePrefix = {arXiv},
arxivId = {1909.10995},
author = {Schlemper, Jo and Oksuz, Ilkay and Clough, James R. and Duan, Jinming and King, Andrew P. and Schnabel, Julia A. and Hajnal, Joseph V. and Rueckert, Daniel},
eprint = {1909.10995},
file = {:home/antonio/Documents/bibliography/files/Schlemper et al. - 2019 - dAUTOMAP decomposing AUTOMAP to achieve scalability and enhance performance.pdf:pdf},
number = {1},
pages = {1--5},
title = {{dAUTOMAP: decomposing AUTOMAP to achieve scalability and enhance performance}},
url = {http://arxiv.org/abs/1909.10995},
volume = {1},
year = {2019}
}

@Article{Wang2016a,
  author   = {Wang, Shanshan and Su, Zhenghang and Ying, Leslie and Peng, Xi and Zhu, Shun and Liang, Feng and Feng, Dagan and Liang, Dong and Technologies, Information},
  journal  = {Isbi 2016},
  title    = {{ACCELERATING MAGNETIC RESONANCE IMAGING VIA DEEP LEARNING Paul C . Lauterbur Research Center for Biomedical Imaging , SIAT , CAS , Shenzhen , P . R . China Department of Biomedical Engineering and Department of Electrical Engineering , The State Universit}},
  year     = {2016},
  pages    = {514--517},
  file     = {:home/antonio/Documents/bibliography/files/Wang et al. - 2016 - ACCELERATING MAGNETIC RESONANCE IMAGING VIA DEEP LEARNING Paul C . Lauterbur Research Center for Biomedical Imaging.pdf:pdf},
  isbn     = {2014061015185},
  keywords = {Image reconstruction - analytical & iterative meth, Magnetic resonance imaging (MRI)},
}

@article{Yang2016,
abstract = {Compressive Sensing (CS) is an effective approach for fast Magnetic Resonance Imaging (MRI). It aims at reconstructing MR image from a small number of under-sampled data in k-space, and accelerating the data acquisition in MRI. To improve the current MRI system in reconstruction accuracy and computational speed, in this paper, we propose a novel deep architecture, dubbed ADMM-Net. ADMM-Net is defined over a data flow graph, which is derived from the iterative procedures in Alternating Direction Method of Multipliers (ADMM) algorithm for optimizing a CS-based MRI model. In the training phase, all parameters of the net, e.g., image transforms, shrinkage functions, etc., are discriminatively trained end-to-end using L-BFGS algorithm. In the testing phase, it has computational overhead similar to ADMM but uses optimized parameters learned from the training data for CS-based reconstruction task. Experiments on MRI image reconstruction under different sampling ratios in k-space demonstrate that it significantly improves the baseline ADMM algorithm and achieves high reconstruction accuracies with fast computational speed.},
author = {Yang, Yan and Sun, Jian and Li, Huibin and Xu, Zongben},
file = {:home/antonio/Documents/bibliography/files/Yang et al. - 2016 - Deep ADMM-Net for compressive sensing MRI.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
number = {Nips},
pages = {10--18},
title = {{Deep ADMM-Net for compressive sensing MRI}},
year = {2016}
}

@Article{Yao2019,
  author        = {Yao, Hantao and Dai, Feng and Zhang, Shiliang and Zhang, Yongdong and Tian, Qi and Xu, Changsheng},
  journal       = {Neurocomputing},
  title         = {{DR2-Net: Deep Residual Reconstruction Network for image compressive sensing}},
  year          = {2019},
  issn          = {18728286},
  pages         = {483--493},
  volume        = {359},
  abstract      = {Most traditional algorithms for compressive sensing image reconstruction suffer from the intensive computation. Recently, deep learning-based reconstruction algorithms have been reported, which dramatically reduce the time complexity than iterative reconstruction algorithms. In this paper, we propose a novel Deep Residual Reconstruction Network (DR2-Net) to reconstruct the image from its Compressively Sensed (CS) measurement. The DR2-Net is proposed based on two observations: (1) linear mapping could reconstruct a high-quality preliminary image, and (2) residual learning could further improve the reconstruction quality. Accordingly, DR2-Net consists of two components, i.e., linear mapping network and residual network, respectively. Specifically, the fully-connected layer in neural network implements the linear mapping network. We then expand the linear mapping network to DR2-Net by adding several residual learning blocks to enhance the preliminary image. Extensive experiments demonstrate that the DR2-Net outperforms traditional iterative methods and recent deep learning-based methods by large margins at measurement rates 0.01, 0.04, 0.1, and 0.25, respectively. The code of DR2-Net has been released on: https://github.com/coldrainyht/caffe_dr2.},
  archiveprefix = {arXiv},
  arxivid       = {1702.05743},
  doi           = {10.1016/j.neucom.2019.05.006},
  eprint        = {1702.05743},
  file          = {:home/antonio/Documents/bibliography/files/Yao et al. - 2019 - DR2-Net Deep Residual Reconstruction Network for image compressive sensing.pdf:pdf},
  keywords      = {Convolutional neural networks, DR2-Net, Image compressive sensing},
}

@article{Oord2016,
abstract = {This paper introduces WaveNet, a deep neural network for generating raw audio waveforms. The model is fully probabilistic and autoregressive, with the predictive distribution for each audio sample conditioned on all previous ones; nonetheless we show that it can be efficiently trained on data with tens of thousands of samples per second of audio. When applied to text-to-speech, it yields state-of-the-art performance, with human listeners rating it as significantly more natural sounding than the best parametric and concatenative systems for both English and Mandarin. A single WaveNet can capture the characteristics of many different speakers with equal fidelity, and can switch between them by conditioning on the speaker identity. When trained to model music, we find that it generates novel and often highly realistic musical fragments. We also show that it can be employed as a discriminative model, returning promising results for phoneme recognition.},
archivePrefix = {arXiv},
arxivId = {1609.03499},
author = {van den Oord, Aaron and Dieleman, Sander and Zen, Heiga and Simonyan, Karen and Vinyals, Oriol and Graves, Alex and Kalchbrenner, Nal and Senior, Andrew and Kavukcuoglu, Koray},
eprint = {1609.03499},
file = {:home/antonio/Documents/bibliography/files/Oord et al. - 2016 - WaveNet A Generative Model for Raw Audio.pdf:pdf},
pages = {1--15},
title = {{WaveNet: A Generative Model for Raw Audio}},
url = {http://arxiv.org/abs/1609.03499},
year = {2016}
}

@Article{Paschalis2004,
  author   = {Paschalis, P. and Giokaris, N. D. and Karabarbounis, A. and Loudos, G. K. and Maintas, D. and Papanicolas, C. N. and Spanoudaki, V. and Tsoumpas, Ch and Stiliaris, E.},
  journal  = {Nuclear Instruments and Methods in Physics Research, Section A: Accelerators, Spectrometers, Detectors and Associated Equipment},
  title    = {{Tomographic image reconstruction using Artificial Neural Networks}},
  year     = {2004},
  issn     = {01689002},
  number   = {1-2},
  pages    = {211--215},
  volume   = {527},
  abstract = {A new image reconstruction technique based on the usage of an Artificial Neural Network (ANN) is presented. The most crucial factor in designing such a reconstruction system is the network architecture and the number of the input projections needed to reconstruct the image. Although the training phase requires a large amount of input samples and a considerable CPU time, the trained network is characterized by simplicity and quick response. The performance of this ANN is tested using several image patterns. It is intended to be used together with a phantom rotating table and the $\gamma$-camera of IASA for SPECT image reconstruction. {\textcopyright} 2004 Elsevier B.V. All rights reserved.},
  doi      = {10.1016/j.nima.2004.03.122},
  file     = {:home/antonio/Documents/bibliography/files/Paschalis et al. - 2004 - Tomographic image reconstruction using Artificial Neural Networks.pdf:pdf},
  keywords = {Artificial Neural Networks (ANN), Image reconstruction, PSPMT, SPECT, $\gamma$-camera},
}

@article{Ledig2017,
abstract = {Despite the breakthroughs in accuracy and speed of single image super-resolution using faster and deeper convolutional neural networks, one central problem remains largely unsolved: how do we recover the finer texture details when we super-resolve at large upscaling factors? The behavior of optimization-based super-resolution methods is principally driven by the choice of the objective function. Recent work has largely focused on minimizing the mean squared reconstruction error. The resulting estimates have high peak signal-to-noise ratios, but they are often lacking high-frequency details and are perceptually unsatisfying in the sense that they fail to match the fidelity expected at the higher resolution. In this paper, we present SRGAN, a generative adversarial network (GAN) for image superresolution (SR). To our knowledge, it is the first framework capable of inferring photo-realistic natural images for 4× upscaling factors. To achieve this, we propose a perceptual loss function which consists of an adversarial loss and a content loss. The adversarial loss pushes our solution to the natural image manifold using a discriminator network that is trained to differentiate between the super-resolved images and original photo-realistic images. In addition, we use a content loss motivated by perceptual similarity instead of similarity in pixel space. Our deep residual network is able to recover photo-realistic textures from heavily downsampled images on public benchmarks. An extensive mean-opinion-score (MOS) test shows hugely significant gains in perceptual quality using SRGAN. The MOS scores obtained with SRGAN are closer to those of the original high-resolution images than to those obtained with any state-of-the-art method.},
archivePrefix = {arXiv},
arxivId = {1609.04802},
author = {Ledig, Christian and Theis, Lucas and Husz{\'{a}}r, Ferenc and Caballero, Jose and Cunningham, Andrew and Acosta, Alejandro and Aitken, Andrew and Tejani, Alykhan and Totz, Johannes and Wang, Zehan and Shi, Wenzhe},
doi = {10.1109/CVPR.2017.19},
eprint = {1609.04802},
file = {:home/antonio/Documents/bibliography/files/Ledig et al. - 2017 - Photo-realistic single image super-resolution using a generative adversarial network.pdf:pdf},
isbn = {9781538604571},
journal = {Proceedings - 30th IEEE Conference on Computer Vision and Pattern Recognition, CVPR 2017},
pages = {105--114},
title = {{Photo-realistic single image super-resolution using a generative adversarial network}},
volume = {2017-Janua},
year = {2017}
}

@article{Kofler2019,
abstract = {In this work we reduce undersampling artefacts in two-dimensional ($2D$) golden-angle radial cine cardiac MRI by applying a modified version of the U-net. We train the network on $2D$ spatio-temporal slices which are previously extracted from the image sequences. We compare our approach to two $2D$ and a $3D$ Deep Learning-based post processing methods and to three iterative reconstruction methods for dynamic cardiac MRI. Our method outperforms the $2D$ spatially trained U-net and the $2D$ spatio-temporal U-net. Compared to the $3D$ spatio-temporal U-net, our method delivers comparable results, but with shorter training times and less training data. Compared to the Compressed Sensing-based methods $kt$-FOCUSS and a total variation regularised reconstruction approach, our method improves image quality with respect to all reported metrics. Further, it achieves competitive results when compared to an iterative reconstruction method based on adaptive regularization with Dictionary Learning and total variation, while only requiring a small fraction of the computational time. A persistent homology analysis demonstrates that the data manifold of the spatio-temporal domain has a lower complexity than the spatial domain and therefore, the learning of a projection-like mapping is facilitated. Even when trained on only one single subject without data-augmentation, our approach yields results which are similar to the ones obtained on a large training dataset. This makes the method particularly suitable for training a network on limited training data. Finally, in contrast to the spatial $2D$ U-net, our proposed method is shown to be naturally robust with respect to image rotation in image space and almost achieves rotation-equivariance where neither data-augmentation nor a particular network design are required.},
archivePrefix = {arXiv},
arxivId = {1904.01574},
author = {Kofler, Andreas and Dewey, Marc and Schaeffter, Tobias and Wald, Christian and Kolbitsch, Christoph},
doi = {10.1109/tmi.2019.2930318},
eprint = {1904.01574},
file = {:home/antonio/Documents/bibliography/files/Kofler et al. - 2019 - Spatio-Temporal Deep Learning-Based Undersampling Artefact Reduction for 2D Radial Cine MRI with Limited Training.pdf:pdf},
issn = {0278-0062},
journal = {IEEE Transactions on Medical Imaging},
pages = {1--1},
title = {{Spatio-Temporal Deep Learning-Based Undersampling Artefact Reduction for 2D Radial Cine MRI with Limited Training Data}},
year = {2019}
}

@article{Yang2017a,
author = {Yang, Guang and Unit, C M R},
file = {:home/antonio/Documents/bibliography/files/Yang, Unit - 2017 - Generative Adversarial Networks ( GAN ) based Deep Learning for Compressed Sensing MRI Compressed Sensing.pdf:pdf},
title = {{Generative Adversarial Networks ( GAN ) based Deep Learning for Compressed Sensing MRI Compressed Sensing}},
year = {2017}
}

@article{Lee2017,
abstract = {Purpose: Compressed sensing MRI (CS-MRI) from single and parallel coils is one of the powerful ways to reduce the scan time of MR imaging with performance guarantee. However, the computational costs are usually expensive. This paper aims to propose a computationally fast and accurate deep learning algorithm for the reconstruction of MR images from highly down-sampled k-space data. Theory: Based on the topological analysis, we show that the data manifold of the aliasing artifact is easier to learn from a uniform subsampling pattern with additional low-frequency k-space data. Thus, we develop deep aliasing artifact learning networks for the magnitude and phase images to estimate and remove the aliasing artifacts from highly accelerated MR acquisition. Methods: The aliasing artifacts are directly estimated from the distorted magnitude and phase images reconstructed from subsampled k-space data so that we can get an aliasing-free images by subtracting the estimated aliasing artifact from corrupted inputs. Moreover, to deal with the globally distributed aliasing artifact, we develop a multi-scale deep neural network with a large receptive field. Results: The experimental results confirm that the proposed deep artifact learning network effectively estimates and removes the aliasing artifacts. Compared to existing CS methods from single and multi-coli data, the proposed network shows minimal errors by removing the coherent aliasing artifacts. Furthermore, the computational time is by order of magnitude faster. Conclusion: As the proposed deep artifact learning network immediately generates accurate reconstruction, it has great potential for clinical applications.},
archivePrefix = {arXiv},
arxivId = {1703.01120},
author = {Lee, Dongwook and Yoo, Jaejun and Ye, Jong Chul},
eprint = {1703.01120},
file = {:home/antonio/Documents/bibliography/files/Lee, Yoo, Ye - 2017 - Deep artifact learning for compressed sensing and parallel MRI.pdf:pdf},
title = {{Deep artifact learning for compressed sensing and parallel MRI}},
url = {http://arxiv.org/abs/1703.01120},
year = {2017}
}

@Article{Qin2019b,
  author        = {Qin, Chen and Schlemper, Jo and Caballero, Jose and Price, Anthony N. and Hajnal, Joseph V. and Rueckert, Daniel},
  journal       = {IEEE Transactions on Medical Imaging},
  title         = {{Convolutional recurrent neural networks for dynamic MR image reconstruction}},
  year          = {2019},
  issn          = {1558254X},
  number        = {1},
  pages         = {280--290},
  volume        = {38},
  abstract      = {Accelerating the data acquisition of dynamic magnetic resonance imaging leads to a challenging ill-posed inverse problem, which has received great interest from both the signal processing and machine learning communities over the last decades. The key ingredient to the problem is how to exploit the temporal correlations of the MR sequence to resolve aliasing artifacts. Traditionally, such observation led to a formulation of an optimization problem, which was solved using iterative algorithms. Recently, however, deep learning-based approaches have gained significant popularity due to their ability to solve general inverse problems. In this paper, we propose a unique, novel convolutional recurrent neural network architecture which reconstructs high quality cardiac MR images from highly undersampled k-space data by jointly exploiting the dependencies of the temporal sequences as well as the iterative nature of the traditional optimization algorithms. In particular, the proposed architecture embeds the structure of the traditional iterative algorithms, efficiently modeling the recurrence of the iterative reconstruction stages by using recurrent hidden connections over such iterations. In addition, spatio-temporal dependencies are simultaneously learnt by exploiting bidirectional recurrent hidden connections across time sequences. The proposed method is able to learn both the temporal dependence and the iterative reconstruction process effectively with only a very small number of parameters, while outperforming current MR reconstruction methods in terms of reconstruction accuracy and speed.},
  archiveprefix = {arXiv},
  arxivid       = {1712.01751},
  doi           = {10.1109/TMI.2018.2863670},
  eprint        = {1712.01751},
  file          = {:home/antonio/Documents/bibliography/files/Qin et al. - 2019 - Convolutional recurrent neural networks for dynamic MR image reconstruction.pdf:pdf},
  keywords      = {Recurrent neural network, cardiac image reconstruction, convolutional neural network, dynamic magnetic resonance imaging},
  pmid          = {30080145},
  publisher     = {IEEE},
}

@article{Hammernik2017,
abstract = {Limited-angle computed tomography suffers from missing data in the projection domain, which results in intensity inhomogeneities and streaking artifacts in the image domain. We address both challenges by a two-step deep learning architecture: First, we learn compensation weights that account for the missing data in the projection domain and correct for intensity changes. Second, we formulate an image restoration problem as a variational network to eliminate coherent streaking artifacts. We perform our experiments on realistic data and we achieve superior results for destreaking compared to state-of-the-art non-linear filtering methods in literature. We show that our approach eliminates the need for manual tuning and enables joint optimization of both correction schemes.},
author = {Hammernik, Kerstin and W{\"{u}}rfl, Tobias and Pock, Thomas and Maier, Andreas},
doi = {10.1007/978-3-662-54345-0_25},
file = {:home/antonio/Documents/bibliography/files/Hammernik et al. - 2017 - A deep learning architecture for limited-angle computed tomography reconstruction.pdf:pdf},
isbn = {9783662543443},
issn = {1431472X},
journal = {Informatik aktuell},
pages = {92--97},
title = {{A deep learning architecture for limited-angle computed tomography reconstruction}},
year = {2017}
}

@article{Han2019,
abstract = {The annihilating filter-based low-rank Hankel matrix approach (ALOHA) is one of the state-of-the-art compressed sensing approaches that directly interpolates the missing k-space data using low-rank Hankel matrix completion. The success of ALOHA is due to the concise signal representation in the k-space domain thanks to the duality between structured low-rankness in the k-space domain and the image domain sparsity. Inspired by the recent mathematical discovery that links convolutional neural networks to Hankel matrix decomposition using data-driven framelet basis, here we propose a fully data-driven deep learning algorithm for k-space interpolation. Our network can be also easily applied to non-Cartesian k-space trajectories by simply adding an additional regridding layer. Extensive numerical experiments show that the proposed deep learning method consistently outperforms the existing image-domain deep learning approaches.},
archivePrefix = {arXiv},
arxivId = {1805.03779},
author = {Han, Yoseob and Sunwoo, Leonard and Ye, Jong Chul},
doi = {10.1109/tmi.2019.2927101},
eprint = {1805.03779},
file = {:home/antonio/Documents/bibliography/files/Han, Sunwoo, Ye - 2019 - k-Space Deep Learning for Accelerated MRI.pdf:pdf},
issn = {0278-0062},
journal = {IEEE Transactions on Medical Imaging},
pages = {1--1},
title = {{k-Space Deep Learning for Accelerated MRI}},
year = {2019}
}

@Article{Seo2019,
  author        = {Seo, Jin Keun and Kim, Kang Cheol and Jargal, Ariungerel and Lee, Kyounghun and Harrach, Bastian},
  journal       = {SIAM Journal on Imaging Sciences},
  title         = {{A learning-based method for solving ill-posed nonlinear inverse problems: A simulation study of lung EIT}},
  year          = {2019},
  issn          = {19364954},
  number        = {3},
  pages         = {1275--1295},
  volume        = {12},
  abstract      = {This paper proposes a new approach for solving ill-posed nonlinear inverse problems. For ease of explanation of the proposed approach, we use the example of lung electrical impedance tomography (EIT), which is known to be a nonlinear and ill-posed inverse problem. Conventionally, penaltybased regularization methods have been used to deal with the ill-posed problem. However, experiences over the last three decades have shown methodological limitations in utilizing prior knowledge about tracking expected imaging features for medical diagnosis. The proposed method's paradigm is completely different from conventional approaches; the proposed reconstruction uses a variety of training data sets to generate a low dimensional manifold of approximate solutions, which allows conversion of the ill-posed problem to a well-posed one. Variational autoencoder was used to produce a compact and dense representation for lung EIT images with a low dimensional latent space. Then, we learn a robust connection between the EIT data and the low dimensional latent data. Numerical simulations validate the effectiveness and feasibility of the proposed approach.},
  archiveprefix = {arXiv},
  arxivid       = {1810.10112},
  doi           = {10.1137/18M1222600},
  eprint        = {1810.10112},
  file          = {:home/antonio/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Seo et al. - 2019 - A learning-based method for solving ill-posed nonlinear inverse problems A simulation study of lung EIT.htm:htm},
  keywords      = {Deep learning, Electrical impedance tomography, Inverse problems, Variational autoencoder},
}

@Article{Sangeetha2006,
  author   = {Sangeetha, V. and Prasad, K. J.Rajendra},
  journal  = {Indian Journal of Chemistry - Section B Organic and Medicinal Chemistry},
  title    = {{Syntheses of novel derivatives of 2-acetylfuro[2,3-a]carbazoles, benzo[1,2-b]-1,4-thiazepino[2,3-a]carbazoles and 1-acetyloxycarbazole-2- carbaldehydes}},
  year     = {2006},
  issn     = {03764699},
  number   = {8},
  pages    = {1951--1954},
  volume   = {45},
  abstract = {An elegant one pot syntheses of the titled compounds 3a-d, 4a-d and 6a-d have been presented starting from 1-hydroxycarbazole-2-carbaldehydes 2a-d in good yields. Treatment of 1-hydroxycarbazole-2-carbaldehydes 2a-d with chloroacetone and with o-aminothiophenol have afforded the novel 2-acetylfuro[2,3-a]carbazoles 3a-d and benzo-[1,2-b]-1,4-thiazepino[2,3-a] carbazoles 4a-d respectively. Further carbazoles 2a-d are treated with phenyl acetic acid in an attempt to synthesize 3-phenyl-2-oxopyrano[2,3-a]-carbazoles 5a-d, but the reaction did not proceed in the anticipated direction and only acetyl derivatives 6a-d are obtained. All the products thus obtained from these reactions are well characterized by spectroscopic and analytical data.},
  doi      = {10.1002/chin.200650130},
  file     = {:home/antonio/Documents/bibliography/files/Sangeetha, Prasad - 2006 - Syntheses of novel derivatives of 2-acetylfuro2,3-acarbazoles, benzo1,2-b-1,4-thiazepino2,3-acarbazoles and 1.pdf:pdf},
  keywords = {1-hydroxycarbazole-2-carbaldehydes, 2-acetylfuro carbazoles, Benzo carbazoles, Phenyl oxopyranocarbazoles, o-aminothiophenol},
}

@Article{Kang2017,
  author        = {Kang, Eunhee and Min, Junhong and Ye, Jong Chul},
  journal       = {Medical Physics},
  title         = {{A deep convolutional neural network using directional wavelets for low-dose X-ray CT reconstruction}},
  year          = {2017},
  issn          = {00942405},
  number        = {10},
  pages         = {e360--e375},
  volume        = {44},
  abstract      = {Purpose: Due to the potential risk of inducing cancer, radiation exposure by X-ray CT devices should be reduced for routine patient scanning. However, in low-dose X-ray CT, severe artifacts typically occur due to photon starvation, beam hardening, and other causes, all of which decrease the reliability of the diagnosis. Thus, a high-quality reconstruction method from low-dose X-ray CT data has become a major research topic in the CT community. Conventional model-based de-noising approaches are, however, computationally very expensive, and image-domain de-noising approaches cannot readily remove CT-specific noise patterns. To tackle these problems, we want to develop a new low-dose X-ray CT algorithm based on a deep-learning approach. Method: We propose an algorithm which uses a deep convolutional neural network (CNN) which is applied to the wavelet transform coefficients of low-dose CT images. More specifically, using a directional wavelet transform to extract the directional component of artifacts and exploit the intra- and inter- band correlations, our deep network can effectively suppress CT-specific noise. In addition, our CNN is designed with a residual learning architecture for faster network training and better performance. Results: Experimental results confirm that the proposed algorithm effectively removes complex noise patterns from CT images derived from a reduced X-ray dose. In addition, we show that the wavelet-domain CNN is efficient when used to remove noise from low-dose CT compared to existing approaches. Our results were rigorously evaluated by several radiologists at the Mayo Clinic and won second place at the 2016 "Low-Dose CT Grand Challenge." Conclusions: To the best of our knowledge, this work is the first deep-learning architecture for low-dose CT reconstruction which has been rigorously evaluated and proven to be effective. In addition, the proposed algorithm, in contrast to existing model-based iterative reconstruction (MBIR) methods, has considerable potential to benefit from large data sets. Therefore, we believe that the proposed algorithm opens a new direction in the area of low-dose CT research.},
  archiveprefix = {arXiv},
  arxivid       = {1610.09736},
  doi           = {10.1002/mp.12344},
  eprint        = {1610.09736},
  file          = {:home/antonio/Documents/bibliography/files/Kang, Min, Ye - 2017 - A deep convolutional neural network using directional wavelets for low-dose X-ray CT reconstruction.pdf:pdf},
  keywords      = {convolutional neural network, deep learning, low-dose x-ray CT, wavelet transform},
}

@article{Liu2018,
author = {Liu, Fang and Hyungseok, Jang and Kijowski, Richard and Bradshaw, Tyler and Mcmillan, Alan B},
doi = {10.1148/radiol.2017170700},
file = {:home/antonio/Documents/bibliography/files/Liu et al. - 2018 - Deep Learning MR Imaging – based Attenuation.pdf:pdf},
isbn = {1527-1315 (Electronic) 0033-8419 (Linking)},
issn = {0033-8419},
journal = {Radiology},
number = {2},
pages = {676--684},
pmid = {28925823},
title = {{Deep Learning MR Imaging – based Attenuation}},
volume = {286},
year = {2018}
}

@Article{Biswas2018,
  author        = {Biswas, Sampurna and Aggarwal, Hemant K. and Poddar, Sunrita and Jacob, Mathews},
  journal       = {ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
  title         = {{Model-based free-breathing cardiac mri reconstruction using deep learned storm priors: MODL-STORM}},
  year          = {2018},
  issn          = {15206149},
  pages         = {6533--6537},
  volume        = {2018-April},
  abstract      = {We introduce a model-based reconstruction framework with deep learned (DL) and smoothness regularization on manifolds (STORM) priors to recover free breathing and ungated (FBU) cardiac MRI from highly undersampled measurements. The DL priors enable us to exploit the local correlations, while the STORM prior enables us to make use of the extensive non-local similarities that are subject dependent. We introduce a novel model-based formulation that allows the seamless integration of deep learning methods with available prior information, which current deep learning algorithms are not capable of. The experimental results demonstrate the preliminary potential of this work in accelerating FBU cardiac MRI.},
  archiveprefix = {arXiv},
  arxivid       = {1807.03845},
  doi           = {10.1109/ICASSP.2018.8462637},
  eprint        = {1807.03845},
  file          = {:home/antonio/Documents/bibliography/files/Biswas et al. - 2018 - Model-based free-breathing cardiac mri reconstruction using deep learned storm priors MODL-STORM.pdf:pdf},
  isbn          = {9781538646588},
  keywords      = {Deep CNNs, Free breathing cardiac MRI, Inverse problems, Model-based},
}

@Article{Maier2018,
  author   = {Maier, Joscha and Sawall, Stefan and Knaup, Michael and Kachelrie{\ss}, Marc},
  journal  = {Journal of Nondestructive Evaluation},
  title    = {{Deep Scatter Estimation (DSE): Accurate Real-Time Scatter Estimation for X-Ray CT Using a Deep Convolutional Neural Network}},
  year     = {2018},
  issn     = {15734862},
  number   = {3},
  volume   = {37},
  abstract = {X-ray scatter is a major cause of image quality degradation in dimensional CT. Especially, in case of highly attenuating components scatter-to-primary ratios may easily be higher than 1. The corresponding artifacts which appear as cupping or dark streaks in the CT reconstruction may impair a metrological assessment. Therefore, an appropriate scatter correction is crucial. Thereby, the gold standard is to predict the scatter distribution using a Monte Carlo (MC) code and subtract the corresponding scatter estimate from the measured raw data. MC, however, is too slow to be used routinely. To correct for scatter in real-time, we developed the deep scatter estimation (DSE). It uses a deep convolutional neural network which is trained to reproduce the output of MC simulations using only the acquired projection data as input. Once trained, DSE can be applied in real-time. The present study demonstrates the potential of the proposed approach using simulations and measurements. In both cases the DSE yields highly accurate scatter estimates that differ by< 3% from our MC scatter predictions. Further, DSE clearly outperforms kernel-based scatter estimation techniques and hybrid approaches, as they are in use today.},
  doi      = {10.1007/s10921-018-0507-z},
  file     = {:home/antonio/Documents/bibliography/files/Maier et al. - 2018 - Deep Scatter Estimation (DSE) Accurate Real-Time Scatter Estimation for X-Ray CT Using a Deep Convolutional Neural.pdf:pdf},
  keywords = {Artifact reduction, CT, Cone-beam CT (CBCT), Convolutional neural network, Deep neural network, X-ray scatter correction},
}

@article{Zhou2019,
author = {Zhou, Weimin and Bhadra, Sayantan and Brooks, Frank and Anastasio, Mark A.},
doi = {10.1117/12.2512633},
file = {:home/antonio/Documents/bibliography/files/Zhou et al. - 2019 - Learning stochastic object model from noisy imaging measurements using AmbientGANs.pdf:pdf},
isbn = {9781510625518},
issn = {16057422},
number = {March},
pages = {21},
title = {{Learning stochastic object model from noisy imaging measurements using AmbientGANs}},
year = {2019}
}

@article{Kelly2017,
abstract = {An approach to incorporate deep learning within an iterative image reconstruction framework to reconstruct images from severely incomplete measurement data is presented. Specifically, we utilize a convolutional neural network (CNN) as a quasi-projection operator within a least squares minimization procedure. The CNN is trained to encode high level information about the class of images being imaged; this information is utilized to mitigate artifacts in intermediate images produced by use of an iterative method. The structure of the method was inspired by the proximal gradient descent method, where the proximal operator is replaced by a deep CNN and the gradient descent step is generalized by use of a linear reconstruction operator. It is demonstrated that this approach improves image quality for several cases of limited-view image reconstruction and that using a CNN in an iterative method increases performance compared to conventional image reconstruction approaches. We test our method on several limited-view image reconstruction problems. Qualitative and quantitative results demonstrate state-of-the-art performance.},
archivePrefix = {arXiv},
arxivId = {1709.00584},
author = {Kelly, Brendan and Matthews, Thomas P. and Anastasio, Mark A.},
eprint = {1709.00584},
file = {:home/antonio/Documents/bibliography/files/Kelly, Matthews, Anastasio - 2017 - Deep Learning-Guided Image Reconstruction from Incomplete Data.pdf:pdf},
number = {Nips},
title = {{Deep Learning-Guided Image Reconstruction from Incomplete Data}},
url = {http://arxiv.org/abs/1709.00584},
year = {2017}
}

@article{Argyrou2012,
abstract = {A new approach for tomographic image reconstruction from projections using Artificial Neural Network (ANN) techniques is presented in this work. The design of the proposed reconstruction system is based on simple but efficient network architecture, which best utilizes all available input information. Due to the computational complexity, which grows quadratically with the image size, the training phase of the system is characterized by relatively large CPU times. The trained network, on the contrary, is able to provide all necessary information in a quick and efficient way giving results comparable to other time consuming iterative reconstruction algorithms. The performance of the network studied with a large number of software phantoms is directly compared to other iterative and analytical techniques. For a given image size and projections number, the role of the hidden layers in the network architecture is examined and the quality dependence of the reconstructed image on the size of the geometrical patterns used in the training phase is also investigated. ANN based tomographic image reconstruction can be easily implemented in modern FPGA devices and can serve as a quick initialization method to other complicated and time consuming procedures. {\textcopyright} 2012 IEEE.},
author = {Argyrou, Maria and Maintas, Dimitris and Tsoumpas, Charalampos and Stiliaris, Efstathios},
doi = {10.1109/NSSMIC.2012.6551757},
file = {:home/antonio/Documents/bibliography/files/Argyrou et al. - 2012 - Tomographic image reconstruction based on artificial neural network (ANN) techniques.pdf:pdf},
isbn = {9781467320306},
issn = {10957863},
journal = {IEEE Nuclear Science Symposium Conference Record},
number = {May},
pages = {3324--3327},
title = {{Tomographic image reconstruction based on artificial neural network (ANN) techniques}},
year = {2012}
}

@Article{Lee2018,
  author        = {Lee, Dongwook and Yoo, Jaejun and Tak, Sungho and Ye, Jong Chul},
  journal       = {IEEE Transactions on Biomedical Engineering},
  title         = {{Deep residual learning for accelerated MRI using magnitude and phase networks}},
  year          = {2018},
  issn          = {15582531},
  number        = {9},
  pages         = {1985--1995},
  volume        = {65},
  abstract      = {Objective: Accelerated magnetic resonance (MR) image acquisition with compressed sensing (CS) and parallel imaging is a powerful method to reduce MR imaging scan time. However, many reconstruction algorithms have high computational costs. To address this, we investigate deep residual learning networks to remove aliasing artifacts from artifact corrupted images. Methods: The deep residual learning networks are composed of magnitude and phase networks that are separately trained. If both phase and magnitude information are available, the proposed algorithm can work as an iterative k-space interpolation algorithm using framelet representation. When only magnitude data are available, the proposed approach works as an image domain postprocessing algorithm. Results: Even with strong coherent aliasing artifacts, the proposed network successfully learned and removed the aliasing artifacts, whereas current parallel and CS reconstruction methods were unable to remove these artifacts. Conclusion: Comparisons using single and multiple coil acquisition show that the proposed residual network provides good reconstruction results with orders of magnitude faster computational time than existing CS methods. Significance: The proposed deep learning framework may have a great potential for accelerated MR reconstruction by generating accurate results immediately.},
  archiveprefix = {arXiv},
  arxivid       = {1804.00432},
  doi           = {10.1109/TBME.2018.2821699},
  eprint        = {1804.00432},
  file          = {:home/antonio/Documents/bibliography/files/Lee et al. - 2018 - Deep residual learning for accelerated MRI using magnitude and phase networks.pdf:pdf},
  keywords      = {Compressed sensing MRI, Deep convolutional framelets, Deep learning, Parallel imaging},
}

@Article{Wu2018c,
  author        = {Wu, Dufan and Kim, Kyungsang and Dong, Bin and Fakhri, Georges El and Li, Quanzheng},
  journal       = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  title         = {{End-to-end lung nodule detection in computed tomography}},
  year          = {2018},
  issn          = {16113349},
  pages         = {37--45},
  volume        = {11046 LNCS},
  abstract      = {Computer aided diagnostic (CAD) system is crucial for modern medical imaging. But almost all CAD systems operate on reconstructed images, which were optimized for radiologists. Computer vision can capture features that is subtle to human observers, so it is desirable to design a CAD system operating on the raw data. In this paper, we proposed a deep-neural-network-based detection system for lung nodule detection in computed tomography (CT). A primal-dual-type deep reconstruction network was applied first to convert the raw data to the image space, followed by a 3-dimensional convolutional neural network (3D-CNN) for the nodule detection. For efficient network training, the deep reconstruction network and the CNN detector was trained sequentially first, then followed by one epoch of end-to-end fine tuning. The method was evaluated on the Lung Image Database Consortium image collection (LIDC-IDRI) with simulated forward projections. With 144 multi-slice fanbeam projections, the proposed end-to-end detector could achieve comparable sensitivity with the reference detector, which was trained and applied on the fully-sampled image data. It also demonstrated superior detection performance compared to detectors trained on the reconstructed images. The proposed method is general and could be expanded to most detection tasks in medical imaging.},
  archiveprefix = {arXiv},
  arxivid       = {1711.02074},
  doi           = {10.1007/978-3-030-00919-9_5},
  eprint        = {1711.02074},
  file          = {:home/antonio/Documents/bibliography/files/Wu et al. - 2018 - End-to-end lung nodule detection in computed tomography.pdf:pdf},
  isbn          = {9783030009182},
  keywords      = {Artificial neural networks, Computed tomography, Computer aided diagnosis},
}

@Book{Knoll2018,
  author    = {Knoll, Florian and Maier, Andreas and Rueckert, Daniel},
  publisher = {Springer International Publishing},
  title     = {{Preface}},
  year      = {2018},
  isbn      = {9783030001285},
  volume    = {11074 LNCS},
  booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  doi       = {10.1007/978-3-030-00129-2},
  file      = {:home/antonio/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Knoll, Maier, Rueckert - 2018 - Preface.pdf:pdf},
  issn      = {16113349},
  keywords  = {Image reconstruction, Neural network, End to end, RNN, automap, end to end, image reconstruction, neural network, renet, rnn},
  pages     = {v},
  url       = {http://dx.doi.org/10.1007/978-3-030-00129-2_2},
}

@article{Marone2018,
author = {Marone, Chris},
doi = {10.1038/s41561-018-0117-5},
file = {:home/antonio/Documents/bibliography/files/Marone - 2018 - Training machines in Earthly ways.pdf:pdf},
issn = {17520908},
journal = {Nature Geoscience},
number = {5},
pages = {301--302},
title = {{Training machines in Earthly ways}},
volume = {11},
year = {2018}
}

@book{1392,
author = {زا, آمارنامه مصرف فرآورده‎های نفتی انرژی},
booktitle = {شرکت ملی پخش فرآرده‎های نفتی انرژی‎زا},
file = {:home/antonio/Documents/bibliography/files/زا - 1392 - Abstract algebra.pdf:pdf},
isbn = {0471433349},
title = {{Abstract algebra}},
year = {1392}
}

@misc{Corrigan1984,
author = {Corrigan, E F},
booktitle = {Physics Bulletin},
doi = {10.1088/0031-9112/35/6/029},
file = {:home/antonio/Documents/bibliography/files/Corrigan - 1984 - Classical Fields General Relativity and Gauge Theory.pdf:pdf},
issn = {0031-9112},
number = {6},
pages = {246--246},
title = {{Classical Fields: General Relativity and Gauge Theory}},
volume = {35},
year = {1984}
}

@Book{Pierce1993,
  author    = {Pierce, Allan D.},
  publisher = {ACADEMIC PRESS, INC.},
  title     = {{Variational Formulations in Acoustic Radiation and Scattering}},
  year      = {1993},
  isbn      = {0124779220},
  number    = {C},
  volume    = {22},
  booktitle = {Physical Acoustics},
  doi       = {10.1016/B978-0-12-477922-8.50007-8},
  file      = {:home/antonio/Documents/bibliography/files/Pierce - 1993 - Variational Formulations in Acoustic Radiation and Scattering.pdf:pdf},
  groups    = {Books},
  issn      = {0893388X},
  pages     = {195--371},
  url       = {http://dx.doi.org/10.1016/B978-0-12-477922-8.50007-8},
}

@article{Woodard2015,
abstract = {Ostrogradsky's construction of a Hamiltonian formalism for nondegenerate higher derivative Lagrangians is reviewed. The resulting instability imposes by far the most powerful restriction on fundamental, interacting, continuum Lagrangian field theories. A discussion is given of the problems raised by attempts to evade this restriction.},
archivePrefix = {arXiv},
arxivId = {1506.02210},
author = {Woodard, R. P.},
eprint = {1506.02210},
file = {:home/antonio/Documents/bibliography/files/Woodard - 2015 - The Theorem of Ostrogradsky.pdf:pdf},
title = {{The Theorem of Ostrogradsky}},
url = {http://arxiv.org/abs/1506.02210},
year = {2015}
}

@article{Woodard2007,
abstract = {Scalar quintessence seems epicyclic because one can choose the potential to reproduce any cosmology (I review the construction) and because the properties of this scalar seem to raise more questions than they answer. This is why there has been so much recent interest in modified gravity. I review the powerful theorem of Ostrogradski which demonstrates that the only potentially stable, local modification of general relativity is to make the Lagrangian an arbitrary function of the Ricci scalar. Such a theory can certainly reproduce the current phase of cosmic acceleration without Dark Energy. However, this explanation again seems epicyclic in that one can construct a function of the Ricci scalar to support any cosmology (I give the technique). Models of this form are also liable to problems in the way they couple to matter, both in terms of matter's impact upon them and in terms of the long range gravitational force they predict. Because of these problems my own preference for avoiding Dark Energy is to bypass Ostrogradski's theorem by considering the fully nonlocal effective action built up by quantum gravitational processes during the epoch of primordial inflation. {\textcopyright} 2007 Springer-Verlag Berlin Heidelberg.},
archivePrefix = {arXiv},
arxivId = {astro-ph/0601672},
author = {Woodard, Richard},
doi = {10.1007/978-3-540-71013-4_14},
eprint = {0601672},
file = {:home/antonio/Documents/bibliography/files/Woodard - 2007 - Avoiding dark energy with 1R modifications of gravity.pdf:pdf},
isbn = {3540710124},
issn = {00758450},
journal = {Lecture Notes in Physics},
pages = {403--433},
primaryClass = {astro-ph},
title = {{Avoiding dark energy with 1/R modifications of gravity}},
volume = {720},
year = {2007}
}

@article{Harmanni2016,
author = {Harmanni, Floris},
file = {:home/antonio/Documents/bibliography/files/Harmanni - 2016 - Higher Order Lagrangians for classical mechanics and scalar fields.pdf:pdf},
number = {July},
title = {{Higher Order Lagrangians for classical mechanics and scalar fields}},
year = {2016}
}

@article{Goodfellow2014,
abstract = {We propose a new framework for estimating generative models via an adversarial process, in which we simultaneously train two models: a generative model G that captures the data distribution, and a discriminative model D that estimates the probability that a sample came from the training data rather than G. The training procedure for G is to maximize the probability of D making a mistake. This framework corresponds to a minimax two-player game. In the space of arbitrary functions G and D, a unique solution exists, with G recovering the training data distribution and D equal to <sup>1</sup>/<inf>2</inf> everywhere. In the case where G and D are defined by multilayer perceptrons, the entire system can be trained with backpropagation. There is no need for any Markov chains or unrolled approximate inference networks during either training or generation of samples. Experiments demonstrate the potential of the framework through qualitative and quantitative evaluation of the generated samples.},
archivePrefix = {arXiv},
arxivId = {1406.2661},
author = {Goodfellow, Ian J. and Pouget-Abadie, Jean and Mirza, Mehdi and Xu, Bing and Warde-Farley, David and Ozair, Sherjil and Courville, Aaron and Bengio, Yoshua},
doi = {10.3156/jsoft.29.5_177_2},
eprint = {1406.2661},
file = {:home/antonio/Documents/bibliography/files/Goodfellow et al. - 2014 - Generative adversarial nets.pdf:pdf},
issn = {10495258},
journal = {Advances in Neural Information Processing Systems},
number = {January},
pages = {2672--2680},
title = {{Generative adversarial nets}},
volume = {3},
year = {2014}
}

@Article{Amjad,
  author        = {Amjad, Jaweria and Lyu, Zhaoyan and Rodrigues, Miguel},
  title         = {{Deep Learning for Inverse Problems: Bounds and Regularizers}},
  pages         = {1--17},
  archiveprefix = {arXiv},
  arxivid       = {arXiv:1901.11352v1},
  eprint        = {arXiv:1901.11352v1},
  file          = {:home/antonio/Documents/bibliography/files/Amjad, Lyu, Rodrigues - Unknown - Deep Learning for Inverse Problems Bounds and Regularizers.pdf:pdf},
  keywords      = {generalization error, inverse problems, lipschitz con-},
}

@Article{Hinton2014,
  author   = {Hinton, Geoffrey},
  title    = {{Dropout : A Simple Way to Prevent Neural Networks from Overfitting}},
  year     = {2014},
  pages    = {1929--1958},
  volume   = {15},
  file     = {:home/antonio/Documents/bibliography/files/Hinton - 2014 - Dropout A Simple Way to Prevent Neural Networks from Overfitting.pdf:pdf},
  keywords = {deep learning, model combination, neural networks, regularization},
}

@article{Mccann,
archivePrefix = {arXiv},
arxivId = {arXiv:1710.04011v1},
author = {Mccann, Michael T and Jin, Kyong Hwan and Unser, Michael},
eprint = {arXiv:1710.04011v1},
file = {:home/antonio/Documents/bibliography/files/Mccann, Jin, Unser - Unknown - A Review of Convolutional Neural Networks for Inverse Problems in Imaging.pdf:pdf},
pages = {1--11},
title = {{A Review of Convolutional Neural Networks for Inverse Problems in Imaging}}
}

@Article{Poggio,
  author   = {Poggio, Tomaso and Mhaskar, Hrushikesh and Miranda, Brando},
  title    = {{Why and When Can Deep-but Not Shallow-networks Avoid the Curse of Dimensionality : A Review}},
  pages    = {1--17},
  doi      = {10.1007/s11633-017-1054-2},
  file     = {:home/antonio/Documents/bibliography/files/Poggio, Mhaskar, Miranda - Unknown - Why and When Can Deep-but Not Shallow-networks Avoid the Curse of Dimensionality A Review.pdf:pdf},
  keywords = {convolutional neural networks, deep and shallow networks, function approximation, machine learning, neural networks},
}

@article{Antun,
archivePrefix = {arXiv},
arxivId = {arXiv:1902.05300v1},
author = {Antun, Vegard},
eprint = {arXiv:1902.05300v1},
file = {:home/antonio/Documents/bibliography/files/Antun - Unknown - On instabilities of deep learning in image reconstruction - Does AI come at a cost.pdf:pdf},
title = {{On instabilities of deep learning in image reconstruction - Does AI come at a cost ?}}
}

@article{Bruna2013a,
author = {Bruna, Joan},
file = {:home/antonio/Documents/bibliography/files/Bruna - 2013 - Invariant Scattering Convolution Networks ´.pdf:pdf},
number = {8},
pages = {1872--1886},
title = {{Invariant Scattering Convolution Networks ´}},
volume = {35},
year = {2013}
}

@article{Dokmani2017,
archivePrefix = {arXiv},
arxivId = {arXiv:1609.05502v2},
author = {Dokmani, Ivan and Bruna, Joan},
eprint = {arXiv:1609.05502v2},
file = {:home/antonio/Documents/bibliography/files/Dokmani, Bruna - 2017 - Inverse Problems with Invariant Multiscale Statistics.pdf:pdf},
number = {September 2016},
title = {{Inverse Problems with Invariant Multiscale Statistics}},
year = {2017}
}

@article{Bronstein2015,
archivePrefix = {arXiv},
arxivId = {arXiv:1412.5896v3},
author = {Bronstein, Alex M},
eprint = {arXiv:1412.5896v3},
file = {:home/antonio/Documents/bibliography/files/Bronstein - 2015 - On the stability of deep networks.pdf:pdf},
number = {1},
pages = {1--4},
title = {{On the stability of deep networks}},
year = {2015}
}

@Article{Weng2021,
  author        = {Weng, Weihao and Zhu, Xin},
  journal       = {IEEE Access},
  title         = {{INet: Convolutional Networks for Biomedical Image Segmentation}},
  year          = {2021},
  issn          = {21693536},
  pages         = {16591--16603},
  volume        = {9},
  abstract      = {Encoder-decoder networks are state-of-the-art approaches to biomedical image segmentation, but have two problems: i.e., the widely used pooling operations may discard spatial information, and therefore low-level semantics are lost. Feature fusion methods can mitigate these problems but feature maps of different scales cannot be easily fused because down- and upsampling change the spatial resolution of feature map. To address these issues, we propose INet, which enlarges receptive fields by increasing the kernel sizes of convolutional layers in steps (e.g., from 3times 3 to 7times 7 and then 15times 15 ) instead of downsampling. Inspired by an Inception module, INet extracts features by kernels of different sizes through concatenating the output feature maps of all preceding convolutional layers. We also find that the large kernel makes the network feasible for biomedical image segmentation. In addition, INet uses two overlapping max-poolings, i.e., max-poolings with stride 1, to extract the sharpest features. Fixed-size and fixed-channel feature maps enable INet to concatenate feature maps and add multiple shortcuts across layers. In this way, INet can recover low-level semantics by concatenating the feature maps of all preceding layers and expedite the training by adding multiple shortcuts. Because INet has additional residual shortcuts, we compare INet with a UNet system that also has residual shortcuts (ResUNet). To confirm INet as a backbone architecture for biomedical image segmentation, we implement dense connections on INet (called DenseINet) and compare it to a DenseUNet system with residual shortcuts (ResDenseUNet). INet and DenseINet require 16.9% and 37.6% fewer parameters than ResUNet and ResDenseUNet, respectively. In comparison with six encoder-decoder approaches using nine public datasets, INet and DenseINet demonstrate efficient improvements in biomedical image segmentation. INet outperforms DeepLabV3, which implementing atrous convolution instead of downsampling to increase receptive fields. INet also outperforms two recent methods (named HRNet and MS-NAS) that maintain high-resolution representations and repeatedly exchange the information across resolutions.},
  archiveprefix = {arXiv},
  arxivid       = {1505.04597},
  doi           = {10.1109/ACCESS.2021.3053408},
  eprint        = {1505.04597},
  file          = {:home/antonio/Documents/bibliography/files/Weng, Zhu - 2021 - INet Convolutional Networks for Biomedical Image Segmentation.pdf:pdf},
  keywords      = {Biomedical image, convolutional networks, encoder-decoder networks, semantic segmentation},
}

@article{Grohs2017a,
author = {Grohs, Philipp and Wiatowski, Thomas and Helmut, B},
file = {:home/antonio/Documents/bibliography/files/Grohs, Wiatowski, Helmut - 2017 - Energy Decay and Conservation in Deep Convolutional Neural Networks.pdf:pdf},
isbn = {9781509040964},
pages = {1356--1360},
title = {{Energy Decay and Conservation in Deep Convolutional Neural Networks}},
volume = {2},
year = {2017}
}

@article{Viroli2018,
author = {Viroli, Cinzia},
file = {:home/antonio/Documents/bibliography/files/Viroli - 2018 - Deep Gaussian Mixture Models.pdf:pdf},
title = {{Deep Gaussian Mixture Models}},
year = {2018}
}

@article{Zhang,
author = {Zhang, Xingcheng and Li, Zhizhong and Lin, Dahua},
file = {:home/antonio/Documents/bibliography/files/Zhang, Li, Lin - Unknown - PolyNet A Pursuit of Structural Diversity in Very Deep Networks.pdf:pdf},
number = {1},
pages = {718--726},
title = {{PolyNet : A Pursuit of Structural Diversity in Very Deep Networks}}
}

@Article{Pedreschi,
  author        = {Pedreschi, Dino and Giannotti, Fosca},
  title         = {{A Survey Of Methods For Explaining Black Box Models}},
  pages         = {1--45},
  archiveprefix = {arXiv},
  arxivid       = {arXiv:1802.01933v3},
  eprint        = {arXiv:1802.01933v3},
  file          = {:home/antonio/Documents/bibliography/files/Pedreschi, Giannotti - Unknown - A Survey Of Methods For Explaining Black Box Models.pdf:pdf},
  keywords      = {explanations, interpretability, open the black box, transparent},
}

@Article{Higham2019,
  author        = {Higham, Catherine F. and Higham, Desmond J},
  journal       = {SIAM Review},
  title         = {{Deep learning: An introduction for applied mathematicians}},
  year          = {2019},
  issn          = {00361445},
  number        = {4},
  pages         = {860--891},
  volume        = {61},
  abstract      = {Multilayered artificial neural networks are becoming a pervasive tool in a host of application fields. At the heart of this deep learning revolution are familiar concepts from applied and computational mathematics, notably from calculus, approximation theory, optimization, and linear algebra. This article provides a very brief introduction to the basic ideas that underlie deep learning from an applied mathematics perspective. Our target audience includes postgraduate and final year undergraduate students in mathematics who are keen to learn about the area. The article may also be useful for instructors in mathematics who wish to enliven their classes with references to the application of deep learning techniques. We focus on three fundamental questions: What is a deep neural network? How is a network trained? What is the stochastic gradient method? We illustrate the ideas with a short MATLAB code that sets up and trains a network. We also demonstrate the use of state-of-the-art software on a large scale image classification problem. We finish with references to the current literature.},
  archiveprefix = {arXiv},
  arxivid       = {1801.05894},
  doi           = {10.1137/18M1165748},
  eprint        = {1801.05894},
  file          = {:home/antonio/Documents/bibliography/files/Higham, Higham - 2019 - Deep learning An introduction for applied mathematicians.pdf:pdf},
  keywords      = {Back propagation, Chain rule, Convolution, Image classification, Neural network, Overfitting, Sigmoid, Stochastic gradient method, Supervised learning},
}

@article{Lucas2018,
author = {Lucas, Alice and Iliadis, Michael and Molina, Rafael},
file = {:home/antonio/Documents/bibliography/files/Lucas, Iliadis, Molina - 2018 - Using Deep Neural Networks for Inverse Problems in Imaging.pdf:pdf},
number = {January},
title = {{Using Deep Neural Networks for Inverse Problems in Imaging}},
year = {2018}
}

@Article{Selvikv2018,
  author        = {Selvikv, Alexander},
  title         = {{An overview of deep learning in medical imaging focusing on MRI}},
  year          = {2018},
  archiveprefix = {arXiv},
  arxivid       = {arXiv:1811.10052v2},
  eprint        = {arXiv:1811.10052v2},
  file          = {:home/antonio/Documents/bibliography/files/Selvikv - 2018 - An overview of deep learning in medical imaging focusing on MRI.pdf:pdf},
  keywords      = {deep learning, machine learning, medical imaging, mri},
}

@Article{Soliman2002,
  author   = {Soliman, E A and Abdelmageed, A K},
  title    = {{Neural Network Model for the Efficient Calculation of Green ' s Functions in Layered Media}},
  year     = {2002},
  number   = {April},
  pages    = {128--135},
  doi      = {10.1002/mmce.10066},
  file     = {:home/antonio/Documents/bibliography/files/Soliman, Abdelmageed - 2002 - Neural Network Model for the Efficient Calculation of Green ' s Functions in Layered Media.pdf:pdf},
  keywords = {discrete complex images, green, neural networks, radial basis functions, s functions},
}

@article{Jia,
archivePrefix = {arXiv},
arxivId = {arXiv:1905.05929v2},
author = {Jia, Kui and Li, Shuai and Wen, Yuxin and Liu, Tongliang and Tao, Dacheng},
eprint = {arXiv:1905.05929v2},
file = {:home/antonio/Documents/bibliography/files/Jia et al. - Unknown - Orthogonal Deep Neural Networks.pdf:pdf},
pages = {1--21},
title = {{Orthogonal Deep Neural Networks}}
}

@article{Kingma,
author = {Kingma, Diederik P Durk and Welling, Max and Welling, Max},
file = {:home/antonio/Documents/bibliography/files/Kingma, Welling, Welling - Unknown - Auto-Encoding Variational Bayes.pdf:pdf},
title = {{Auto-Encoding Variational Bayes}}
}

@article{Learningb,
author = {Learning, Deep},
file = {:home/antonio/Documents/bibliography/files/Learning - Unknown - Beyond Image Data.pdf:pdf},
title = {{Beyond Image Data}}
}

@article{Lu2018a,
author = {Lu, Y and Dong, B},
file = {:home/antonio/Documents/bibliography/files/Lu, Dong - 2018 - Supplementary Materials.pdf:pdf},
pages = {7--9},
title = {{Supplementary Materials}},
year = {2018}
}

@article{Long2017,
author = {Long, Zichao and Lu, Yiping and Ma, Xianzhong and Dong, Bin},
file = {:home/antonio/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Long et al. - 2017 - PDE-Net.pdf:pdf},
title = {{PDE-Net}},
year = {2017}
}

@article{Long,
archivePrefix = {arXiv},
arxivId = {arXiv:1812.04426v1},
author = {Long, Zichao and Lu, Yiping},
eprint = {arXiv:1812.04426v1},
file = {:home/antonio/Documents/bibliography/files/Long, Lu - Unknown - N UMERIC -S YMBOLIC H YBRID D EEP N ETWORK.pdf:pdf},
title = {{N UMERIC -S YMBOLIC H YBRID D EEP N ETWORK}}
}

@inproceedings{Long2018a,
abstract = {Partial differential equations (PDEs) play a prominent role in many disciplines of science and engineering. PDEs are commonly derived based on empirical observations. However, with the rapid development of sensors, computational power, and data storage in the past decade, huge quantities of data can be easily collected and efficiently stored. Such vast quantity of data offers new opportunities for data-driven discovery of physical laws. Inspired by the latest development of neural network designs in deep learning, we propose a new feed-forward deep network, called PDE- Net, to fulfill two objectives at the same time: To accurately predict dynamics of complex sys-tems and to uncover the underlying hidden PDE models. Comparing with existing approaches, our approach has the most flexibility by learning both differential operators and the nonlinear response function of the underlying PDE model. A special feature of the proposed PDE-Net is that all filters are properly constrained, which enables us to easily identify the governing PDE models while still maintaining the expressive and predictive power of the network. These constrains are carefully designed by fully exploiting the relation between the orders of differential operators and the orders of sum rules of filters (an important concept originated from wavelet theory). Numerical experiments show that the PDE-Net has the potential to uncover the hidden PDE of the observed dynamics, and predict the dynamical behavior for a relatively long time, even in a noisy environment.},
archivePrefix = {arXiv},
arxivId = {1710.09668},
author = {Long, Zichao and Lu, Yiping and Ma, Xianzhong and Dong, Bin},
booktitle = {35th International Conference on Machine Learning, ICML 2018},
eprint = {1710.09668},
file = {:home/antonio/Documents/bibliography/files/Long et al. - 2018 - PDE-Net Learning PDEs from data.pdf:pdf},
isbn = {9781510867963},
pages = {5067--5078},
title = {{PDE-Net: Learning PDEs from data}},
volume = {7},
year = {2018}
}

@Article{Mathematics,
  author        = {Mathematics, Applied},
  title         = {{Deep relaxation: partial differential equations for optimizing deep neural networks}},
  pages         = {1--22},
  archiveprefix = {arXiv},
  arxivid       = {arXiv:1704.04932v1},
  eprint        = {arXiv:1704.04932v1},
  file          = {:home/antonio/Documents/bibliography/files/Mathematics - Unknown - Deep relaxation partial differential equations for optimizing deep neural networks.pdf:pdf},
  keywords      = {deep learning, entropy, inf-convolution, local, local convexity, neural networks, non-convex optimization, optimal control, partial differential equations, proximal, regularization, smoothing, stochastic gradient descent},
}

@article{Pang,
archivePrefix = {arXiv},
arxivId = {arXiv:1811.08967v1},
author = {Pang, Guofei and Lu, Lu and Karniadakis, George Em},
eprint = {arXiv:1811.08967v1},
file = {:home/antonio/Documents/bibliography/files/Pang, Lu, Karniadakis - Unknown - fPINNs Fractional Physics-Informed Neural Networks.pdf:pdf},
pages = {1--29},
title = {{fPINNs : Fractional Physics-Informed Neural Networks}}
}

@Article{Fan,
  author        = {Fan, Yuwei},
  title         = {{Solving Electrical Impedance Tomography with Deep Learning}},
  archiveprefix = {arXiv},
  arxivid       = {arXiv:1906.03944v1},
  eprint        = {arXiv:1906.03944v1},
  file          = {:home/antonio/Documents/bibliography/files/Fan - Unknown - Solving Electrical Impedance Tomography with Deep Learning.pdf:pdf},
  keywords      = {bcr-net, convolutional neural network, dirichlet-to-neumann map, electrical impedance tomography, forward problem, inverse, neural networks, problem},
}

@article{Girosi1989,
author = {Girosi, Federico and Poggio, Tomaso},
file = {:home/antonio/Documents/bibliography/files/Girosi, Poggio - 1989 - Networks and the Best Approximation Property 1 Introduction.pdf:pdf},
title = {{Networks and the Best Approximation Property 1 Introduction}},
year = {1989}
}

@article{Khoo,
archivePrefix = {arXiv},
arxivId = {arXiv:1810.09675v1},
author = {Khoo, Yuehaw and Ying, Lexing},
eprint = {arXiv:1810.09675v1},
file = {:home/antonio/Documents/bibliography/files/Khoo, Ying - Unknown - Switchnet a neural network model for forward and inverse scattering problems.pdf:pdf},
pages = {1--19},
title = {{Switchnet: a neural network model for forward and inverse scattering problems}}
}

@article{Ruthotto2017,
archivePrefix = {arXiv},
arxivId = {arXiv:1703.02009v2},
author = {Ruthotto, Lars},
eprint = {arXiv:1703.02009v2},
file = {:home/antonio/Documents/bibliography/files/Ruthotto - 2017 - Learning Across Scales - Multiscale Methods for Convolution Neural Networks.pdf:pdf},
pages = {1--12},
title = {{Learning Across Scales - Multiscale Methods for Convolution Neural Networks}},
year = {2017}
}

@article{Larsson2016,
abstract = {We introduce a design strategy for neural network macro-architecture based on self-similarity. Repeated application of a simple expansion rule generates deep networks whose structural layouts are precisely truncated fractals. These networks contain interacting subpaths of different lengths, but do not include any pass-through or residual connections; every internal signal is transformed by a filter and nonlinearity before being seen by subsequent layers. In experiments, fractal networks match the excellent performance of standard residual networks on both CIFAR and ImageNet classification tasks, thereby demonstrating that residual representations may not be fundamental to the success of extremely deep convolutional neural networks. Rather, the key may be the ability to transition, during training, from effectively shallow to deep. We note similarities with student-teacher behavior and develop drop-path, a natural extension of dropout, to regularize co-adaptation of subpaths in fractal architectures. Such regularization allows extraction of high-performance fixed-depth subnetworks. Additionally, fractal networks exhibit an anytime property: shallow subnetworks provide a quick answer, while deeper subnetworks, with higher latency, provide a more accurate answer.},
archivePrefix = {arXiv},
arxivId = {1605.07648},
author = {Larsson, Gustav and Maire, Michael and Shakhnarovich, Gregory},
eprint = {1605.07648},
file = {:home/antonio/Documents/bibliography/files/Larsson, Maire, Shakhnarovich - 2016 - FractalNet Ultra-Deep Neural Networks without Residuals.pdf:pdf},
pages = {1--11},
title = {{FractalNet: Ultra-Deep Neural Networks without Residuals}},
url = {http://arxiv.org/abs/1605.07648},
year = {2016}
}

@Article{Liu2018a,
  author        = {Liu, Huan and Wang, Hong and Zheng, Xiangcheng},
  title         = {{Data-driven physics informed deep learning of solute transport with anomalous diffusion}},
  year          = {2018},
  archiveprefix = {arXiv},
  arxivid       = {arXiv:1812.01492v1},
  eprint        = {arXiv:1812.01492v1},
  file          = {:home/antonio/Documents/bibliography/files/Liu, Wang, Zheng - 2018 - Data-driven physics informed deep learning of solute transport with anomalous diffusion.pdf:pdf},
  groups        = {PDEs and neural networks},
  keywords      = {data-driven scientific computing, deep learning, equations, fractional advection-dispersion, parameter identification},
}

@article{Chenb,
author = {Chen, Yunjin and Pock, Thomas},
file = {:home/antonio/Documents/bibliography/files/Chen, Pock - Unknown - On learning optimized reaction diffusion processes for effective image restoration.pdf:pdf},
title = {{On learning optimized reaction diffusion processes for effective image restoration}}
}

@article{Chiaramonte,
author = {Chiaramonte, M M and Kiener, M},
file = {:home/antonio/Documents/bibliography/files/Chiaramonte, Kiener - Unknown - Solving differential equations using neural networks.pdf:pdf},
number = {4},
pages = {1--5},
title = {{Solving differential equations using neural networks}},
volume = {1}
}

@article{Dong2017,
author = {Dong, B I N and Jiang, Qingtang and Shen, Zuowei},
file = {:home/antonio/Documents/bibliography/files/Dong, Jiang, Shen - 2017 - IMAGE RESTORATION WAVELET FRAME SHRINKAGE , 1 . Introduction . Image restoration , including image denoising.pdf:pdf},
number = {1},
pages = {606--660},
title = {{IMAGE RESTORATION : WAVELET FRAME SHRINKAGE , 1 . Introduction . Image restoration , including image denoising , deblurring , in- painting , and computed tomography , is one of the most important areas in imaging science . Its major purpose is to enhance }},
volume = {15},
year = {2017}
}

@Article{Feliufab,
  author        = {Feliu-fab, Jordi and Fan, Yuwei},
  title         = {{Meta-learning Pseudo-differential Operators with Deep Neural Networks}},
  pages         = {1--20},
  archiveprefix = {arXiv},
  arxivid       = {arXiv:1906.06782v1},
  eprint        = {arXiv:1906.06782v1},
  file          = {:home/antonio/Documents/bibliography/files/Feliu-fab, Fan - Unknown - Meta-learning Pseudo-differential Operators with Deep Neural Networks.pdf:pdf},
  keywords      = {convolutional neural networks, deep neural networks, green, learning, meta-, nonstandard wavelet form, radiative transfer equation, s functions},
}

@Article{Fan2018a,
  author   = {Fan, Yuwei},
  title    = {{Fast algorithms for integral formulations of steady-state radiative transfer equation}},
  year     = {2018},
  pages    = {1--24},
  file     = {:home/antonio/Documents/bibliography/files/Fan - 2018 - Fast algorithms for integral formulations of steady-state radiative transfer equation.pdf:pdf},
  keywords = {anisotropic scattering, fast algorithm, fft, fredholm integral equation, radiative transfer, recursive skele-, tonization},
}

@article{Fan2019,
author = {Fan, Yuwei and Orozco, Cindy and Ying, Lexing},
doi = {10.1016/j.jcp.2019.02.002},
file = {:home/antonio/Documents/bibliography/files/Fan, Orozco, Ying - 2019 - BCR-Net A neural network based on the nonstandard wavelet form.pdf:pdf},
issn = {0021-9991},
journal = {Journal of Computational Physics},
pages = {1--15},
publisher = {Elsevier Inc.},
title = {{BCR-Net : A neural network based on the nonstandard wavelet form}},
url = {https://doi.org/10.1016/j.jcp.2019.02.002},
volume = {384},
year = {2019}
}

@Article{Fana,
  author        = {Fan, Yuwei},
  title         = {{Solving Optical Tomography with Deep Learning}},
  pages         = {1--16},
  archiveprefix = {arXiv},
  arxivid       = {arXiv:1910.04756v1},
  eprint        = {arXiv:1910.04756v1},
  file          = {:home/antonio/Documents/bibliography/files/Fan - Unknown - Solving Optical Tomography with Deep Learning.pdf:pdf},
  keywords      = {albedo operator, convolutional neural network, inverse problem, networks, neural, optical tomography, radiative transfer equation},
}

@article{Gregor2010,
author = {Gregor, Karol and Lecun, Yann},
file = {:home/antonio/Documents/bibliography/files/Gregor, Lecun - 2010 - Learning Fast Approximations of Sparse Coding.pdf:pdf},
keywords = {sparse coding, feature extraction, deep learning},
title = {{Learning Fast Approximations of Sparse Coding}},
year = {2010}
}

@Article{Anden2014,
  author        = {And{\'{e}}n, Joakim and Mallat, St{\'{e}}phane},
  journal       = {IEEE Transactions on Signal Processing},
  title         = {{Deep scattering spectrum}},
  year          = {2014},
  issn          = {1053587X},
  number        = {16},
  pages         = {4114--4128},
  volume        = {62},
  abstract      = {A scattering transform defines a locally translation invariant representation which is stable to time-warping deformation. It extends MFCC representations by computing modulation spectrum coefficients of multiple orders, through cascades of wavelet convolutions and modulus operators. Second-order scattering coefficients characterize transient phenomena such as attacks and amplitude modulation. A frequency transposition invariant representation is obtained by applying a scattering transform along log-frequency. State-the-of-art classification results are obtained for musical genre and phone classification on GTZAN and TIMIT databases, respectively. {\textcopyright} 1991-2012 IEEE.},
  archiveprefix = {arXiv},
  arxivid       = {1304.6763},
  doi           = {10.1109/TSP.2014.2326991},
  eprint        = {1304.6763},
  file          = {:home/antonio/Documents/bibliography/files/And{\'{e}}n, Mallat - 2014 - Deep scattering spectrum.pdf:pdf},
  keywords      = {Audio classification, MFCC, deep neural networks, modulation spectrum, wavelets},
}

@article{Benning2019,
author = {Benning, Martin and Mary, Queen and Celledoni, Elena and Ehrhardt, Matthias J},
file = {:home/antonio/Documents/bibliography/files/Benning et al. - 2019 - Deep learning as optimal control problems models and numerical methods.pdf:pdf},
number = {July},
title = {{Deep learning as optimal control problems : models and numerical methods}},
year = {2019}
}

@article{Horesh2014,
author = {Horesh, Lior},
doi = {10.1007/978-3-642-38398-4},
file = {:home/antonio/Documents/bibliography/files/Horesh - 2014 - Nuclear Norm Optimization and Its Application to Observation Model Specification Nuclear Norm Optimization and its Appli.pdf:pdf},
isbn = {9783642383984},
number = {September},
title = {{Nuclear Norm Optimization and Its Application to Observation Model Specification Nuclear Norm Optimization and its Application to Observation Model Specification}},
year = {2014}
}

@article{Adler,
archivePrefix = {arXiv},
arxivId = {arXiv:1704.04058v1},
author = {Adler, Jonas},
eprint = {arXiv:1704.04058v1},
file = {:home/antonio/Documents/bibliography/files/Adler - Unknown - Solving ill-posed inverse problems using iterative deep neural networks.pdf:pdf},
pages = {1--24},
title = {{Solving ill-posed inverse problems using iterative deep neural networks}}
}

@article{Adlera,
archivePrefix = {arXiv},
arxivId = {arXiv:1707.06474v1},
author = {Adler, Jonas and Oktem, Ozan},
eprint = {arXiv:1707.06474v1},
file = {:home/antonio/Documents/bibliography/files/Adler, Oktem - Unknown - Learned Primal-dual Reconstruction.pdf:pdf},
number = {4},
pages = {1--10},
title = {{Learned Primal-dual Reconstruction}}
}

@article{Karlsson,
archivePrefix = {arXiv},
arxivId = {arXiv:1710.10898v1},
author = {Karlsson, Johan},
eprint = {arXiv:1710.10898v1},
file = {:home/antonio/Documents/bibliography/files/Karlsson - Unknown - Learning to solve inverse problems using Wasserstein loss.pdf:pdf},
pages = {1--11},
title = {{Learning to solve inverse problems using Wasserstein loss}}
}

@article{Gupta,
archivePrefix = {arXiv},
arxivId = {arXiv:1709.01809v1},
author = {Gupta, Harshit and Jin, Kyong Hwan and Nguyen, Ha Q and Mccann, Michael T and Unser, Michael and Fellow, Ieee and Sep, C V},
eprint = {arXiv:1709.01809v1},
file = {:home/antonio/Documents/bibliography/files/Gupta et al. - Unknown - CNN-Based Projected Gradient Descent for Consistent Image Reconstruction.pdf:pdf},
pages = {1--12},
title = {{CNN-Based Projected Gradient Descent for Consistent Image Reconstruction}}
}

@InProceedings{Kokkinos2018,
  author        = {Kokkinos, Filippos and Lefkimmiatis, Stamatios},
  booktitle     = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  title         = {{Deep image demosaicking using a cascade of convolutional residual denoising networks}},
  year          = {2018},
  pages         = {317--333},
  volume        = {11218 LNCS},
  abstract      = {Demosaicking and denoising are among the most crucial steps of modern digital camera pipelines and their joint treatment is a highly ill-posed inverse problem where at-least two-thirds of the information are missing and the rest are corrupted by noise. This poses a great challenge in obtaining meaningful reconstructions and a special care for the efficient treatment of the problem is required. While there are several machine learning approaches that have been recently introduced to deal with joint image demosaicking-denoising, in this work we propose a novel deep learning architecture which is inspired by powerful classical image regularization methods and large-scale convex optimization techniques. Consequently, our derived network is more transparent and has a clear interpretation compared to alternative competitive deep learning approaches. Our extensive experiments demonstrate that our network outperforms any previous approaches on both noisy and noise-free data. This improvement in reconstruction quality is attributed to the principled way we design our network architecture, which also requires fewer trainable parameters than the current state-of-the-art deep network solution. Finally, we show that our network has the ability to generalize well even when it is trained on small datasets, while keeping the overall number of trainable parameters low.},
  archiveprefix = {arXiv},
  arxivid       = {1803.05215},
  doi           = {10.1007/978-3-030-01264-9_19},
  eprint        = {1803.05215},
  file          = {:home/antonio/Documents/bibliography/files/Kokkinos, Lefkimmiatis - 2018 - Deep image demosaicking using a cascade of convolutional residual denoising networks.pdf:pdf},
  isbn          = {9783030012632},
  issn          = {16113349},
  keywords      = {Deep learning, Demosaicking, Denoising, Proximal method, Residual denoising},
}

@misc{Smith2017,
abstract = {We consider two questions at the heart of machine learning; how can we predict if a minimum will generalize to the test set, and why does stochastic gradient descent find minima that generalize well? Our work responds to Zhang et al. (2016), who showed deep neural networks can easily memorize randomly labeled training data, despite generalizing well on real labels of the same inputs. We show that the same phenomenon occurs in small linear models. These observations are explained by the Bayesian evidence, which penalizes sharp minima but is invariant to model parameterization. We also demonstrate that, when one holds the learning rate fixed, there is an optimum batch size which maximizes the test set accuracy. We propose that the noise introduced by small mini-batches drives the parameters towards minima whose evidence is large. Interpreting stochastic gradient descent as a stochastic differential equation, we identify the "noise scale" g = ∈(N/B-1) ≈ ∈N/B, where ∈ is the learning rate, N the training set size and B the batch size. Consequently the optimum batch size is proportional to both the learning rate and the size of the training set, Bopt/∝ ∈ N. We verify these predictions empirically.},
archivePrefix = {arXiv},
arxivId = {1710.06451},
author = {Smith, Samuel L and Le, Quoc V},
booktitle = {arXiv},
eprint = {1710.06451},
file = {:home/antonio/Documents/bibliography/files/Smith, Le - 2017 - A Bayesian perspective on generalization and stochastic gradient descent.pdf:pdf},
issn = {23318422},
pages = {1--11},
title = {{A Bayesian perspective on generalization and stochastic gradient descent}},
year = {2017}
}

@article{Szegedy,
archivePrefix = {arXiv},
arxivId = {arXiv:1312.6199v4},
author = {Szegedy, Christian and Bruna, Joan and Erhan, Dumitru and Goodfellow, Ian},
eprint = {arXiv:1312.6199v4},
file = {:home/antonio/Documents/bibliography/files/Szegedy et al. - Unknown - Intriguing properties of neural networks.pdf:pdf},
pages = {1--10},
title = {{Intriguing properties of neural networks}}
}

@article{Sup2016,
archivePrefix = {arXiv},
arxivId = {arXiv:1601.04920v1},
author = {Sup, Ecole Normale and To, France and Transactions, Philosophical},
eprint = {arXiv:1601.04920v1},
file = {:home/antonio/Documents/bibliography/files/Sup, To, Transactions - 2016 - Understanding Deep Convolutional Networks.pdf:pdf},
pages = {1--17},
title = {{Understanding Deep Convolutional Networks}},
year = {2016}
}

@article{Han,
archivePrefix = {arXiv},
arxivId = {arXiv:1708.08333v1},
author = {Han, Yoseob and Ye, Jong Chul and Member, Senior},
eprint = {arXiv:1708.08333v1},
file = {:home/antonio/Documents/bibliography/files/Han, Ye, Member - Unknown - Framing U-Net via Deep Convolutional Framelets Application to Sparse-view CT.pdf:pdf},
number = {1},
pages = {1--10},
title = {{Framing U-Net via Deep Convolutional Framelets : Application to Sparse-view CT}}
}

@article{Hand2017,
archivePrefix = {arXiv},
arxivId = {arXiv:submit/1898187},
author = {Hand, Paul and Voroninski, Vladislav},
eprint = {1898187},
file = {:home/antonio/Documents/bibliography/files/Hand, Voroninski - 2017 - Empirical Risk.pdf:pdf},
primaryClass = {arXiv:submit},
title = {{Empirical Risk}},
year = {2017}
}

@article{Newman,
archivePrefix = {arXiv},
arxivId = {arXiv:1706.09693v1},
author = {Newman, Elizabeth and Kilmer, Misha},
eprint = {arXiv:1706.09693v1},
file = {:home/antonio/Documents/bibliography/files/Newman, Kilmer - Unknown - Image classification using local tensor singular value decompositions.pdf:pdf},
number = {d},
title = {{Image classification using local tensor singular value decompositions}}
}

@article{Fawzi,
archivePrefix = {arXiv},
arxivId = {arXiv:1610.08401v2},
author = {Fawzi, Omar and Frossard, Pascal},
eprint = {arXiv:1610.08401v2},
file = {:home/antonio/Documents/bibliography/files/Fawzi, Frossard - Unknown - Universal adversarial perturbations.pdf:pdf},
title = {{Universal adversarial perturbations}}
}

@article{Networks,
author = {Networks, Neural},
file = {:home/antonio/Documents/bibliography/files/Networks - Unknown - 5.5. Regularization in Neural Networks.pdf:pdf},
pages = {256--272},
title = {{5.5. Regularization in Neural Networks}}
}

@article{Trouble2017,
author = {Trouble, Deep},
file = {:home/antonio/Documents/bibliography/files/Trouble - 2017 - Deep , Deep Trouble.pdf:pdf},
pages = {1--5},
title = {{Deep , Deep Trouble}},
year = {2017}
}

@article{Marcus,
author = {Marcus, Gary},
file = {:home/antonio/Documents/bibliography/files/Marcus - Unknown - Deep Learning A Critical Appraisal.pdf:pdf},
pages = {1--27},
title = {{Deep Learning : A Critical Appraisal}}
}

@Article{Igami2018,
  author        = {Igami, Mitsuru},
  title         = {{Artificial Intelligence as Structural Estimation : Economic Interpretations of Deep Blue , Bonanza , and}},
  year          = {2018},
  pages         = {1--28},
  archiveprefix = {arXiv},
  arxivid       = {arXiv:1710.10967v3},
  eprint        = {arXiv:1710.10967v3},
  file          = {:home/antonio/Documents/bibliography/files/Igami - 2018 - Artificial Intelligence as Structural Estimation Economic Interpretations of Deep Blue , Bonanza , and.pdf:pdf},
  keywords      = {2017, a12, aip, artificial intelligence, c45, c57, c63, c73, conditional choice probability, deep neural network, dynamic game, dynamic structural model, first version, georgetown, jel classifications, october 30, seminar comments at riken, simulation estimator, this paper benefited from},
}

@article{Polytechnique2010,
author = {Polytechnique, Ecole},
file = {:home/antonio/Documents/bibliography/files/Polytechnique - 2010 - Recursive interferometric representations.pdf:pdf},
pages = {1--5},
title = {{Recursive interferometric representations}},
year = {2010}
}

@article{Liang2018,
author = {Liang, Liang and Liu, Minliang and Martin, Caitlin and Sun, Wei},
file = {:home/antonio/Documents/bibliography/files/Liang et al. - 2018 - A deep learning approach to estimate stress distribution a fast and accurate surrogate of finite-element analysis.pdf:pdf},
number = {ML},
title = {{A deep learning approach to estimate stress distribution : a fast and accurate surrogate of finite-element analysis}},
year = {2018}
}

@article{Paris2016,
author = {Paris, C R Acad Sci and Ser, I and Maday, Yvon and Manzoni, Andrea and Quarteroni, Alfio},
doi = {10.1016/j.crma.2016.10.008},
file = {:home/antonio/Documents/bibliography/files/Paris et al. - 2016 - An online intrinsic stabilization strategy for the reduced basis approximation of parametrized advection-dominated.pdf:pdf},
issn = {1631-073X},
journal = {C. R. Acad. Sci. Paris, Ser. I},
number = {12},
pages = {1188--1194},
publisher = {Elsevier Masson SAS},
title = {{An online intrinsic stabilization strategy for the reduced basis approximation of parametrized advection-dominated problems}},
url = {http://dx.doi.org/10.1016/j.crma.2016.10.008},
volume = {354},
year = {2016}
}

@misc{Maier2019,
abstract = {We describe an approach for incorporating prior knowledge into machine learning algorithms. We aim at applications in physics and signal processing in which we know that certain operations must be embedded into the algorithm. Any operation that allows computation of a gradient or sub-gradient towards its inputs is suited for our framework. We derive a maximal error bound for deep nets that demonstrates that inclusion of prior knowledge results in its reduction. Furthermore, we also show experimentally that known operators reduce the number of free parameters. We apply this approach to various tasks ranging from CT image reconstruction over vessel segmentation to the derivation of previously unknown imaging algorithms. As such the concept is widely applicable for many researchers in physics, imaging, and signal processing. We assume that our analysis will support further investigation of known operators in other fields of physics, imaging, and signal processing.},
archivePrefix = {arXiv},
arxivId = {1907.01992},
author = {Maier, Andreas K and Syben, Christopher and Stimpel, Bernhard and W{\"{u}}rfl, Tobias and Hoffmann, Mathis and Schebesch, Frank and Fu, Weilin and Mill, Leonid and Kling, Lasse and Christiansen, Silke},
booktitle = {arXiv},
doi = {10.1038/s42256-019-0077-5},
eprint = {1907.01992},
file = {:home/antonio/Documents/bibliography/files/Maier et al. - 2019 - Learning with known operators reduces maximum training error bounds.pdf:pdf},
issn = {23318422},
pages = {1--20},
title = {{Learning with known operators reduces maximum training error bounds}},
year = {2019}
}

@Article{Raissi,
  author        = {Raissi, Maziar and Karniadakis, George Em},
  title         = {{Hidden Physics Models : Machine Learning of Nonlinear Partial Differential Equations}},
  archiveprefix = {arXiv},
  arxivid       = {arXiv:1708.00588v2},
  eprint        = {arXiv:1708.00588v2},
  file          = {:home/antonio/Documents/bibliography/files/Raissi, Karniadakis - Unknown - Hidden Physics Models Machine Learning of Nonlinear Partial Differential Equations.pdf:pdf},
  keywords      = {bayesian, fractional equations, modeling, name, preprint submitted to journal, probabilistic machine learning, small data, system identification, uncertainty quantification},
}

@article{Maier,
author = {Maier, Andreas K and Syben, Christopher and Stimpel, Bernhard and W{\"{u}}rfl, Tobias and Hoffmann, Mathis and Schebesch, Frank and Fu, Weilin and Mill, Leonid and Kling, Lasse and Christiansen, Silke and Maier, Andreas K and Syben, Christopher and Stimpel, Bernhard and Tobias, W and Hoffmann, Mathis and Schebesch, Frank and Fu, Weilin and Mill, Leonid},
file = {:home/antonio/Documents/bibliography/files/Maier et al. - Unknown - Learning with known operators reduces maximum error bounds Operators reduces Maximum Training Error.pdf:pdf},
isbn = {4225601900},
title = {{Learning with known operators reduces maximum error bounds Operators reduces Maximum Training Error}}
}

@article{Tompson2017,
archivePrefix = {arXiv},
arxivId = {arXiv:1607.03597v6},
author = {Tompson, Jonathan and Schlachter, Kristofer and Sprechmann, Pablo and Perlin, Ken},
eprint = {arXiv:1607.03597v6},
file = {:home/antonio/Documents/bibliography/files/Tompson et al. - 2017 - Accelerating Eulerian Fluid Simulation With Convolutional Networks.pdf:pdf},
title = {{Accelerating Eulerian Fluid Simulation With Convolutional Networks}},
year = {2017}
}

@article{Fawzia,
archivePrefix = {arXiv},
arxivId = {arXiv:1511.04599v3},
author = {Fawzi, Alhussein and Frossard, Pascal},
eprint = {arXiv:1511.04599v3},
file = {:home/antonio/Documents/bibliography/files/Fawzi, Frossard - Unknown - DeepFool a simple and accurate method to fool deep neural networks.pdf:pdf},
title = {{DeepFool : a simple and accurate method to fool deep neural networks}}
}

@article{Ilg,
archivePrefix = {arXiv},
arxivId = {arXiv:1612.01925v1},
author = {Ilg, Eddy and Mayer, Nikolaus and Saikia, Tonmoy and Keuper, Margret and Dosovitskiy, Alexey and Brox, Thomas},
eprint = {arXiv:1612.01925v1},
file = {:home/antonio/Documents/bibliography/files/Ilg et al. - Unknown - FlowNet 2.0 Evolution of Optical Flow Estimation with Deep Networks.pdf:pdf},
title = {{FlowNet 2.0: Evolution of Optical Flow Estimation with Deep Networks}}
}

@article{Mining,
author = {Mining, Data},
file = {:home/antonio/Documents/bibliography/files/Mining - Unknown - Springer Series in Statistics The Elements of.pdf:pdf},
title = {{Springer Series in Statistics The Elements of}}
}

@article{Wu2018d,
archivePrefix = {arXiv},
arxivId = {arXiv:1802.03930v2},
author = {Wu, Yadong and Zhang, Pengfei and Shen, Huitao and Zhai, Hui},
eprint = {arXiv:1802.03930v2},
file = {:home/antonio/Documents/bibliography/files/Wu et al. - 2018 - Visualizing Neural Network Developing Perturbation Theory.pdf:pdf},
pages = {1--5},
title = {{Visualizing Neural Network Developing Perturbation Theory}},
year = {2018}
}

@article{Tianyi2017,
author = {Tianyi, Joey and Ivor, Zhou and Sinno, W Tsang and Pan, Jialin and Qin, Zheng and Siow, Rick and Goh, Mong},
file = {:home/antonio/Documents/bibliography/files/Tianyi et al. - 2017 - An End-to-End Sparse Coding.pdf:pdf},
title = {{An End-to-End Sparse Coding}},
year = {2017}
}

@book{Moritz2005,
author = {Moritz, Helmut},
booktitle = {Theory of Satellite Geodesy and Gravity Field Determination},
doi = {10.1007/bfb0010548},
file = {:home/antonio/Documents/bibliography/files/Moritz - 2005 - Introduction to classical mechanics.pdf:pdf},
isbn = {9780521876223},
pages = {9--68},
title = {{Introduction to classical mechanics}},
year = {2005}
}

@Misc{Cai2017,
  author    = {Cai, Lihui and Wang, Jiang and Wang, Ruofan and Deng, Bin and Yu, Haitao and Wei, Xile},
  title     = {{Functional Connectivity Analysis of EEG in AD Patients with Normalized Permutation Index}},
  year      = {2017},
  abstract  = {In this work, we proposed Normalized Permutation Index (NPI) to analysis the functional connectivity of EEG from human brain with Alzheimer's disease. NPI is modified method of permutation disalignment index based on permutation entropy, and can be used for the functional network analysis. The simulation analysis of NPI is first performed and the results show that NPI could effectively estimate the coupling strength with high sensitivity. Then NPI is applied to the synchronization and network analysis of AD brain. It can be observed that the functional connectivity in AD brain is weakened in most channel pairs, and the network properties are also altered with decreased global and local efficiency. These preliminary results demonstrate that NPI could be used to provide a new biomarker for AD pathology.},
  booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  doi       = {10.1007/978-3-319-70093-9_59},
  file      = {:home/antonio/Documents/bibliography/files/Cai et al. - 2017 - Functional Connectivity Analysis of EEG in AD Patients with Normalized Permutation Index.pdf:pdf},
  isbn      = {9783319700922},
  issn      = {16113349},
  keywords  = {Alzheimer's disease, EEG, Functional connectivity, Normalized Permutation Index},
  pages     = {563--571},
  volume    = {10637 LNCS},
}

@article{Galley2013,
abstract = {Hamilton's principle of stationary action lies at the foundation of theoretical physics and is applied in many other disciplines from pure mathematics to economics. Despite its utility, Hamilton's principle has a subtle pitfall that often goes unnoticed in physics: it is formulated as a boundary value problem in time but is used to derive equations of motion that are solved with initial data. This subtlety can have undesirable effects. I present a formulation of Hamilton's principle that is compatible with initial value problems. Remarkably, this leads to a natural formulation for the Lagrangian and Hamiltonian dynamics of generic nonconservative systems, thereby filling a long-standing gap in classical mechanics. Thus, dissipative effects, for example, can be studied with new tools that may have applications in a variety of disciplines. The new formalism is demonstrated by two examples of nonconservative systems: an object moving in a fluid with viscous drag forces and a harmonic oscillator coupled to a dissipative environment. {\textcopyright} 2013 American Physical Society.},
archivePrefix = {arXiv},
arxivId = {1210.2745},
author = {Galley, Chad R.},
doi = {10.1103/PhysRevLett.110.174301},
eprint = {1210.2745},
file = {:home/antonio/Documents/bibliography/files/Galley - 2013 - Classical mechanics of nonconservative systems.pdf:pdf},
issn = {00319007},
journal = {Physical Review Letters},
number = {17},
pages = {1--5},
title = {{Classical mechanics of nonconservative systems}},
volume = {110},
year = {2013}
}

@Article{Baechle2018,
  author        = {B{\"{a}}chle, Andreas and Janssens, Geoffrey and Jespers, Eric and Kiefer, Ann and Temmerman, Doryan},
  title         = {{Higher modular groups as amalgamated products and a dichotomy for integral group rings}},
  year          = {2018},
  abstract      = {We give a concrete presentation for the general linear group defined over a ring which is a finitely generated free $\mathbb{Z}$-module or the integral Clifford group $\Gamma_n(\mathbb{Z})$ of invertible elements in the Clifford algebra with integral coefficients. We then use this presentation to prove that the elementary linear group over $\Gamma_n(\mathbb{Z})$ has a non-trivial decomposition as a free product with amalgamated subgroup the elementary linear group over $\Gamma_{n-1}(\mathbb{Z})$. This allows to obtain applications to the unit group $\mathcal{U}(\mathbb{Z} G)$ of an integral group ring $\mathbb{Z} G$ of a finite group $G$. In particular, we prove that $\mathcal{U} (\mathbb{Z} G)$ is either hereditary (FA), i.e. every subgroup of finite index has property (FA), or commensurable with a non-trivial amalgamated product for a huge class of groups. In the case $\mathcal{U}(\mathbb{Z} G)$ is not hereditary (FA), we investigate subgroups of finite index in $\mathcal{U}(\mathbb{Z} G)$ that have a non-trivial decomposition as an amalgamated product.},
  archiveprefix = {arXiv},
  arxivid       = {1811.12226},
  eprint        = {1811.12226},
  file          = {:home/antonio/Documents/bibliography/files/B{\"{a}}chle et al. - 2018 - Higher modular groups as amalgamated products and a dichotomy for integral group rings.pdf:pdf},
  url           = {http://arxiv.org/abs/1811.12226},
}

@Article{Shi2019,
  author   = {Shi, Chengzhi and Zhao, Rongkuo and Long, Yang and Yang, Sui and Wang, Yuan and Chen, Hong and Ren, Jie and Zhang, Xiang},
  journal  = {National Science Review},
  title    = {{Observation of acoustic spin}},
  year     = {2019},
  issn     = {2053714X},
  number   = {4},
  pages    = {707--712},
  volume   = {6},
  abstract = {Unlike optical waves, acoustic waves in fluids are described by scalar pressure fields, and therefore are considered spinless. Here, we demonstrate experimentally the existence of spin in acoustics. In the interference of two acoustic waves propagating perpendicularly to each other, we observed the spin angular momentum in free space as a result of the rotation of local particle velocity. We successfully measured the acoustic spin, and spin-induced torque acting on a designed lossy acoustic probe that results from absorption of the spin angular momentum. The acoustic spin is also observed in the evanescent field of a guided mode traveling along a metamaterial waveguide. We found spin-momentum locking in acoustic waves whose propagation direction is determined by the sign of spin. The observed acoustic spin could open a new door in acoustics and its applications for the control of wave propagation and particle rotation.},
  doi      = {10.1093/nsr/nwz059},
  file     = {:home/antonio/Documents/bibliography/files/Shi et al. - 2019 - Observation of acoustic spin.pdf:pdf},
  keywords = {acoustic spin, spin-induced torque, spin-momentum locking},
}

@techreport{Hochreiter1997,
abstract = {We present a new algorithm for nding low complexity neural networks with high generalization capability. The algorithm searches for a \\at" minimum of the error function. A at minimum is a large connected region in weight-space where the error remains approximately constant. An MDL-based, Bayesian argument suggests that at minima correspond to \simple" networks and low expected overrtting. The argument is based on a Gibbs algorithm variant and a novel way of splitting generalization error into underrtting and overrtting error. Unlike many previous approaches, ours does not require Gaussian assumptions and does not depend on a \good" weight prior { instead we have a prior over input/output functions, thus taking into account net architecture and training set. Although our algorithm requires the computation of second order derivatives, it has backprop's order of complexity. Automatically, it eeectively prunes units, weights, and input lines. Various experiments with feedforward and recurrent nets are described. In an application to stock market prediction, at minimum search outperforms (1) conventional backprop, (2) weight decay, (3) \optimal brain surgeon" / \optimal brain damage". We also provide pseudo code of the algorithm (omitted from the NC-version).}},
author = {Hochreiter, Sepp and {Urgen Schmidhuber}, J J},
booktitle = {Neural Computation},
file = {:home/antonio/Documents/bibliography/files/Hochreiter, Urgen Schmidhuber - 1997 - Flat Minima.pdf:pdf},
number = {1},
pages = {1--42},
title = {{Flat Minima}},
volume = {9},
year = {1997}
}

@techreport{Dinh,
abstract = {Despite their overwhelming capacity to overfit, deep learning architectures tend to generalize relatively well to unseen data, allowing them to be deployed in practice. However, explaining why this is the case is still an open area of research. One standing hypothesis that is gaining popularity, e.g. Hochreiter & Schmidhuber (1997); Keskar et al. (2017), is that the flatness of minima of the loss function found by stochastic gradient based methods results in good generalization. This paper argues that most notions of flatness are problematic for deep models and can not be directly applied to explain generalization. Specifically, when focusing on deep networks with rectifier units, we can exploit the particular geometry of parameter space induced by the inherent symmetries that these architectures exhibit to build equivalent models corresponding to arbitrarily sharper minima. Furthermore, if we allow to reparametrize a function, the geometry of its parameters can change drastically without affecting its generalization properties.},
archivePrefix = {arXiv},
arxivId = {1703.04933v2},
author = {Dinh, Laurent and Pascanu, Razvan and Bengio, Samy and Bengio, Yoshua},
eprint = {1703.04933v2},
file = {:home/antonio/Documents/bibliography/files/Dinh et al. - Unknown - Sharp Minima Can Generalize For Deep Nets.pdf:pdf},
title = {{Sharp Minima Can Generalize For Deep Nets}}
}

@TechReport{Graham2018,
  author        = {Graham, I G and Pembery, O R and Spence, E A},
  title         = {{The Helmholtz equation in heterogeneous media: a priori bounds, well-posedness, and resonances}},
  year          = {2018},
  abstract      = {We consider the exterior Dirichlet problem for the heterogeneous Helmholtz equation, i.e. the equation ∇ {\textperiodcentered} (A∇u) + k 2 nu = −f where both A and n are functions of position. We prove new a priori bounds on the solution under conditions on A, n, and the domain that ensure nontrapping of rays; the novelty is that these bounds are explicit in k, A, n, and geometric parameters of the domain. We then show that these a priori bounds hold when A and n are L ∞ and satisfy certain monotonicity conditions, and thereby obtain new results both about the well-posedness of such problems and about the resonances of acoustic transmission problems (i.e. A and n discontinuous) where the transmission interfaces are only assumed to be C 0 and star-shaped; the novelty of this latter result is that until recently the only known results about resonances of acoustic transmission problems were for C ∞ convex interfaces with strictly positive curvature.},
  archiveprefix = {arXiv},
  arxivid       = {1801.08095v5},
  eprint        = {1801.08095v5},
  file          = {:home/antonio/Documents/bibliography/files/Graham, Pembery, Spence - 2018 - The Helmholtz equation in heterogeneous media a priori bounds, well-posedness, and resonances.pdf:pdf},
  keywords      = {35B34, 35J25, 35P25, 78A45, Helmholtz equation, heterogeneous, high frequency, nontrapping, resolvent, resonance, semiclassical AMS subject classifications: 35J05, trans-mission problem, uniqueness, variable wave speed},
}

@TechReport{Meng2019,
  author        = {Meng, Xuhui and Li, Zhen and Zhang, Dongkun and Karniadakis, George Em},
  title         = {{PPINN: Parareal Physics-Informed Neural Network for time-dependent PDEs}},
  year          = {2019},
  abstract      = {Physics-informed neural networks (PINNs) encode physical conservation laws and prior physical knowledge into the neural networks, ensuring the correct physics is represented accurately while alleviating the need for supervised learning to a great degree [1]. While effective for relatively short-term time integration, when long time integration of the time-dependent PDEs is sought, the time-space domain may become arbitrarily large and hence training of the neural network may become prohibitively expensive. To this end, we develop a parareal physics-informed neural network (PPINN), hence decomposing a long-time problem into many independent short-time problems supervised by an inexpensive/fast coarse-grained (CG) solver. In particular, the serial CG solver is designed to provide approximate predictions of the solution at discrete times, while initiate many fine PINNs simultaneously to correct the solution iteratively. There is a twofold benefit from training PINNs with small-data sets rather than working on a large-data set directly, i.e., training of individual PINNs with small-data is much faster, while training the fine PINNs can be readily parallelized. Consequently, compared to the original PINN approach, the proposed PPINN approach may achieve a significant speedup for long-time integration of PDEs, assuming that the CG solver is fast and can provide reasonable predictions of the solution, hence aiding the PPINN solution to converge in just a few iterations. To investigate the PPINN performance on solving time-dependent PDEs, we first apply the PPINN to solve the Burgers equation, and subsequently we apply the PPINN to solve a two-dimensional nonlinear diffusion-reaction equation. Our results demonstrate that PPINNs converge in a couple of iterations with significant speed-ups proportional to the number of time-subdomains employed.},
  archiveprefix = {arXiv},
  arxivid       = {1909.10145v1},
  eprint        = {1909.10145v1},
  file          = {:home/antonio/Documents/bibliography/files/Meng et al. - 2019 - PPINN Parareal Physics-Informed Neural Network for time-dependent PDEs.pdf:pdf},
  groups        = {PDEs and neural networks},
  isbn          = {1909.10145v1},
}

@TechReport{Zang,
  author        = {Zang, Yaohua and Bao, Gang and Ye, Xiaojing and Zhou, Haomin},
  title         = {{Weak Adversarial Networks for High-dimensional Partial Differential Equations}},
  abstract      = {Solving general high-dimensional partial differential equations (PDE) is a long-standing challenge in numerical mathematics. In this paper, we propose a novel approach to solve high-dimensional linear and nonlinear PDEs defined on arbitrary domains by leveraging their weak formulations. We convert the problem of finding the weak solution of PDEs into an operator norm minimization problem induced from the weak formulation. The weak solution and the test function in the weak formulation are then parame-terized as the primal and adversarial networks respectively, which are alternately updated to approximate the optimal network parameter setting. Our approach, termed as the weak adversarial network (WAN), is fast, stable, and completely mesh-free, which is particularly suitable for high-dimensional PDEs defined on irregular domains where the classical numerical methods based on finite differences and finite elements suffer the issues of slow computation, instability and the curse of dimensionality. We apply our method to a variety of test problems with high-dimensional PDEs to demonstrate its promising performance.},
  archiveprefix = {arXiv},
  arxivid       = {1907.08272v2},
  eprint        = {1907.08272v2},
  file          = {:home/antonio/Documents/bibliography/files/Zang et al. - Unknown - Weak Adversarial Networks for High-dimensional Partial Differential Equations.pdf:pdf},
  keywords      = {Adversarial Network, Deep Neural Network, High Dimensional PDE, Weak Solution},
}

@Article{Anitescu2019,
  author    = {Anitescu, Cosmin and Atroshchenko, Elena and Alajlan, Naif and Rabczuk, Timon},
  journal   = {CMC},
  title     = {{Artificial Neural Network Methods for the Solution of Second Order Boundary Value Problems}},
  year      = {2019},
  number    = {1},
  pages     = {345--359},
  volume    = {59},
  abstract  = {We present a method for solving partial differential equations using artificial neural networks and an adaptive collocation strategy. In this procedure, a coarse grid of training points is used at the initial training stages, while more points are added at later stages based on the value of the residual at a larger set of evaluation points. This method increases the robustness of the neural network approximation and can result in significant computational savings, particularly when the solution is non-smooth. Numerical results are presented for benchmark problems for scalar-valued PDEs, namely Poisson and Helmholtz equations, as well as for an inverse acoustics problem.},
  doi       = {10.32604/cmc.2019.06641},
  file      = {:home/antonio/Documents/bibliography/files/Anitescu et al. - 2019 - Artificial Neural Network Methods for the Solution of Second Order Boundary Value Problems.pdf:pdf},
  keywords  = {Deep learning, adaptive collocation, artificial neural networks, inverse problems},
  publisher = {CMC},
  url       = {www.techscience.com/cmc},
}

@Article{Pang2019,
  author        = {Pang, Guofei and Lu, L. U. and Karniadakis, George E.M.},
  journal       = {SIAM Journal on Scientific Computing},
  title         = {{FPinns: Fractional physics-informed neural networks}},
  year          = {2019},
  issn          = {10957197},
  number        = {4},
  pages         = {A2603--A2626},
  volume        = {41},
  abstract      = {Physics-informed neural networks (PINNs), introduced in [M. Raissi, P. Perdikaris, and G. Karniadakis, J. Comput. Phys., 378 (2019), pp. 686-707], are effective in solving integer-order partial differential equations (PDEs) based on scattered and noisy data. PINNs employ standard feedforward neural networks (NNs) with the PDEs explicitly encoded into the NN using automatic differentiation, while the sum of the mean-squared PDE residuals and the mean-squared error in initial-boundary conditions is minimized with respect to the NN parameters. Here we extend PINNs to fractional PINNs (fPINNs) to solve space-time fractional advection-diffusion equations (fractional ADEs), and we study systematically their convergence, hence explaining both fPINNs and PINNs for the first time. Specifically, we demonstrate their accuracy and effectiveness in solving multidimensional forward and inverse problems with forcing terms whose values are only known at randomly scattered spatio-temporal coordinates (black-box (BB) forcing terms). A novel element of the fPINNs is the hybrid approach that we introduce for constructing the residual in the loss function using both automatic differentiation for the integer-order operators and numerical discretization for the fractional operators. This approach bypasses the difficulties stemming from the fact that automatic differentiation is not applicable to fractional operators because the standard chain rule in integer calculus is not valid in fractional calculus. To discretize the fractional operators, we employ the Gr\" unwald-Letnikov (GL) formula in one-dimensional fractional ADEs and the vector GL formula in conjunction with the directional fractional Laplacian in two- and three-dimensional fractional ADEs. We first consider the one-dimensional fractional Poisson equation and compare the convergence of the fPINNs against the finite difference method (FDM). We present the solution convergence using both the mean L2 error as well as the standard deviation due to sensitivity to NN parameter initializations. Using different GL formulas we observe first-, second-, and third-order convergence rates for small size training sets but the error saturates for larger training sets. We explain these results by analyzing the four sources of numerical errors due to discretization, sampling, NN approximation, and optimization. The total error decays monotonically (below 10 - 5 for a third-order GL formula) but it saturates beyond that point due to the optimization error. We also analyze the relative balance between discretization and sampling errors and observe that the sampling size and the number of discretization points (auxiliary points) should be comparable to achieve the highest accuracy. As we increase the depth of the NN up to certain value, the mean error decreases and the standard deviation increases, whereas the width has essentially no effect unless its value is either too small or too large. We next consider time-dependent fractional ADEs and compare white-box (WB) and BB forcing. We observe that for the WB forcing, our results are similar to the aforementioned cases; however, for the BB forcing fPINNs outperform FDM. Subsequently, we consider multidimensional time-, space-, and space-time-fractional ADEs using the directional fractional Laplacian and we observe relative errors of 10 - 3 \sim 10 - 4. Finally, we solve several inverse problems in one, two, and three dimensions to identify the fractional orders, diffusion coefficients, and transport velocities and obtain accurate results given proper initializations even in the presence of significant noise.},
  archiveprefix = {arXiv},
  arxivid       = {1811.08967},
  doi           = {10.1137/18M1229845},
  eprint        = {1811.08967},
  file          = {:home/antonio/Documents/bibliography/files/Pang, Lu, Karniadakis - 2019 - FPinns Fractional physics-informed neural networks.pdf:pdf},
  groups        = {PDEs and neural networks},
  keywords      = {Fractional advection-diffusion, Fractional inverse problem, Numerical error analysis, Parameter identification, Physics-informed learning machines},
  publisher     = {Society for Industrial and Applied Mathematics Publications},
}

@article{Angeles2019,
author = {Angeles, Los and Ruthotto, Lars},
file = {:home/antonio/Documents/bibliography/files/Angeles, Ruthotto - 2019 - Deep Neural Networks Motivated By Ordinary Differential Equations Agenda Deep Neural Networks Motivated By O.pdf:pdf},
pages = {1--36},
title = {{Deep Neural Networks Motivated By Ordinary Differential Equations Agenda : Deep Neural Networks Motivated By ODEs}},
year = {2019}
}

@article{Angeles2019a,
author = {Angeles, Los and Ruthotto, Lars},
file = {:home/antonio/Documents/bibliography/files/Angeles, Ruthotto - 2019 - Deep Neural Networks Motivated by Partial Differential Equations Agenda Deep Neural Networks motivated by PD.pdf:pdf},
pages = {1--37},
title = {{Deep Neural Networks Motivated by Partial Differential Equations Agenda : Deep Neural Networks motivated by PDEs}},
year = {2019}
}

@Article{BondTaylor2020a,
  author        = {Bond-Taylor, Sam and Willcocks, Chris G.},
  title         = {{Gradient Origin Networks}},
  year          = {2020},
  month         = {jul},
  abstract      = {This paper proposes a new type of generative model that is able to quickly learn a latent representation without an encoder. This is achieved using empirical Bayes to calculate the expectation of the posterior, which is implemented by initialising a latent vector with zeros, then using the gradient of the log-likelihood of the data with respect to this zero vector as new latent points. The approach has similar characteristics to autoencoders, but with a simpler architecture, and is demonstrated in a variational autoencoder equivalent that permits sampling. This also allows implicit representation networks to learn a space of implicit functions without requiring a hypernetwork, retaining their representation advantages across datasets. The experiments show that the proposed method converges faster, with significantly lower reconstruction error than autoencoders, while requiring half the parameters.},
  archiveprefix = {arXiv},
  arxivid       = {2007.02798},
  eprint        = {2007.02798},
  file          = {:home/antonio/Documents/bibliography/files/Bond-Taylor, Willcocks - 2020 - Gradient Origin Networks(2).pdf:pdf},
  url           = {http://arxiv.org/abs/2007.02798},
}

@article{English2018,
author = {English, The and Table, Although},
file = {:home/antonio/Documents/bibliography/files/English, Table - 2018 - Major Comments References.pdf:pdf},
pages = {1--2},
title = {{Major Comments References}},
year = {2018}
}

@article{Goodfellow2016i,
author = {Goodfellow, Ian},
file = {:home/antonio/Documents/bibliography/files/Goodfellow - 2016 - Machine Learning Basics.pdf:pdf},
title = {{Machine Learning Basics}},
year = {2016}
}

@article{Gwqhbq,
author = {Gwqhbq, Dchbak and Dqdapbg, A M C X and Shbj, X and Opdqdmrarhnm, Rpsbrspd Uphrhmf and Dqg, Sdudjudskv and Wr, Vhfwlrqv and Lghdv, Suhvhqw and Duh, Vwuxfwxuhv and Li, Dffhswdeoh and Hqkdqfh, W K H and Glvuxsw, D Q G and Iorz, W K H},
file = {:home/antonio/Documents/bibliography/files/Gwqhbq et al. - Unknown - Dchbak Gwqhbq Amc 2Hnldchbak 5Mfhmddphmf X Dqdapbg Pnidbr 1Qqdqqldmr 3Phrdpha (&'%', X =Shbj 7Shcd.pdf:pdf},
pages = {2--3},
title = {{;Dchbak <Gwqhbq Amc 2Hnldchbak 5Mfhmddphmf X >Dqdapbg <Pnidbr 1Qqdqqldmr 3Phrdpha (&'+%', X =Shbj 7Shcd}}
}

@Article{Haber2017,
  author        = {Haber, Eldad and Ruthotto, Lars},
  title         = {{Stable Architectures for Deep Neural Networks}},
  year          = {2017},
  pages         = {1--22},
  archiveprefix = {arXiv},
  arxivid       = {arXiv:1705.03341v1},
  eprint        = {arXiv:1705.03341v1},
  file          = {:home/antonio/Documents/bibliography/files/Haber, Ruthotto - 2017 - Stable Architectures for Deep Neural Networks.pdf:pdf},
  keywords      = {deep neural networks, dynamic inverse problems, image classification, machine learning, optimization, parameter estimation, pde-constrained},
}

@article{Hammernik,
archivePrefix = {arXiv},
arxivId = {arXiv:1704.00447v1},
author = {Hammernik, Kerstin and Klatzer, Teresa and Kobler, Erich and Recht, Michael P and Sodickson, Daniel K and Pock, Thomas and Knoll, Florian},
eprint = {arXiv:1704.00447v1},
file = {:home/antonio/Documents/bibliography/files/Hammernik et al. - Unknown - Learning a Variational Network for Reconstruction of Accelerated MRI Data.pdf:pdf},
title = {{Learning a Variational Network for Reconstruction of Accelerated MRI Data}}
}

@Article{Lu,
  author        = {Lu, L U and Meng, Xuhui and Mao, Zhiping and Karniadakis, George E M},
  title         = {{Deepxde: a deep learning library for solving differential equations}},
  pages         = {1--17},
  archiveprefix = {arXiv},
  arxivid       = {arXiv:1907.04502v1},
  eprint        = {arXiv:1907.04502v1},
  file          = {:home/antonio/Documents/bibliography/files/Lu et al. - Unknown - Deepxde a deep learning library for solving differential equations.pdf:pdf},
  keywords      = {65-01, 65-04, 65l99, 65m99, 65n99, ams subject classifications, deep learning, deepxde, differential equations, education software, informed neural networks, physics-, scientific machine learning},
}

@Article{2006,
  title = {{Linear Algebra}},
  year  = {2006},
  pages = {1--22},
  file  = {:home/antonio/Documents/bibliography/files/Unknown - 2006 - Linear Algebra.pdf:pdf},
}

@Article{2017a,
  title = {{Chapter 1 Introduction}},
  year  = {2017},
  pages = {1--28},
  file  = {:home/antonio/Documents/bibliography/files/Unknown - 2017 - Chapter 1 Introduction.pdf:pdf},
}

@techreport{,
file = {:home/antonio/Documents/bibliography/files/Unknown - Unknown - A Unifying Review of Linear Gaussian Models.pdf:pdf},
title = {{A Unifying Review of Linear Gaussian Models}}
}

@book{,
file = {:home/antonio/Documents/bibliography/files/Unknown - Unknown - Independent component analysis.pdf:pdf},
isbn = {9781626239777},
title = {{Independent component analysis}}
}

@article{,
file = {:home/antonio/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - Unknown - The black box 2 0.pdf:pdf},
title = {{The black box 2 0 |}}
}

@InProceedings{Wolterink2017a,
  author        = {Wolterink, Jelmer M. and Dinkla, Anna M. and Savenije, Mark H.F. and Seevinck, Peter R. and van den Berg, Cornelis A.T. and I{\v{s}}gum, Ivana},
  booktitle     = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  title         = {{Deep MR to CT synthesis using unpaired data}},
  year          = {2017},
  month         = {aug},
  pages         = {14--23},
  volume        = {10557 LNCS},
  abstract      = {MR-only radiotherapy treatment planning requires accurate MR-to-CT synthesis. Current deep learning methods for MR-to-CT synthesis depend on pairwise aligned MR and CT training images of the same patient. However, misalignment between paired images could lead to errors in synthesized CT images. To overcome this, we propose to train a generative adversarial network (GAN) with unpaired MR and CT images. A GAN consisting of two synthesis convolutional neural networks (CNNs) and two discriminator CNNs was trained with cycle consistency to transform 2D brain MR image slices into 2D brain CT image slices and vice versa. Brain MR and CT images of 24 patients were analyzed. A quantitative evaluation showed that the model was able to synthesize CT images that closely approximate reference CT images, and was able to outperform a GAN model trained with paired MR and CT images.},
  archiveprefix = {arXiv},
  arxivid       = {1708.01155},
  doi           = {10.1007/978-3-319-68127-6_2},
  eprint        = {1708.01155},
  file          = {:home/antonio/Documents/bibliography/files/Wolterink et al. - 2017 - Deep MR to CT Synthesis using Unpaired Data.pdf:pdf},
  isbn          = {9783319681269},
  issn          = {16113349},
  keywords      = {CT synthesis, Computer Science - Computer Vision and Pattern Rec, Deep learning, Generative adversarial networks, Radiotherapy, Treatment planning},
  language      = {en},
  mendeley-tags = {Computer Science - Computer Vision and Pattern Rec},
  url           = {http://arxiv.org/abs/1708.01155},
}

@article{Kidger2021a,
abstract = {JAX and PyTorch are two popular Python autodifferentiation frameworks. JAX is based around pure functions and functional programming. PyTorch has popu-larised the use of an object-oriented (OO) class-based syntax for defining param-eterised functions, such as neural networks. That this seems like a fundamental difference means current libraries for building parameterised functions in JAX have either rejected the OO approach entirely (Stax) or have introduced OO-to-functional transformations, multiple new abstractions, and been limited in the extent to which they integrate with JAX (Flax, Haiku, Objax). Either way this OO/-functional difference has been a source of tension. Here, we introduce 'Equinox', a small neural network library showing how a PyTorch-like class-based approach may be admitted without sacrificing JAX-like functional programming. We provide two main ideas. One: parameterised functions are themselves represented as 'PyTrees', which means that the parameterisation of a function is transparent to the JAX framework. Two: we filter a PyTree to isolate just those components that should be treated when transforming ('jit', 'grad' or 'vmap'-ing) a higher-order function of a parameterised function-such as a loss function applied to a model. Overall Equinox resolves the above tension without introducing any new program-matic abstractions: only PyTrees and transformations, just as with regular JAX. Equinox is available at https://github.com/patrick-kidger/equinox.},
archivePrefix = {arXiv},
arxivId = {2111.00254v1},
author = {Kidger, Patrick and Quansight, Cristian Garcia},
eprint = {2111.00254v1},
file = {:home/antonio/Documents/bibliography/files/Kidger, Quansight - 2021 - Equinox neural networks in JAX via callable PyTrees and filtered transformations.pdf:pdf},
title = {{Equinox: neural networks in JAX via callable PyTrees and filtered transformations}},
url = {https://github.com/patrick-kidger/equinox},
year = {2021}
}

@article{Wei,
author = {Wei, Zhun and Chen, Xudong},
file = {:home/antonio/Documents/bibliography/files/Wei, Chen - Unknown - Physics-Inspired Convolutional Neural Network for Solving Full-Wave Inverse Scattering Problems.pdf:pdf},
pages = {1--11},
title = {{Physics-Inspired Convolutional Neural Network for Solving Full-Wave Inverse Scattering Problems}}
}

@article{Weia,
author = {Wei, Zhun and Chen, Xudong},
file = {:home/antonio/Documents/bibliography/files/Wei, Chen - Unknown - Deep Learning Schemes for Full-Wave Nonlinear Inverse Scattering Problems.pdf:pdf},
pages = {1--12},
title = {{Deep Learning Schemes for Full-Wave Nonlinear Inverse Scattering Problems}}
}

@article{Chen2020b,
abstract = {This paper studies numerical solutions for parameterized partial differential equations (P-PDEs) with deep learning (DL). P-PDEs arise in many important application areas and the computational cost using traditional numerical schemes can be exorbitant, especially when the parameters fall into a particular range and the underlying PDE is required to be solved with high accuracy. Recently, solving PDEs with DL has become an emerging field. Existing works demonstrate great potentials of the DL based approach in speeding up numerical solutions of PDEs. However, there is still limited research on the DL approach for P-PDEs. If we directly apply existing supervised learning models to P-PDEs, the models need to be constantly fine-tuned or retrained when the parameters change. This drastically limits the applicability and utility of these models in practice. To resolve this issue, we propose a meta-learning-based method that can efficiently solve P-PDEs with a wide range of parameters without retraining. Our key observation is to regard training a solver for the P-PDE with a given set of parameters as a learning task. Then, training a solver for the P-PDEs with varied parameters can be viewed as a multi-task learning problem, to which meta-learning is one of the most effective approaches. This new perspective can be applied to many existing PDE solvers. As an example, we adopt the Multigrid Network (MgNet) as the base solver. To achieve multi-task learning, we introduce a new hypernetwork, called Meta-NN, in MgNet and refer to the entire network as the Meta-MgNet. Meta-NN takes the differential operators and the right-hand-side of the underlying P-PDEs as inputs and generates appropriate smoothers for MgNet which can significantly affect the convergent speed. Finally, extensive numerical experiments demonstrate that Meta-MgNet is more efficient in solving P-PDEs than the MG methods and MgNet.},
archivePrefix = {arXiv},
arxivId = {2010.14088},
author = {Chen, Yuyan and Dong, Bin and Xu, Jinchao},
eprint = {2010.14088},
file = {:home/antonio/Documents/bibliography/files/Chen, Dong, Xu - 2020 - Meta-MgNet Meta Multigrid Networks for Solving Parameterized Partial Differential Equations.pdf:pdf},
title = {{Meta-MgNet: Meta Multigrid Networks for Solving Parameterized Partial Differential Equations}},
url = {http://arxiv.org/abs/2010.14088},
year = {2020}
}

@article{Fung2021,
abstract = {A growing trend in deep learning replaces fixed depth models by approximations of the limit as network depth approaches infinity. This approach uses a portion of network weights to prescribe behavior by defining a limit condition. This makes network depth implicit, varying based on the provided data and an error tolerance. Moreover, existing implicit models can be implemented and trained with fixed memory costs in exchange for additional computational costs. In particular, backpropagation through implicit depth models requires solving a Jacobian-based equation arising from the implicit function theorem. We propose fixed point networks (FPNs), a simple setup for implicit depth learning that guarantees convergence of forward propagation to a unique limit defined by network weights and input data. Our key contribution is to provide a new Jacobian-free backpropagation (JFB) scheme that circumvents the need to solve Jacobian-based equations while maintaining fixed memory costs. This makes FPNs much cheaper to train and easy to implement. Our numerical examples yield state of the art classification results for implicit depth models and outperform corresponding explicit models.},
archivePrefix = {arXiv},
arxivId = {2103.12803},
author = {Fung, Samy Wu and Heaton, Howard and Li, Qiuwei and McKenzie, Daniel and Osher, Stanley and Yin, Wotao},
eprint = {2103.12803},
file = {:home/antonio/Documents/bibliography/files/Fung et al. - 2021 - Fixed Point Networks Implicit Depth Models with Jacobian-Free Backprop.pdf:pdf},
pages = {1--19},
title = {{Fixed Point Networks: Implicit Depth Models with Jacobian-Free Backprop}},
url = {http://arxiv.org/abs/2103.12803},
year = {2021}
}

@article{Wong,
author = {Wong, Christopher A and Caday, Peter and Lassas, Matti},
file = {:home/antonio/Documents/bibliography/files/Wong, Caday, Lassas - Unknown - Deep neural networks learning to solve nonlinear inverse problems for the wave equation.pdf:pdf},
title = {{Deep neural networks learning to solve nonlinear inverse problems for the wave equation}}
}

@Article{Raissia,
  author        = {Raissi, Maziar and Perdikaris, Paris and Karniadakis, George Em},
  title         = {{Physics Informed Deep Learning ( Part I ): Data-driven Solutions of Nonlinear Partial Differential Equations}},
  number        = {Part I},
  pages         = {1--22},
  archiveprefix = {arXiv},
  arxivid       = {arXiv:1711.10561v1},
  eprint        = {arXiv:1711.10561v1},
  file          = {:home/antonio/Documents/bibliography/files/Raissi, Perdikaris, Karniadakis - Unknown - Physics Informed Deep Learning ( Part I ) Data-driven Solutions of Nonlinear Partial Differe.pdf:pdf},
  keywords      = {data-driven scientific computing, machine learning, modeling, nonlinear dynamics, predictive, runge-kutta methods},
}

@article{Hughes2019,
abstract = {Analog machine learning hardware platforms promise to be faster and more energy efficient than their digital counterparts. Wave physics, as found in acoustics and optics, is a natural candidate for building analog processors for time-varying signals. Here, we identify a mapping between the dynamics of wave physics and the computation in recurrent neural networks. This mapping indicates that physical wave systems can be trained to learn complex features in temporal data, using standard training techniques for neural networks. As a demonstration, we show that an inverse-designed inhomogeneous medium can perform vowel classification on raw audio signals as their waveforms scatter and propagate through it, achieving performance comparable to a standard digital implementation of a recurrent neural network. These findings pave the way for a new class of analog machine learning platforms, capable of fast and efficient processing of information in its native domain.},
archivePrefix = {arXiv},
arxivId = {1904.12831},
author = {Hughes, Tyler W. and Williamson, Ian A.D. and Minkov, Momchil and Fan, Shanhui},
doi = {10.1126/sciadv.aay6946},
eprint = {1904.12831},
file = {:home/antonio/Documents/bibliography/files/Hughes et al. - 2019 - Wave physics as an analog recurrent neural network.pdf:pdf},
issn = {23752548},
journal = {Science Advances},
number = {12},
pages = {1--7},
title = {{Wave physics as an analog recurrent neural network}},
volume = {5},
year = {2019}
}

@Article{Mukherjee2020,
  author        = {Mukherjee, Subhadip and Dittmer, S{\"{o}}ren and Shumaylov, Zakhar and Lunz, Sebastian and {\"{O}}ktem, Ozan and Sch{\"{o}}nlieb, Carola Bibiane},
  journal       = {arXiv},
  title         = {{Learned convex regularizers for inverse problems}},
  year          = {2020},
  issn          = {23318422},
  pages         = {1--13},
  abstract      = {We consider the variational reconstruction framework for inverse problems and propose to learn a data-adaptive input-convex neural network (ICNN) as the regularization functional. The ICNN-based convex regularizer is trained adversarially to discern ground-truth images from unregularized reconstructions. Convexity of the regularizer is attractive since (i) one can establish analytical convergence guarantees for the corresponding variational reconstruction problem and (ii) devise efficient and provable algorithms for reconstruction. In particular, we show that the optimal solution to the variational problem converges to the ground-truth if the penalty parameter decays sub-linearly with respect to the norm of the noise. Further, we prove the existence of a subgradient-based algorithm that leads to monotonically decreasing error in the parameter space with iterations. To demonstrate the performance of our approach for solving inverse problems, we consider the tasks of deblurring natural images and reconstructing images in computed tomography (CT), and show that the proposed convex regularizer is at least competitive with and sometimes superior to state-of-the-art data-driven techniques for inverse problems.},
  archiveprefix = {arXiv},
  arxivid       = {2008.02839},
  eprint        = {2008.02839},
  file          = {:home/antonio/Documents/bibliography/files/Mukherjee et al. - 2020 - Learned convex regularizers for inverse problems.pdf:pdf},
  keywords      = {Adversarial learning, Data-driven convex regularization, Inverse problems},
}

@article{Ichnowski2021,
abstract = {First-order methods for quadratic optimization such as OSQP are widely used
for large-scale machine learning and embedded optimal control, where many
related problems must be rapidly solved. These methods face two persistent
challenges: manual hyperparameter tuning and convergence time to high-accuracy
solutions. To address these, we explore how Reinforcement Learning (RL) can
learn a policy to tune parameters to accelerate convergence. In experiments
with well-known QP benchmarks we find that our RL policy, RLQP, significantly
outperforms state-of-the-art QP solvers by up to 3x. RLQP generalizes
surprisingly well to previously unseen problems with varying dimension and
structure from different applications, including the QPLIB, Netlib LP and
Maros-Meszaros problems. Code for RLQP is available at
https://github.com/berkeleyautomation/rlqp.},
archivePrefix = {arXiv},
arxivId = {2107.10847},
author = {Ichnowski, Jeffrey and Jain, Paras and Stellato, Bartolomeo and Banjac, Goran and Luo, Michael and Borrelli, Francesco and Gonzalez, Joseph E. and Stoica, Ion and Goldberg, Ken},
eprint = {2107.10847},
file = {:home/antonio/Documents/bibliography/files/Ichnowski et al. - 2021 - Accelerating Quadratic Optimization with Reinforcement Learning.pdf:pdf},
month = {jul},
title = {{Accelerating Quadratic Optimization with Reinforcement Learning}},
url = {https://arxiv.org/abs/2107.10847v1},
year = {2021}
}

@Misc{Bai2020a,
  author        = {Bai, Shaojie and Koltun, Vladlen and Kolter, J. Zico},
  month         = {nov},
  title         = {{Multiscale deep equilibrium models}},
  year          = {2020},
  abstract      = {We propose a new class of implicit networks, the multiscale deep equilibrium model (MDEQ), suited to large-scale and highly hierarchical pattern recognition domains. An MDEQ directly solves for and backpropagates through the equilibrium points of multiple feature resolutions simultaneously, using implicit differentiation to avoid storing intermediate states (and thus requiring only O(1) memory consumption). These simultaneously-learned multi-resolution features allow us to train a single model on a diverse set of tasks and loss functions, such as using a single MDEQ to perform both image classification and semantic segmentation. We illustrate the effectiveness of this approach on two large-scale vision tasks: ImageNet classification and semantic segmentation on high-resolution images from the Cityscapes dataset. In both settings, MDEQs are able to match or exceed the performance of recent competitive computer vision models: the first time such performance and scale have been achieved by an implicit deep learning approach. The code and pre-trained models are at https://github.com/locuslab/mdeq.},
  archiveprefix = {arXiv},
  arxivid       = {2006.08656},
  booktitle     = {arXiv},
  eprint        = {2006.08656},
  file          = {:home/antonio/Documents/bibliography/files/Bai, Koltun, Kolter - 2020 - Multiscale deep equilibrium models.pdf:pdf},
  issn          = {23318422},
  keywords      = {Computer Science - Computer Vision and Pattern Rec, Computer Science - Machine Learning, Statistics - Machine Learning},
  language      = {en},
  mendeley-tags = {Computer Science - Computer Vision and Pattern Rec,Computer Science - Machine Learning,Statistics - Machine Learning},
  url           = {http://arxiv.org/abs/2006.08656},
}

@article{Wright2021,
abstract = {Deep neural networks have become a pervasive tool in science and engineering. However, modern deep neural networks' growing energy requirements now increasingly limit their scaling and broader use. We propose a radical alternative for implementing deep neural network models: Physical Neural Networks. We introduce a hybrid physical-digital algorithm called Physics-Aware Training to efficiently train sequences of controllable physical systems to act as deep neural networks. This method automatically trains the functionality of any sequence of real physical systems, directly, using backpropagation, the same technique used for modern deep neural networks. To illustrate their generality, we demonstrate physical neural networks with three diverse physical systems-optical, mechanical, and electrical. Physical neural networks may facilitate unconventional machine learning hardware that is orders of magnitude faster and more energy efficient than conventional electronic processors.},
archivePrefix = {arXiv},
arxivId = {2104.13386},
author = {Wright, Logan G. and Onodera, Tatsuhiro and Stein, Martin M. and Wang, Tianyu and Schachter, Darren T. and Hu, Zoey and McMahon, Peter L.},
eprint = {2104.13386},
file = {:home/antonio/Documents/bibliography/files/Wright et al. - 2021 - Deep physical neural networks enabled by a backpropagation algorithm for arbitrary physical systems.pdf:pdf},
title = {{Deep physical neural networks enabled by a backpropagation algorithm for arbitrary physical systems}},
url = {http://arxiv.org/abs/2104.13386},
year = {2021}
}

@article{Louboutin2021,
abstract = {Inspired by recent work on extended image volumes that lays the ground for randomized probing of extremely large seismic wavefield matrices, we present a memory frugal and computationally efficient inversion methodology that uses techniques from randomized linear algebra. By means of a carefully selected realistic synthetic example, we demonstrate that we are capable of achieving competitive inversion results at a fraction of the memory cost of conventional full-waveform inversion with limited computational overhead. By exchanging memory for negligible computational overhead, we open with the presented technology the door towards the use of low-memory accelerators such as GPUs.},
archivePrefix = {arXiv},
arxivId = {2104.00794},
author = {Louboutin, Mathias and Herrmann, Felix J.},
eprint = {2104.00794},
file = {:home/antonio/Documents/bibliography/files/Louboutin, Herrmann - 2021 - Ultra-low memory seismic inversion with randomized trace estimation.pdf:pdf},
number = {2009},
pages = {1--9},
title = {{Ultra-low memory seismic inversion with randomized trace estimation}},
url = {http://arxiv.org/abs/2104.00794},
year = {2021}
}

@Article{Um2020,
  author        = {Um, Kiwon and Fei, Yun Raymond and Holl, Philipp and Brand, Robert and Thuerey, Nils},
  journal       = {arXiv},
  title         = {{Solver-in-the-Loop: Learning from Differentiable Physics to Interact with Iterative PDE-Solvers}},
  year          = {2020},
  issn          = {23318422},
  number        = {c},
  pages         = {1--12},
  volume        = {1},
  abstract      = {Finding accurate solutions to partial differential equations (PDEs) is a crucial task in all scientific and engineering disciplines. It has recently been shown that machine learning methods can improve the solution accuracy by correcting for effects not captured by the discretized PDE. We target the problem of reducing numerical errors of iterative PDE solvers and compare different learning approaches for finding complex correction functions. We find that previously used learning approaches are significantly outperformed by methods that integrate the solver into the training loop and thereby allow the model to interact with the PDE during training. This provides the model with realistic input distributions that take previous corrections into account, yielding improvements in accuracy with stable rollouts of several hundred recurrent evaluation steps and surpassing even tailored supervised variants. We highlight the performance of the differentiable physics networks for a wide variety of PDEs, from non-linear advection-diffusion systems to three-dimensional Navier-Stokes flows.},
  archiveprefix = {arXiv},
  arxivid       = {2007.00016},
  eprint        = {2007.00016},
  file          = {:home/antonio/Documents/bibliography/files/Um et al. - 2020 - Solver-in-the-Loop Learning from Differentiable Physics to Interact with Iterative PDE-Solvers.pdf:pdf},
  groups        = {Differentiable programming and simulation},
}

@Article{Vay2013,
  author    = {Vay, Jean Luc and Haber, Irving and Godfrey, Brendan B.},
  journal   = {Journal of Computational Physics},
  title     = {{A domain decomposition method for pseudo-spectral electromagnetic simulations of plasmas}},
  year      = {2013},
  issn      = {10902716},
  pages     = {260--268},
  volume    = {243},
  abstract  = {Pseudo-spectral electromagnetic solvers (i.e. representing the fields in Fourier space) have extraordinary precision. In particular, Haber et al. presented in 1973 a pseudo-spectral solver that integrates analytically the solution over a finite time step, under the usual assumption that the source is constant over that time step. Yet, pseudo-spectral solvers have not been widely used, due in part to the difficulty for efficient parallelization owing to global communications associated with global FFTs on the entire computational domains.A method for the parallelization of electromagnetic pseudo-spectral solvers is proposed and tested on single electromagnetic pulses, and on Particle-In-Cell simulations of the wakefield formation in a laser plasma accelerator.The method takes advantage of the properties of the Discrete Fourier Transform, the linearity of Maxwell's equations and the finite speed of light for limiting the communications of data within guard regions between neighboring computational domains.Although this requires a small approximation, test results show that no significant error is made on the test cases that have been presented.The proposed method opens the way to solvers combining the favorable parallel scaling of standard finite-difference methods with the accuracy advantages of pseudo-spectral methods. {\textcopyright} 2013 Elsevier Inc.},
  doi       = {10.1016/j.jcp.2013.03.010},
  file      = {:home/antonio/Documents/bibliography/files/Vay, Haber, Godfrey - 2013 - A domain decomposition method for pseudo-spectral electromagnetic simulations of plasmas.pdf:pdf},
  keywords  = {Domain decomposition, Electromagnetic, FFT, Fast fourier transform, Parallel, Particle-In-Cell, Spectral},
  publisher = {Elsevier Inc.},
  url       = {http://dx.doi.org/10.1016/j.jcp.2013.03.010},
}

@misc{Choromanski2020,
abstract = {We introduce Performers, Transformer architectures which can estimate regular (softmax) full-rank-attention Transformers with provable accuracy, but using only linear (as opposed to quadratic) space and time complexity, without relying on any priors such as sparsity or low-rankness. To approximate softmax attention-kernels, Performers use a novel Fast Attention Via positive Orthogonal Random features approach (FAVOR+), which may be of independent interest for scalable kernel methods. FAVOR+ can be also used to efficiently model kernelizable attention mechanisms beyond softmax. This representational power is crucial to accurately compare softmax with other kernels for the first time on large-scale tasks, beyond the reach of regular Transformers, and investigate optimal attention-kernels. Performers are linear architectures fully compatible with regular Transformers and with strong theoretical guarantees: unbiased or nearly-unbiased estimation of the attention matrix, uniform convergence and low estimation variance. We tested Performers on a rich set of tasks stretching from pixel-prediction through text models to protein sequence modeling. We demonstrate competitive results with other examined efficient sparse and dense attention methods, showcasing effectiveness of the novel attention-learning paradigm leveraged by Performers.},
archivePrefix = {arXiv},
arxivId = {2009.14794},
author = {Choromanski, Krzysztof and Likhosherstov, Valerii and Dohan, David and Song, Xingyou and Gane, Andreea and Sarlos, Tamas and Hawkins, Peter and Davis, Jared and Mohiuddin, Afroz and Kaiser, Lukasz and Belanger, David and Colwell, Lucy and Weller, Adrian},
booktitle = {arXiv},
eprint = {2009.14794},
file = {:home/antonio/Documents/bibliography/files/Choromanski et al. - 2020 - Rethinking attention with performers.pdf:pdf},
issn = {23318422},
pages = {1--38},
title = {{Rethinking attention with performers}},
year = {2020}
}

@article{Oktay2021,
author = {Oktay, Deniz and McGreivy, Nick and Aduol, Joshua and Beatson, Alex and Adams, Ryan P},
file = {:home/antonio/Documents/bibliography/files/Oktay et al. - 2021 - Randomized automatic differentiation.pdf:pdf},
journal = {Iclr},
pages = {1--19},
title = {{Randomized automatic differentiation}},
year = {2021}
}

@Article{Wandel,
  author        = {Wandel, Nils and Weinmann, Michael and Neidlin, Michael and Klein, Reinhard},
  title         = {{Spline-PINN: Approaching PDEs without Data using Fast, Physics-Informed Hermite-Spline CNNs}},
  year          = {2021},
  month         = {sep},
  abstract      = {Partial Differential Equations (PDEs) are notoriously difficult to solve. In general, closed-form solutions are not available and numerical approximation schemes are computationally expensive. In this paper, we propose to approach the solution of PDEs based on a novel technique that combines the advantages of two recently emerging machine learning based approaches. First, physics-informed neural networks (PINNs) learn continuous solutions of PDEs and can be trained with little to no ground truth data. However, PINNs do not generalize well to unseen domains. Second, convolutional neural networks provide fast inference and generalize but either require large amounts of training data or a physics-constrained loss based on finite differences that can lead to inaccuracies and discretization artifacts. We leverage the advantages of both of these approaches by using Hermite spline kernels in order to continuously interpolate a grid-based state representation that can be handled by a CNN. This allows for training without any precomputed training data using a physics-informed loss function only and provides fast, continuous solutions that generalize to unseen domains. We demonstrate the potential of our method at the examples of the incompressible Navier-Stokes equation and the damped wave equation. Our models are able to learn several intriguing phenomena such as Karman vortex streets, the Magnus effect, Doppler effect, interference patterns and wave reflections. Our quantitative assessment and an interactive real-time demo show that we are narrowing the gap in accuracy of unsupervised ML based methods to industrial CFD solvers while being orders of magnitude faster.},
  archiveprefix = {arXiv},
  arxivid       = {2109.07143v1},
  eprint        = {2109.07143v1},
  file          = {:home/antonio/Documents/bibliography/files/Wandel et al. - 2022 - Spline-PINN Approaching PDEs without Data using Fast, Physics-Informed Hermite-Spline CNNs.pdf:pdf},
  keywords      = {cs.LG, cs.CE, physics.flu-dyn},
  primaryclass  = {cs.LG},
  readstatus    = {skimmed},
  url           = {www.aaai.org http://arxiv.org/abs/2109.07143},
}

@Misc{wandel2021learning,
  author        = {Nils Wandel and Michael Weinmann and Reinhard Klein},
  title         = {Learning Incompressible Fluid Dynamics from Scratch -- Towards Fast, Differentiable Fluid Models that Generalize},
  year          = {2021},
  archiveprefix = {arXiv},
  eprint        = {2006.08762},
  file          = {:/home/antonio/Downloads/2006.08762.pdf:PDF},
  primaryclass  = {cs.LG},
}

@InProceedings{Saharia2111,
  author = {Chitwan Saharia and William Chan and Huiwen Chang and Chris A. Lee and Jonathan Ho and Tim Salimans and David J. Fleet and Mohammad Norouzi and ∗},
  title  = {Palette: Image-to-Image Diffusion Models},
  year   = {2021},
  file   = {:/home/antonio/Downloads/2111.05826(1).pdf:PDF},
  groups = {Diffusion},
}

@InProceedings{Saharia2104,
  author   = {Chitwan Saharia and Jonathan Ho and William Chan and Tim Salimans and David J. Fleet and Mohammad Norouzi and {sahariac and jonathanho and williamchan and salimans and davidfleet and mnorouzi}@google.com},
  title    = {Image Super-Resolution via Iterative Refinement},
  year     = {2021},
  abstract = {Input SR3 output Reference},
  file     = {:/home/antonio/Downloads/2104.07636.pdf:PDF},
  groups   = {Diffusion},
}

@InProceedings{Sasaki2104,
  author = {Hiroshi Sasaki and Chris G. Willcocks and Toby P. Breckon},
  title  = {UNIT-DDPM: UNpaired Image Translation with Denoising Diffusion Probabilistic Models},
  year   = {2021},
  file   = {:/home/antonio/Downloads/2104.05358(1).pdf:PDF},
  groups = {Diffusion},
}

@InProceedings{Ho2006,
  author = {Jonathan Ho and Ajay Jain and Pieter Abbeel and UC Berkeley and UC Berkeley and UC Berkeley},
  title  = {Denoising Diffusion Probabilistic Models},
  year   = {2020},
  file   = {:/home/antonio/Downloads/2006.11239.pdf:PDF},
  groups = {Diffusion},
}

@Article{Yedida2021,
  author        = {Yedida, Rahul and Saha, Snehanshu and Prashanth, Tejas},
  journal       = {Applied Intelligence},
  title         = {{LipschitzLR: Using theoretically computed adaptive learning rates for fast convergence}},
  year          = {2021},
  issn          = {15737497},
  number        = {3},
  pages         = {1460--1478},
  volume        = {51},
  abstract      = {We present a novel theoretical framework for computing large, adaptive learning rates. Our framework makes minimal assumptions on the activations used and exploits the functional properties of the loss function. Specifically, we show that the inverse of the Lipschitz constant of the loss function is an ideal learning rate. We analytically compute formulas for the Lipschitz constant of several loss functions, and through extensive experimentation, demonstrate the strength of our approach using several architectures and datasets. In addition, we detail the computation of learning rates when other optimizers, namely, SGD with momentum, RMSprop, and Adam, are used. Compared to standard choices of learning rates, our approach converges faster, and yields better results.},
  archiveprefix = {arXiv},
  arxivid       = {1902.07399},
  doi           = {10.1007/s10489-020-01892-0},
  eprint        = {1902.07399},
  file          = {:home/antonio/Downloads/1902.07399.pdf:pdf},
  groups        = {General deep learning},
  keywords      = {Adaptive learning, Deep learning, Lipschitz constant, Machine learning},
  primaryclass  = {cs.LG},
}

@Article{Lefkimmiatis,
  author        = {Lefkimmiatis, Stamatios},
  title         = {{Universal Denoising Networks : A Novel CNN Architecture for Image Denoising}},
  number        = {1},
  archiveprefix = {arXiv},
  arxivid       = {arXiv:1711.07807v2},
  eprint        = {arXiv:1711.07807v2},
  file          = {:home/antonio/Documents/bibliography/files/Lefkimmiatis - Unknown - Universal Denoising Networks A Novel CNN Architecture for Image Denoising.pdf:pdf;:home/antonio/Documents/bibliography/files/Lefkimmiatis - Unknown - Universal Denoising Networks A Novel CNN Architecture for Image Denoising(2).pdf:pdf},
}

@Book{X2019,
  author     = {X},
  publisher  = {SPRINGER NATURE},
  title      = {{ACOUSTICS: an introduction to its physical principles and applications, fully updated and... revised.}},
  year       = {2019},
  address    = {S.l.},
  isbn       = {978-3-030-11213-4},
  booktitle  = {Acoustics},
  doi        = {10.1007/978-3-030-11214-1},
  file       = {:home/antonio/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Pierce - 2019 - Acoustics.pdf:pdf},
  groups     = {Books},
  language   = {en},
  shorttitle = {ACOUSTICS},
}

@InProceedings{Kong2021,
  author = {Lingke Kong and Chenyu Lian and Manteia Tech and Xiamen University},
  title  = {Breaking the Dilemma of Medical Image-to-image Translation},
  year   = {2021},
  file   = {:/home/antonio/Downloads/breaking_the_dilemma_of_medica.pdf:PDF},
  groups = {img 2 img translation},
}

@InProceedings{Mode1508,
  author   = {J. Mann & J. N. Kutz},
  title    = {Dynamic Mode and Decomposition for Financial and Trading Strategies},
  year     = {2015},
  abstract = {We demonstrate the application of an algorithmic trading strategy based upon the recently developed
dynamic mode decomposition (DMD) on portfolios of financial data. The method is capable of
characterizing complex dynamical systems, in this case financial market dynamics, in an equation-
free manner by decomposing the state of the system into low-rank terms whose temporal coefficients
in time are known. By extracting key temporal coherent structures (portfolios) in its sampling
window, it provides a regression to a best fit linear dynamical system, allowing for a predictive
assessment of the market dynamics and informing an investment strategy. The data-driven analytics
capitalizes on stock market patterns, either real or perceived, to inform buy/sell/hold investment
decisions. Critical to the method is an associated learning algorithm that optimizes the sampling and
prediction windows of the algorithm by discovering trading hot-spots. The underlying mathematical
structure of the algorithms is rooted in methods from nonlinear dynamical systems and shows that
the decomposition is an effective mathematical tool for data-driven discovery of market patterns.},
  file     = {:/home/antonio/Downloads/1508.04487.pdf:PDF},
  groups   = {Finance},
}

@TechReport{Bezgin2112,
  author = {Deniz A. Bezgin and Aaron B. Buhendwa and Chair of Aerodynamics and Fluid Mechanics and Chair of Aerodynamics and Fluid Mechanics},
  title  = {A fully-differentiable compressible high-order computational fluid dynamics solver},
  year   = {2112},
  number = {Munich},
  file   = {:/home/antonio/Downloads/2112.04979v1.pdf:PDF},
  groups = {Differentiable programming and simulation},
}

@Article{koopman1931hamiltonian,
  author    = {Koopman, Bernard O},
  journal   = {Proceedings of the national academy of sciences of the united states of america},
  title     = {Hamiltonian systems and transformation in Hilbert space},
  year      = {1931},
  number    = {5},
  pages     = {315},
  volume    = {17},
  file      = {:/home/antonio/Downloads/315.full.pdf:PDF},
  groups    = {Dynamics and control},
  publisher = {National Academy of Sciences},
}

@Article{otto2019linearly,
  author    = {Otto, Samuel E and Rowley, Clarence W},
  journal   = {SIAM Journal on Applied Dynamical Systems},
  title     = {Linearly recurrent autoencoder networks for learning dynamics},
  year      = {2019},
  number    = {1},
  pages     = {558--593},
  volume    = {18},
  file      = {:/home/antonio/Downloads/1712.01378.pdf:PDF},
  groups    = {Dynamics and control},
  publisher = {SIAM},
}

@Article{Klus2018,
  author    = {Stefan Klus and Feliks Nüske and P{\'{e}}ter Koltai and Hao Wu and Ioannis Kevrekidis and Christof Schütte and Frank No{\'{e}}},
  journal   = {Journal of Nonlinear Science},
  title     = {Data-Driven Model Reduction and Transfer Operator Approximation},
  year      = {2018},
  month     = {jan},
  number    = {3},
  pages     = {985--1010},
  volume    = {28},
  doi       = {10.1007/s00332-017-9437-7},
  file      = {:/home/antonio/Downloads/Klus2018_Article_Data-DrivenModelReductionAndTr.pdf:PDF},
  groups    = {Dynamics and control},
  publisher = {Springer Science and Business Media {LLC}},
}

@Article{otto2021koopman,
  author    = {Otto, Samuel E and Rowley, Clarence W},
  journal   = {Annual Review of Control, Robotics, and Autonomous Systems},
  title     = {Koopman operators for estimation and control of dynamical systems},
  year      = {2021},
  pages     = {59--87},
  volume    = {4},
  file      = {:/home/antonio/Downloads/annurev-control-071020-010108.pdf:PDF},
  groups    = {Dynamics and control},
  publisher = {Annual Reviews},
}

@InProceedings{IvanG.Graham2020,
  author   = {Ivan G. Graham, Euan A. Spence, and Jun Zou},
  title    = {Domain Decomposition with Local Impedance Conditions for the Helmholtz Equation with Absorption | SIAM Journal on Numerical Analysis | Vol. 58, No. 5 | Society for Industrial and Applied Mathematics},
  year     = {2020},
  abstract = {SIAM J. Numer. Anal. 2020.58:2515-2543},
  doi      = {.org/10.1137/19M1272512},
  file     = {:/home/antonio/Downloads/19m1272512.pdf:PDF},
  groups   = {Helmholtz, Helmholtz and wave algorithms},
  keywords = {Helmholtz equation, high frequency, preconditioning, GMRES, domain decomposition, subproblems with impedance conditions, robustness, 65F08, 65F10, 65N55},
}

@InProceedings{Fan1808,
  author   = {Yuwei Fan and Jordi Feliu-Faba and Lin Lin and Lexing Ying and Leonardo Zepeda-Núñez},
  title    = {A multiscale neural network based on hierarchical nested bases},
  year     = {1808},
  file     = {:/home/antonio/Downloads/1808.02376.pdf:PDF},
  groups   = {Representation, architectures and DL layers},
  keywords = {Hierarchical nested bases; fast multipole method; H2-matrix; nonlinear mappings; artificial neural network; locally connected neural network; convolutional neural network},
}

@InProceedings{Li2111,
  author = {Zongyi Li and Hongkai Zheng and Nikola Kovachki and David Jin and Haoxuan Chen and Burigede Liu and Kamyar Azizzadenesheli and Anima Anandkumar},
  title  = {Physics-Informed Neural Operator for Learning Partial Differential Equations},
  year   = {2111},
  file   = {:/home/antonio/Downloads/2111.03794.pdf:PDF},
  groups = {Neural Operators},
}

@InProceedings{Li2020d,
  author = {Zongyi Li and Nikola Kovachki and Caltech Caltech},
  title  = {Multipole Graph Neural Operator for Parametric Partial Differential Equations},
  year   = {2020},
  file   = {:/home/antonio/Downloads/NeurIPS-2020-multipole-graph-neural-operator-for-parametric-partial-differential-equations-Paper.pdf:PDF},
  groups = {Neural Operators},
}

@InProceedings{Gupta2021,
  author = {Gaurav Gupta and Xiongye Xiao and Paul Bogdan and Ming Hsieh and Department of Electrical and Computer Engineering},
  title  = {Multiwavelet-based Operator Learning for Differential Equations},
  year   = {2021},
  file   = {:/home/antonio/Downloads/multiwavelet_based_operator_le.pdf:PDF},
  groups = {Neural Operators},
}

@InProceedings{PRECONDITIONING1811,
  author   = {PRECONDITIONING},
  title    = {SOLVING THE 3D HIGH-FREQUENCY HELMHOLTZ EQUATION USING CONTOUR INTEGRATION AND POLYNOMIAL},
  year     = {1811},
  abstract = {We propose an iterative solution method for the 3D high-frequency Helmholtz equa-
tion that exploits a contour integral formulation of spectral projectors. In this framework, the
solution in certain invariant subspaces is approximated by solving complex-shifted linear systems,
resulting in faster GMRES iterations due to the restricted spectrum. The shifted systems are solved
by exploiting a polynomial fixed-point iteration, which is a robust scheme even if the magnitude of
the shift is small. Numerical tests in 3D indicate that O(n1/3) matrix-vector products are needed
to solve a high-frequency problem with a matrix size n with high accuracy. The method has a
small storage requirement, can be applied to both dense and sparse linear systems, and is highly
parallelizable.},
  file     = {:/home/antonio/Downloads/1811.12378.pdf:PDF},
  groups   = {Helmholtz and wave algorithms},
}

@InProceedings{Journal0377,
  author   = {M. B. van Gijzen},
  title    = {A polynomial preconditioner for the GMRES algorithm},
  year     = {0377},
  pages    = {91-107},
  volume   = {59},
  doi      = {10.1016/0377-0427(94)00015-s},
  file     = {:/home/antonio/Downloads/1-s2.0-037704279400015S-main.pdf:PDF},
  groups   = {Helmholtz and wave algorithms},
  issn     = {0377-0427},
  keywords = {Preconditioning; GMRES; Ritz values; Nonsymmetric linear systems},
}

@InProceedings{Finzi2019,
  author   = {Marc Finzi, Pavel Izmailov, Wesley Maddox, Polina Kirichenko, Andrew Gordon Wilson},
  title    = {Invertible Convolutional Networks},
  year     = {2019},
  abstract = {Proceedings of the International Conference on Machine Learning 2019},
  file     = {:/home/antonio/Downloads/INNF_2019_paper_26.pdf:PDF},
  groups   = {Normalizing flows},
  keywords = {Machine Learning, ICML},
}

@InProceedings{Ramos2019,
  author   = {Luis García Ramos, Olivier Sète, Reinhard Nabben},
  title    = {Preconditioning the Helmholtz equation with the shifted Laplacian and Faber polynomials},
  year     = {2019},
  abstract = {We introduce a new polynomial preconditioner for solving the discretized Helmholtz equation
preconditioned with the complex shifted Laplace (CSL) operator. We exploit the localization of the spectrum of the
CSL-preconditioned system to approximately enclose the eigenvalues by a non-convex ‘bratwurst’ set. On this set,
we expand the function 1/z into a Faber series. Truncating the series gives a polynomial, which we apply to the
Helmholtz matrix preconditioned by the shifted Laplacian to obtain a new preconditioner, the Faber preconditioner.
We prove that the Faber preconditioner is nonsingular for degrees one and two of the truncated series. Our numerical
experiments (for problems with constant and varying wavenumber) show that the Faber preconditioner reduces the
number of GMRES iterations.},
  file     = {:/home/antonio/Downloads/pp534-557.pdf:PDF},
  groups   = {Helmholtz and wave algorithms},
  keywords = {Helmholtz equation, shifted Laplace preconditioner, iterative methods, GMRES, preconditioning, Faber polynomials, `bratwurst' sets},
}

@Misc{This1501,
  author = {Siegfried Cools and Wim Vanroose},
  title  = {On the Optimality of Shifted Laplacian in a Class of Polynomial Preconditioners for the Helmholtz Equation},
  year   = {2017},
  doi    = {10.1007/978-3-319-28832-1_3},
  file   = {:/home/antonio/Downloads/1501.04445.pdf:PDF},
  groups = {Helmholtz and wave algorithms},
  issn   = {2510-1544},
  pages  = {53-81},
}

@InProceedings{N.UMETANI2006,
  author   = {N. Umetani and S. P. MacLachlan and C. W. Oosterlee},
  title    = {A multigrid-based shifted Laplacian preconditioner for a fourth-order Helmholtz discretization},
  year     = {2009},
  pages    = {603-626},
  volume   = {16},
  abstract = {In this paper, an iterative solution method for a fourth-order accurate discretization
of the Helmholtz equation is presented. The method is a generalization of that presented in [10],
where multigrid was employed as a preconditioner for a Krylov subspace iterative method. This
multigrid preconditioner is based on the solution of a second Helmholtz operator with a complex-
valued shift. In particular, we compare preconditioners based on a point-wise Jacobi smoother
with those using an ILU(0) smoother, we compare using the prolongation operator developed by de
Zeeuw in [37] with interpolation operators based on algebraic multigrid principles, and we compare
the performance of the Krylov subspace method Bi-CGSTAB with the recently introduced induced
dimension reduction method, IDR(s). These three improvements are combined to yield an efficient
solver for heterogeneous high-wavenumber problems.},
  doi      = {10.1002/nla.634},
  file     = {:/home/antonio/Downloads/helmholtz.pdf:PDF},
  groups   = {Helmholtz and wave algorithms},
  issn     = {1070-5325},
}

@InProceedings{North2103,
  author   = {North, Evan and Tsynkov, Semyon and Turkel, Eli},
  title    = {Non-Iterative Domain Decomposition for the Helmholtz Equation Using the Method of Difference Potentials},
  year     = {2021},
  month    = {3},
  abstract = {We use the Method of Difference Potentials (MDP) to solve a non-overlapping domain decomposition formulation of the Helmholtz equation. The MDP reduces the Helmholtz equation on each subdomain to a Calderon's boundary equation with projection on its boundary. The unknowns for the Calderon's equation are the Dirichlet and Neumann data. Coupling between neighboring subdomains is rendered by applying their respective Calderon's equations to the same data at the common interface. Solutions on individual subdomains are computed concurrently using a straightforward direct solver. We provide numerical examples demonstrating that our method is insensitive to interior cross-points and mixed boundary conditions, as well as large jumps in the wavenumber for transmission problems, which are known to be problematic for many other Domain Decomposition Methods.},
  date     = {2021-03-24},
  day      = {24},
  eprint   = {arXiv:2103.12172v1[math.NA]},
  file     = {:/home/antonio/Downloads/2103.12172.pdf:PDF},
  groups   = {Helmholtz and wave algorithms},
  keywords = {Time-harmonic waves, Non-overlapping domain decomposition, Calderon's operators, Exact coupling between subdomains, High-order accuracy, Compact finite difference schemes, Direct solution, Complexity bounds, Material interfaces, Interior cross-points},
}

@Article{Trivedi2019,
  author    = {Rahul Trivedi and Logan Su and Jesse Lu and Martin F. Schubert and Jelena Vuckovic},
  journal   = {Scientific Reports},
  title     = {Data-driven acceleration of photonic simulations},
  year      = {2019},
  issn      = {2045-2322},
  month     = {dec},
  number    = {1},
  volume    = {9},
  abstract  = {Designing modern photonic devices often involves traversing a large parameter space via an optimization procedure, gradient based or otherwise, and typically results in the designer performing electromagnetic simulations of a large number of correlated devices. In this paper, we investigate the possibility of accelerating electromagnetic simulations using the data collected from such correlated simulations. In particular, we present an approach to accelerate the Generalized Minimal Residual (GMRES) algorithm for the solution of frequency-domain Maxwell's equations using two machine learning models (principal component analysis and a convolutional neural network). These data-driven models are trained to predict a subspace within which the solution of the frequency-domain Maxwell's equations approximately lies. This subspace is then used for augmenting the Krylov subspace generated during the GMRES iterations, thus effectively reducing the size of the Krylov subspace and hence the number of iterations needed for solving Maxwell's equations. By training the proposed models on a dataset of wavelength-splitting gratings, we show an order of magnitude reduction (~10-50) in the number of GMRES iterations required for solving frequency-domain Maxwell's equations.},
  doi       = {10.1038/s41598-019-56212-5},
  file      = {:/home/antonio/Downloads/s41598-019-56212-5.pdf:PDF},
  groups    = {Physics as NN},
  publisher = {Springer Science and Business Media {LLC}},
}

@Article{Azulai2021,
  author   = {Azulai, Yael and Treister, Eran},
  title    = {Multigrid-augmented deep learning preconditioners for the Helmholtz equation},
  year     = {2021},
  abstract = {We present a data-driven approach to iteratively solve the discrete heterogeneous Helmholtz equation at high wavenumbers. We combine multigrid ingredients with convolutional neural networks (CNNs) to form a preconditioner which is applied within a Krylov solver. Two types of preconditioners are proposed 1) U-Net as a coarse grid solver, and 2) U-Net as a deflation operator with shifted Laplacian V-cycles. The resulting CNN preconditioner can generalize over residuals and a relatively general set of wave slowness models. On top of that, we offer an encoder-solver framework where an "encoder" network generalizes over the medium and sends context vectors to another "solver" network, which generalizes over the right-hand-sides. We show that this option is more efficient than the stand-alone variant. Lastly, we suggest a mini-retraining procedure, to improve the solver after the model is known. We demonstrate the efficiency and generalization abilities of our approach on a variety of 2D problems.},
  file     = {:home/antonio/Documents/bibliography/files/Azulai, Treister - Unknown - Multigrid-augmented deep learning preconditioners for the Helmholtz equation.pdf:pdf},
  groups   = {Helmholtz, Helmholtz and waves},
}

@Misc{Winston2020,
  author        = {Winston, Ezra and Kolter, J. Zico},
  title         = {{Monotone operator equilibrium networks}},
  year          = {2020},
  abstract      = {Implicit-depth models such as Deep Equilibrium Networks have recently been shown to match or exceed the performance of traditional deep networks while being much more memory efficient. However, these models suffer from unstable convergence to a solution and lack guarantees that a solution exists. On the other hand, Neural ODEs, another class of implicit-depth models, do guarantee existence of a unique solution but perform poorly compared with traditional networks. In this paper, we develop a new class of implicit-depth model based on the theory of monotone operators, the Monotone Operator Equilibrium Network (MON). We show the close connection between finding the equilibrium point of an implicit network and solving a form of monotone operator splitting problem, which admits efficient solvers with guaranteed, stable convergence. We then develop a parameterization of the network which ensures that all operators remain monotone, which guarantees the existence of a unique equilibrium point. Finally, we show how to instantiate several versions of these models, and implement the resulting iterative solvers, for structured linear operators such as multi-scale convolutions. The resulting models vastly outperform the Neural ODE-based models while also being more computationally efficient. Code is available at http://github.com/locuslab/monotone_op_net.},
  archiveprefix = {arXiv},
  arxivid       = {2006.08591},
  booktitle     = {arXiv},
  eprint        = {2006.08591},
  file          = {:home/antonio/Documents/bibliography/files/Winston, Kolter - Unknown - Monotone operator equilibrium networks.pdf:pdf},
  groups        = {Helmholtz and waves},
  issn          = {23318422},
  language      = {en},
  pages         = {11},
  url           = {http://github.com/locuslab/monotone_op_net.},
}

@Article{Zhu2018,
  author        = {Zhu, Bo and Liu, Jeremiah Z. and Cauley, Stephen F. and Rosen, Bruce R. and Rosen, Matthew S.},
  journal       = {Nature},
  title         = {{Image reconstruction by domain-transform manifold learning}},
  year          = {2018},
  issn          = {14764687},
  number        = {7697},
  pages         = {487--492},
  volume        = {555},
  abstract      = {Image reconstruction is essential for imaging applications across the physical and life sciences, including optical and radar systems, magnetic resonance imaging, X-ray computed tomography, positron emission tomography, ultrasound imaging and radio astronomy. During image acquisition, the sensor encodes an intermediate representation of an object in the sensor domain, which is subsequently reconstructed into an image by an inversion of the encoding function. Image reconstruction is challenging because analytic knowledge of the exact inverse transform may not exist a priori, especially in the presence of sensor non-idealities and noise. Thus, the standard reconstruction approach involves approximating the inverse function with multiple ad hoc stages in a signal processing chain, the composition of which depends on the details of each acquisition strategy, and often requires expert parameter tuning to optimize reconstruction performance. Here we present a unified framework for image reconstruction - automated transform by manifold approximation (AUTOMAP) - which recasts image reconstruction as a data-driven supervised learning task that allows a mapping between the sensor and the image domain to emerge from an appropriate corpus of training data. We implement AUTOMAP with a deep neural network and exhibit its flexibility in learning reconstruction transforms for various magnetic resonance imaging acquisition strategies, using the same network architecture and hyperparameters. We further demonstrate that manifold learning during training results in sparse representations of domain transforms along low-dimensional data manifolds, and observe superior immunity to noise and a reduction in reconstruction artefacts compared with conventional handcrafted reconstruction methods. In addition to improving the reconstruction performance of existing acquisition methodologies, we anticipate that AUTOMAP and other learned reconstruction approaches will accelerate the development of new acquisition strategies across imaging modalities.},
  archiveprefix = {arXiv},
  arxivid       = {1704.08841},
  doi           = {10.1038/nature25988},
  eprint        = {1704.08841},
  file          = {:home/antonio/Documents/bibliography/files/Zhu et al. - 2018 - Image reconstruction by domain-transform manifold learning.pdf:pdf},
  groups        = {Helmholtz and waves},
  publisher     = {Nature Publishing Group},
  url           = {http://dx.doi.org/10.1038/nature25988},
}

@Comment{jabref-meta: databaseType:bibtex;}

@Comment{jabref-meta: grouping:
0 AllEntriesGroup:;
1 StaticGroup:General deep learning\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:RL\;0\;0\;0x8a8a8aff\;\;\;;
2 StaticGroup:Training\;0\;0\;0x8a8a8aff\;\;\;;
2 StaticGroup:GANs\;0\;0\;0x8a8a8aff\;\;\;;
2 StaticGroup:Implicit- and Meta- learning\;0\;0\;0x8a8a8aff\;\;\;;
2 StaticGroup:Attention\;0\;0\;0x8a8a8aff\;\;\;;
2 StaticGroup:Diffusion\;0\;0\;0x8a8a8aff\;\;\;;
2 StaticGroup:Representation, architectures and DL layers\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:Normalizing flows\;0\;0\;0x8a8a8aff\;\;\;;
2 StaticGroup:Equivariant etc\;0\;1\;0x8a8a8aff\;\;\;;
1 StaticGroup:Super Resolution\;0\;1\;0x008080ff\;\;\;;
1 StaticGroup:PDEs and neural networks\;0\;1\;0x0000ffff\;\;\;;
2 StaticGroup:Acceleration\;0\;0\;0x8a8a8aff\;\;\;;
2 StaticGroup:Helmholtz and waves\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:Latent\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:Neural Operators\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:Physics as NN\;0\;1\;0x8a8a8aff\;\;\;;
1 StaticGroup:Ultrasound and wave physics\;0\;1\;0x008000ff\;\;\;;
2 StaticGroup:Helmholtz\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:Experimental\;0\;1\;0x8a8a8aff\;\;\;;
1 StaticGroup:Computer vision and Deep Learning\;0\;1\;0x800080ff\;\;\;;
2 StaticGroup:img 2 img translation\;0\;1\;0x8a8a8aff\;\;\;;
1 StaticGroup:Computer Vision\;0\;1\;0xffff4dff\;\;\;;
1 StaticGroup:Inverse problems\;0\;1\;0x99b3ffff\;\;\;;
1 StaticGroup:Ultrasound and wave imaging\;0\;1\;0xff9980ff\;\;\;;
2 StaticGroup:Classical US imaging\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:Motion\;0\;1\;0x8a8a8aff\;\;\;;
1 StaticGroup:Dynamics and control\;0\;1\;0xe6b3e6ff\;\;\;;
1 StaticGroup:Differentiable programming and simulation\;0\;0\;0x336666ff\;\;\;;
1 StaticGroup:Numerical computing\;0\;1\;0x808000ff\;\;\;;
2 StaticGroup:Helmholtz and wave algorithms\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:Acceleration\;0\;0\;0x8a8a8aff\;\;\;;
1 StaticGroup:Books\;0\;1\;0x000000ff\;\;\;;
1 StaticGroup:Misc\;0\;1\;0x8a8a8aff\;\;\;;
2 StaticGroup:Finance\;0\;1\;0x8a8a8aff\;\;\;;
}
